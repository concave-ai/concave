{"data": [{"id": "setuptools_scm.git.REF_TAG_RE", "kind": "variable", "range": [29, 0, 29, 49, 692, 741], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "REF_TAG_RE = re.compile(r\"(?<=\\btag: )([^,]+)\\b\")"}, {"id": "setuptools_scm.git.DESCRIBE_UNSUPPORTED", "kind": "variable", "range": [30, 0, 30, 35, 742, 777], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "DESCRIBE_UNSUPPORTED = \"%(describe\""}, {"id": "setuptools_scm.git.DEFAULT_DESCRIBE", "kind": "variable", "range": [35, 0, 43, 1, 963, 1085], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "DEFAULT_DESCRIBE = [\n    \"git\",\n    \"describe\",\n    \"--dirty\",\n    \"--tags\",\n    \"--long\",\n    \"--match\",\n    \"*[0-9]*\",\n]"}, {"id": "setuptools_scm.git.GitWorkdir", "kind": "class", "range": [46, 0, 128, 9, 1088, 4071], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "class GitWorkdir(Workdir):\n    \"\"\"experimental, may change at any time\"\"\"\n\n    COMMAND = \"git\"\n\n    @classmethod\n    def from_potential_worktree(cls, wd: _t.PathT) -> GitWorkdir | None:\n        require_command(cls.COMMAND)\n        wd = os.path.abspath(wd)\n        git_dir = join(wd, \".git\")\n        real_wd, _, ret = do_ex(\n            [\"git\", \"--git-dir\", git_dir, \"rev-parse\", \"--show-prefix\"], wd\n        )\n        real_wd = real_wd[:-1]  # remove the trailing pathsep\n        if ret:\n            return None\n        if not real_wd:\n            real_wd = wd\n        else:\n            assert wd.replace(\"\\\\\", \"/\").endswith(real_wd)\n            # In windows wd contains ``\\`` which should be replaced by ``/``\n            # for this assertion to work.  Length of string isn't changed by replace\n            # ``\\\\`` is just and escape for `\\`\n            real_wd = wd[: -len(real_wd)]\n        trace(\"real root\", real_wd)\n        if not samefile(real_wd, wd):\n            return None\n\n        return cls(real_wd)\n\n    def do_ex_git(self, cmd: list[str]) -> _CmdResult:\n        return self.do_ex([\"git\", \"--git-dir\", join(self.path, \".git\")] + cmd)\n\n    def is_dirty(self) -> bool:\n        out, _, _ = self.do_ex_git([\"status\", \"--porcelain\", \"--untracked-files=no\"])\n        return bool(out)\n\n    def get_branch(self) -> str | None:\n        branch, err, ret = self.do_ex_git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])\n        if ret:\n            trace(\"branch err\", branch, err, ret)\n            branch, err, ret = self.do_ex_git([\"symbolic-ref\", \"--short\", \"HEAD\"])\n            if ret:\n                trace(\"branch err (symbolic-ref)\", branch, err, ret)\n                return None\n        return branch\n\n    def get_head_date(self) -> date | None:\n        timestamp, err, ret = self.do_ex_git(\n            [\"-c\", \"log.showSignature=false\", \"log\", \"-n\", \"1\", \"HEAD\", \"--format=%cI\"]\n        )\n        if ret:\n            trace(\"timestamp err\", timestamp, err, ret)\n            return None\n        # TODO, when dropping python3.6 use fromiso\n        date_part = timestamp.split(\"T\")[0]\n        if \"%c\" in date_part:\n            trace(\"git too old -> timestamp is \", timestamp)\n            return None\n        return datetime.strptime(date_part, r\"%Y-%m-%d\").date()\n\n    def is_shallow(self) -> bool:\n        return isfile(join(self.path, \".git/shallow\"))\n\n    def fetch_shallow(self) -> None:\n        self.do_ex_git([\"fetch\", \"--unshallow\"])\n\n    def node(self) -> str | None:\n        node, _, ret = self.do_ex_git([\"rev-parse\", \"--verify\", \"--quiet\", \"HEAD\"])\n        if not ret:\n            return node[:7]\n        else:\n            return None\n\n    def count_all_nodes(self) -> int:\n        revs, _, _ = self.do_ex_git([\"rev-list\", \"HEAD\"])\n        return revs.count(\"\\n\") + 1\n\n    def default_describe(self) -> _CmdResult:\n        git_dir = join(self.path, \".git\")\n        return self.do_ex(\n            DEFAULT_DESCRIBE[:1] + [\"--git-dir\", git_dir] + DEFAULT_DESCRIBE[1:]\n        )"}, {"id": "setuptools_scm.git.GitWorkdir.COMMAND", "kind": "variable", "range": [49, 4, 49, 19, 1167, 1182], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "COMMAND = \"git\""}, {"id": "setuptools_scm.git.GitWorkdir.from_potential_worktree", "kind": "function", "range": [51, 4, 74, 27, 1188, 2100], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "@classmethod\n    def from_potential_worktree(cls, wd: _t.PathT) -> GitWorkdir | None:\n        require_command(cls.COMMAND)\n        wd = os.path.abspath(wd)\n        git_dir = join(wd, \".git\")\n        real_wd, _, ret = do_ex(\n            [\"git\", \"--git-dir\", git_dir, \"rev-parse\", \"--show-prefix\"], wd\n        )\n        real_wd = real_wd[:-1]  # remove the trailing pathsep\n        if ret:\n            return None\n        if not real_wd:\n            real_wd = wd\n        else:\n            assert wd.replace(\"\\\\\", \"/\").endswith(real_wd)\n            # In windows wd contains ``\\`` which should be replaced by ``/``\n            # for this assertion to work.  Length of string isn't changed by replace\n            # ``\\\\`` is just and escape for `\\`\n            real_wd = wd[: -len(real_wd)]\n        trace(\"real root\", real_wd)\n        if not samefile(real_wd, wd):\n            return None\n\n        return cls(real_wd)"}, {"id": "setuptools_scm.git.GitWorkdir.do_ex_git", "kind": "function", "range": [76, 4, 77, 78, 2106, 2235], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def do_ex_git(self, cmd: list[str]) -> _CmdResult:\n        return self.do_ex([\"git\", \"--git-dir\", join(self.path, \".git\")] + cmd)"}, {"id": "setuptools_scm.git.GitWorkdir.is_dirty", "kind": "function", "range": [79, 4, 81, 24, 2241, 2379], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def is_dirty(self) -> bool:\n        out, _, _ = self.do_ex_git([\"status\", \"--porcelain\", \"--untracked-files=no\"])\n        return bool(out)"}, {"id": "setuptools_scm.git.GitWorkdir.get_branch", "kind": "function", "range": [83, 4, 91, 21, 2385, 2789], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def get_branch(self) -> str | None:\n        branch, err, ret = self.do_ex_git([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"])\n        if ret:\n            trace(\"branch err\", branch, err, ret)\n            branch, err, ret = self.do_ex_git([\"symbolic-ref\", \"--short\", \"HEAD\"])\n            if ret:\n                trace(\"branch err (symbolic-ref)\", branch, err, ret)\n                return None\n        return branch"}, {"id": "setuptools_scm.git.GitWorkdir.get_head_date", "kind": "function", "range": [93, 4, 105, 63, 2795, 3349], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def get_head_date(self) -> date | None:\n        timestamp, err, ret = self.do_ex_git(\n            [\"-c\", \"log.showSignature=false\", \"log\", \"-n\", \"1\", \"HEAD\", \"--format=%cI\"]\n        )\n        if ret:\n            trace(\"timestamp err\", timestamp, err, ret)\n            return None\n        # TODO, when dropping python3.6 use fromiso\n        date_part = timestamp.split(\"T\")[0]\n        if \"%c\" in date_part:\n            trace(\"git too old -> timestamp is \", timestamp)\n            return None\n        return datetime.strptime(date_part, r\"%Y-%m-%d\").date()"}, {"id": "setuptools_scm.git.GitWorkdir.is_shallow", "kind": "function", "range": [107, 4, 108, 54, 3355, 3439], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def is_shallow(self) -> bool:\n        return isfile(join(self.path, \".git/shallow\"))"}, {"id": "setuptools_scm.git.GitWorkdir.fetch_shallow", "kind": "function", "range": [110, 4, 111, 48, 3445, 3526], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def fetch_shallow(self) -> None:\n        self.do_ex_git([\"fetch\", \"--unshallow\"])"}, {"id": "setuptools_scm.git.GitWorkdir.node", "kind": "function", "range": [113, 4, 118, 23, 3532, 3731], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def node(self) -> str | None:\n        node, _, ret = self.do_ex_git([\"rev-parse\", \"--verify\", \"--quiet\", \"HEAD\"])\n        if not ret:\n            return node[:7]\n        else:\n            return None"}, {"id": "setuptools_scm.git.GitWorkdir.count_all_nodes", "kind": "function", "range": [120, 4, 122, 35, 3737, 3864], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def count_all_nodes(self) -> int:\n        revs, _, _ = self.do_ex_git([\"rev-list\", \"HEAD\"])\n        return revs.count(\"\\n\") + 1"}, {"id": "setuptools_scm.git.GitWorkdir.default_describe", "kind": "function", "range": [124, 4, 128, 9, 3870, 4071], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def default_describe(self) -> _CmdResult:\n        git_dir = join(self.path, \".git\")\n        return self.do_ex(\n            DEFAULT_DESCRIBE[:1] + [\"--git-dir\", git_dir] + DEFAULT_DESCRIBE[1:]\n        )"}, {"id": "setuptools_scm.git.warn_on_shallow", "kind": "function", "range": [131, 0, 134, 69, 4074, 4259], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def warn_on_shallow(wd: GitWorkdir) -> None:\n    \"\"\"experimental, may change at any time\"\"\"\n    if wd.is_shallow():\n        warnings.warn(f'\"{wd.path}\" is shallow and may cause errors')"}, {"id": "setuptools_scm.git.fetch_on_shallow", "kind": "function", "range": [137, 0, 141, 26, 4262, 4486], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def fetch_on_shallow(wd: GitWorkdir) -> None:\n    \"\"\"experimental, may change at any time\"\"\"\n    if wd.is_shallow():\n        warnings.warn(f'\"{wd.path}\" was shallow, git fetch was used to rectify')\n        wd.fetch_shallow()"}, {"id": "setuptools_scm.git.fail_on_shallow", "kind": "function", "range": [144, 0, 149, 9, 4489, 4721], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def fail_on_shallow(wd: GitWorkdir) -> None:\n    \"\"\"experimental, may change at any time\"\"\"\n    if wd.is_shallow():\n        raise ValueError(\n            f'{wd.path} is shallow, please correct with \"git fetch --unshallow\"'\n        )"}, {"id": "setuptools_scm.git.get_working_directory", "kind": "function", "range": [152, 0, 163, 67, 4724, 5111], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def get_working_directory(config: Configuration) -> GitWorkdir | None:\n    \"\"\"\n    Return the working directory (``GitWorkdir``).\n    \"\"\"\n\n    if config.parent:\n        return GitWorkdir.from_potential_worktree(config.parent)\n\n    if config.search_parent_directories:\n        return search_parent(config.absolute_root)\n\n    return GitWorkdir.from_potential_worktree(config.absolute_root)"}, {"id": "setuptools_scm.git.parse", "kind": "function", "range": [166, 0, 184, 19, 5114, 5676], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def parse(\n    root: str,\n    describe_command: str | list[str] | None = None,\n    pre_parse: Callable[[GitWorkdir], None] = warn_on_shallow,\n    config: Configuration | None = None,\n) -> ScmVersion | None:\n    \"\"\"\n    :param pre_parse: experimental pre_parse action, may change at any time\n    \"\"\"\n    if not config:\n        config = Configuration(root=root)\n\n    wd = get_working_directory(config)\n    if wd:\n        return _git_parse_inner(\n            config, wd, describe_command=describe_command, pre_parse=pre_parse\n        )\n    else:\n        return None"}, {"id": "setuptools_scm.git._git_parse_inner", "kind": "function", "range": [187, 0, 231, 5, 5679, 6963], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def _git_parse_inner(\n    config: Configuration,\n    wd: GitWorkdir | GitWorkdirHgClient,\n    pre_parse: None | (Callable[[GitWorkdir | GitWorkdirHgClient], None]) = None,\n    describe_command: _t.CMD_TYPE | None = None,\n) -> ScmVersion:\n    if pre_parse:\n        pre_parse(wd)\n\n    if config.git_describe_command is not None:\n        describe_command = config.git_describe_command\n\n    if describe_command is not None:\n        out, _, ret = wd.do_ex(describe_command)\n    else:\n        out, _, ret = wd.default_describe()\n    distance: int | None\n    node: str | None\n    if ret == 0:\n        tag, distance, node, dirty = _git_parse_describe(out)\n        if distance == 0 and not dirty:\n            distance = None\n    else:\n        # If 'git git_describe_command' failed, try to get the information otherwise.\n        tag = \"0.0\"\n        node = wd.node()\n        if node is None:\n            distance = 0\n        else:\n            distance = wd.count_all_nodes()\n            node = \"g\" + node\n        dirty = wd.is_dirty()\n\n    branch = wd.get_branch()\n    node_date = wd.get_head_date() or date.today()\n\n    return meta(\n        tag,\n        branch=branch,\n        node=node,\n        node_date=node_date,\n        distance=distance,\n        dirty=dirty,\n        config=config,\n    )"}, {"id": "setuptools_scm.git._git_parse_describe", "kind": "function", "range": [234, 0, 256, 35, 6966, 7706], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def _git_parse_describe(\n    describe_output: str,\n) -> tuple[str, int | None, str | None, bool]:\n    # 'describe_output' looks e.g. like 'v1.5.0-0-g4060507' or\n    # 'v1.15.1rc1-37-g9bd1298-dirty'.\n    # It may also just be a bare tag name if this is a tagged commit and we are\n    # parsing a .git_archival.txt file.\n\n    if describe_output.endswith(\"-dirty\"):\n        dirty = True\n        describe_output = describe_output[:-6]\n    else:\n        dirty = False\n\n    split = describe_output.rsplit(\"-\", 2)\n    if len(split) < 3:  # probably a tagged commit\n        tag = describe_output\n        number = None\n        node = None\n    else:\n        tag, number_, node = split\n        number = int(number_)\n    return tag, number, node, dirty"}, {"id": "setuptools_scm.git.search_parent", "kind": "function", "range": [259, 0, 284, 15, 7709, 8343], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def search_parent(dirname: _t.PathT) -> GitWorkdir | None:\n    \"\"\"\n    Walk up the path to find the `.git` directory.\n    :param dirname: Directory from which to start searching.\n    \"\"\"\n\n    # Code based on:\n    # https://github.com/gitpython-developers/GitPython/blob/main/git/repo/base.py\n\n    curpath = os.path.abspath(dirname)\n\n    while curpath:\n\n        try:\n            wd = GitWorkdir.from_potential_worktree(curpath)\n        except Exception:\n            wd = None\n\n        if wd is not None:\n            return wd\n\n        curpath, tail = os.path.split(curpath)\n\n        if not tail:\n            return None\n    return None"}, {"id": "setuptools_scm.git.archival_to_version", "kind": "function", "range": [287, 0, 314, 56, 8346, 9353], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def archival_to_version(\n    data: dict[str, str], config: Configuration | None = None\n) -> ScmVersion | None:\n    node: str | None\n    trace(\"data\", data)\n    archival_describe = data.get(\"describe-name\", DESCRIBE_UNSUPPORTED)\n    if DESCRIBE_UNSUPPORTED in archival_describe:\n        warnings.warn(\"git archive did not support describe output\")\n    else:\n        tag, number, node, _ = _git_parse_describe(archival_describe)\n        return meta(\n            tag,\n            config=config,\n            distance=None if number == 0 else number,\n            node=node,\n        )\n    versions = tags_to_versions(REF_TAG_RE.findall(data.get(\"ref-names\", \"\")))\n    if versions:\n        return meta(versions[0], config=config)\n    else:\n        node = data.get(\"node\")\n        if node is None:\n            return None\n        elif \"$FORMAT\" in node.upper():\n            warnings.warn(\"unexported git archival found\")\n            return None\n        else:\n            return meta(\"0.0\", node=node, config=config)"}, {"id": "setuptools_scm.git.parse_archival", "kind": "function", "range": [317, 0, 322, 51, 9356, 9598], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/git.py", "content": "def parse_archival(\n    root: _t.PathT, config: Configuration | None = None\n) -> ScmVersion | None:\n    archival = os.path.join(root, \".git_archival.txt\")\n    data = data_from_mime(archival)\n    return archival_to_version(data, config=config)"}, {"id": "setuptools_scm._types.PathT", "kind": "variable", "range": [16, 0, 16, 38, 332, 370], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "PathT = Union[\"os.PathLike[str]\", str]"}, {"id": "setuptools_scm._types.CMD_TYPE", "kind": "variable", "range": [18, 0, 18, 43, 372, 415], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "CMD_TYPE: TypeAlias = Union[List[str], str]"}, {"id": "setuptools_scm._types.VERSION_SCHEME", "kind": "variable", "range": [20, 0, 20, 66, 417, 483], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "VERSION_SCHEME = Union[str, Callable[[\"version.ScmVersion\"], str]]"}, {"id": "setuptools_scm._types.EntrypointProtocol", "kind": "class", "range": [23, 0, 27, 12, 486, 576], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "class EntrypointProtocol(Protocol):\n    name: str\n\n    def load(self) -> Any:\n        pass"}, {"id": "setuptools_scm._types.EntrypointProtocol.name", "kind": "variable", "range": [24, 4, 24, 13, 526, 535], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "name: str"}, {"id": "setuptools_scm._types.EntrypointProtocol.load", "kind": "function", "range": [26, 4, 27, 12, 541, 576], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "def load(self) -> Any:\n        pass"}, {"id": "setuptools_scm._types.T", "kind": "variable", "range": [30, 0, 30, 16, 579, 595], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "T = TypeVar(\"T\")"}, {"id": "setuptools_scm._types.T2", "kind": "variable", "range": [31, 0, 31, 18, 596, 614], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "T2 = TypeVar(\"T2\")"}, {"id": "setuptools_scm._types.P", "kind": "variable", "range": [32, 0, 32, 18, 615, 633], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "P = ParamSpec(\"P\")"}, {"id": "setuptools_scm._types.transfer_input_args", "kind": "function", "range": [35, 0, 41, 19, 636, 844], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_types.py", "content": "def transfer_input_args(\n    template: Callable[P, T],\n) -> Callable[[Callable[..., T]], Callable[P, T]]:\n    def decorate(func: Callable[..., T2]) -> Callable[P, T2]:\n        return func\n\n    return decorate"}, {"id": "setuptools_scm.file_finder_hg._hg_toplevel", "kind": "function", "range": [16, 0, 30, 19, 322, 814], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_hg.py", "content": "def _hg_toplevel(path: str) -> str | None:\n    try:\n        out: str = subprocess.check_output(\n            [\"hg\", \"root\"],\n            cwd=(path or \".\"),\n            text=True,\n            stderr=subprocess.DEVNULL,\n        )\n        return os.path.normcase(os.path.realpath(out.strip()))\n    except subprocess.CalledProcessError:\n        # hg returned error, we are not in a mercurial repo\n        return None\n    except OSError:\n        # hg command not found, probably\n        return None"}, {"id": "setuptools_scm.file_finder_hg._hg_ls_files_and_dirs", "kind": "function", "range": [33, 0, 47, 28, 817, 1428], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_hg.py", "content": "def _hg_ls_files_and_dirs(toplevel: str) -> tuple[set[str], set[str]]:\n    hg_files: set[str] = set()\n    hg_dirs = {toplevel}\n    out, err, ret = do_ex([\"hg\", \"files\"], cwd=toplevel)\n    if ret:\n        (), ()\n    for name in out.splitlines():\n        name = os.path.normcase(name).replace(\"/\", os.path.sep)\n        fullname = os.path.join(toplevel, name)\n        hg_files.add(fullname)\n        dirname = os.path.dirname(fullname)\n        while len(dirname) > len(toplevel) and dirname not in hg_dirs:\n            hg_dirs.add(dirname)\n            dirname = os.path.dirname(dirname)\n    return hg_files, hg_dirs"}, {"id": "setuptools_scm.file_finder_hg.hg_find_files", "kind": "function", "range": [50, 0, 56, 50, 1431, 1714], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_hg.py", "content": "def hg_find_files(path: str = \"\") -> list[str]:\n    toplevel = _hg_toplevel(path)\n    if not is_toplevel_acceptable(toplevel):\n        return []\n    assert toplevel is not None\n    hg_files, hg_dirs = _hg_ls_files_and_dirs(toplevel)\n    return scm_find_files(path, hg_files, hg_dirs)"}, {"id": "setuptools_scm.file_finder_hg.hg_archive_find_files", "kind": "function", "range": [59, 0, 73, 67, 1717, 2292], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_hg.py", "content": "def hg_archive_find_files(path: _t.PathT = \"\") -> list[str]:\n    # This function assumes that ``path`` is obtained from a mercurial archive\n    # and therefore all the files that should be ignored were already removed.\n    archival = os.path.join(path, \".hg_archival.txt\")\n    if not os.path.exists(archival):\n        return []\n\n    data = data_from_mime(archival)\n\n    if \"node\" not in data:\n        # Ensure file is valid\n        return []\n\n    trace(\"hg archive detected - fallback to listing all files\")\n    return scm_find_files(path, set(), set(), force_all_files=True)"}, {"id": "setuptools_scm.config.DEFAULT_TAG_REGEX", "kind": "variable", "range": [27, 0, 27, 87, 668, 755], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "DEFAULT_TAG_REGEX = r\"^(?:[\\w-]+-)?(?P<version>[vV]?\\d+(?:\\.\\d+){0,2}[^\\+]*)(?:\\+.*)?$\""}, {"id": "setuptools_scm.config.DEFAULT_VERSION_SCHEME", "kind": "variable", "range": [28, 0, 28, 41, 756, 797], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "DEFAULT_VERSION_SCHEME = \"guess-next-dev\""}, {"id": "setuptools_scm.config.DEFAULT_LOCAL_SCHEME", "kind": "variable", "range": [29, 0, 29, 38, 798, 836], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "DEFAULT_LOCAL_SCHEME = \"node-and-date\""}, {"id": "setuptools_scm.config._check_tag_regex", "kind": "function", "range": [32, 0, 44, 16, 839, 1315], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "def _check_tag_regex(value: str | Pattern[str] | None) -> Pattern[str]:\n    if not value:\n        value = DEFAULT_TAG_REGEX\n    regex = re.compile(value)\n\n    group_names = regex.groupindex.keys()\n    if regex.groups == 0 or (regex.groups > 1 and \"version\" not in group_names):\n        warnings.warn(\n            \"Expected tag_regex to contain a single match group or a group named\"\n            \" 'version' to identify the version part of any tag.\"\n        )\n\n    return regex"}, {"id": "setuptools_scm.config._check_absolute_root", "kind": "function", "range": [47, 0, 70, 32, 1318, 2266], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "def _check_absolute_root(root: _t.PathT, relative_to: _t.PathT | None) -> str:\n    trace(\"abs root\", repr(locals()))\n    if relative_to:\n        if (\n            os.path.isabs(root)\n            and os.path.isabs(relative_to)\n            and not os.path.commonpath([root, relative_to]) == root\n        ):\n            warnings.warn(\n                \"absolute root path '%s' overrides relative_to '%s'\"\n                % (root, relative_to)\n            )\n        if os.path.isdir(relative_to):\n            warnings.warn(\n                \"relative_to is expected to be a file,\"\n                \" its the directory %r\\n\"\n                \"assuming the parent directory was passed\" % (relative_to,)\n            )\n            trace(\"dir\", relative_to)\n            root = os.path.join(relative_to, root)\n        else:\n            trace(\"file\", relative_to)\n            root = os.path.join(os.path.dirname(relative_to), root)\n    return os.path.abspath(root)"}, {"id": "setuptools_scm.config._VersionT", "kind": "variable", "range": [73, 0, 73, 48, 2269, 2317], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "_VersionT = Union[Version, NonNormalizedVersion]"}, {"id": "setuptools_scm.config._validate_version_cls", "kind": "function", "range": [76, 0, 102, 30, 2320, 3410], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "def _validate_version_cls(\n    version_cls: type[_VersionT] | str | None, normalize: bool\n) -> type[_VersionT]:\n    if not normalize:\n        # `normalize = False` means `version_cls = NonNormalizedVersion`\n        if version_cls is not None:\n            raise ValueError(\n                \"Providing a custom `version_cls` is not permitted when \"\n                \"`normalize=False`\"\n            )\n        return NonNormalizedVersion\n    else:\n        # Use `version_cls` if provided, default to packaging or pkg_resources\n        if version_cls is None:\n            return Version\n        elif isinstance(version_cls, str):\n            try:\n                # Not sure this will work in old python\n                import importlib\n\n                pkg, cls_name = version_cls.rsplit(\".\", 1)\n                version_cls_host = importlib.import_module(pkg)\n                return cast(Type[_VersionT], getattr(version_cls_host, cls_name))\n            except:  # noqa\n                raise ValueError(f\"Unable to import version_cls='{version_cls}'\")\n        else:\n            return version_cls"}, {"id": "setuptools_scm.config.Configuration", "kind": "class", "range": [105, 0, 215, 44, 3413, 7236], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "class Configuration:\n    \"\"\"Global configuration model\"\"\"\n\n    parent: _t.PathT | None\n    _root: str\n    _relative_to: str | None\n    version_cls: type[_VersionT]\n\n    def __init__(\n        self,\n        relative_to: _t.PathT | None = None,\n        root: _t.PathT = \".\",\n        version_scheme: (\n            str | Callable[[ScmVersion], str | None]\n        ) = DEFAULT_VERSION_SCHEME,\n        local_scheme: (str | Callable[[ScmVersion], str | None]) = DEFAULT_LOCAL_SCHEME,\n        write_to: _t.PathT | None = None,\n        write_to_template: str | None = None,\n        tag_regex: str | Pattern[str] = DEFAULT_TAG_REGEX,\n        parentdir_prefix_version: str | None = None,\n        fallback_version: str | None = None,\n        fallback_root: _t.PathT = \".\",\n        parse: Any | None = None,\n        git_describe_command: _t.CMD_TYPE | None = None,\n        dist_name: str | None = None,\n        version_cls: type[_VersionT] | type | str | None = None,\n        normalize: bool = True,\n        search_parent_directories: bool = False,\n    ):\n        # TODO:\n        self._relative_to = None if relative_to is None else os.fspath(relative_to)\n        self._root = \".\"\n\n        self.root = os.fspath(root)\n        self.version_scheme = version_scheme\n        self.local_scheme = local_scheme\n        self.write_to = write_to\n        self.write_to_template = write_to_template\n        self.parentdir_prefix_version = parentdir_prefix_version\n        self.fallback_version = fallback_version\n        self.fallback_root = fallback_root  # type: ignore\n        self.parse = parse\n        self.tag_regex = tag_regex  # type: ignore\n        self.git_describe_command = git_describe_command\n        self.dist_name = dist_name\n        self.search_parent_directories = search_parent_directories\n        self.parent = None\n\n        self.version_cls = _validate_version_cls(version_cls, normalize)\n\n    @property\n    def fallback_root(self) -> str:\n        return self._fallback_root\n\n    @fallback_root.setter\n    def fallback_root(self, value: _t.PathT) -> None:\n        self._fallback_root = os.path.abspath(value)\n\n    @property\n    def absolute_root(self) -> str:\n        return self._absolute_root\n\n    @property\n    def relative_to(self) -> str | None:\n        return self._relative_to\n\n    @relative_to.setter\n    def relative_to(self, value: _t.PathT) -> None:\n        self._absolute_root = _check_absolute_root(self._root, value)\n        self._relative_to = os.fspath(value)\n        trace(\"root\", repr(self._absolute_root))\n        trace(\"relative_to\", repr(value))\n\n    @property\n    def root(self) -> str:\n        return self._root\n\n    @root.setter\n    def root(self, value: _t.PathT) -> None:\n        self._absolute_root = _check_absolute_root(value, self._relative_to)\n        self._root = os.fspath(value)\n        trace(\"root\", repr(self._absolute_root))\n        trace(\"relative_to\", repr(self._relative_to))\n\n    @property\n    def tag_regex(self) -> Pattern[str]:\n        return self._tag_regex\n\n    @tag_regex.setter\n    def tag_regex(self, value: str | Pattern[str]) -> None:\n        self._tag_regex = _check_tag_regex(value)\n\n    @classmethod\n    def from_file(\n        cls,\n        name: str = \"pyproject.toml\",\n        dist_name: str | None = None,\n        _load_toml: Callable[[str], dict[str, Any]] | None = None,\n        **kwargs: Any,\n    ) -> Configuration:\n        \"\"\"\n        Read Configuration from pyproject.toml (or similar).\n        Raises exceptions when file is not found or toml is\n        not installed or the file has invalid format or does\n        not contain the [tool.setuptools_scm] section.\n        \"\"\"\n\n        pyproject_data = _read_pyproject(name, _load_toml=_load_toml)\n        args = _get_args_for_pyproject(pyproject_data, dist_name, kwargs)\n\n        return cls(relative_to=name, **args)"}, {"id": "setuptools_scm.config.Configuration.parent", "kind": "variable", "range": [108, 4, 108, 27, 3476, 3499], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "parent: _t.PathT | None"}, {"id": "setuptools_scm.config.Configuration._root", "kind": "variable", "range": [109, 4, 109, 14, 3504, 3514], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "_root: str"}, {"id": "setuptools_scm.config.Configuration._relative_to", "kind": "variable", "range": [110, 4, 110, 28, 3519, 3543], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "_relative_to: str | None"}, {"id": "setuptools_scm.config.Configuration.version_cls", "kind": "variable", "range": [111, 4, 111, 32, 3548, 3576], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "version_cls: type[_VersionT]"}, {"id": "setuptools_scm.config.Configuration.__init__", "kind": "function", "range": [113, 4, 153, 72, 3582, 5297], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "def __init__(\n        self,\n        relative_to: _t.PathT | None = None,\n        root: _t.PathT = \".\",\n        version_scheme: (\n            str | Callable[[ScmVersion], str | None]\n        ) = DEFAULT_VERSION_SCHEME,\n        local_scheme: (str | Callable[[ScmVersion], str | None]) = DEFAULT_LOCAL_SCHEME,\n        write_to: _t.PathT | None = None,\n        write_to_template: str | None = None,\n        tag_regex: str | Pattern[str] = DEFAULT_TAG_REGEX,\n        parentdir_prefix_version: str | None = None,\n        fallback_version: str | None = None,\n        fallback_root: _t.PathT = \".\",\n        parse: Any | None = None,\n        git_describe_command: _t.CMD_TYPE | None = None,\n        dist_name: str | None = None,\n        version_cls: type[_VersionT] | type | str | None = None,\n        normalize: bool = True,\n        search_parent_directories: bool = False,\n    ):\n        # TODO:\n        self._relative_to = None if relative_to is None else os.fspath(relative_to)\n        self._root = \".\"\n\n        self.root = os.fspath(root)\n        self.version_scheme = version_scheme\n        self.local_scheme = local_scheme\n        self.write_to = write_to\n        self.write_to_template = write_to_template\n        self.parentdir_prefix_version = parentdir_prefix_version\n        self.fallback_version = fallback_version\n        self.fallback_root = fallback_root  # type: ignore\n        self.parse = parse\n        self.tag_regex = tag_regex  # type: ignore\n        self.git_describe_command = git_describe_command\n        self.dist_name = dist_name\n        self.search_parent_directories = search_parent_directories\n        self.parent = None\n\n        self.version_cls = _validate_version_cls(version_cls, normalize)"}, {"id": "setuptools_scm.config.Configuration.fallback_root", "kind": "function", "range": [155, 4, 157, 34, 5303, 5383], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@property\n    def fallback_root(self) -> str:\n        return self._fallback_root"}, {"id": "setuptools_scm.config.Configuration.fallback_root", "kind": "function", "range": [159, 4, 161, 52, 5389, 5517], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@fallback_root.setter\n    def fallback_root(self, value: _t.PathT) -> None:\n        self._fallback_root = os.path.abspath(value)"}, {"id": "setuptools_scm.config.Configuration.absolute_root", "kind": "function", "range": [163, 4, 165, 34, 5523, 5603], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@property\n    def absolute_root(self) -> str:\n        return self._absolute_root"}, {"id": "setuptools_scm.config.Configuration.relative_to", "kind": "function", "range": [167, 4, 169, 32, 5609, 5692], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@property\n    def relative_to(self) -> str | None:\n        return self._relative_to"}, {"id": "setuptools_scm.config.Configuration.relative_to", "kind": "function", "range": [171, 4, 176, 41, 5698, 5975], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@relative_to.setter\n    def relative_to(self, value: _t.PathT) -> None:\n        self._absolute_root = _check_absolute_root(self._root, value)\n        self._relative_to = os.fspath(value)\n        trace(\"root\", repr(self._absolute_root))\n        trace(\"relative_to\", repr(value))"}, {"id": "setuptools_scm.config.Configuration.root", "kind": "function", "range": [178, 4, 180, 25, 5981, 6043], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@property\n    def root(self) -> str:\n        return self._root"}, {"id": "setuptools_scm.config.Configuration.root", "kind": "function", "range": [182, 4, 187, 53, 6049, 6324], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@root.setter\n    def root(self, value: _t.PathT) -> None:\n        self._absolute_root = _check_absolute_root(value, self._relative_to)\n        self._root = os.fspath(value)\n        trace(\"root\", repr(self._absolute_root))\n        trace(\"relative_to\", repr(self._relative_to))"}, {"id": "setuptools_scm.config.Configuration.tag_regex", "kind": "function", "range": [189, 4, 191, 30, 6330, 6411], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@property\n    def tag_regex(self) -> Pattern[str]:\n        return self._tag_regex"}, {"id": "setuptools_scm.config.Configuration.tag_regex", "kind": "function", "range": [193, 4, 195, 49, 6417, 6544], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@tag_regex.setter\n    def tag_regex(self, value: str | Pattern[str]) -> None:\n        self._tag_regex = _check_tag_regex(value)"}, {"id": "setuptools_scm.config.Configuration.from_file", "kind": "function", "range": [197, 4, 215, 44, 6550, 7236], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/config.py", "content": "@classmethod\n    def from_file(\n        cls,\n        name: str = \"pyproject.toml\",\n        dist_name: str | None = None,\n        _load_toml: Callable[[str], dict[str, Any]] | None = None,\n        **kwargs: Any,\n    ) -> Configuration:\n        \"\"\"\n        Read Configuration from pyproject.toml (or similar).\n        Raises exceptions when file is not found or toml is\n        not installed or the file has invalid format or does\n        not contain the [tool.setuptools_scm] section.\n        \"\"\"\n\n        pyproject_data = _read_pyproject(name, _load_toml=_load_toml)\n        args = _get_args_for_pyproject(pyproject_data, dist_name, kwargs)\n\n        return cls(relative_to=name, **args)"}, {"id": "setuptools_scm.version.SEMVER_MINOR", "kind": "variable", "range": [28, 0, 28, 16, 632, 648], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "SEMVER_MINOR = 2"}, {"id": "setuptools_scm.version.SEMVER_PATCH", "kind": "variable", "range": [29, 0, 29, 16, 649, 665], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "SEMVER_PATCH = 3"}, {"id": "setuptools_scm.version.SEMVER_LEN", "kind": "variable", "range": [30, 0, 30, 14, 666, 680], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "SEMVER_LEN = 3"}, {"id": "setuptools_scm.version._parse_version_tag", "kind": "function", "range": [33, 0, 54, 17, 683, 1287], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _parse_version_tag(\n    tag: str | object, config: Configuration\n) -> dict[str, str] | None:\n    tagstring = tag if isinstance(tag, str) else str(tag)\n    match = config.tag_regex.match(tagstring)\n\n    result = None\n    if match:\n        key: str | int\n        if len(match.groups()) == 1:\n            key = 1\n        else:\n            key = \"version\"\n\n        result = {\n            \"version\": match.group(key),\n            \"prefix\": match.group(0)[: match.start(key)],\n            \"suffix\": match.group(0)[match.end(key) :],\n        }\n\n    trace(f\"tag '{tag}' parsed to {result}\")\n    return result"}, {"id": "setuptools_scm.version.callable_or_entrypoint", "kind": "function", "range": [57, 0, 66, 24, 1290, 1644], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def callable_or_entrypoint(group: str, callable_or_name: str | Any) -> Any:\n    trace(\"ep\", (group, callable_or_name))\n\n    if callable(callable_or_name):\n        return callable_or_name\n    from ._entrypoints import iter_entry_points\n\n    for ep in iter_entry_points(group, callable_or_name):\n        trace(\"ep found:\", ep.name)\n        return ep.load()"}, {"id": "setuptools_scm.version.tag_to_version", "kind": "function", "range": [69, 0, 99, 18, 1647, 2546], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def tag_to_version(\n    tag: _VersionT | str, config: Configuration | None = None\n) -> _VersionT | None:\n    \"\"\"\n    take a tag that might be prefixed with a keyword and return only the version part\n    :param config: optional configuration object\n    \"\"\"\n    trace(\"tag\", tag)\n\n    if not config:\n        config = Configuration()\n\n    tagdict = _parse_version_tag(tag, config)\n    if not isinstance(tagdict, dict) or not tagdict.get(\"version\", None):\n        warnings.warn(f\"tag {tag!r} no version found\")\n        return None\n\n    version_str = tagdict[\"version\"]\n    trace(\"version pre parse\", version_str)\n\n    if tagdict.get(\"suffix\", \"\"):\n        warnings.warn(\n            \"tag {!r} will be stripped of its suffix '{}'\".format(\n                tag, tagdict[\"suffix\"]\n            )\n        )\n\n    version = config.version_cls(version_str)\n    trace(\"version\", repr(version))\n\n    return version"}, {"id": "setuptools_scm.version.tags_to_versions", "kind": "function", "range": [102, 0, 115, 17, 2549, 3013], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def tags_to_versions(\n    tags: list[str], config: Configuration | None = None\n) -> list[_VersionT]:\n    \"\"\"\n    take tags that might be prefixed with a keyword and return only the version part\n    :param tags: an iterable of tags\n    :param config: optional configuration object\n    \"\"\"\n    result: list[_VersionT] = []\n    for tag in tags:\n        parsed = tag_to_version(tag, config=config)\n        if parsed:\n            result.append(parsed)\n    return result"}, {"id": "setuptools_scm.version.ScmVersion", "kind": "class", "range": [118, 0, 192, 53, 3016, 5373], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "class ScmVersion:\n    def __init__(\n        self,\n        tag_version: Any,\n        config: Configuration,\n        distance: int | None = None,\n        node: str | None = None,\n        dirty: bool = False,\n        preformatted: bool = False,\n        branch: str | None = None,\n        node_date: date | None = None,\n        **kw: object,\n    ):\n        if kw:\n            trace(\"unknown args\", kw)\n        self.tag = tag_version\n        if dirty and distance is None:\n            distance = 0\n        self.distance = distance\n        self.node = node\n        self.node_date = node_date\n        if \"SOURCE_DATE_EPOCH\" in os.environ:\n            date_epoch = int(os.environ[\"SOURCE_DATE_EPOCH\"])\n            self.time = datetime.fromtimestamp(date_epoch, timezone.utc)\n        else:\n            self.time = datetime.now(timezone.utc)\n        self._extra = kw\n        self.dirty = dirty\n        self.preformatted = preformatted\n        self.branch = branch\n        self.config = config\n\n    @property\n    def extra(self) -> dict[str, Any]:\n        warnings.warn(\n            \"ScmVersion.extra is deprecated and will be removed in future\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        return self._extra\n\n    @property\n    def exact(self) -> bool:\n        return self.distance is None\n\n    def __repr__(self) -> str:\n        return self.format_with(\n            \"<ScmVersion {tag} dist={distance} \"\n            \"node={node} dirty={dirty} branch={branch}>\"\n        )\n\n    def format_with(self, fmt: str, **kw: object) -> str:\n        return fmt.format(\n            time=self.time,\n            tag=self.tag,\n            distance=self.distance,\n            node=self.node,\n            dirty=self.dirty,\n            branch=self.branch,\n            node_date=self.node_date,\n            **kw,\n        )\n\n    def format_choice(self, clean_format: str, dirty_format: str, **kw: object) -> str:\n        return self.format_with(dirty_format if self.dirty else clean_format, **kw)\n\n    def format_next_version(\n        self,\n        guess_next: Callable[Concatenate[ScmVersion, _t.P], str],\n        fmt: str = \"{guessed}.dev{distance}\",\n        *k: _t.P.args,  # type: ignore\n        **kw: _t.P.kwargs,  # type: ignore\n    ) -> str:\n        guessed = guess_next(self, *k, **kw)\n        return self.format_with(fmt, guessed=guessed)"}, {"id": "setuptools_scm.version.ScmVersion.__init__", "kind": "function", "range": [119, 4, 148, 28, 3038, 3998], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def __init__(\n        self,\n        tag_version: Any,\n        config: Configuration,\n        distance: int | None = None,\n        node: str | None = None,\n        dirty: bool = False,\n        preformatted: bool = False,\n        branch: str | None = None,\n        node_date: date | None = None,\n        **kw: object,\n    ):\n        if kw:\n            trace(\"unknown args\", kw)\n        self.tag = tag_version\n        if dirty and distance is None:\n            distance = 0\n        self.distance = distance\n        self.node = node\n        self.node_date = node_date\n        if \"SOURCE_DATE_EPOCH\" in os.environ:\n            date_epoch = int(os.environ[\"SOURCE_DATE_EPOCH\"])\n            self.time = datetime.fromtimestamp(date_epoch, timezone.utc)\n        else:\n            self.time = datetime.now(timezone.utc)\n        self._extra = kw\n        self.dirty = dirty\n        self.preformatted = preformatted\n        self.branch = branch\n        self.config = config"}, {"id": "setuptools_scm.version.ScmVersion.extra", "kind": "function", "range": [150, 4, 157, 26, 4004, 4255], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "@property\n    def extra(self) -> dict[str, Any]:\n        warnings.warn(\n            \"ScmVersion.extra is deprecated and will be removed in future\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        return self._extra"}, {"id": "setuptools_scm.version.ScmVersion.exact", "kind": "function", "range": [159, 4, 161, 36, 4261, 4336], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "@property\n    def exact(self) -> bool:\n        return self.distance is None"}, {"id": "setuptools_scm.version.ScmVersion.__repr__", "kind": "function", "range": [163, 4, 167, 9, 4342, 4517], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def __repr__(self) -> str:\n        return self.format_with(\n            \"<ScmVersion {tag} dist={distance} \"\n            \"node={node} dirty={dirty} branch={branch}>\"\n        )"}, {"id": "setuptools_scm.version.ScmVersion.format_with", "kind": "function", "range": [169, 4, 179, 9, 4523, 4849], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def format_with(self, fmt: str, **kw: object) -> str:\n        return fmt.format(\n            time=self.time,\n            tag=self.tag,\n            distance=self.distance,\n            node=self.node,\n            dirty=self.dirty,\n            branch=self.branch,\n            node_date=self.node_date,\n            **kw,\n        )"}, {"id": "setuptools_scm.version.ScmVersion.format_choice", "kind": "function", "range": [181, 4, 182, 83, 4855, 5022], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def format_choice(self, clean_format: str, dirty_format: str, **kw: object) -> str:\n        return self.format_with(dirty_format if self.dirty else clean_format, **kw)"}, {"id": "setuptools_scm.version.ScmVersion.format_next_version", "kind": "function", "range": [184, 4, 192, 53, 5028, 5373], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def format_next_version(\n        self,\n        guess_next: Callable[Concatenate[ScmVersion, _t.P], str],\n        fmt: str = \"{guessed}.dev{distance}\",\n        *k: _t.P.args,  # type: ignore\n        **kw: _t.P.kwargs,  # type: ignore\n    ) -> str:\n        guessed = guess_next(self, *k, **kw)\n        return self.format_with(fmt, guessed=guessed)"}, {"id": "setuptools_scm.version._parse_tag", "kind": "function", "range": [195, 0, 205, 18, 5376, 5729], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _parse_tag(\n    tag: _VersionT | str, preformatted: bool, config: Configuration | None\n) -> _VersionT | str:\n    if preformatted:\n        return tag\n    elif config is None or not isinstance(tag, config.version_cls):\n        version = tag_to_version(tag, config)\n        assert version is not None\n        return version\n    else:\n        return tag"}, {"id": "setuptools_scm.version.meta", "kind": "function", "range": [208, 0, 238, 5, 5732, 6639], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def meta(\n    tag: str | _VersionT,\n    distance: int | None = None,\n    dirty: bool = False,\n    node: str | None = None,\n    preformatted: bool = False,\n    branch: str | None = None,\n    config: Configuration | None = None,\n    node_date: date | None = None,\n    **kw: Any,\n) -> ScmVersion:\n    if not config:\n        warnings.warn(\n            \"meta invoked without explicit configuration,\"\n            \" will use defaults where required.\"\n        )\n        config = Configuration()\n    parsed_version = _parse_tag(tag, preformatted, config)\n    trace(\"version\", tag, \"->\", parsed_version)\n    assert parsed_version is not None, \"Can't parse version %s\" % tag\n    return ScmVersion(\n        parsed_version,\n        distance=distance,\n        node=node,\n        dirty=dirty,\n        preformatted=preformatted,\n        branch=branch,\n        config=config,\n        node_date=node_date,\n        **kw,\n    )"}, {"id": "setuptools_scm.version.guess_next_version", "kind": "function", "range": [241, 0, 243, 53, 6642, 6800], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def guess_next_version(tag_version: ScmVersion) -> str:\n    version = _strip_local(str(tag_version.tag))\n    return _bump_dev(version) or _bump_regex(version)"}, {"id": "setuptools_scm.version._dont_guess_next_version", "kind": "function", "range": [246, 0, 248, 51, 6803, 6965], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _dont_guess_next_version(tag_version: ScmVersion) -> str:\n    version = _strip_local(str(tag_version.tag))\n    return _bump_dev(version) or _add_post(version)"}, {"id": "setuptools_scm.version._strip_local", "kind": "function", "range": [251, 0, 253, 17, 6968, 7086], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _strip_local(version_string: str) -> str:\n    public, sep, local = version_string.partition(\"+\")\n    return public"}, {"id": "setuptools_scm.version._add_post", "kind": "function", "range": [256, 0, 261, 29, 7089, 7297], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _add_post(version: str) -> str:\n    if \"post\" in version:\n        raise ValueError(\n            f\"{version} already is a post release, refusing to guess the update\"\n        )\n    return f\"{version}.post1\""}, {"id": "setuptools_scm.version._bump_dev", "kind": "function", "range": [264, 0, 276, 17, 7300, 7738], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _bump_dev(version: str) -> str | None:\n    if \".dev\" not in version:\n        return None\n\n    prefix, tail = version.rsplit(\".dev\", 1)\n    if tail != \"0\":\n        raise ValueError(\n            \"choosing custom numbers for the `.devX` distance \"\n            \"is not supported.\\n \"\n            f\"The {version} can't be bumped\\n\"\n            \"Please drop the tag or create a new supported one ending in .dev0\"\n        )\n    return prefix"}, {"id": "setuptools_scm.version._bump_regex", "kind": "function", "range": [279, 0, 288, 47, 7741, 8123], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _bump_regex(version: str) -> str:\n    match = re.match(r\"(.*?)(\\d+)$\", version)\n    if match is None:\n        raise ValueError(\n            \"{version} does not end with a number to bump, \"\n            \"please correct or use a custom version scheme\".format(version=version)\n        )\n    else:\n        prefix, tail = match.groups()\n        return \"%s%d\" % (prefix, int(tail) + 1)"}, {"id": "setuptools_scm.version.guess_next_dev_version", "kind": "function", "range": [291, 0, 295, 62, 8126, 8320], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def guess_next_dev_version(version: ScmVersion) -> str:\n    if version.exact:\n        return version.format_with(\"{tag}\")\n    else:\n        return version.format_next_version(guess_next_version)"}, {"id": "setuptools_scm.version.guess_next_simple_semver", "kind": "function", "range": [298, 0, 311, 42, 8323, 8798], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def guess_next_simple_semver(\n    version: ScmVersion, retain: int, increment: bool = True\n) -> str:\n    try:\n        parts = [int(i) for i in str(version.tag).split(\".\")[:retain]]\n    except ValueError:\n        raise ValueError(f\"{version} can't be parsed as numeric version\")\n    while len(parts) < retain:\n        parts.append(0)\n    if increment:\n        parts[-1] += 1\n    while len(parts) < SEMVER_LEN:\n        parts.append(0)\n    return \".\".join(str(i) for i in parts)"}, {"id": "setuptools_scm.version.simplified_semver_version", "kind": "function", "range": [314, 0, 325, 13, 8801, 9309], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def simplified_semver_version(version: ScmVersion) -> str:\n    if version.exact:\n        return guess_next_simple_semver(version, retain=SEMVER_LEN, increment=False)\n    else:\n        if version.branch is not None and \"feature\" in version.branch:\n            return version.format_next_version(\n                guess_next_simple_semver, retain=SEMVER_MINOR\n            )\n        else:\n            return version.format_next_version(\n                guess_next_simple_semver, retain=SEMVER_PATCH\n            )"}, {"id": "setuptools_scm.version.release_branch_semver_version", "kind": "function", "range": [328, 0, 350, 85, 9312, 10650], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def release_branch_semver_version(version: ScmVersion) -> str:\n    if version.exact:\n        return version.format_with(\"{tag}\")\n    if version.branch is not None:\n        # Does the branch name (stripped of namespace) parse as a version?\n        branch_ver_data = _parse_version_tag(\n            version.branch.split(\"/\")[-1], version.config\n        )\n        if branch_ver_data is not None:\n            branch_ver = branch_ver_data[\"version\"]\n            if branch_ver[0] == \"v\":\n                # Allow branches that start with 'v', similar to Version.\n                branch_ver = branch_ver[1:]\n            # Does the branch version up to the minor part match the tag? If not it\n            # might be like, an issue number or something and not a version number, so\n            # we only want to use it if it matches.\n            tag_ver_up_to_minor = str(version.tag).split(\".\")[:SEMVER_MINOR]\n            branch_ver_up_to_minor = branch_ver.split(\".\")[:SEMVER_MINOR]\n            if branch_ver_up_to_minor == tag_ver_up_to_minor:\n                # We're in a release/maintenance branch, next is a patch/rc/beta bump:\n                return version.format_next_version(guess_next_version)\n    # We're in a development branch, next is a minor bump:\n    return version.format_next_version(guess_next_simple_semver, retain=SEMVER_MINOR)"}, {"id": "setuptools_scm.version.release_branch_semver", "kind": "function", "range": [353, 0, 360, 49, 10653, 10974], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def release_branch_semver(version: ScmVersion) -> str:\n    warnings.warn(\n        \"release_branch_semver is deprecated and will be removed in future. \"\n        + \"Use release_branch_semver_version instead\",\n        category=DeprecationWarning,\n        stacklevel=2,\n    )\n    return release_branch_semver_version(version)"}, {"id": "setuptools_scm.version.no_guess_dev_version", "kind": "function", "range": [363, 0, 367, 68, 10977, 11175], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def no_guess_dev_version(version: ScmVersion) -> str:\n    if version.exact:\n        return version.format_with(\"{tag}\")\n    else:\n        return version.format_next_version(_dont_guess_next_version)"}, {"id": "setuptools_scm.version.date_ver_match", "kind": "function", "range": [370, 0, 378, 16, 11178, 11414], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def date_ver_match(ver: str) -> Match[str] | None:\n    match = re.match(\n        (\n            r\"^(?P<date>(?P<year>\\d{2}|\\d{4})(?:\\.\\d{1,2}){2})\"\n            r\"(?:\\.(?P<patch>\\d*)){0,1}?$\"\n        ),\n        ver,\n    )\n    return match"}, {"id": "setuptools_scm.version.guess_next_date_ver", "kind": "function", "range": [381, 0, 431, 23, 11417, 13129], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def guess_next_date_ver(\n    version: ScmVersion,\n    node_date: date | None = None,\n    date_fmt: str | None = None,\n    version_cls: type | None = None,\n) -> str:\n    \"\"\"\n    same-day -> patch +1\n    other-day -> today\n\n    distance is always added as .devX\n    \"\"\"\n    match = date_ver_match(str(version.tag))\n    if match is None:\n        warnings.warn(\n            f\"{version} does not correspond to a valid versioning date, \"\n            \"assuming legacy version\"\n        )\n        if date_fmt is None:\n            date_fmt = \"%y.%m.%d\"\n    else:\n        # deduct date format if not provided\n        if date_fmt is None:\n            date_fmt = \"%Y.%m.%d\" if len(match.group(\"year\")) == 4 else \"%y.%m.%d\"\n    today = datetime.now(timezone.utc).date()\n    head_date = node_date or today\n    # compute patch\n    if match is None:\n        tag_date = today\n    else:\n        tag_date = datetime.strptime(match.group(\"date\"), date_fmt).date()\n    if tag_date == head_date:\n        patch = \"0\" if match is None else (match.group(\"patch\") or \"0\")\n        patch = int(patch) + 1\n    else:\n        if tag_date > head_date and match is not None:\n            # warn on future times\n            warnings.warn(\n                \"your previous tag  ({}) is ahead your node date ({})\".format(\n                    tag_date, head_date\n                )\n            )\n        patch = 0\n    next_version = \"{node_date:{date_fmt}}.{patch}\".format(\n        node_date=head_date, date_fmt=date_fmt, patch=patch\n    )\n    # rely on the Version object to ensure consistency (e.g. remove leading 0s)\n    if version_cls is None:\n        version_cls = PkgVersion\n    next_version = str(version_cls(next_version))\n    return next_version"}, {"id": "setuptools_scm.version.calver_by_date", "kind": "function", "range": [434, 0, 449, 5, 13132, 13808], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def calver_by_date(version: ScmVersion) -> str:\n    if version.exact and not version.dirty:\n        return version.format_with(\"{tag}\")\n    # TODO: move the release-X check to a new scheme\n    if version.branch is not None and version.branch.startswith(\"release-\"):\n        branch_ver = _parse_version_tag(version.branch.split(\"-\")[-1], version.config)\n        if branch_ver is not None:\n            ver = branch_ver[\"version\"]\n            match = date_ver_match(ver)\n            if match:\n                return ver\n    return version.format_next_version(\n        guess_next_date_ver,\n        node_date=version.node_date,\n        version_cls=version.config.version_cls,\n    )"}, {"id": "setuptools_scm.version._format_local_with_time", "kind": "function", "range": [452, 0, 461, 9, 13811, 14184], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _format_local_with_time(version: ScmVersion, time_format: str) -> str:\n\n    if version.exact or version.node is None:\n        return version.format_choice(\n            \"\", \"+d{time:{time_format}}\", time_format=time_format\n        )\n    else:\n        return version.format_choice(\n            \"+{node}\", \"+{node}.d{time:{time_format}}\", time_format=time_format\n        )"}, {"id": "setuptools_scm.version.get_local_node_and_date", "kind": "function", "range": [464, 0, 465, 65, 14187, 14309], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def get_local_node_and_date(version: ScmVersion) -> str:\n    return _format_local_with_time(version, time_format=\"%Y%m%d\")"}, {"id": "setuptools_scm.version.get_local_node_and_timestamp", "kind": "function", "range": [468, 0, 469, 60, 14312, 14461], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def get_local_node_and_timestamp(version: ScmVersion, fmt: str = \"%Y%m%d%H%M%S\") -> str:\n    return _format_local_with_time(version, time_format=fmt)"}, {"id": "setuptools_scm.version.get_local_dirty_tag", "kind": "function", "range": [472, 0, 473, 46, 14464, 14563], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def get_local_dirty_tag(version: ScmVersion) -> str:\n    return version.format_choice(\"\", \"+dirty\")"}, {"id": "setuptools_scm.version.get_no_local_node", "kind": "function", "range": [476, 0, 477, 13, 14566, 14617], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def get_no_local_node(_: Any) -> str:\n    return \"\""}, {"id": "setuptools_scm.version.postrelease_version", "kind": "function", "range": [480, 0, 484, 58, 14620, 14807], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def postrelease_version(version: ScmVersion) -> str:\n    if version.exact:\n        return version.format_with(\"{tag}\")\n    else:\n        return version.format_with(\"{tag}.post{distance}\")"}, {"id": "setuptools_scm.version._get_ep", "kind": "function", "range": [487, 0, 494, 19, 14810, 15045], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _get_ep(group: str, name: str) -> Any | None:\n    from ._entrypoints import iter_entry_points\n\n    for ep in iter_entry_points(group, name):\n        trace(\"ep found:\", ep.name)\n        return ep.load()\n    else:\n        return None"}, {"id": "setuptools_scm.version._iter_version_schemes", "kind": "function", "range": [497, 0, 520, 26, 15048, 15832], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _iter_version_schemes(\n    entrypoint: str,\n    scheme_value: str\n    | list[str]\n    | tuple[str, ...]\n    | Callable[[ScmVersion], str]\n    | None,\n    _memo: set[object] | None = None,\n) -> Iterator[Callable[[ScmVersion], str]]:\n    if _memo is None:\n        _memo = set()\n    if isinstance(scheme_value, str):\n        scheme_value = cast(\n            'str|List[str]|Tuple[str, ...]|Callable[[\"ScmVersion\"], str]|None',\n            _get_ep(entrypoint, scheme_value),\n        )\n\n    if isinstance(scheme_value, (list, tuple)):\n        for variant in scheme_value:\n            if variant not in _memo:\n                _memo.add(variant)\n                yield from _iter_version_schemes(entrypoint, variant, _memo=_memo)\n    elif callable(scheme_value):\n        yield scheme_value"}, {"id": "setuptools_scm.version._call_version_scheme", "kind": "function", "range": [523, 0, 527, 7, 15835, 15960], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "@overload\ndef _call_version_scheme(\n    version: ScmVersion, entypoint: str, given_value: str, default: str\n) -> str:\n    ..."}, {"id": "setuptools_scm.version._call_version_scheme", "kind": "function", "range": [530, 0, 534, 7, 15963, 16096], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "@overload\ndef _call_version_scheme(\n    version: ScmVersion, entypoint: str, given_value: str, default: None\n) -> str | None:\n    ..."}, {"id": "setuptools_scm.version._call_version_scheme", "kind": "function", "range": [537, 0, 544, 18, 16099, 16394], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def _call_version_scheme(\n    version: ScmVersion, entypoint: str, given_value: str, default: str | None\n) -> str | None:\n    for scheme in _iter_version_schemes(entypoint, given_value):\n        result = scheme(version)\n        if result is not None:\n            return result\n    return default"}, {"id": "setuptools_scm.version.format_version", "kind": "function", "range": [547, 0, 562, 39, 16397, 17033], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/version.py", "content": "def format_version(version: ScmVersion, **config: Any) -> str:\n    trace(\"scm version\", version)\n    trace(\"config\", config)\n    if version.preformatted:\n        assert isinstance(version.tag, str)\n        return version.tag\n    main_version = _call_version_scheme(\n        version, \"setuptools_scm.version_scheme\", config[\"version_scheme\"], None\n    )\n    trace(\"version\", main_version)\n    assert main_version is not None\n    local_version = _call_version_scheme(\n        version, \"setuptools_scm.local_scheme\", config[\"local_scheme\"], \"+unknown\"\n    )\n    trace(\"local_version\", local_version)\n    return main_version + local_version"}, {"id": "setuptools_scm._overrides.PRETEND_KEY", "kind": "variable", "range": [10, 0, 10, 46, 166, 212], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_overrides.py", "content": "PRETEND_KEY = \"SETUPTOOLS_SCM_PRETEND_VERSION\""}, {"id": "setuptools_scm._overrides.PRETEND_KEY_NAMED", "kind": "variable", "range": [11, 0, 11, 47, 213, 260], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_overrides.py", "content": "PRETEND_KEY_NAMED = PRETEND_KEY + \"_FOR_{name}\""}, {"id": "setuptools_scm._overrides._read_pretended_version_for", "kind": "function", "range": [14, 0, 37, 19, 263, 1066], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_overrides.py", "content": "def _read_pretended_version_for(config: Configuration) -> ScmVersion | None:\n    \"\"\"read a a overridden version from the environment\n\n    tries ``SETUPTOOLS_SCM_PRETEND_VERSION``\n    and ``SETUPTOOLS_SCM_PRETEND_VERSION_FOR_$UPPERCASE_DIST_NAME``\n    \"\"\"\n    trace(\"dist name:\", config.dist_name)\n    pretended: str | None\n    if config.dist_name is not None:\n        pretended = os.environ.get(\n            PRETEND_KEY_NAMED.format(name=config.dist_name.upper())\n        )\n    else:\n        pretended = None\n\n    if pretended is None:\n        pretended = os.environ.get(PRETEND_KEY)\n\n    if pretended:\n        # we use meta here since the pretended version\n        # must adhere to the pep to begin with\n        return meta(tag=pretended, preformatted=True, config=config)\n    else:\n        return None"}, {"id": "setuptools_scm.discover.walk_potential_roots", "kind": "function", "range": [13, 0, 30, 40, 246, 667], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/discover.py", "content": "def walk_potential_roots(\n    root: _t.PathT, search_parents: bool = True\n) -> Iterator[_t.PathT]:\n    \"\"\"\n    Iterate though a path and each of its parents.\n    :param root: File path.\n    :param search_parents: If ``False`` the parents are not considered.\n    \"\"\"\n\n    if not search_parents:\n        yield root\n        return\n\n    tail = root\n\n    while tail:\n        yield root\n        root, tail = os.path.split(root)"}, {"id": "setuptools_scm.discover.match_entrypoint", "kind": "function", "range": [33, 0, 46, 16, 670, 1081], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/discover.py", "content": "def match_entrypoint(root: _t.PathT, name: str) -> bool:\n    \"\"\"\n    Consider a ``root`` as entry-point.\n    :param root: File path.\n    :param name: Subdirectory name.\n    :return: ``True`` if a subdirectory ``name`` exits in ``root``.\n    \"\"\"\n\n    if os.path.exists(os.path.join(root, name)):\n        if not os.path.isabs(name):\n            return True\n        trace(\"ignoring bad ep\", name)\n\n    return False"}, {"id": "setuptools_scm.discover.iter_matching_entrypoints", "kind": "function", "range": [49, 0, 68, 24, 1084, 1866], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/discover.py", "content": "def iter_matching_entrypoints(\n    root: _t.PathT, entrypoint: str, config: Configuration\n) -> Iterable[_t.EntrypointProtocol]:\n    \"\"\"\n    Consider different entry-points in ``root`` and optionally its parents.\n    :param root: File path.\n    :param entrypoint: Entry-point to consider.\n    :param config: Configuration,\n        read ``search_parent_directories``, write found parent to ``parent``.\n    \"\"\"\n\n    trace(\"looking for ep\", entrypoint, root)\n    from ._entrypoints import iter_entry_points\n\n    for wd in walk_potential_roots(root, config.search_parent_directories):\n        for ep in iter_entry_points(entrypoint):\n            if match_entrypoint(wd, ep.name):\n                trace(\"found ep\", ep, \"in\", wd)\n                config.parent = wd\n                yield ep"}, {"id": "setuptools_scm.file_finder_git.log", "kind": "variable", "range": [19, 0, 19, 33, 374, 407], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_git.py", "content": "log = logging.getLogger(__name__)"}, {"id": "setuptools_scm.file_finder_git._git_toplevel", "kind": "function", "range": [22, 0, 56, 19, 410, 1900], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_git.py", "content": "def _git_toplevel(path: str) -> str | None:\n    try:\n        cwd = os.path.abspath(path or \".\")\n        out, err, ret = do_ex([\"git\", \"rev-parse\", \"HEAD\"], cwd=cwd)\n        if ret != 0:\n            # BAIL if there is no commit\n            log.error(\"listing git files failed - pretending there aren't any\")\n            return None\n        out, err, ret = do_ex(\n            [\"git\", \"rev-parse\", \"--show-prefix\"],\n            cwd=cwd,\n        )\n        if ret != 0:\n            return None\n        out = out.strip()[:-1]  # remove the trailing pathsep\n        if not out:\n            out = cwd\n        else:\n            # Here, ``out`` is a relative path to root of git.\n            # ``cwd`` is absolute path to current working directory.\n            # the below method removes the length of ``out`` from\n            # ``cwd``, which gives the git toplevel\n            assert cwd.replace(\"\\\\\", \"/\").endswith(out), f\"cwd={cwd!r}\\nout={out!r}\"\n            # In windows cwd contains ``\\`` which should be replaced by ``/``\n            # for this assertion to work. Length of string isn't changed by replace\n            # ``\\\\`` is just and escape for `\\`\n            out = cwd[: -len(out)]\n        trace(\"find files toplevel\", out)\n        return os.path.normcase(os.path.realpath(out.strip()))\n    except subprocess.CalledProcessError:\n        # git returned error, we are not in a git repo\n        return None\n    except OSError:\n        # git command not found, probably\n        return None"}, {"id": "setuptools_scm.file_finder_git._git_interpret_archive", "kind": "function", "range": [59, 0, 69, 34, 1903, 2383], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_git.py", "content": "def _git_interpret_archive(fd: IO[bytes], toplevel: str) -> tuple[set[str], set[str]]:\n    with tarfile.open(fileobj=fd, mode=\"r|*\") as tf:\n        git_files = set()\n        git_dirs = {toplevel}\n        for member in tf.getmembers():\n            name = os.path.normcase(member.name).replace(\"/\", os.path.sep)\n            if member.type == tarfile.DIRTYPE:\n                git_dirs.add(name)\n            else:\n                git_files.add(name)\n        return git_files, git_dirs"}, {"id": "setuptools_scm.file_finder_git._git_ls_files_and_dirs", "kind": "function", "range": [72, 0, 91, 27, 2386, 3165], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_git.py", "content": "def _git_ls_files_and_dirs(toplevel: str) -> tuple[set[str], set[str]]:\n    # use git archive instead of git ls-file to honor\n    # export-ignore git attribute\n\n    cmd = [\"git\", \"archive\", \"--prefix\", toplevel + os.path.sep, \"HEAD\"]\n    proc = subprocess.Popen(\n        cmd, stdout=subprocess.PIPE, cwd=toplevel, stderr=subprocess.DEVNULL\n    )\n    assert proc.stdout is not None\n    try:\n        try:\n            return _git_interpret_archive(proc.stdout, toplevel)\n        finally:\n            # ensure we avoid resource warnings by cleaning up the process\n            proc.stdout.close()\n            proc.terminate()\n    except Exception:\n        if proc.wait() != 0:\n            log.error(\"listing git files failed - pretending there aren't any\")\n        return set(), set()"}, {"id": "setuptools_scm.file_finder_git.git_find_files", "kind": "function", "range": [94, 0, 103, 52, 3168, 3652], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_git.py", "content": "def git_find_files(path: _t.PathT = \"\") -> list[str]:\n    toplevel = _git_toplevel(os.fspath(path))\n    if not is_toplevel_acceptable(toplevel):\n        return []\n    assert toplevel is not None  # mypy ignores typeguard\n    fullpath = os.path.abspath(os.path.normpath(path))\n    if not fullpath.startswith(toplevel):\n        trace(\"toplevel mismatch\", toplevel, fullpath)\n    git_files, git_dirs = _git_ls_files_and_dirs(toplevel)\n    return scm_find_files(path, git_files, git_dirs)"}, {"id": "setuptools_scm.file_finder_git.git_archive_find_files", "kind": "function", "range": [106, 0, 120, 67, 3655, 4286], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder_git.py", "content": "def git_archive_find_files(path: _t.PathT = \"\") -> list[str]:\n    # This function assumes that ``path`` is obtained from a git archive\n    # and therefore all the files that should be ignored were already removed.\n    archival = os.path.join(path, \".git_archival.txt\")\n    if not os.path.exists(archival):\n        return []\n\n    data = data_from_mime(archival)\n\n    if \"$Format\" in data.get(\"node\", \"\"):\n        # Substitutions have not been performed, so not a reliable archive\n        return []\n\n    trace(\"git archive detected - fallback to listing all files\")\n    return scm_find_files(path, set(), set(), force_all_files=True)"}, {"id": "setuptools_scm._cli.main", "kind": "function", "range": [12, 0, 43, 24, 271, 1287], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_cli.py", "content": "def main(args: list[str] | None = None) -> None:\n    opts = _get_cli_opts(args)\n    inferred_root: str = opts.root or \".\"\n\n    pyproject = opts.config or _find_pyproject(inferred_root)\n\n    try:\n\n        config = Configuration.from_file(\n            pyproject,\n            root=(os.path.abspath(opts.root) if opts.root is not None else None),\n        )\n    except (LookupError, FileNotFoundError) as ex:\n        # no pyproject.toml OR no [tool.setuptools_scm]\n        print(\n            f\"Warning: could not use {os.path.relpath(pyproject)},\"\n            \" using default configuration.\\n\"\n            f\" Reason: {ex}.\",\n            file=sys.stderr,\n        )\n        config = Configuration(inferred_root)\n\n    version = _get_version(config)\n    if version is None:\n        raise SystemExit(\"ERROR: no version found for\", opts)\n    if opts.strip_dev:\n        version = version.partition(\".dev\")[0]\n    print(version)\n\n    if opts.command == \"ls\":\n        for fname in find_files(config.root):\n            print(fname)"}, {"id": "setuptools_scm._cli._get_cli_opts", "kind": "function", "range": [46, 0, 74, 34, 1290, 2494], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_cli.py", "content": "def _get_cli_opts(args: list[str] | None) -> argparse.Namespace:\n    prog = \"python -m setuptools_scm\"\n    desc = \"Print project version according to SCM metadata\"\n    parser = argparse.ArgumentParser(prog, description=desc)\n    # By default, help for `--help` starts with lower case, so we keep the pattern:\n    parser.add_argument(\n        \"-r\",\n        \"--root\",\n        default=None,\n        help='directory managed by the SCM, default: inferred from config file, or \".\"',\n    )\n    parser.add_argument(\n        \"-c\",\n        \"--config\",\n        default=None,\n        metavar=\"PATH\",\n        help=\"path to 'pyproject.toml' with setuptools_scm config, \"\n        \"default: looked up in the current or parent directories\",\n    )\n    parser.add_argument(\n        \"--strip-dev\",\n        action=\"store_true\",\n        help=\"remove the dev/local parts of the version before printing the version\",\n    )\n    sub = parser.add_subparsers(title=\"extra commands\", dest=\"command\", metavar=\"\")\n    # We avoid `metavar` to prevent printing repetitive information\n    desc = \"List files managed by the SCM\"\n    sub.add_parser(\"ls\", help=desc[0].lower() + desc[1:], description=desc)\n    return parser.parse_args(args)"}, {"id": "setuptools_scm._cli._find_pyproject", "kind": "function", "range": [77, 0, 85, 55, 2497, 2844], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_cli.py", "content": "def _find_pyproject(parent: str) -> str:\n    for directory in walk_potential_roots(os.path.abspath(parent)):\n        pyproject = os.path.join(directory, \"pyproject.toml\")\n        if os.path.isfile(pyproject):\n            return pyproject\n\n    return os.path.abspath(\n        \"pyproject.toml\"\n    )  # use default name to trigger the default errors"}, {"id": "setuptools_scm.__init__.TEMPLATES", "kind": "variable", "range": [36, 0, 44, 1, 1009, 1242], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "TEMPLATES = {\n    \".py\": \"\"\"\\\n# file generated by setuptools_scm\n# don't change, don't track in version control\n__version__ = version = {version!r}\n__version_tuple__ = version_tuple = {version_tuple!r}\n\"\"\",\n    \".txt\": \"{version}\",\n}"}, {"id": "setuptools_scm.__init__.version_from_scm", "kind": "function", "range": [47, 0, 54, 44, 1245, 1535], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "def version_from_scm(root: _t.PathT) -> ScmVersion | None:\n    warnings.warn(\n        \"version_from_scm is deprecated please use get_version\",\n        category=DeprecationWarning,\n        stacklevel=2,\n    )\n    config = Configuration(root=root)\n    return _version_from_entrypoints(config)"}, {"id": "setuptools_scm.__init__.dump_version", "kind": "function", "range": [57, 0, 77, 79, 1538, 2219], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "def dump_version(\n    root: _t.PathT,\n    version: str,\n    write_to: _t.PathT,\n    template: str | None = None,\n) -> None:\n    assert isinstance(version, str)\n    target = os.path.normpath(os.path.join(root, write_to))\n    ext = os.path.splitext(target)[1]\n    template = template or TEMPLATES.get(ext)\n\n    if template is None:\n        raise ValueError(\n            \"bad file format: '{}' (of {}) \\nonly *.txt and *.py are supported\".format(\n                os.path.splitext(target)[1], target\n            )\n        )\n    version_tuple = _version_as_tuple(version)\n\n    with open(target, \"w\") as fp:\n        fp.write(template.format(version=version, version_tuple=version_tuple))"}, {"id": "setuptools_scm.__init__._do_parse", "kind": "function", "range": [80, 0, 103, 18, 2222, 3130], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "def _do_parse(config: Configuration) -> ScmVersion | None:\n    pretended = _read_pretended_version_for(config)\n    if pretended is not None:\n        return pretended\n\n    if config.parse:\n        parse_result = _call_entrypoint_fn(config.absolute_root, config, config.parse)\n        if isinstance(parse_result, str):\n            raise TypeError(\n                f\"version parse result was {str!r}\\nplease return a parsed version\"\n            )\n        version: ScmVersion | None\n        if parse_result:\n            assert isinstance(parse_result, ScmVersion)\n            version = parse_result\n        else:\n            version = _version_from_entrypoints(config, fallback=True)\n    else:\n        # include fallbacks after dropping them from the main entrypoint\n        version = _version_from_entrypoints(config) or _version_from_entrypoints(\n            config, fallback=True\n        )\n\n    return version"}, {"id": "setuptools_scm.__init__._version_missing", "kind": "function", "range": [106, 0, 116, 5, 3133, 3756], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "def _version_missing(config: Configuration) -> NoReturn:\n    raise LookupError(\n        f\"setuptools-scm was unable to detect version for {config.absolute_root}.\\n\\n\"\n        \"Make sure you're either building from a fully intact git repository \"\n        \"or PyPI tarballs. Most other sources (such as GitHub's tarballs, a \"\n        \"git checkout without the .git folder) don't contain the necessary \"\n        \"metadata and will not work.\\n\\n\"\n        \"For example, if you're using pip, instead of \"\n        \"https://github.com/user/proj/archive/master.zip \"\n        \"use git+https://github.com/user/proj.git#egg=proj\"\n    )"}, {"id": "setuptools_scm.__init__.get_version", "kind": "function", "range": [119, 0, 148, 24, 3759, 4900], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "def get_version(\n    root: str = \".\",\n    version_scheme: Callable[[ScmVersion], str] | str = DEFAULT_VERSION_SCHEME,\n    local_scheme: Callable[[ScmVersion], str] | str = DEFAULT_LOCAL_SCHEME,\n    write_to: _t.PathT | None = None,\n    write_to_template: str | None = None,\n    relative_to: str | None = None,\n    tag_regex: str = DEFAULT_TAG_REGEX,\n    parentdir_prefix_version: str | None = None,\n    fallback_version: str | None = None,\n    fallback_root: _t.PathT = \".\",\n    parse: Any | None = None,\n    git_describe_command: Any | None = None,\n    dist_name: str | None = None,\n    version_cls: Any | None = None,\n    normalize: bool = True,\n    search_parent_directories: bool = False,\n) -> str:\n    \"\"\"\n    If supplied, relative_to should be a file from which root may\n    be resolved. Typically called by a script or module that is not\n    in the root of the repository to direct setuptools_scm to the\n    root of the repository by supplying ``__file__``.\n    \"\"\"\n\n    config = Configuration(**locals())\n    maybe_version = _get_version(config)\n    if maybe_version is None:\n        _version_missing(config)\n    return maybe_version"}, {"id": "setuptools_scm.__init__._get_version", "kind": "function", "range": [151, 0, 168, 25, 4903, 5448], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "def _get_version(config: Configuration) -> str | None:\n    parsed_version = _do_parse(config)\n    if parsed_version is None:\n        return None\n    version_string = format_version(\n        parsed_version,\n        version_scheme=config.version_scheme,\n        local_scheme=config.local_scheme,\n    )\n    if config.write_to is not None:\n        dump_version(\n            root=config.root,\n            version=version_string,\n            write_to=config.write_to,\n            template=config.write_to_template,\n        )\n\n    return version_string"}, {"id": "setuptools_scm.__init__.__all__", "kind": "variable", "range": [172, 0, 190, 1, 5464, 5890], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/__init__.py", "content": "__all__ = [\n    \"get_version\",\n    \"dump_version\",\n    \"version_from_scm\",\n    \"Configuration\",\n    \"DEFAULT_VERSION_SCHEME\",\n    \"DEFAULT_LOCAL_SCHEME\",\n    \"DEFAULT_TAG_REGEX\",\n    \"PRETEND_KEY\",\n    \"PRETEND_KEY_NAMED\",\n    \"Version\",\n    \"NonNormalizedVersion\",\n    # TODO: are the symbols below part of public API ?\n    \"function_has_arg\",\n    \"trace\",\n    \"format_version\",\n    \"meta\",\n    \"iter_matching_entrypoints\",\n]"}, {"id": "setuptools_scm._integration.read_dist_name_from_setup_cfg", "kind": "function", "range": [6, 0, 21, 20, 70, 529], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/setuptools.py", "content": "def read_dist_name_from_setup_cfg(\n    input: str | os.PathLike[str] | IO[str] = \"setup.cfg\",\n) -> str | None:\n\n    # minimal effort to read dist_name off setup.cfg metadata\n    import configparser\n\n    parser = configparser.ConfigParser()\n\n    if isinstance(input, (os.PathLike, str)):\n        parser.read([input], encoding=\"utf-8\")\n    else:\n        parser.read_file(input)\n\n    dist_name = parser.get(\"metadata\", \"name\", fallback=None)\n    return dist_name"}, {"id": "setuptools_scm._integration._ROOT", "kind": "variable", "range": [15, 0, 15, 14, 320, 334], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "_ROOT = \"root\""}, {"id": "setuptools_scm._integration.TOML_RESULT", "kind": "variable", "range": [16, 0, 16, 39, 335, 374], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "TOML_RESULT: TypeAlias = Dict[str, Any]"}, {"id": "setuptools_scm._integration.TOML_LOADER", "kind": "variable", "range": [17, 0, 17, 53, 375, 428], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "TOML_LOADER: TypeAlias = Callable[[str], TOML_RESULT]"}, {"id": "setuptools_scm._integration.PyProjectData", "kind": "class", "range": [20, 0, 28, 39, 431, 643], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "class PyProjectData(NamedTuple):\n    name: str\n    tool_name: str\n    project: TOML_RESULT\n    section: TOML_RESULT\n\n    @property\n    def project_name(self) -> str | None:\n        return self.project.get(\"name\")"}, {"id": "setuptools_scm._integration.PyProjectData.name", "kind": "variable", "range": [21, 4, 21, 13, 468, 477], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "name: str"}, {"id": "setuptools_scm._integration.PyProjectData.tool_name", "kind": "variable", "range": [22, 4, 22, 18, 482, 496], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "tool_name: str"}, {"id": "setuptools_scm._integration.PyProjectData.project", "kind": "variable", "range": [23, 4, 23, 24, 501, 521], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "project: TOML_RESULT"}, {"id": "setuptools_scm._integration.PyProjectData.section", "kind": "variable", "range": [24, 4, 24, 24, 526, 546], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "section: TOML_RESULT"}, {"id": "setuptools_scm._integration.PyProjectData.project_name", "kind": "function", "range": [26, 4, 28, 39, 552, 643], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "@property\n    def project_name(self) -> str | None:\n        return self.project.get(\"name\")"}, {"id": "setuptools_scm._integration.lazy_toml_load", "kind": "function", "range": [31, 0, 37, 22, 646, 827], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "def lazy_toml_load(data: str) -> TOML_RESULT:\n    if sys.version_info >= (3, 11):\n        from tomllib import loads\n    else:\n        from tomli import loads\n\n    return loads(data)"}, {"id": "setuptools_scm._integration.read_pyproject", "kind": "function", "range": [40, 0, 55, 59, 830, 1424], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "def read_pyproject(\n    name: str = \"pyproject.toml\",\n    tool_name: str = \"setuptools_scm\",\n    _load_toml: TOML_LOADER | None = None,\n) -> PyProjectData:\n    if _load_toml is None:\n        _load_toml = lazy_toml_load\n    with open(name, encoding=\"UTF-8\") as strm:\n        data = strm.read()\n    defn = _load_toml(data)\n    try:\n        section = defn.get(\"tool\", {})[tool_name]\n    except LookupError as e:\n        raise LookupError(f\"{name} does not contain a tool.{tool_name} section\") from e\n    project = defn.get(\"project\", {})\n    return PyProjectData(name, tool_name, project, section)"}, {"id": "setuptools_scm._integration.get_args_for_pyproject", "kind": "function", "range": [58, 0, 94, 56, 1427, 2837], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_integration/pyproject_reading.py", "content": "def get_args_for_pyproject(\n    pyproject: PyProjectData,\n    dist_name: str | None,\n    kwargs: TOML_RESULT,\n) -> TOML_RESULT:\n    \"\"\"drops problematic details and figures the distribution name\"\"\"\n    section = pyproject.section.copy()\n    kwargs = kwargs.copy()\n    if \"relative_to\" in section:\n        relative = section.pop(\"relative_to\")\n        warnings.warn(\n            f\"{pyproject.name}: at [tool.{pyproject.tool_name}]\\n\"\n            f\"ignoring value relative_to={relative!r}\"\n            \" as its always relative to the config file\"\n        )\n    if \"dist_name\" in section:\n        if dist_name is None:\n            dist_name = section.pop(\"dist_name\")\n        else:\n            assert dist_name == section[\"dist_name\"]\n            del section[\"dist_name\"]\n    if dist_name is None:\n        # minimal pep 621 support for figuring the pretend keys\n        dist_name = pyproject.project_name\n    if dist_name is None:\n        dist_name = read_dist_name_from_setup_cfg()\n    if _ROOT in kwargs:\n        if kwargs[_ROOT] is None:\n            kwargs.pop(_ROOT, None)\n        elif _ROOT in section:\n            if section[_ROOT] != kwargs[_ROOT]:\n                warnings.warn(\n                    f\"root {section[_ROOT]} is overridden\"\n                    f\" by the cli arg {kwargs[_ROOT]}\"\n                )\n            section.pop(\"root\", None)\n    return {\"dist_name\": dist_name, **section, **kwargs}"}, {"id": "setuptools_scm.integration._warn_on_old_setuptools", "kind": "function", "range": [25, 0, 52, 9, 528, 1655], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/integration.py", "content": "def _warn_on_old_setuptools(_version: str = setuptools.__version__) -> None:\n    if int(_version.split(\".\")[0]) < 45:\n        warnings.warn(\n            RuntimeWarning(\n                f\"\"\"\nERROR: setuptools=={_version} is used in combination with setuptools_scm>=6.x\n\nYour build configuration is incomplete and previously worked by accident!\nsetuptools_scm requires setuptools>=45\n\n\nThis happens as setuptools is unable to replace itself when a activated build dependency\nrequires a more recent setuptools version\n(it does not respect \"setuptools>X\" in setup_requires).\n\n\nsetuptools>=31 is required for setup.cfg metadata support\nsetuptools>=42 is required for pyproject.toml configuration support\n\nSuggested workarounds if applicable:\n - preinstalling build dependencies like setuptools_scm before running setup.py\n - installing setuptools_scm using the system package manager to ensure consistency\n - migrating from the deprecated setup_requires mechanism to pep517/518\n   and using a pyproject.toml to declare build dependencies\n   which are reliably pre-installed before running the build tools\n\"\"\"\n            )\n        )"}, {"id": "setuptools_scm.integration._assign_version", "kind": "function", "range": [58, 0, 64, 45, 1686, 1929], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/integration.py", "content": "def _assign_version(dist: setuptools.Distribution, config: Configuration) -> None:\n    maybe_version = _get_version(config)\n\n    if maybe_version is None:\n        _version_missing(config)\n    else:\n        dist.metadata.version = maybe_version"}, {"id": "setuptools_scm.integration.version_keyword", "kind": "function", "range": [67, 0, 90, 33, 1932, 2614], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/integration.py", "content": "def version_keyword(\n    dist: setuptools.Distribution,\n    keyword: str,\n    value: bool | dict[str, Any] | Callable[[], dict[str, Any]],\n) -> None:\n    if not value:\n        return\n    elif value is True:\n        value = {}\n    elif callable(value):\n        value = value()\n    assert (\n        \"dist_name\" not in value\n    ), \"dist_name may not be specified in the setup keyword \"\n\n    trace(\n        \"version keyword\",\n        vars(dist.metadata),\n    )\n    dist_name = dist.metadata.name  # type: str | None\n    if dist_name is None:\n        dist_name = _read_dist_name_from_setup_cfg()\n    config = Configuration(dist_name=dist_name, **value)\n    _assign_version(dist, config)"}, {"id": "setuptools_scm.integration.find_files", "kind": "function", "range": [93, 0, 106, 13, 2617, 3096], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/integration.py", "content": "def find_files(path: _t.PathT = \"\") -> list[str]:\n    for ep in itertools.chain(\n        iter_entry_points(\"setuptools_scm.files_command\"),\n        iter_entry_points(\"setuptools_scm.files_command_fallback\"),\n    ):\n        command = ep.load()\n        if isinstance(command, str):\n            # this technique is deprecated\n            res = do(ep.load(), path or \".\").splitlines()\n        else:\n            res = command(path)\n        if res:\n            return res\n    return []"}, {"id": "setuptools_scm.integration.infer_version", "kind": "function", "range": [109, 0, 126, 37, 3099, 3619], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/integration.py", "content": "def infer_version(dist: setuptools.Distribution) -> None:\n    trace(\n        \"finalize hook\",\n        vars(dist.metadata),\n    )\n    dist_name = dist.metadata.name\n    if dist_name is None:\n        dist_name = _read_dist_name_from_setup_cfg()\n    if not os.path.isfile(\"pyproject.toml\"):\n        return\n    if dist_name == \"setuptools_scm\":\n        return\n    try:\n        config = Configuration.from_file(dist_name=dist_name)\n    except LookupError as e:\n        trace(e)\n    else:\n        _assign_version(dist, config)"}, {"id": "setuptools_scm.utils.DEBUG", "kind": "variable", "range": [23, 0, 23, 52, 378, 430], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "DEBUG = bool(os.environ.get(\"SETUPTOOLS_SCM_DEBUG\"))"}, {"id": "setuptools_scm.utils.IS_WINDOWS", "kind": "variable", "range": [24, 0, 24, 43, 431, 474], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "IS_WINDOWS = platform.system() == \"Windows\""}, {"id": "setuptools_scm.utils._CmdResult", "kind": "class", "range": [27, 0, 30, 19, 477, 552], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "class _CmdResult(NamedTuple):\n    out: str\n    err: str\n    returncode: int"}, {"id": "setuptools_scm.utils._CmdResult.out", "kind": "variable", "range": [28, 4, 28, 12, 511, 519], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "out: str"}, {"id": "setuptools_scm.utils._CmdResult.err", "kind": "variable", "range": [29, 4, 29, 12, 524, 532], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "err: str"}, {"id": "setuptools_scm.utils._CmdResult.returncode", "kind": "variable", "range": [30, 4, 30, 19, 537, 552], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "returncode: int"}, {"id": "setuptools_scm.utils.no_git_env", "kind": "function", "range": [33, 0, 51, 5, 555, 1361], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def no_git_env(env: Mapping[str, str]) -> dict[str, str]:\n    # adapted from pre-commit\n    # Too many bugs dealing with environment variables and GIT:\n    # https://github.com/pre-commit/pre-commit/issues/300\n    # In git 2.6.3 (maybe others), git exports GIT_WORK_TREE while running\n    # pre-commit hooks\n    # In git 1.9.1 (maybe others), git exports GIT_DIR and GIT_INDEX_FILE\n    # while running pre-commit hooks in submodules.\n    # GIT_DIR: Causes git clone to clone wrong thing\n    # GIT_INDEX_FILE: Causes 'error invalid object ...' during commit\n    for k, v in env.items():\n        if k.startswith(\"GIT_\"):\n            trace(k, v)\n    return {\n        k: v\n        for k, v in env.items()\n        if not k.startswith(\"GIT_\")\n        or k in (\"GIT_EXEC_PATH\", \"GIT_SSH\", \"GIT_SSH_COMMAND\")\n    }"}, {"id": "setuptools_scm.utils.avoid_pip_isolation", "kind": "function", "range": [54, 0, 72, 18, 1364, 1973], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def avoid_pip_isolation(env: Mapping[str, str]) -> dict[str, str]:\n    \"\"\"\n    pip build isolation can break Mercurial\n    (see https://github.com/pypa/pip/issues/10635)\n\n    pip uses PYTHONNOUSERSITE and a path in PYTHONPATH containing \"pip-build-env-\".\n    \"\"\"\n    new_env = {k: v for k, v in env.items() if k != \"PYTHONNOUSERSITE\"}\n    if \"PYTHONPATH\" not in new_env:\n        return new_env\n\n    new_env[\"PYTHONPATH\"] = os.pathsep.join(\n        [\n            path\n            for path in new_env[\"PYTHONPATH\"].split(os.pathsep)\n            if \"pip-build-env-\" not in path\n        ]\n    )\n    return new_env"}, {"id": "setuptools_scm.utils.trace", "kind": "function", "range": [75, 0, 79, 46, 1976, 2203], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def trace(*k: object, indent: bool = False) -> None:\n    if DEBUG:\n        if indent and len(k) > 1:\n            k = (k[0],) + tuple(textwrap.indent(str(s), \"    \") for s in k[1:])\n        print(*k, file=sys.stderr, flush=True)"}, {"id": "setuptools_scm.utils.ensure_stripped_str", "kind": "function", "range": [82, 0, 86, 70, 2206, 2419], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def ensure_stripped_str(str_or_bytes: str | bytes) -> str:\n    if isinstance(str_or_bytes, str):\n        return str_or_bytes.strip()\n    else:\n        return str_or_bytes.decode(\"utf-8\", \"surrogateescape\").strip()"}, {"id": "setuptools_scm.utils._run", "kind": "function", "range": [89, 0, 103, 5, 2422, 2836], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def _run(cmd: _t.CMD_TYPE, cwd: _t.PathT) -> subprocess.CompletedProcess[str]:\n    return subprocess.run(\n        cmd,\n        capture_output=True,\n        cwd=str(cwd),\n        env=dict(\n            avoid_pip_isolation(no_git_env(os.environ)),\n            # os.environ,\n            # try to disable i18n\n            LC_ALL=\"C\",\n            LANGUAGE=\"\",\n            HGPLAIN=\"1\",\n        ),\n        text=True,\n    )"}, {"id": "setuptools_scm.utils.do_ex", "kind": "function", "range": [106, 0, 128, 5, 2839, 3677], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def do_ex(cmd: _t.CMD_TYPE, cwd: _t.PathT = \".\") -> _CmdResult:\n    if not DEBUG or not isinstance(cmd, list):\n        cmd_4_trace = cmd\n    else:\n        # give better results than shlex.join in our cases\n        cmd_4_trace = \" \".join(\n            [s if all(c not in s for c in \" {[:\") else f'\"{s}\"' for s in cmd]\n        )\n    trace(\"----\\ncmd:\\n\", cmd_4_trace, indent=True)\n    trace(\" in:\", cwd)\n    if os.name == \"posix\" and not isinstance(cmd, (list, tuple)):\n        cmd = shlex.split(cmd)\n\n    res = _run(cmd, cwd)\n    if res.stdout:\n        trace(\"out:\\n\", res.stdout, indent=True)\n    if res.stderr:\n        trace(\"err:\\n\", res.stderr, indent=True)\n    if res.returncode:\n        trace(\"ret:\", res.returncode)\n    return _CmdResult(\n        ensure_stripped_str(res.stdout), ensure_stripped_str(res.stderr), res.returncode\n    )"}, {"id": "setuptools_scm.utils.do", "kind": "function", "range": [131, 0, 135, 14, 3680, 3839], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def do(cmd: list[str] | str, cwd: str | _t.PathT = \".\") -> str:\n    out, err, ret = do_ex(cmd, cwd)\n    if ret and not DEBUG:\n        print(err)\n    return out"}, {"id": "setuptools_scm.utils.data_from_mime", "kind": "function", "range": [138, 0, 145, 15, 3842, 4189], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def data_from_mime(path: _t.PathT) -> dict[str, str]:\n    with open(path, encoding=\"utf-8\") as fp:\n        content = fp.read()\n    trace(\"content\", repr(content))\n    # the complex conditions come from reading pseudo-mime-messages\n    data = dict(x.split(\": \", 1) for x in content.splitlines() if \": \" in x)\n    trace(\"data\", data)\n    return data"}, {"id": "setuptools_scm.utils.function_has_arg", "kind": "function", "range": [148, 0, 151, 38, 4192, 4374], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def function_has_arg(fn: object | FunctionType, argname: str) -> bool:\n    assert isinstance(fn, FunctionType)\n    code: CodeType = fn.__code__\n    return argname in code.co_varnames"}, {"id": "setuptools_scm.utils.has_command", "kind": "function", "range": [154, 0, 165, 14, 4377, 4788], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def has_command(name: str, args: list[str] | None = None, warn: bool = True) -> bool:\n    try:\n        cmd = [name, \"help\"] if args is None else [name, *args]\n        p = _run(cmd, \".\")\n    except OSError:\n        trace(*sys.exc_info())\n        res = False\n    else:\n        res = not p.returncode\n    if not res and warn:\n        warnings.warn(\"%r was not found\" % name, category=RuntimeWarning)\n    return res"}, {"id": "setuptools_scm.utils.require_command", "kind": "function", "range": [168, 0, 170, 48, 4791, 4921], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def require_command(name: str) -> None:\n    if not has_command(name, warn=False):\n        raise OSError(\"%r was not found\" % name)"}, {"id": "setuptools_scm.utils.iter_entry_points", "kind": "function", "range": [173, 0, 179, 41, 4924, 5116], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/utils.py", "content": "def iter_entry_points(\n    group: str, name: str | None = None\n) -> Iterator[_t.EntrypointProtocol]:\n\n    from ._entrypoints import iter_entry_points\n\n    return iter_entry_points(group, name)"}, {"id": "setuptools_scm.hg_git._FAKE_GIT_DESCRIBE_ERROR", "kind": "variable", "range": [16, 0, 16, 63, 333, 396], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "_FAKE_GIT_DESCRIBE_ERROR = _CmdResult(\"<>hg git failed\", \"\", 1)"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient", "kind": "class", "range": [19, 0, 145, 38, 399, 4165], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "class GitWorkdirHgClient(GitWorkdir, HgWorkdir):\n    COMMAND = \"hg\"\n\n    @classmethod\n    def from_potential_worktree(cls, wd: _t.PathT) -> GitWorkdirHgClient | None:\n        require_command(cls.COMMAND)\n        root, _, ret = do_ex([\"hg\", \"root\"], wd)\n        if ret:\n            return None\n        return cls(root)\n\n    def is_dirty(self) -> bool:\n        out, _, _ = self.do_ex('hg id -T \"{dirty}\"')\n        return bool(out)\n\n    def get_branch(self) -> str | None:\n        res = self.do_ex('hg id -T \"{bookmarks}\"')\n        if res.returncode:\n            trace(\"branch err\", res)\n            return None\n        return res.out\n\n    def get_head_date(self) -> date | None:\n        date_part, err, ret = self.do_ex('hg log -r . -T \"{shortdate(date)}\"')\n        if ret:\n            trace(\"head date err\", date_part, err, ret)\n            return None\n        return datetime.strptime(date_part, r\"%Y-%m-%d\").date()\n\n    def is_shallow(self) -> bool:\n        return False\n\n    def fetch_shallow(self) -> None:\n        pass\n\n    def get_hg_node(self) -> str | None:\n        node, _, ret = self.do_ex('hg log -r . -T \"{node}\"')\n        if not ret:\n            return node\n        else:\n            return None\n\n    def _hg2git(self, hg_node: str) -> str | None:\n        with suppress(FileNotFoundError):\n            with open(os.path.join(self.path, \".hg/git-mapfile\")) as map_items:\n                for item in map_items:\n                    if hg_node in item:\n                        git_node, hg_node = item.split()\n                        return git_node\n        return None\n\n    def node(self) -> str | None:\n        hg_node = self.get_hg_node()\n        if hg_node is None:\n            return None\n\n        git_node = self._hg2git(hg_node)\n\n        if git_node is None:\n            # trying again after hg -> git\n            self.do_ex(\"hg gexport\")\n            git_node = self._hg2git(hg_node)\n\n            if git_node is None:\n                trace(\"Cannot get git node so we use hg node\", hg_node)\n\n                if hg_node == \"0\" * len(hg_node):\n                    # mimic Git behavior\n                    return None\n\n                return hg_node\n\n        return git_node[:7]\n\n    def count_all_nodes(self) -> int:\n        revs, _, _ = self.do_ex([\"hg\", \"log\", \"-r\", \"ancestors(.)\", \"-T\", \".\"])\n        return len(revs)\n\n    def default_describe(self) -> _CmdResult:\n        \"\"\"\n        Tentative to reproduce the output of\n\n        `git describe --dirty --tags --long --match *[0-9]*`\n\n        \"\"\"\n        hg_tags_str, _, ret = self.do_ex(\n            [\n                \"hg\",\n                \"log\",\n                \"-r\",\n                \"(reverse(ancestors(.)) and tag(r're:v?[0-9].*'))\",\n                \"-T\",\n                \"{tags}{if(tags, ' ', '')}\",\n            ]\n        )\n        if ret:\n            return _FAKE_GIT_DESCRIBE_ERROR\n        hg_tags: list[str] = hg_tags_str.split()\n\n        if not hg_tags:\n            return _FAKE_GIT_DESCRIBE_ERROR\n\n        with open(os.path.join(self.path, \".hg/git-tags\")) as fp:\n            git_tags: dict[str, str] = dict(line.split()[::-1] for line in fp)\n\n        tag: str\n        for hg_tag in hg_tags:\n            if hg_tag in git_tags:\n                tag = hg_tag\n                break\n        else:\n            trace(\"tag not found\", hg_tags, git_tags)\n            return _FAKE_GIT_DESCRIBE_ERROR\n\n        out, _, ret = self.do_ex([\"hg\", \"log\", \"-r\", f\"'{tag}'::.\", \"-T\", \".\"])\n        if ret:\n            return _FAKE_GIT_DESCRIBE_ERROR\n        distance = len(out) - 1\n\n        node = self.node()\n        assert node is not None\n        desc = f\"{tag}-{distance}-g{node}\"\n\n        if self.is_dirty():\n            desc += \"-dirty\"\n        trace(\"desc\", desc)\n        return _CmdResult(desc, \"\", 0)"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.COMMAND", "kind": "variable", "range": [20, 4, 20, 18, 452, 466], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "COMMAND = \"hg\""}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.from_potential_worktree", "kind": "function", "range": [22, 4, 28, 24, 472, 716], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "@classmethod\n    def from_potential_worktree(cls, wd: _t.PathT) -> GitWorkdirHgClient | None:\n        require_command(cls.COMMAND)\n        root, _, ret = do_ex([\"hg\", \"root\"], wd)\n        if ret:\n            return None\n        return cls(root)"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.is_dirty", "kind": "function", "range": [30, 4, 32, 24, 722, 827], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def is_dirty(self) -> bool:\n        out, _, _ = self.do_ex('hg id -T \"{dirty}\"')\n        return bool(out)"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.get_branch", "kind": "function", "range": [34, 4, 39, 22, 833, 1030], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def get_branch(self) -> str | None:\n        res = self.do_ex('hg id -T \"{bookmarks}\"')\n        if res.returncode:\n            trace(\"branch err\", res)\n            return None\n        return res.out"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.get_head_date", "kind": "function", "range": [41, 4, 46, 63, 1036, 1314], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def get_head_date(self) -> date | None:\n        date_part, err, ret = self.do_ex('hg log -r . -T \"{shortdate(date)}\"')\n        if ret:\n            trace(\"head date err\", date_part, err, ret)\n            return None\n        return datetime.strptime(date_part, r\"%Y-%m-%d\").date()"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.is_shallow", "kind": "function", "range": [48, 4, 49, 20, 1320, 1370], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def is_shallow(self) -> bool:\n        return False"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.fetch_shallow", "kind": "function", "range": [51, 4, 52, 12, 1376, 1421], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def fetch_shallow(self) -> None:\n        pass"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.get_hg_node", "kind": "function", "range": [54, 4, 59, 23, 1427, 1606], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def get_hg_node(self) -> str | None:\n        node, _, ret = self.do_ex('hg log -r . -T \"{node}\"')\n        if not ret:\n            return node\n        else:\n            return None"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient._hg2git", "kind": "function", "range": [61, 4, 68, 19, 1612, 1976], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def _hg2git(self, hg_node: str) -> str | None:\n        with suppress(FileNotFoundError):\n            with open(os.path.join(self.path, \".hg/git-mapfile\")) as map_items:\n                for item in map_items:\n                    if hg_node in item:\n                        git_node, hg_node = item.split()\n                        return git_node\n        return None"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.node", "kind": "function", "range": [70, 4, 91, 27, 1982, 2588], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def node(self) -> str | None:\n        hg_node = self.get_hg_node()\n        if hg_node is None:\n            return None\n\n        git_node = self._hg2git(hg_node)\n\n        if git_node is None:\n            # trying again after hg -> git\n            self.do_ex(\"hg gexport\")\n            git_node = self._hg2git(hg_node)\n\n            if git_node is None:\n                trace(\"Cannot get git node so we use hg node\", hg_node)\n\n                if hg_node == \"0\" * len(hg_node):\n                    # mimic Git behavior\n                    return None\n\n                return hg_node\n\n        return git_node[:7]"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.count_all_nodes", "kind": "function", "range": [93, 4, 95, 24, 2594, 2732], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def count_all_nodes(self) -> int:\n        revs, _, _ = self.do_ex([\"hg\", \"log\", \"-r\", \"ancestors(.)\", \"-T\", \".\"])\n        return len(revs)"}, {"id": "setuptools_scm.hg_git.GitWorkdirHgClient.default_describe", "kind": "function", "range": [97, 4, 145, 38, 2738, 4165], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg_git.py", "content": "def default_describe(self) -> _CmdResult:\n        \"\"\"\n        Tentative to reproduce the output of\n\n        `git describe --dirty --tags --long --match *[0-9]*`\n\n        \"\"\"\n        hg_tags_str, _, ret = self.do_ex(\n            [\n                \"hg\",\n                \"log\",\n                \"-r\",\n                \"(reverse(ancestors(.)) and tag(r're:v?[0-9].*'))\",\n                \"-T\",\n                \"{tags}{if(tags, ' ', '')}\",\n            ]\n        )\n        if ret:\n            return _FAKE_GIT_DESCRIBE_ERROR\n        hg_tags: list[str] = hg_tags_str.split()\n\n        if not hg_tags:\n            return _FAKE_GIT_DESCRIBE_ERROR\n\n        with open(os.path.join(self.path, \".hg/git-tags\")) as fp:\n            git_tags: dict[str, str] = dict(line.split()[::-1] for line in fp)\n\n        tag: str\n        for hg_tag in hg_tags:\n            if hg_tag in git_tags:\n                tag = hg_tag\n                break\n        else:\n            trace(\"tag not found\", hg_tags, git_tags)\n            return _FAKE_GIT_DESCRIBE_ERROR\n\n        out, _, ret = self.do_ex([\"hg\", \"log\", \"-r\", f\"'{tag}'::.\", \"-T\", \".\"])\n        if ret:\n            return _FAKE_GIT_DESCRIBE_ERROR\n        distance = len(out) - 1\n\n        node = self.node()\n        assert node is not None\n        desc = f\"{tag}-{distance}-g{node}\"\n\n        if self.is_dirty():\n            desc += \"-dirty\"\n        trace(\"desc\", desc)\n        return _CmdResult(desc, \"\", 0)"}, {"id": "setuptools_scm._entrypoints.MaybeConfigFunction", "kind": "class", "range": [23, 0, 32, 12, 455, 710], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "class MaybeConfigFunction(Protocol):\n    __name__: str\n\n    @overload\n    def __call__(self, root: _t.PathT, config: Configuration) -> ScmVersion | None:\n        pass\n\n    @overload\n    def __call__(self, root: _t.PathT) -> ScmVersion | None:\n        pass"}, {"id": "setuptools_scm._entrypoints.MaybeConfigFunction.__name__", "kind": "variable", "range": [24, 4, 24, 17, 496, 509], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "__name__: str"}, {"id": "setuptools_scm._entrypoints.MaybeConfigFunction.__call__", "kind": "function", "range": [26, 4, 28, 12, 515, 621], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "@overload\n    def __call__(self, root: _t.PathT, config: Configuration) -> ScmVersion | None:\n        pass"}, {"id": "setuptools_scm._entrypoints.MaybeConfigFunction.__call__", "kind": "function", "range": [30, 4, 32, 12, 627, 710], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "@overload\n    def __call__(self, root: _t.PathT) -> ScmVersion | None:\n        pass"}, {"id": "setuptools_scm._entrypoints._call_entrypoint_fn", "kind": "function", "range": [35, 0, 48, 23, 713, 1223], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "def _call_entrypoint_fn(\n    root: _t.PathT, config: Configuration, fn: MaybeConfigFunction\n) -> ScmVersion | None:\n    if function_has_arg(fn, \"config\"):\n        return fn(root, config=config)\n    else:\n        warnings.warn(\n            f\"parse function {fn.__module__}.{fn.__name__}\"\n            \" are required to provide a named argument\"\n            \" 'config', setuptools_scm>=8.0 will remove support.\",\n            category=DeprecationWarning,\n            stacklevel=2,\n        )\n        return fn(root)"}, {"id": "setuptools_scm._entrypoints._version_from_entrypoints", "kind": "function", "range": [51, 0, 69, 15, 1226, 1874], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "def _version_from_entrypoints(\n    config: Configuration, fallback: bool = False\n) -> ScmVersion | None:\n    if fallback:\n        entrypoint = \"setuptools_scm.parse_scm_fallback\"\n        root = config.fallback_root\n    else:\n        entrypoint = \"setuptools_scm.parse_scm\"\n        root = config.absolute_root\n\n    from .discover import iter_matching_entrypoints\n\n    trace(\"version_from_ep\", entrypoint, root)\n    for ep in iter_matching_entrypoints(root, entrypoint, config):\n        version: ScmVersion | None = _call_entrypoint_fn(root, config, ep.load())\n        trace(ep, version)\n        if version:\n            return version\n    return None"}, {"id": "setuptools_scm._entrypoints.iter_entry_points", "kind": "function", "range": [88, 0, 98, 48, 2355, 2695], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_entrypoints.py", "content": "def iter_entry_points(\n    group: str, name: str | None = None\n) -> Iterator[_t.EntrypointProtocol]:\n    all_eps = entry_points()\n    if hasattr(all_eps, \"select\"):\n        eps = all_eps.select(group=group)\n    else:\n        eps = all_eps[group]\n    if name is None:\n        return iter(eps)\n    return (ep for ep in eps if ep.name == name)"}, {"id": "setuptools_scm.hg.HgWorkdir", "kind": "class", "range": [22, 0, 142, 45, 487, 4421], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "class HgWorkdir(Workdir):\n\n    COMMAND = \"hg\"\n\n    @classmethod\n    def from_potential_worktree(cls, wd: _t.PathT) -> HgWorkdir | None:\n        require_command(cls.COMMAND)\n        root, err, ret = do_ex(\"hg root\", wd)\n        if ret:\n            return None\n        return cls(root)\n\n    def get_meta(self, config: Configuration) -> ScmVersion | None:\n\n        node: str\n        tags_str: str\n        bookmark: str\n        node_date_str: str\n        node, tags_str, bookmark, node_date_str = self.hg_log(\n            \".\", \"{node}\\n{tag}\\n{bookmark}\\n{date|shortdate}\"\n        ).split(\"\\n\")\n\n        # TODO: support bookmarks and topics (but nowadays bookmarks are\n        # mainly used to emulate Git branches, which is already supported with\n        # the dedicated class GitWorkdirHgClient)\n\n        branch, dirty_str, dirty_date = self.do(\n            [\"hg\", \"id\", \"-T\", \"{branch}\\n{if(dirty, 1, 0)}\\n{date|shortdate}\"]\n        ).split(\"\\n\")\n        dirty = bool(int(dirty_str))\n        # todo: fromiso\n        node_date = datetime.date(\n            *map(int, (dirty_date if dirty else node_date_str).split(\"-\"))\n        )\n\n        if node.count(\"0\") == len(node):\n            trace(\"initial node\", self.path)\n            return meta(\n                \"0.0\", config=config, dirty=dirty, branch=branch, node_date=node_date\n            )\n\n        node = \"h\" + node[:7]\n\n        tags = tags_str.split()\n        if \"tip\" in tags:\n            # tip is not a real tag\n            tags.remove(\"tip\")\n\n        if tags:\n            tag = tag_to_version(tags[0])\n            if tag:\n                return meta(tag, dirty=dirty, branch=branch, config=config)\n\n        try:\n            tag_str = self.get_latest_normalizable_tag()\n            if tag_str is None:\n                dist = self.get_distance_revs(\"\")\n            else:\n                dist = self.get_distance_revs(tag_str)\n\n            if tag_str == \"null\" or tag_str is None:\n                tag = Version(\"0.0\")\n                dist = int(dist) + 1\n            else:\n                tag = tag_to_version(tag_str, config=config)\n                assert tag is not None\n\n            if self.check_changes_since_tag(tag_str) or dirty:\n                return meta(\n                    tag,\n                    distance=dist,\n                    node=node,\n                    dirty=dirty,\n                    branch=branch,\n                    config=config,\n                    node_date=node_date,\n                )\n            else:\n                return meta(tag, config=config, node_date=node_date)\n\n        except ValueError as e:\n            trace(\"error\", e)\n            pass  # unpacking failed, old hg\n\n        return None\n\n    def hg_log(self, revset: str, template: str) -> str:\n        cmd = [\"hg\", \"log\", \"-r\", revset, \"-T\", template]\n        return self.do(cmd)\n\n    def get_latest_normalizable_tag(self) -> str | None:\n        # Gets all tags containing a '.' (see #229) from oldest to newest\n        outlines = self.hg_log(\n            revset=\"ancestors(.) and tag('re:\\\\.')\",\n            template=\"{tags}{if(tags, '\\n', '')}\",\n        ).split()\n        if not outlines:\n            return None\n        tag = outlines[-1].split()[-1]\n        return tag\n\n    def get_distance_revs(self, rev1: str, rev2: str = \".\") -> int:\n\n        revset = f\"({rev1}::{rev2})\"\n        out = self.hg_log(revset, \".\")\n        return len(out) - 1\n\n    def check_changes_since_tag(self, tag: str | None) -> bool:\n\n        if tag == \"0.0\" or tag is None:\n            return True\n\n        revset = (\n            \"(branch(.)\"  # look for revisions in this branch only\n            f\" and tag({tag!r})::.\"  # after the last tag\n            # ignore commits that only modify .hgtags and nothing else:\n            \" and (merge() or file('re:^(?!\\\\.hgtags).*$'))\"\n            f\" and not tag({tag!r}))\"  # ignore the tagged commit itself\n        )\n\n        return bool(self.hg_log(revset, \".\"))"}, {"id": "setuptools_scm.hg.HgWorkdir.COMMAND", "kind": "variable", "range": [24, 4, 24, 18, 518, 532], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "COMMAND = \"hg\""}, {"id": "setuptools_scm.hg.HgWorkdir.from_potential_worktree", "kind": "function", "range": [26, 4, 32, 24, 538, 770], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "@classmethod\n    def from_potential_worktree(cls, wd: _t.PathT) -> HgWorkdir | None:\n        require_command(cls.COMMAND)\n        root, err, ret = do_ex(\"hg root\", wd)\n        if ret:\n            return None\n        return cls(root)"}, {"id": "setuptools_scm.hg.HgWorkdir.get_meta", "kind": "function", "range": [34, 4, 106, 19, 776, 3172], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def get_meta(self, config: Configuration) -> ScmVersion | None:\n\n        node: str\n        tags_str: str\n        bookmark: str\n        node_date_str: str\n        node, tags_str, bookmark, node_date_str = self.hg_log(\n            \".\", \"{node}\\n{tag}\\n{bookmark}\\n{date|shortdate}\"\n        ).split(\"\\n\")\n\n        # TODO: support bookmarks and topics (but nowadays bookmarks are\n        # mainly used to emulate Git branches, which is already supported with\n        # the dedicated class GitWorkdirHgClient)\n\n        branch, dirty_str, dirty_date = self.do(\n            [\"hg\", \"id\", \"-T\", \"{branch}\\n{if(dirty, 1, 0)}\\n{date|shortdate}\"]\n        ).split(\"\\n\")\n        dirty = bool(int(dirty_str))\n        # todo: fromiso\n        node_date = datetime.date(\n            *map(int, (dirty_date if dirty else node_date_str).split(\"-\"))\n        )\n\n        if node.count(\"0\") == len(node):\n            trace(\"initial node\", self.path)\n            return meta(\n                \"0.0\", config=config, dirty=dirty, branch=branch, node_date=node_date\n            )\n\n        node = \"h\" + node[:7]\n\n        tags = tags_str.split()\n        if \"tip\" in tags:\n            # tip is not a real tag\n            tags.remove(\"tip\")\n\n        if tags:\n            tag = tag_to_version(tags[0])\n            if tag:\n                return meta(tag, dirty=dirty, branch=branch, config=config)\n\n        try:\n            tag_str = self.get_latest_normalizable_tag()\n            if tag_str is None:\n                dist = self.get_distance_revs(\"\")\n            else:\n                dist = self.get_distance_revs(tag_str)\n\n            if tag_str == \"null\" or tag_str is None:\n                tag = Version(\"0.0\")\n                dist = int(dist) + 1\n            else:\n                tag = tag_to_version(tag_str, config=config)\n                assert tag is not None\n\n            if self.check_changes_since_tag(tag_str) or dirty:\n                return meta(\n                    tag,\n                    distance=dist,\n                    node=node,\n                    dirty=dirty,\n                    branch=branch,\n                    config=config,\n                    node_date=node_date,\n                )\n            else:\n                return meta(tag, config=config, node_date=node_date)\n\n        except ValueError as e:\n            trace(\"error\", e)\n            pass  # unpacking failed, old hg\n\n        return None"}, {"id": "setuptools_scm.hg.HgWorkdir.hg_log", "kind": "function", "range": [108, 4, 110, 27, 3178, 3316], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def hg_log(self, revset: str, template: str) -> str:\n        cmd = [\"hg\", \"log\", \"-r\", revset, \"-T\", template]\n        return self.do(cmd)"}, {"id": "setuptools_scm.hg.HgWorkdir.get_latest_normalizable_tag", "kind": "function", "range": [112, 4, 121, 18, 3322, 3709], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def get_latest_normalizable_tag(self) -> str | None:\n        # Gets all tags containing a '.' (see #229) from oldest to newest\n        outlines = self.hg_log(\n            revset=\"ancestors(.) and tag('re:\\\\.')\",\n            template=\"{tags}{if(tags, '\\n', '')}\",\n        ).split()\n        if not outlines:\n            return None\n        tag = outlines[-1].split()[-1]\n        return tag"}, {"id": "setuptools_scm.hg.HgWorkdir.get_distance_revs", "kind": "function", "range": [123, 4, 127, 27, 3715, 3883], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def get_distance_revs(self, rev1: str, rev2: str = \".\") -> int:\n\n        revset = f\"({rev1}::{rev2})\"\n        out = self.hg_log(revset, \".\")\n        return len(out) - 1"}, {"id": "setuptools_scm.hg.HgWorkdir.check_changes_since_tag", "kind": "function", "range": [129, 4, 142, 45, 3889, 4421], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def check_changes_since_tag(self, tag: str | None) -> bool:\n\n        if tag == \"0.0\" or tag is None:\n            return True\n\n        revset = (\n            \"(branch(.)\"  # look for revisions in this branch only\n            f\" and tag({tag!r})::.\"  # after the last tag\n            # ignore commits that only modify .hgtags and nothing else:\n            \" and (merge() or file('re:^(?!\\\\.hgtags).*$'))\"\n            f\" and not tag({tag!r}))\"  # ignore the tagged commit itself\n        )\n\n        return bool(self.hg_log(revset, \".\"))"}, {"id": "setuptools_scm.hg.parse", "kind": "function", "range": [145, 0, 168, 30, 4424, 5362], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def parse(root: _t.PathT, config: Configuration | None = None) -> ScmVersion | None:\n    if not config:\n        config = Configuration(root=root)\n\n    if os.path.exists(os.path.join(root, \".hg/git\")):\n        paths, _, ret = do_ex(\"hg path\", root)\n        if not ret:\n            for line in paths.split(\"\\n\"):\n                if line.startswith(\"default =\"):\n                    path = Path(line.split()[2])\n                    if path.name.endswith(\".git\") or (path / \".git\").exists():\n                        from .git import _git_parse_inner\n                        from .hg_git import GitWorkdirHgClient\n\n                        wd_hggit = GitWorkdirHgClient.from_potential_worktree(root)\n                        if wd_hggit:\n                            return _git_parse_inner(config, wd_hggit)\n\n    wd = HgWorkdir.from_potential_worktree(config.absolute_root)\n\n    if wd is None:\n        return None\n\n    return wd.get_meta(config)"}, {"id": "setuptools_scm.hg.archival_to_version", "kind": "function", "range": [171, 0, 188, 52, 5365, 5896], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def archival_to_version(\n    data: dict[str, str], config: Configuration | None = None\n) -> ScmVersion:\n    trace(\"data\", data)\n    node = data.get(\"node\", \"\")[:12]\n    if node:\n        node = \"h\" + node\n    if \"tag\" in data:\n        return meta(data[\"tag\"], config=config)\n    elif \"latesttag\" in data:\n        return meta(\n            data[\"latesttag\"],\n            distance=int(data[\"latesttagdistance\"]),\n            node=node,\n            config=config,\n        )\n    else:\n        return meta(\"0.0\", node=node, config=config)"}, {"id": "setuptools_scm.hg.parse_archival", "kind": "function", "range": [191, 0, 194, 51, 5899, 6127], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hg.py", "content": "def parse_archival(root: _t.PathT, config: Configuration | None = None) -> ScmVersion:\n    archival = os.path.join(root, \".hg_archival.txt\")\n    data = data_from_mime(archival)\n    return archival_to_version(data, config=config)"}, {"id": "setuptools_scm.file_finder.scm_find_files", "kind": "function", "range": [12, 0, 72, 14, 201, 2765], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder.py", "content": "def scm_find_files(\n    path: _t.PathT,\n    scm_files: set[str],\n    scm_dirs: set[str],\n    force_all_files: bool = False,\n) -> list[str]:\n    \"\"\" setuptools compatible file finder that follows symlinks\n\n    - path: the root directory from which to search\n    - scm_files: set of scm controlled files and symlinks\n      (including symlinks to directories)\n    - scm_dirs: set of scm controlled directories\n      (including directories containing no scm controlled files)\n    - force_all_files: ignore ``scm_files`` and ``scm_dirs`` and list everything.\n\n    scm_files and scm_dirs must be absolute with symlinks resolved (realpath),\n    with normalized case (normcase)\n\n    Spec here: http://setuptools.readthedocs.io/en/latest/setuptools.html#\\\n        adding-support-for-revision-control-systems\n    \"\"\"\n    realpath = os.path.normcase(os.path.realpath(path))\n    seen: set[str] = set()\n    res: list[str] = []\n    for dirpath, dirnames, filenames in os.walk(realpath, followlinks=True):\n        # dirpath with symlinks resolved\n        realdirpath = os.path.normcase(os.path.realpath(dirpath))\n\n        def _link_not_in_scm(n: str) -> bool:\n            fn = os.path.join(realdirpath, os.path.normcase(n))\n            return os.path.islink(fn) and fn not in scm_files\n\n        if not force_all_files and realdirpath not in scm_dirs:\n            # directory not in scm, don't walk it's content\n            dirnames[:] = []\n            continue\n        if os.path.islink(dirpath) and not os.path.relpath(\n            realdirpath, realpath\n        ).startswith(os.pardir):\n            # a symlink to a directory not outside path:\n            # we keep it in the result and don't walk its content\n            res.append(os.path.join(path, os.path.relpath(dirpath, path)))\n            dirnames[:] = []\n            continue\n        if realdirpath in seen:\n            # symlink loop protection\n            dirnames[:] = []\n            continue\n        dirnames[:] = [\n            dn for dn in dirnames if force_all_files or not _link_not_in_scm(dn)\n        ]\n        for filename in filenames:\n            if not force_all_files and _link_not_in_scm(filename):\n                continue\n            # dirpath + filename with symlinks preserved\n            fullfilename = os.path.join(dirpath, filename)\n            is_tracked = os.path.normcase(os.path.realpath(fullfilename)) in scm_files\n            if force_all_files or is_tracked:\n                res.append(os.path.join(path, os.path.relpath(fullfilename, realpath)))\n        seen.add(realdirpath)\n    return res"}, {"id": "setuptools_scm.file_finder.is_toplevel_acceptable", "kind": "function", "range": [75, 0, 85, 34, 2768, 3099], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/file_finder.py", "content": "def is_toplevel_acceptable(toplevel: str | None) -> TypeGuard[str]:\n    \"\"\" \"\"\"\n    if toplevel is None:\n        return False\n\n    ignored = os.environ.get(\"SETUPTOOLS_SCM_IGNORE_VCS_ROOTS\", \"\").split(os.pathsep)\n    ignored = [os.path.normcase(p) for p in ignored]\n\n    trace(toplevel, ignored)\n\n    return toplevel not in ignored"}, {"id": "setuptools_scm.scm_workdir.Workdir", "kind": "class", "range": [14, 0, 25, 37, 262, 584], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/scm_workdir.py", "content": "class Workdir:\n    COMMAND: ClassVar[str]\n\n    def __init__(self, path: _t.PathT):\n        require_command(self.COMMAND)\n        self.path = path\n\n    def do_ex(self, cmd: _t.CMD_TYPE) -> _CmdResult:\n        return do_ex(cmd, cwd=self.path)\n\n    def do(self, cmd: _t.CMD_TYPE) -> str:\n        return do(cmd, cwd=self.path)"}, {"id": "setuptools_scm.scm_workdir.Workdir.COMMAND", "kind": "variable", "range": [15, 4, 15, 26, 281, 303], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/scm_workdir.py", "content": "COMMAND: ClassVar[str]"}, {"id": "setuptools_scm.scm_workdir.Workdir.__init__", "kind": "function", "range": [17, 4, 19, 24, 309, 407], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/scm_workdir.py", "content": "def __init__(self, path: _t.PathT):\n        require_command(self.COMMAND)\n        self.path = path"}, {"id": "setuptools_scm.scm_workdir.Workdir.do_ex", "kind": "function", "range": [21, 4, 22, 40, 413, 502], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/scm_workdir.py", "content": "def do_ex(self, cmd: _t.CMD_TYPE) -> _CmdResult:\n        return do_ex(cmd, cwd=self.path)"}, {"id": "setuptools_scm.scm_workdir.Workdir.do", "kind": "function", "range": [24, 4, 25, 37, 508, 584], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/scm_workdir.py", "content": "def do(self, cmd: _t.CMD_TYPE) -> str:\n        return do(cmd, cwd=self.path)"}, {"id": "setuptools_scm.hacks._UNKNOWN", "kind": "variable", "range": [14, 0, 14, 20, 317, 337], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hacks.py", "content": "_UNKNOWN = \"UNKNOWN\""}, {"id": "setuptools_scm.hacks.parse_pkginfo", "kind": "function", "range": [17, 0, 28, 19, 340, 714], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hacks.py", "content": "def parse_pkginfo(\n    root: _t.PathT, config: Configuration | None = None\n) -> ScmVersion | None:\n\n    pkginfo = os.path.join(root, \"PKG-INFO\")\n    trace(\"pkginfo\", pkginfo)\n    data = data_from_mime(pkginfo)\n    version = data.get(\"Version\", _UNKNOWN)\n    if version != _UNKNOWN:\n        return meta(version, preformatted=True, config=config)\n    else:\n        return None"}, {"id": "setuptools_scm.hacks.parse_pip_egg_info", "kind": "function", "range": [31, 0, 41, 71, 717, 1104], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hacks.py", "content": "def parse_pip_egg_info(\n    root: _t.PathT, config: Configuration | None = None\n) -> ScmVersion | None:\n    pipdir = os.path.join(root, \"pip-egg-info\")\n    if not os.path.isdir(pipdir):\n        return None\n    items = os.listdir(pipdir)\n    trace(\"pip-egg-info\", pipdir, items)\n    if not items:\n        return None\n    return parse_pkginfo(os.path.join(pipdir, items[0]), config=config)"}, {"id": "setuptools_scm.hacks.fallback_version", "kind": "function", "range": [44, 0, 56, 15, 1107, 1775], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/hacks.py", "content": "def fallback_version(root: _t.PathT, config: Configuration) -> ScmVersion | None:\n    if config.parentdir_prefix_version is not None:\n        _, parent_name = os.path.split(os.path.abspath(root))\n        if parent_name.startswith(config.parentdir_prefix_version):\n            version = tag_to_version(\n                parent_name[len(config.parentdir_prefix_version) :], config\n            )\n            if version is not None:\n                return meta(str(version), preformatted=True, config=config)\n    if config.fallback_version is not None:\n        trace(\"FALLBACK\")\n        return meta(config.fallback_version, preformatted=True, config=config)\n    return None"}, {"id": "setuptools_scm._version_cls.NonNormalizedVersion", "kind": "class", "range": [8, 0, 30, 63, 163, 973], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_version_cls.py", "content": "class NonNormalizedVersion(Version):\n    \"\"\"A non-normalizing version handler.\n\n    You can use this class to preserve version verification but skip normalization.\n    For example you can use this to avoid git release candidate version tags\n    (\"1.0.0-rc1\") to be normalized to \"1.0.0rc1\". Only use this if you fully\n    trust the version tags.\n    \"\"\"\n\n    def __init__(self, version: str) -> None:\n        # parse and validate using parent\n        super().__init__(version)\n\n        # store raw for str\n        self._raw_version = version\n\n    def __str__(self) -> str:\n        # return the non-normalized version (parent returns the normalized)\n        return self._raw_version\n\n    def __repr__(self) -> str:\n        # same pattern as parent\n        return f\"<NonNormalizedVersion({self._raw_version!r})>\""}, {"id": "setuptools_scm._version_cls.NonNormalizedVersion.__init__", "kind": "function", "range": [17, 4, 22, 35, 522, 704], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_version_cls.py", "content": "def __init__(self, version: str) -> None:\n        # parse and validate using parent\n        super().__init__(version)\n\n        # store raw for str\n        self._raw_version = version"}, {"id": "setuptools_scm._version_cls.NonNormalizedVersion.__str__", "kind": "function", "range": [24, 4, 26, 32, 710, 844], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_version_cls.py", "content": "def __str__(self) -> str:\n        # return the non-normalized version (parent returns the normalized)\n        return self._raw_version"}, {"id": "setuptools_scm._version_cls.NonNormalizedVersion.__repr__", "kind": "function", "range": [28, 4, 30, 63, 850, 973], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_version_cls.py", "content": "def __repr__(self) -> str:\n        # same pattern as parent\n        return f\"<NonNormalizedVersion({self._raw_version!r})>\""}, {"id": "setuptools_scm._version_cls._version_as_tuple", "kind": "function", "range": [33, 0, 47, 29, 976, 1574], "file_path": ".eggs/setuptools_scm-7.1.0-py3.7.egg/setuptools_scm/_version_cls.py", "content": "def _version_as_tuple(version_str: str) -> tuple[int | str, ...]:\n    try:\n        parsed_version = Version(version_str)\n    except InvalidVersion:\n\n        log = getLogger(\"setuptools_scm\")\n        log.exception(\"failed to parse version %s\", version_str)\n        return (version_str,)\n    else:\n        version_fields: tuple[int | str, ...] = parsed_version.release\n        if parsed_version.dev is not None:\n            version_fields += (f\"dev{parsed_version.dev}\",)\n        if parsed_version.local is not None:\n            version_fields += (parsed_version.local,)\n        return version_fields"}, {"id": "pytest.collect.COLLECT_FAKEMODULE_ATTRIBUTES", "kind": "variable", "range": [8, 0, 18, 1, 126, 297], "file_path": "src/pytest/collect.py", "content": "COLLECT_FAKEMODULE_ATTRIBUTES = [\n    \"Collector\",\n    \"Module\",\n    \"Function\",\n    \"Instance\",\n    \"Session\",\n    \"Item\",\n    \"Class\",\n    \"File\",\n    \"_fillfuncargs\",\n]"}, {"id": "pytest.collect.FakeCollectModule", "kind": "class", "range": [21, 0, 34, 36, 300, 784], "file_path": "src/pytest/collect.py", "content": "class FakeCollectModule(ModuleType):\n    def __init__(self):\n        super().__init__(\"pytest.collect\")\n        self.__all__ = list(COLLECT_FAKEMODULE_ATTRIBUTES)\n        self.__pytest = pytest\n\n    def __dir__(self):\n        return dir(super()) + self.__all__\n\n    def __getattr__(self, name):\n        if name not in self.__all__:\n            raise AttributeError(name)\n        warnings.warn(PYTEST_COLLECT_MODULE.format(name=name), stacklevel=2)\n        return getattr(pytest, name)"}, {"id": "pytest.collect.FakeCollectModule.__init__", "kind": "function", "range": [22, 4, 25, 30, 341, 493], "file_path": "src/pytest/collect.py", "content": "def __init__(self):\n        super().__init__(\"pytest.collect\")\n        self.__all__ = list(COLLECT_FAKEMODULE_ATTRIBUTES)\n        self.__pytest = pytest"}, {"id": "pytest.collect.FakeCollectModule.__dir__", "kind": "function", "range": [27, 4, 28, 42, 499, 560], "file_path": "src/pytest/collect.py", "content": "def __dir__(self):\n        return dir(super()) + self.__all__"}, {"id": "pytest.collect.FakeCollectModule.__getattr__", "kind": "function", "range": [30, 4, 34, 36, 566, 784], "file_path": "src/pytest/collect.py", "content": "def __getattr__(self, name):\n        if name not in self.__all__:\n            raise AttributeError(name)\n        warnings.warn(PYTEST_COLLECT_MODULE.format(name=name), stacklevel=2)\n        return getattr(pytest, name)"}, {"id": "pytest.__init__.set_trace", "kind": "variable", "range": [49, 0, 49, 33, 1928, 1961], "file_path": "src/pytest/__init__.py", "content": "set_trace = __pytestPDB.set_trace"}, {"id": "pytest.__init__.__all__", "kind": "variable", "range": [51, 0, 96, 1, 1963, 2823], "file_path": "src/pytest/__init__.py", "content": "__all__ = [\n    \"__version__\",\n    \"_fillfuncargs\",\n    \"approx\",\n    \"Class\",\n    \"cmdline\",\n    \"collect\",\n    \"Collector\",\n    \"deprecated_call\",\n    \"exit\",\n    \"ExitCode\",\n    \"fail\",\n    \"File\",\n    \"fixture\",\n    \"FixtureLookupError\",\n    \"freeze_includes\",\n    \"Function\",\n    \"hookimpl\",\n    \"hookspec\",\n    \"importorskip\",\n    \"Instance\",\n    \"Item\",\n    \"main\",\n    \"mark\",\n    \"Module\",\n    \"Package\",\n    \"param\",\n    \"PytestAssertRewriteWarning\",\n    \"PytestCacheWarning\",\n    \"PytestCollectionWarning\",\n    \"PytestConfigWarning\",\n    \"PytestDeprecationWarning\",\n    \"PytestExperimentalApiWarning\",\n    \"PytestUnhandledCoroutineWarning\",\n    \"PytestUnknownMarkWarning\",\n    \"PytestWarning\",\n    \"raises\",\n    \"register_assert_rewrite\",\n    \"Session\",\n    \"set_trace\",\n    \"skip\",\n    \"UsageError\",\n    \"warns\",\n    \"xfail\",\n    \"yield_fixture\",\n]"}, {"id": "_pytest.skipping.skipped_by_mark_key", "kind": "variable", "range": [9, 0, 9, 38, 278, 316], "file_path": "src/_pytest/skipping.py", "content": "skipped_by_mark_key = StoreKey[bool]()"}, {"id": "_pytest.skipping.evalxfail_key", "kind": "variable", "range": [10, 0, 10, 41, 317, 358], "file_path": "src/_pytest/skipping.py", "content": "evalxfail_key = StoreKey[MarkEvaluator]()"}, {"id": "_pytest.skipping.unexpectedsuccess_key", "kind": "variable", "range": [11, 0, 11, 39, 359, 398], "file_path": "src/_pytest/skipping.py", "content": "unexpectedsuccess_key = StoreKey[str]()"}, {"id": "_pytest.skipping.pytest_addoption", "kind": "function", "range": [14, 0, 30, 5, 401, 881], "file_path": "src/_pytest/skipping.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--runxfail\",\n        action=\"store_true\",\n        dest=\"runxfail\",\n        default=False,\n        help=\"report the results of xfail tests as if they were not marked\",\n    )\n\n    parser.addini(\n        \"xfail_strict\",\n        \"default for the strict parameter of xfail \"\n        \"markers when not given explicitly (default: False)\",\n        default=False,\n        type=\"bool\",\n    )"}, {"id": "_pytest.skipping.pytest_configure", "kind": "function", "range": [33, 0, 70, 5, 884, 2449], "file_path": "src/_pytest/skipping.py", "content": "def pytest_configure(config):\n    if config.option.runxfail:\n        # yay a hack\n        import pytest\n\n        old = pytest.xfail\n        config._cleanup.append(lambda: setattr(pytest, \"xfail\", old))\n\n        def nop(*args, **kwargs):\n            pass\n\n        nop.Exception = xfail.Exception\n        setattr(pytest, \"xfail\", nop)\n\n    config.addinivalue_line(\n        \"markers\",\n        \"skip(reason=None): skip the given test function with an optional reason. \"\n        'Example: skip(reason=\"no way of currently testing this\") skips the '\n        \"test.\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"skipif(condition): skip the given test function if eval(condition) \"\n        \"results in a True value.  Evaluation happens within the \"\n        \"module global context. Example: skipif('sys.platform == \\\"win32\\\"') \"\n        \"skips the test if we are on the win32 platform. see \"\n        \"https://docs.pytest.org/en/latest/skipping.html\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"xfail(condition, reason=None, run=True, raises=None, strict=False): \"\n        \"mark the test function as an expected failure if eval(condition) \"\n        \"has a True value. Optionally specify a reason for better reporting \"\n        \"and run=False if you don't even want to execute the test function. \"\n        \"If only specific exception(s) are expected, you can list them in \"\n        \"raises, and if the test fails in other ways, it will be reported as \"\n        \"a true failure. See https://docs.pytest.org/en/latest/skipping.html\",\n    )"}, {"id": "_pytest.skipping.pytest_runtest_setup", "kind": "function", "range": [73, 0, 92, 28, 2452, 3179], "file_path": "src/_pytest/skipping.py", "content": "@hookimpl(tryfirst=True)\ndef pytest_runtest_setup(item):\n    # Check if skip or skipif are specified as pytest marks\n    item._store[skipped_by_mark_key] = False\n    eval_skipif = MarkEvaluator(item, \"skipif\")\n    if eval_skipif.istrue():\n        item._store[skipped_by_mark_key] = True\n        skip(eval_skipif.getexplanation())\n\n    for skip_info in item.iter_markers(name=\"skip\"):\n        item._store[skipped_by_mark_key] = True\n        if \"reason\" in skip_info.kwargs:\n            skip(skip_info.kwargs[\"reason\"])\n        elif skip_info.args:\n            skip(skip_info.args[0])\n        else:\n            skip(\"unconditional skip\")\n\n    item._store[evalxfail_key] = MarkEvaluator(item, \"xfail\")\n    check_xfail_no_run(item)"}, {"id": "_pytest.skipping.pytest_pyfunc_call", "kind": "function", "range": [95, 0, 101, 38, 3182, 3391], "file_path": "src/_pytest/skipping.py", "content": "@hookimpl(hookwrapper=True)\ndef pytest_pyfunc_call(pyfuncitem):\n    check_xfail_no_run(pyfuncitem)\n    outcome = yield\n    passed = outcome.excinfo is None\n    if passed:\n        check_strict_xfail(pyfuncitem)"}, {"id": "_pytest.skipping.check_xfail_no_run", "kind": "function", "range": [104, 0, 110, 63, 3394, 3685], "file_path": "src/_pytest/skipping.py", "content": "def check_xfail_no_run(item):\n    \"\"\"check xfail(run=False)\"\"\"\n    if not item.config.option.runxfail:\n        evalxfail = item._store[evalxfail_key]\n        if evalxfail.istrue():\n            if not evalxfail.get(\"run\", True):\n                xfail(\"[NOTRUN] \" + evalxfail.getexplanation())"}, {"id": "_pytest.skipping.check_strict_xfail", "kind": "function", "range": [113, 0, 122, 65, 3688, 4189], "file_path": "src/_pytest/skipping.py", "content": "def check_strict_xfail(pyfuncitem):\n    \"\"\"check xfail(strict=True) for the given PASSING test\"\"\"\n    evalxfail = pyfuncitem._store[evalxfail_key]\n    if evalxfail.istrue():\n        strict_default = pyfuncitem.config.getini(\"xfail_strict\")\n        is_strict_xfail = evalxfail.get(\"strict\", strict_default)\n        if is_strict_xfail:\n            del pyfuncitem._store[evalxfail_key]\n            explanation = evalxfail.getexplanation()\n            fail(\"[XPASS(strict)] \" + explanation, pytrace=False)"}, {"id": "_pytest.skipping.pytest_runtest_makereport", "kind": "function", "range": [125, 0, 171, 49, 4192, 6231], "file_path": "src/_pytest/skipping.py", "content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_makereport(item, call):\n    outcome = yield\n    rep = outcome.get_result()\n    evalxfail = item._store.get(evalxfail_key, None)\n    # unittest special case, see setting of unexpectedsuccess_key\n    if unexpectedsuccess_key in item._store and rep.when == \"call\":\n        reason = item._store[unexpectedsuccess_key]\n        if reason:\n            rep.longrepr = \"Unexpected success: {}\".format(reason)\n        else:\n            rep.longrepr = \"Unexpected success\"\n        rep.outcome = \"failed\"\n\n    elif item.config.option.runxfail:\n        pass  # don't interfere\n    elif call.excinfo and call.excinfo.errisinstance(xfail.Exception):\n        rep.wasxfail = \"reason: \" + call.excinfo.value.msg\n        rep.outcome = \"skipped\"\n    elif evalxfail and not rep.skipped and evalxfail.wasvalid() and evalxfail.istrue():\n        if call.excinfo:\n            if evalxfail.invalidraise(call.excinfo.value):\n                rep.outcome = \"failed\"\n            else:\n                rep.outcome = \"skipped\"\n                rep.wasxfail = evalxfail.getexplanation()\n        elif call.when == \"call\":\n            strict_default = item.config.getini(\"xfail_strict\")\n            is_strict_xfail = evalxfail.get(\"strict\", strict_default)\n            explanation = evalxfail.getexplanation()\n            if is_strict_xfail:\n                rep.outcome = \"failed\"\n                rep.longrepr = \"[XPASS(strict)] {}\".format(explanation)\n            else:\n                rep.outcome = \"passed\"\n                rep.wasxfail = explanation\n    elif (\n        item._store.get(skipped_by_mark_key, True)\n        and rep.skipped\n        and type(rep.longrepr) is tuple\n    ):\n        # skipped by mark.skipif; change the location of the failure\n        # to point to the item definition, otherwise it will display\n        # the location of where the skip exception was raised within pytest\n        _, _, reason = rep.longrepr\n        filename, line = item.location[:2]\n        rep.longrepr = filename, line + 1, reason"}, {"id": "_pytest.skipping.pytest_report_teststatus", "kind": "function", "range": [177, 0, 182, 42, 6284, 6498], "file_path": "src/_pytest/skipping.py", "content": "def pytest_report_teststatus(report):\n    if hasattr(report, \"wasxfail\"):\n        if report.skipped:\n            return \"xfailed\", \"x\", \"XFAIL\"\n        elif report.passed:\n            return \"xpassed\", \"X\", \"XPASS\""}, {"id": "_pytest.resultlog.resultlog_key", "kind": "variable", "range": [10, 0, 10, 39, 143, 182], "file_path": "src/_pytest/resultlog.py", "content": "resultlog_key = StoreKey[\"ResultLog\"]()"}, {"id": "_pytest.resultlog.pytest_addoption", "kind": "function", "range": [13, 0, 22, 5, 185, 501], "file_path": "src/_pytest/resultlog.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"terminal reporting\", \"resultlog plugin options\")\n    group.addoption(\n        \"--resultlog\",\n        \"--result-log\",\n        action=\"store\",\n        metavar=\"path\",\n        default=None,\n        help=\"DEPRECATED path for machine-readable result log.\",\n    )"}, {"id": "_pytest.resultlog.pytest_configure", "kind": "function", "range": [25, 0, 39, 70, 504, 1195], "file_path": "src/_pytest/resultlog.py", "content": "def pytest_configure(config):\n    resultlog = config.option.resultlog\n    # prevent opening resultlog on slave nodes (xdist)\n    if resultlog and not hasattr(config, \"slaveinput\"):\n        dirname = os.path.dirname(os.path.abspath(resultlog))\n        if not os.path.isdir(dirname):\n            os.makedirs(dirname)\n        logfile = open(resultlog, \"w\", 1)  # line buffered\n        config._store[resultlog_key] = ResultLog(config, logfile)\n        config.pluginmanager.register(config._store[resultlog_key])\n\n        from _pytest.deprecated import RESULT_LOG\n        from _pytest.warnings import _issue_warning_captured\n\n        _issue_warning_captured(RESULT_LOG, config.hook, stacklevel=2)"}, {"id": "_pytest.resultlog.pytest_unconfigure", "kind": "function", "range": [42, 0, 47, 50, 1198, 1428], "file_path": "src/_pytest/resultlog.py", "content": "def pytest_unconfigure(config):\n    resultlog = config._store.get(resultlog_key, None)\n    if resultlog:\n        resultlog.logfile.close()\n        del config._store[resultlog_key]\n        config.pluginmanager.unregister(resultlog)"}, {"id": "_pytest.resultlog.ResultLog", "kind": "class", "range": [50, 0, 101, 53, 1431, 3301], "file_path": "src/_pytest/resultlog.py", "content": "class ResultLog:\n    def __init__(self, config, logfile):\n        self.config = config\n        self.logfile = logfile  # preferably line buffered\n\n    def write_log_entry(self, testpath, lettercode, longrepr):\n        print(\"{} {}\".format(lettercode, testpath), file=self.logfile)\n        for line in longrepr.splitlines():\n            print(\" %s\" % line, file=self.logfile)\n\n    def log_outcome(self, report, lettercode, longrepr):\n        testpath = getattr(report, \"nodeid\", None)\n        if testpath is None:\n            testpath = report.fspath\n        self.write_log_entry(testpath, lettercode, longrepr)\n\n    def pytest_runtest_logreport(self, report):\n        if report.when != \"call\" and report.passed:\n            return\n        res = self.config.hook.pytest_report_teststatus(\n            report=report, config=self.config\n        )\n        code = res[1]\n        if code == \"x\":\n            longrepr = str(report.longrepr)\n        elif code == \"X\":\n            longrepr = \"\"\n        elif report.passed:\n            longrepr = \"\"\n        elif report.skipped:\n            longrepr = str(report.longrepr[2])\n        else:\n            longrepr = str(report.longrepr)\n        self.log_outcome(report, code, longrepr)\n\n    def pytest_collectreport(self, report):\n        if not report.passed:\n            if report.failed:\n                code = \"F\"\n                longrepr = str(report.longrepr)\n            else:\n                assert report.skipped\n                code = \"S\"\n                longrepr = \"%s:%d: %s\" % report.longrepr\n            self.log_outcome(report, code, longrepr)\n\n    def pytest_internalerror(self, excrepr):\n        reprcrash = getattr(excrepr, \"reprcrash\", None)\n        path = getattr(reprcrash, \"path\", None)\n        if path is None:\n            path = \"cwd:%s\" % py.path.local()\n        self.write_log_entry(path, \"!\", str(excrepr))"}, {"id": "_pytest.resultlog.ResultLog.__init__", "kind": "function", "range": [51, 4, 53, 58, 1452, 1576], "file_path": "src/_pytest/resultlog.py", "content": "def __init__(self, config, logfile):\n        self.config = config\n        self.logfile = logfile  # preferably line buffered"}, {"id": "_pytest.resultlog.ResultLog.write_log_entry", "kind": "function", "range": [55, 4, 58, 50, 1582, 1805], "file_path": "src/_pytest/resultlog.py", "content": "def write_log_entry(self, testpath, lettercode, longrepr):\n        print(\"{} {}\".format(lettercode, testpath), file=self.logfile)\n        for line in longrepr.splitlines():\n            print(\" %s\" % line, file=self.logfile)"}, {"id": "_pytest.resultlog.ResultLog.log_outcome", "kind": "function", "range": [60, 4, 64, 60, 1811, 2041], "file_path": "src/_pytest/resultlog.py", "content": "def log_outcome(self, report, lettercode, longrepr):\n        testpath = getattr(report, \"nodeid\", None)\n        if testpath is None:\n            testpath = report.fspath\n        self.write_log_entry(testpath, lettercode, longrepr)"}, {"id": "_pytest.resultlog.ResultLog.pytest_runtest_logreport", "kind": "function", "range": [66, 4, 83, 48, 2047, 2653], "file_path": "src/_pytest/resultlog.py", "content": "def pytest_runtest_logreport(self, report):\n        if report.when != \"call\" and report.passed:\n            return\n        res = self.config.hook.pytest_report_teststatus(\n            report=report, config=self.config\n        )\n        code = res[1]\n        if code == \"x\":\n            longrepr = str(report.longrepr)\n        elif code == \"X\":\n            longrepr = \"\"\n        elif report.passed:\n            longrepr = \"\"\n        elif report.skipped:\n            longrepr = str(report.longrepr[2])\n        else:\n            longrepr = str(report.longrepr)\n        self.log_outcome(report, code, longrepr)"}, {"id": "_pytest.resultlog.ResultLog.pytest_collectreport", "kind": "function", "range": [85, 4, 94, 52, 2659, 3026], "file_path": "src/_pytest/resultlog.py", "content": "def pytest_collectreport(self, report):\n        if not report.passed:\n            if report.failed:\n                code = \"F\"\n                longrepr = str(report.longrepr)\n            else:\n                assert report.skipped\n                code = \"S\"\n                longrepr = \"%s:%d: %s\" % report.longrepr\n            self.log_outcome(report, code, longrepr)"}, {"id": "_pytest.resultlog.ResultLog.pytest_internalerror", "kind": "function", "range": [96, 4, 101, 53, 3032, 3301], "file_path": "src/_pytest/resultlog.py", "content": "def pytest_internalerror(self, excrepr):\n        reprcrash = getattr(excrepr, \"reprcrash\", None)\n        path = getattr(reprcrash, \"path\", None)\n        if path is None:\n            path = \"cwd:%s\" % py.path.local()\n        self.write_log_entry(path, \"!\", str(excrepr))"}, {"id": "_pytest.store.__all__", "kind": "variable", "range": [8, 0, 8, 31, 152, 183], "file_path": "src/_pytest/store.py", "content": "__all__ = [\"Store\", \"StoreKey\"]"}, {"id": "_pytest.store.T", "kind": "variable", "range": [11, 0, 11, 16, 186, 202], "file_path": "src/_pytest/store.py", "content": "T = TypeVar(\"T\")"}, {"id": "_pytest.store.D", "kind": "variable", "range": [12, 0, 12, 16, 203, 219], "file_path": "src/_pytest/store.py", "content": "D = TypeVar(\"D\")"}, {"id": "_pytest.store.StoreKey", "kind": "class", "range": [15, 0, 23, 18, 222, 467], "file_path": "src/_pytest/store.py", "content": "class StoreKey(Generic[T]):\n    \"\"\"StoreKey is an object used as a key to a Store.\n\n    A StoreKey is associated with the type T of the value of the key.\n\n    A StoreKey is unique and cannot conflict with another key.\n    \"\"\"\n\n    __slots__ = ()"}, {"id": "_pytest.store.StoreKey.__slots__", "kind": "variable", "range": [23, 4, 23, 18, 453, 467], "file_path": "src/_pytest/store.py", "content": "__slots__ = ()"}, {"id": "_pytest.store.Store", "kind": "class", "range": [26, 0, 124, 33, 470, 3633], "file_path": "src/_pytest/store.py", "content": "class Store:\n    \"\"\"Store is a type-safe heterogenous mutable mapping that\n    allows keys and value types to be defined separately from\n    where it (the Store) is created.\n\n    Usually you will be given an object which has a ``Store``:\n\n    .. code-block:: python\n\n        store: Store = some_object.store\n\n    If a module wants to store data in this Store, it creates StoreKeys\n    for its keys (at the module level):\n\n    .. code-block:: python\n\n        some_str_key = StoreKey[str]()\n        some_bool_key = StoreKey[bool]()\n\n    To store information:\n\n    .. code-block:: python\n\n        # Value type must match the key.\n        store[some_str_key] = \"value\"\n        store[some_bool_key] = True\n\n    To retrieve the information:\n\n    .. code-block:: python\n\n        # The static type of some_str is str.\n        some_str = store[some_str_key]\n        # The static type of some_bool is bool.\n        some_bool = store[some_bool_key]\n\n    Why use this?\n    -------------\n\n    Problem: module Internal defines an object. Module External, which\n    module Internal doesn't know about, receives the object and wants to\n    attach information to it, to be retrieved later given the object.\n\n    Bad solution 1: Module External assigns private attributes directly on\n    the object. This doesn't work well because the type checker doesn't\n    know about these attributes and it complains about undefined attributes.\n\n    Bad solution 2: module Internal adds a ``Dict[str, Any]`` attribute to\n    the object. Module External stores its data in private keys of this dict.\n    This doesn't work well because retrieved values are untyped.\n\n    Good solution: module Internal adds a ``Store`` to the object. Module\n    External mints StoreKeys for its own keys. Module External stores and\n    retrieves its data using these keys.\n    \"\"\"\n\n    __slots__ = (\"_store\",)\n\n    def __init__(self) -> None:\n        self._store = {}  # type: Dict[StoreKey[Any], object]\n\n    def __setitem__(self, key: StoreKey[T], value: T) -> None:\n        \"\"\"Set a value for key.\"\"\"\n        self._store[key] = value\n\n    def __getitem__(self, key: StoreKey[T]) -> T:\n        \"\"\"Get the value for key.\n\n        Raises KeyError if the key wasn't set before.\n        \"\"\"\n        return cast(T, self._store[key])\n\n    def get(self, key: StoreKey[T], default: D) -> Union[T, D]:\n        \"\"\"Get the value for key, or return default if the key wasn't set\n        before.\"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default\n\n    def setdefault(self, key: StoreKey[T], default: T) -> T:\n        \"\"\"Return the value of key if already set, otherwise set the value\n        of key to default and return default.\"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n            return default\n\n    def __delitem__(self, key: StoreKey[T]) -> None:\n        \"\"\"Delete the value for key.\n\n        Raises KeyError if the key wasn't set before.\n        \"\"\"\n        del self._store[key]\n\n    def __contains__(self, key: StoreKey[T]) -> bool:\n        \"\"\"Returns whether key was set.\"\"\"\n        return key in self._store"}, {"id": "_pytest.store.Store.__slots__", "kind": "variable", "range": [82, 4, 82, 27, 2307, 2330], "file_path": "src/_pytest/store.py", "content": "__slots__ = (\"_store\",)"}, {"id": "_pytest.store.Store.__init__", "kind": "function", "range": [84, 4, 85, 61, 2336, 2425], "file_path": "src/_pytest/store.py", "content": "def __init__(self) -> None:\n        self._store = {}  # type: Dict[StoreKey[Any], object]"}, {"id": "_pytest.store.Store.__setitem__", "kind": "function", "range": [87, 4, 89, 32, 2431, 2557], "file_path": "src/_pytest/store.py", "content": "def __setitem__(self, key: StoreKey[T], value: T) -> None:\n        \"\"\"Set a value for key.\"\"\"\n        self._store[key] = value"}, {"id": "_pytest.store.Store.__getitem__", "kind": "function", "range": [91, 4, 96, 40, 2563, 2750], "file_path": "src/_pytest/store.py", "content": "def __getitem__(self, key: StoreKey[T]) -> T:\n        \"\"\"Get the value for key.\n\n        Raises KeyError if the key wasn't set before.\n        \"\"\"\n        return cast(T, self._store[key])"}, {"id": "_pytest.store.Store.get", "kind": "function", "range": [98, 4, 104, 26, 2756, 3002], "file_path": "src/_pytest/store.py", "content": "def get(self, key: StoreKey[T], default: D) -> Union[T, D]:\n        \"\"\"Get the value for key, or return default if the key wasn't set\n        before.\"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            return default"}, {"id": "_pytest.store.Store.setdefault", "kind": "function", "range": [106, 4, 113, 26, 3008, 3314], "file_path": "src/_pytest/store.py", "content": "def setdefault(self, key: StoreKey[T], default: T) -> T:\n        \"\"\"Return the value of key if already set, otherwise set the value\n        of key to default and return default.\"\"\"\n        try:\n            return self[key]\n        except KeyError:\n            self[key] = default\n            return default"}, {"id": "_pytest.store.Store.__delitem__", "kind": "function", "range": [115, 4, 120, 28, 3320, 3501], "file_path": "src/_pytest/store.py", "content": "def __delitem__(self, key: StoreKey[T]) -> None:\n        \"\"\"Delete the value for key.\n\n        Raises KeyError if the key wasn't set before.\n        \"\"\"\n        del self._store[key]"}, {"id": "_pytest.store.Store.__contains__", "kind": "function", "range": [122, 4, 124, 33, 3507, 3633], "file_path": "src/_pytest/store.py", "content": "def __contains__(self, key: StoreKey[T]) -> bool:\n        \"\"\"Returns whether key was set.\"\"\"\n        return key in self._store"}, {"id": "_pytest.logging.DEFAULT_LOG_FORMAT", "kind": "variable", "range": [20, 0, 20, 83, 528, 611], "file_path": "src/_pytest/logging.py", "content": "DEFAULT_LOG_FORMAT = \"%(levelname)-8s %(name)s:%(filename)s:%(lineno)d %(message)s\""}, {"id": "_pytest.logging.DEFAULT_LOG_DATE_FORMAT", "kind": "variable", "range": [21, 0, 21, 36, 612, 648], "file_path": "src/_pytest/logging.py", "content": "DEFAULT_LOG_DATE_FORMAT = \"%H:%M:%S\""}, {"id": "_pytest.logging._ANSI_ESCAPE_SEQ", "kind": "variable", "range": [22, 0, 22, 47, 649, 696], "file_path": "src/_pytest/logging.py", "content": "_ANSI_ESCAPE_SEQ = re.compile(r\"\\x1b\\[[\\d;]+m\")"}, {"id": "_pytest.logging._remove_ansi_escape_sequences", "kind": "function", "range": [25, 0, 26, 41, 699, 781], "file_path": "src/_pytest/logging.py", "content": "def _remove_ansi_escape_sequences(text):\n    return _ANSI_ESCAPE_SEQ.sub(\"\", text)"}, {"id": "_pytest.logging.ColoredLevelFormatter", "kind": "class", "range": [29, 0, 73, 37, 784, 2534], "file_path": "src/_pytest/logging.py", "content": "class ColoredLevelFormatter(logging.Formatter):\n    \"\"\"\n    Colorize the %(levelname)..s part of the log format passed to __init__.\n    \"\"\"\n\n    LOGLEVEL_COLOROPTS = {\n        logging.CRITICAL: {\"red\"},\n        logging.ERROR: {\"red\", \"bold\"},\n        logging.WARNING: {\"yellow\"},\n        logging.WARN: {\"yellow\"},\n        logging.INFO: {\"green\"},\n        logging.DEBUG: {\"purple\"},\n        logging.NOTSET: set(),\n    }  # type: Mapping[int, AbstractSet[str]]\n    LEVELNAME_FMT_REGEX = re.compile(r\"%\\(levelname\\)([+-.]?\\d*s)\")\n\n    def __init__(self, terminalwriter, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._original_fmt = self._style._fmt\n        self._level_to_fmt_mapping = {}  # type: Dict[int, str]\n\n        assert self._fmt is not None\n        levelname_fmt_match = self.LEVELNAME_FMT_REGEX.search(self._fmt)\n        if not levelname_fmt_match:\n            return\n        levelname_fmt = levelname_fmt_match.group()\n\n        for level, color_opts in self.LOGLEVEL_COLOROPTS.items():\n            formatted_levelname = levelname_fmt % {\n                \"levelname\": logging.getLevelName(level)\n            }\n\n            # add ANSI escape sequences around the formatted levelname\n            color_kwargs = {name: True for name in color_opts}\n            colorized_formatted_levelname = terminalwriter.markup(\n                formatted_levelname, **color_kwargs\n            )\n            self._level_to_fmt_mapping[level] = self.LEVELNAME_FMT_REGEX.sub(\n                colorized_formatted_levelname, self._fmt\n            )\n\n    def format(self, record):\n        fmt = self._level_to_fmt_mapping.get(record.levelno, self._original_fmt)\n        self._style._fmt = fmt\n        return super().format(record)"}, {"id": "_pytest.logging.ColoredLevelFormatter.LOGLEVEL_COLOROPTS", "kind": "variable", "range": [34, 4, 42, 5, 929, 1202], "file_path": "src/_pytest/logging.py", "content": "LOGLEVEL_COLOROPTS = {\n        logging.CRITICAL: {\"red\"},\n        logging.ERROR: {\"red\", \"bold\"},\n        logging.WARNING: {\"yellow\"},\n        logging.WARN: {\"yellow\"},\n        logging.INFO: {\"green\"},\n        logging.DEBUG: {\"purple\"},\n        logging.NOTSET: set(),\n    }"}, {"id": "_pytest.logging.ColoredLevelFormatter.LEVELNAME_FMT_REGEX", "kind": "variable", "range": [43, 4, 43, 67, 1247, 1310], "file_path": "src/_pytest/logging.py", "content": "LEVELNAME_FMT_REGEX = re.compile(r\"%\\(levelname\\)([+-.]?\\d*s)\")"}, {"id": "_pytest.logging.ColoredLevelFormatter.__init__", "kind": "function", "range": [45, 4, 68, 13, 1316, 2353], "file_path": "src/_pytest/logging.py", "content": "def __init__(self, terminalwriter, *args, **kwargs) -> None:\n        super().__init__(*args, **kwargs)\n        self._original_fmt = self._style._fmt\n        self._level_to_fmt_mapping = {}  # type: Dict[int, str]\n\n        assert self._fmt is not None\n        levelname_fmt_match = self.LEVELNAME_FMT_REGEX.search(self._fmt)\n        if not levelname_fmt_match:\n            return\n        levelname_fmt = levelname_fmt_match.group()\n\n        for level, color_opts in self.LOGLEVEL_COLOROPTS.items():\n            formatted_levelname = levelname_fmt % {\n                \"levelname\": logging.getLevelName(level)\n            }\n\n            # add ANSI escape sequences around the formatted levelname\n            color_kwargs = {name: True for name in color_opts}\n            colorized_formatted_levelname = terminalwriter.markup(\n                formatted_levelname, **color_kwargs\n            )\n            self._level_to_fmt_mapping[level] = self.LEVELNAME_FMT_REGEX.sub(\n                colorized_formatted_levelname, self._fmt\n            )"}, {"id": "_pytest.logging.ColoredLevelFormatter.format", "kind": "function", "range": [70, 4, 73, 37, 2359, 2534], "file_path": "src/_pytest/logging.py", "content": "def format(self, record):\n        fmt = self._level_to_fmt_mapping.get(record.levelno, self._original_fmt)\n        self._style._fmt = fmt\n        return super().format(record)"}, {"id": "_pytest.logging.PercentStyleMultiline", "kind": "class", "range": [76, 0, 163, 42, 2537, 5927], "file_path": "src/_pytest/logging.py", "content": "class PercentStyleMultiline(logging.PercentStyle):\n    \"\"\"A logging style with special support for multiline messages.\n\n    If the message of a record consists of multiple lines, this style\n    formats the message as if each line were logged separately.\n    \"\"\"\n\n    def __init__(self, fmt, auto_indent):\n        super().__init__(fmt)\n        self._auto_indent = self._get_auto_indent(auto_indent)\n\n    @staticmethod\n    def _update_message(record_dict, message):\n        tmp = record_dict.copy()\n        tmp[\"message\"] = message\n        return tmp\n\n    @staticmethod\n    def _get_auto_indent(auto_indent_option) -> int:\n        \"\"\"Determines the current auto indentation setting\n\n        Specify auto indent behavior (on/off/fixed) by passing in\n        extra={\"auto_indent\": [value]} to the call to logging.log() or\n        using a --log-auto-indent [value] command line or the\n        log_auto_indent [value] config option.\n\n        Default behavior is auto-indent off.\n\n        Using the string \"True\" or \"on\" or the boolean True as the value\n        turns auto indent on, using the string \"False\" or \"off\" or the\n        boolean False or the int 0 turns it off, and specifying a\n        positive integer fixes the indentation position to the value\n        specified.\n\n        Any other values for the option are invalid, and will silently be\n        converted to the default.\n\n        :param any auto_indent_option: User specified option for indentation\n            from command line, config or extra kwarg. Accepts int, bool or str.\n            str option accepts the same range of values as boolean config options,\n            as well as positive integers represented in str form.\n\n        :returns: indentation value, which can be\n            -1 (automatically determine indentation) or\n            0 (auto-indent turned off) or\n            >0 (explicitly set indentation position).\n        \"\"\"\n\n        if type(auto_indent_option) is int:\n            return int(auto_indent_option)\n        elif type(auto_indent_option) is str:\n            try:\n                return int(auto_indent_option)\n            except ValueError:\n                pass\n            try:\n                if _strtobool(auto_indent_option):\n                    return -1\n            except ValueError:\n                return 0\n        elif type(auto_indent_option) is bool:\n            if auto_indent_option:\n                return -1\n\n        return 0\n\n    def format(self, record):\n        if \"\\n\" in record.message:\n            if hasattr(record, \"auto_indent\"):\n                # passed in from the \"extra={}\" kwarg on the call to logging.log()\n                auto_indent = self._get_auto_indent(record.auto_indent)\n            else:\n                auto_indent = self._auto_indent\n\n            if auto_indent:\n                lines = record.message.splitlines()\n                formatted = self._fmt % self._update_message(record.__dict__, lines[0])\n\n                if auto_indent < 0:\n                    indentation = _remove_ansi_escape_sequences(formatted).find(\n                        lines[0]\n                    )\n                else:\n                    # optimizes logging by allowing a fixed indentation\n                    indentation = auto_indent\n                lines[0] = formatted\n                return (\"\\n\" + \" \" * indentation).join(lines)\n        return self._fmt % record.__dict__"}, {"id": "_pytest.logging.PercentStyleMultiline.__init__", "kind": "function", "range": [83, 4, 85, 62, 2804, 2934], "file_path": "src/_pytest/logging.py", "content": "def __init__(self, fmt, auto_indent):\n        super().__init__(fmt)\n        self._auto_indent = self._get_auto_indent(auto_indent)"}, {"id": "_pytest.logging.PercentStyleMultiline._update_message", "kind": "function", "range": [87, 4, 91, 18, 2940, 3085], "file_path": "src/_pytest/logging.py", "content": "@staticmethod\n    def _update_message(record_dict, message):\n        tmp = record_dict.copy()\n        tmp[\"message\"] = message\n        return tmp"}, {"id": "_pytest.logging.PercentStyleMultiline._get_auto_indent", "kind": "function", "range": [93, 4, 140, 16, 3091, 4969], "file_path": "src/_pytest/logging.py", "content": "@staticmethod\n    def _get_auto_indent(auto_indent_option) -> int:\n        \"\"\"Determines the current auto indentation setting\n\n        Specify auto indent behavior (on/off/fixed) by passing in\n        extra={\"auto_indent\": [value]} to the call to logging.log() or\n        using a --log-auto-indent [value] command line or the\n        log_auto_indent [value] config option.\n\n        Default behavior is auto-indent off.\n\n        Using the string \"True\" or \"on\" or the boolean True as the value\n        turns auto indent on, using the string \"False\" or \"off\" or the\n        boolean False or the int 0 turns it off, and specifying a\n        positive integer fixes the indentation position to the value\n        specified.\n\n        Any other values for the option are invalid, and will silently be\n        converted to the default.\n\n        :param any auto_indent_option: User specified option for indentation\n            from command line, config or extra kwarg. Accepts int, bool or str.\n            str option accepts the same range of values as boolean config options,\n            as well as positive integers represented in str form.\n\n        :returns: indentation value, which can be\n            -1 (automatically determine indentation) or\n            0 (auto-indent turned off) or\n            >0 (explicitly set indentation position).\n        \"\"\"\n\n        if type(auto_indent_option) is int:\n            return int(auto_indent_option)\n        elif type(auto_indent_option) is str:\n            try:\n                return int(auto_indent_option)\n            except ValueError:\n                pass\n            try:\n                if _strtobool(auto_indent_option):\n                    return -1\n            except ValueError:\n                return 0\n        elif type(auto_indent_option) is bool:\n            if auto_indent_option:\n                return -1\n\n        return 0"}, {"id": "_pytest.logging.PercentStyleMultiline.format", "kind": "function", "range": [142, 4, 163, 42, 4975, 5927], "file_path": "src/_pytest/logging.py", "content": "def format(self, record):\n        if \"\\n\" in record.message:\n            if hasattr(record, \"auto_indent\"):\n                # passed in from the \"extra={}\" kwarg on the call to logging.log()\n                auto_indent = self._get_auto_indent(record.auto_indent)\n            else:\n                auto_indent = self._auto_indent\n\n            if auto_indent:\n                lines = record.message.splitlines()\n                formatted = self._fmt % self._update_message(record.__dict__, lines[0])\n\n                if auto_indent < 0:\n                    indentation = _remove_ansi_escape_sequences(formatted).find(\n                        lines[0]\n                    )\n                else:\n                    # optimizes logging by allowing a fixed indentation\n                    indentation = auto_indent\n                lines[0] = formatted\n                return (\"\\n\" + \" \" * indentation).join(lines)\n        return self._fmt % record.__dict__"}, {"id": "_pytest.logging.get_option_ini", "kind": "function", "range": [166, 0, 172, 22, 5930, 6166], "file_path": "src/_pytest/logging.py", "content": "def get_option_ini(config, *names):\n    for name in names:\n        ret = config.getoption(name)  # 'default' arg won't work as expected\n        if ret is None:\n            ret = config.getini(name)\n        if ret:\n            return ret"}, {"id": "_pytest.logging.pytest_addoption", "kind": "function", "range": [175, 0, 267, 5, 6169, 9018], "file_path": "src/_pytest/logging.py", "content": "def pytest_addoption(parser):\n    \"\"\"Add options to control log capturing.\"\"\"\n    group = parser.getgroup(\"logging\")\n\n    def add_option_ini(option, dest, default=None, type=None, **kwargs):\n        parser.addini(\n            dest, default=default, type=type, help=\"default value for \" + option\n        )\n        group.addoption(option, dest=dest, **kwargs)\n\n    add_option_ini(\n        \"--no-print-logs\",\n        dest=\"log_print\",\n        action=\"store_const\",\n        const=False,\n        default=True,\n        type=\"bool\",\n        help=\"disable printing caught logs on failed tests.\",\n    )\n    add_option_ini(\n        \"--log-level\",\n        dest=\"log_level\",\n        default=None,\n        metavar=\"LEVEL\",\n        help=(\n            \"level of messages to catch/display.\\n\"\n            \"Not set by default, so it depends on the root/parent log handler's\"\n            ' effective level, where it is \"WARNING\" by default.'\n        ),\n    )\n    add_option_ini(\n        \"--log-format\",\n        dest=\"log_format\",\n        default=DEFAULT_LOG_FORMAT,\n        help=\"log format as used by the logging module.\",\n    )\n    add_option_ini(\n        \"--log-date-format\",\n        dest=\"log_date_format\",\n        default=DEFAULT_LOG_DATE_FORMAT,\n        help=\"log date format as used by the logging module.\",\n    )\n    parser.addini(\n        \"log_cli\",\n        default=False,\n        type=\"bool\",\n        help='enable log display during test run (also known as \"live logging\").',\n    )\n    add_option_ini(\n        \"--log-cli-level\", dest=\"log_cli_level\", default=None, help=\"cli logging level.\"\n    )\n    add_option_ini(\n        \"--log-cli-format\",\n        dest=\"log_cli_format\",\n        default=None,\n        help=\"log format as used by the logging module.\",\n    )\n    add_option_ini(\n        \"--log-cli-date-format\",\n        dest=\"log_cli_date_format\",\n        default=None,\n        help=\"log date format as used by the logging module.\",\n    )\n    add_option_ini(\n        \"--log-file\",\n        dest=\"log_file\",\n        default=None,\n        help=\"path to a file when logging will be written to.\",\n    )\n    add_option_ini(\n        \"--log-file-level\",\n        dest=\"log_file_level\",\n        default=None,\n        help=\"log file logging level.\",\n    )\n    add_option_ini(\n        \"--log-file-format\",\n        dest=\"log_file_format\",\n        default=DEFAULT_LOG_FORMAT,\n        help=\"log format as used by the logging module.\",\n    )\n    add_option_ini(\n        \"--log-file-date-format\",\n        dest=\"log_file_date_format\",\n        default=DEFAULT_LOG_DATE_FORMAT,\n        help=\"log date format as used by the logging module.\",\n    )\n    add_option_ini(\n        \"--log-auto-indent\",\n        dest=\"log_auto_indent\",\n        default=None,\n        help=\"Auto-indent multiline messages passed to the logging module. Accepts true|on, false|off or an integer.\",\n    )"}, {"id": "_pytest.logging.catching_logs", "kind": "function", "range": [270, 0, 295, 46, 9021, 9865], "file_path": "src/_pytest/logging.py", "content": "@contextmanager\ndef catching_logs(handler, formatter=None, level=None):\n    \"\"\"Context manager that prepares the whole logging machinery properly.\"\"\"\n    root_logger = logging.getLogger()\n\n    if formatter is not None:\n        handler.setFormatter(formatter)\n    if level is not None:\n        handler.setLevel(level)\n\n    # Adding the same handler twice would confuse logging system.\n    # Just don't do that.\n    add_new_handler = handler not in root_logger.handlers\n\n    if add_new_handler:\n        root_logger.addHandler(handler)\n    if level is not None:\n        orig_level = root_logger.level\n        root_logger.setLevel(min(orig_level, level))\n    try:\n        yield handler\n    finally:\n        if level is not None:\n            root_logger.setLevel(orig_level)\n        if add_new_handler:\n            root_logger.removeHandler(handler)"}, {"id": "_pytest.logging.LogCaptureHandler", "kind": "class", "range": [298, 0, 313, 32, 9868, 10479], "file_path": "src/_pytest/logging.py", "content": "class LogCaptureHandler(logging.StreamHandler):\n    \"\"\"A logging handler that stores log records and the log text.\"\"\"\n\n    def __init__(self) -> None:\n        \"\"\"Creates a new log handler.\"\"\"\n        logging.StreamHandler.__init__(self, StringIO())\n        self.records = []  # type: List[logging.LogRecord]\n\n    def emit(self, record: logging.LogRecord) -> None:\n        \"\"\"Keep the log records in a list in addition to the log text.\"\"\"\n        self.records.append(record)\n        logging.StreamHandler.emit(self, record)\n\n    def reset(self) -> None:\n        self.records = []\n        self.stream = StringIO()"}, {"id": "_pytest.logging.LogCaptureHandler.__init__", "kind": "function", "range": [301, 4, 304, 58, 9991, 10175], "file_path": "src/_pytest/logging.py", "content": "def __init__(self) -> None:\n        \"\"\"Creates a new log handler.\"\"\"\n        logging.StreamHandler.__init__(self, StringIO())\n        self.records = []  # type: List[logging.LogRecord]"}, {"id": "_pytest.logging.LogCaptureHandler.emit", "kind": "function", "range": [306, 4, 309, 48, 10181, 10390], "file_path": "src/_pytest/logging.py", "content": "def emit(self, record: logging.LogRecord) -> None:\n        \"\"\"Keep the log records in a list in addition to the log text.\"\"\"\n        self.records.append(record)\n        logging.StreamHandler.emit(self, record)"}, {"id": "_pytest.logging.LogCaptureHandler.reset", "kind": "function", "range": [311, 4, 313, 32, 10396, 10479], "file_path": "src/_pytest/logging.py", "content": "def reset(self) -> None:\n        self.records = []\n        self.stream = StringIO()"}, {"id": "_pytest.logging.LogCaptureFixture", "kind": "class", "range": [316, 0, 432, 39, 10482, 14767], "file_path": "src/_pytest/logging.py", "content": "class LogCaptureFixture:\n    \"\"\"Provides access and control of log capturing.\"\"\"\n\n    def __init__(self, item) -> None:\n        \"\"\"Creates a new funcarg.\"\"\"\n        self._item = item\n        # dict of log name -> log level\n        self._initial_log_levels = {}  # type: Dict[str, int]\n\n    def _finalize(self) -> None:\n        \"\"\"Finalizes the fixture.\n\n        This restores the log levels changed by :meth:`set_level`.\n        \"\"\"\n        # restore log levels\n        for logger_name, level in self._initial_log_levels.items():\n            logger = logging.getLogger(logger_name)\n            logger.setLevel(level)\n\n    @property\n    def handler(self) -> LogCaptureHandler:\n        \"\"\"\n        :rtype: LogCaptureHandler\n        \"\"\"\n        return self._item.catch_log_handler  # type: ignore[no-any-return]  # noqa: F723\n\n    def get_records(self, when: str) -> List[logging.LogRecord]:\n        \"\"\"\n        Get the logging records for one of the possible test phases.\n\n        :param str when:\n            Which test phase to obtain the records from. Valid values are: \"setup\", \"call\" and \"teardown\".\n\n        :rtype: List[logging.LogRecord]\n        :return: the list of captured records at the given stage\n\n        .. versionadded:: 3.4\n        \"\"\"\n        handler = self._item.catch_log_handlers.get(when)\n        if handler:\n            return handler.records  # type: ignore[no-any-return]  # noqa: F723\n        else:\n            return []\n\n    @property\n    def text(self):\n        \"\"\"Returns the formatted log text.\"\"\"\n        return _remove_ansi_escape_sequences(self.handler.stream.getvalue())\n\n    @property\n    def records(self):\n        \"\"\"Returns the list of log records.\"\"\"\n        return self.handler.records\n\n    @property\n    def record_tuples(self):\n        \"\"\"Returns a list of a stripped down version of log records intended\n        for use in assertion comparison.\n\n        The format of the tuple is:\n\n            (logger_name, log_level, message)\n        \"\"\"\n        return [(r.name, r.levelno, r.getMessage()) for r in self.records]\n\n    @property\n    def messages(self):\n        \"\"\"Returns a list of format-interpolated log messages.\n\n        Unlike 'records', which contains the format string and parameters for interpolation, log messages in this list\n        are all interpolated.\n        Unlike 'text', which contains the output from the handler, log messages in this list are unadorned with\n        levels, timestamps, etc, making exact comparisons more reliable.\n\n        Note that traceback or stack info (from :func:`logging.exception` or the `exc_info` or `stack_info` arguments\n        to the logging functions) is not included, as this is added by the formatter in the handler.\n\n        .. versionadded:: 3.7\n        \"\"\"\n        return [r.getMessage() for r in self.records]\n\n    def clear(self):\n        \"\"\"Reset the list of log records and the captured log text.\"\"\"\n        self.handler.reset()\n\n    def set_level(self, level, logger=None):\n        \"\"\"Sets the level for capturing of logs. The level will be restored to its previous value at the end of\n        the test.\n\n        :param int level: the logger to level.\n        :param str logger: the logger to update the level. If not given, the root logger level is updated.\n\n        .. versionchanged:: 3.4\n            The levels of the loggers changed by this function will be restored to their initial values at the\n            end of the test.\n        \"\"\"\n        logger_name = logger\n        logger = logging.getLogger(logger_name)\n        # save the original log-level to restore it during teardown\n        self._initial_log_levels.setdefault(logger_name, logger.level)\n        logger.setLevel(level)\n\n    @contextmanager\n    def at_level(self, level, logger=None):\n        \"\"\"Context manager that sets the level for capturing of logs. After the end of the 'with' statement the\n        level is restored to its original value.\n\n        :param int level: the logger to level.\n        :param str logger: the logger to update the level. If not given, the root logger level is updated.\n        \"\"\"\n        logger = logging.getLogger(logger)\n        orig_level = logger.level\n        logger.setLevel(level)\n        try:\n            yield\n        finally:\n            logger.setLevel(orig_level)"}, {"id": "_pytest.logging.LogCaptureFixture.__init__", "kind": "function", "range": [319, 4, 323, 61, 10568, 10766], "file_path": "src/_pytest/logging.py", "content": "def __init__(self, item) -> None:\n        \"\"\"Creates a new funcarg.\"\"\"\n        self._item = item\n        # dict of log name -> log level\n        self._initial_log_levels = {}  # type: Dict[str, int]"}, {"id": "_pytest.logging.LogCaptureFixture._finalize", "kind": "function", "range": [325, 4, 333, 34, 10772, 11098], "file_path": "src/_pytest/logging.py", "content": "def _finalize(self) -> None:\n        \"\"\"Finalizes the fixture.\n\n        This restores the log levels changed by :meth:`set_level`.\n        \"\"\"\n        # restore log levels\n        for logger_name, level in self._initial_log_levels.items():\n            logger = logging.getLogger(logger_name)\n            logger.setLevel(level)"}, {"id": "_pytest.logging.LogCaptureFixture.handler", "kind": "function", "range": [335, 4, 340, 88, 11104, 11304], "file_path": "src/_pytest/logging.py", "content": "@property\n    def handler(self) -> LogCaptureHandler:\n        \"\"\"\n        :rtype: LogCaptureHandler\n        \"\"\"\n        return self._item.catch_log_handler  # type: ignore[no-any-return]  # noqa: F723"}, {"id": "_pytest.logging.LogCaptureFixture.get_records", "kind": "function", "range": [342, 4, 358, 21, 11310, 11927], "file_path": "src/_pytest/logging.py", "content": "def get_records(self, when: str) -> List[logging.LogRecord]:\n        \"\"\"\n        Get the logging records for one of the possible test phases.\n\n        :param str when:\n            Which test phase to obtain the records from. Valid values are: \"setup\", \"call\" and \"teardown\".\n\n        :rtype: List[logging.LogRecord]\n        :return: the list of captured records at the given stage\n\n        .. versionadded:: 3.4\n        \"\"\"\n        handler = self._item.catch_log_handlers.get(when)\n        if handler:\n            return handler.records  # type: ignore[no-any-return]  # noqa: F723\n        else:\n            return []"}, {"id": "_pytest.logging.LogCaptureFixture.text", "kind": "function", "range": [360, 4, 363, 76, 11933, 12085], "file_path": "src/_pytest/logging.py", "content": "@property\n    def text(self):\n        \"\"\"Returns the formatted log text.\"\"\"\n        return _remove_ansi_escape_sequences(self.handler.stream.getvalue())"}, {"id": "_pytest.logging.LogCaptureFixture.records", "kind": "function", "range": [365, 4, 368, 35, 12091, 12206], "file_path": "src/_pytest/logging.py", "content": "@property\n    def records(self):\n        \"\"\"Returns the list of log records.\"\"\"\n        return self.handler.records"}, {"id": "_pytest.logging.LogCaptureFixture.record_tuples", "kind": "function", "range": [370, 4, 379, 74, 12212, 12539], "file_path": "src/_pytest/logging.py", "content": "@property\n    def record_tuples(self):\n        \"\"\"Returns a list of a stripped down version of log records intended\n        for use in assertion comparison.\n\n        The format of the tuple is:\n\n            (logger_name, log_level, message)\n        \"\"\"\n        return [(r.name, r.levelno, r.getMessage()) for r in self.records]"}, {"id": "_pytest.logging.LogCaptureFixture.messages", "kind": "function", "range": [381, 4, 395, 53, 12545, 13293], "file_path": "src/_pytest/logging.py", "content": "@property\n    def messages(self):\n        \"\"\"Returns a list of format-interpolated log messages.\n\n        Unlike 'records', which contains the format string and parameters for interpolation, log messages in this list\n        are all interpolated.\n        Unlike 'text', which contains the output from the handler, log messages in this list are unadorned with\n        levels, timestamps, etc, making exact comparisons more reliable.\n\n        Note that traceback or stack info (from :func:`logging.exception` or the `exc_info` or `stack_info` arguments\n        to the logging functions) is not included, as this is added by the formatter in the handler.\n\n        .. versionadded:: 3.7\n        \"\"\"\n        return [r.getMessage() for r in self.records]"}, {"id": "_pytest.logging.LogCaptureFixture.clear", "kind": "function", "range": [397, 4, 399, 28, 13299, 13415], "file_path": "src/_pytest/logging.py", "content": "def clear(self):\n        \"\"\"Reset the list of log records and the captured log text.\"\"\"\n        self.handler.reset()"}, {"id": "_pytest.logging.LogCaptureFixture.set_level", "kind": "function", "range": [401, 4, 416, 30, 13421, 14178], "file_path": "src/_pytest/logging.py", "content": "def set_level(self, level, logger=None):\n        \"\"\"Sets the level for capturing of logs. The level will be restored to its previous value at the end of\n        the test.\n\n        :param int level: the logger to level.\n        :param str logger: the logger to update the level. If not given, the root logger level is updated.\n\n        .. versionchanged:: 3.4\n            The levels of the loggers changed by this function will be restored to their initial values at the\n            end of the test.\n        \"\"\"\n        logger_name = logger\n        logger = logging.getLogger(logger_name)\n        # save the original log-level to restore it during teardown\n        self._initial_log_levels.setdefault(logger_name, logger.level)\n        logger.setLevel(level)"}, {"id": "_pytest.logging.LogCaptureFixture.at_level", "kind": "function", "range": [418, 4, 432, 39, 14184, 14767], "file_path": "src/_pytest/logging.py", "content": "@contextmanager\n    def at_level(self, level, logger=None):\n        \"\"\"Context manager that sets the level for capturing of logs. After the end of the 'with' statement the\n        level is restored to its original value.\n\n        :param int level: the logger to level.\n        :param str logger: the logger to update the level. If not given, the root logger level is updated.\n        \"\"\"\n        logger = logging.getLogger(logger)\n        orig_level = logger.level\n        logger.setLevel(level)\n        try:\n            yield\n        finally:\n            logger.setLevel(orig_level)"}, {"id": "_pytest.logging.caplog", "kind": "function", "range": [435, 0, 449, 22, 14770, 15393], "file_path": "src/_pytest/logging.py", "content": "@pytest.fixture\ndef caplog(request):\n    \"\"\"Access and control log capturing.\n\n    Captured logs are available through the following properties/methods::\n\n    * caplog.messages        -> list of format-interpolated log messages\n    * caplog.text            -> string containing formatted log output\n    * caplog.records         -> list of logging.LogRecord instances\n    * caplog.record_tuples   -> list of (logger_name, level, message) tuples\n    * caplog.clear()         -> clear captured records and formatted log output string\n    \"\"\"\n    result = LogCaptureFixture(request.node)\n    yield result\n    result._finalize()"}, {"id": "_pytest.logging.get_log_level_for_setting", "kind": "function", "range": [452, 0, 472, 9, 15396, 16186], "file_path": "src/_pytest/logging.py", "content": "def get_log_level_for_setting(config: Config, *setting_names: str) -> Optional[int]:\n    for setting_name in setting_names:\n        log_level = config.getoption(setting_name)\n        if log_level is None:\n            log_level = config.getini(setting_name)\n        if log_level:\n            break\n    else:\n        return None\n\n    if isinstance(log_level, str):\n        log_level = log_level.upper()\n    try:\n        return int(getattr(logging, log_level, log_level))\n    except ValueError:\n        # Python logging does not recognise this as a logging level\n        raise pytest.UsageError(\n            \"'{}' is not recognized as a logging level name for \"\n            \"'{}'. Please consider passing the \"\n            \"logging level num instead.\".format(log_level, setting_name)\n        )"}, {"id": "_pytest.logging.pytest_configure", "kind": "function", "range": [476, 0, 478, 74, 16248, 16383], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(trylast=True)\ndef pytest_configure(config):\n    config.pluginmanager.register(LoggingPlugin(config), \"logging-plugin\")"}, {"id": "_pytest.logging.LoggingPlugin", "kind": "class", "range": [481, 0, 735, 42, 16386, 26217], "file_path": "src/_pytest/logging.py", "content": "class LoggingPlugin:\n    \"\"\"Attaches to the logging module and captures log messages for each test.\n    \"\"\"\n\n    def __init__(self, config: Config) -> None:\n        \"\"\"Creates a new plugin to capture log messages.\n\n        The formatter can be safely shared across all handlers so\n        create a single one for the entire test session here.\n        \"\"\"\n        self._config = config\n\n        self.print_logs = get_option_ini(config, \"log_print\")\n        if not self.print_logs:\n            from _pytest.warnings import _issue_warning_captured\n            from _pytest.deprecated import NO_PRINT_LOGS\n\n            _issue_warning_captured(NO_PRINT_LOGS, self._config.hook, stacklevel=2)\n\n        self.formatter = self._create_formatter(\n            get_option_ini(config, \"log_format\"),\n            get_option_ini(config, \"log_date_format\"),\n            get_option_ini(config, \"log_auto_indent\"),\n        )\n        self.log_level = get_log_level_for_setting(config, \"log_level\")\n\n        self.log_file_level = get_log_level_for_setting(config, \"log_file_level\")\n        self.log_file_format = get_option_ini(config, \"log_file_format\", \"log_format\")\n        self.log_file_date_format = get_option_ini(\n            config, \"log_file_date_format\", \"log_date_format\"\n        )\n        self.log_file_formatter = logging.Formatter(\n            self.log_file_format, datefmt=self.log_file_date_format\n        )\n\n        log_file = get_option_ini(config, \"log_file\")\n        if log_file:\n            self.log_file_handler = logging.FileHandler(\n                log_file, mode=\"w\", encoding=\"UTF-8\"\n            )  # type: Optional[logging.FileHandler]\n            self.log_file_handler.setFormatter(self.log_file_formatter)\n        else:\n            self.log_file_handler = None\n\n        self.log_cli_handler = None\n\n        self.live_logs_context = lambda: nullcontext()\n        # Note that the lambda for the live_logs_context is needed because\n        # live_logs_context can otherwise not be entered multiple times due\n        # to limitations of contextlib.contextmanager.\n\n        if self._log_cli_enabled():\n            self._setup_cli_logging()\n\n    def _create_formatter(self, log_format, log_date_format, auto_indent):\n        # color option doesn't exist if terminal plugin is disabled\n        color = getattr(self._config.option, \"color\", \"no\")\n        if color != \"no\" and ColoredLevelFormatter.LEVELNAME_FMT_REGEX.search(\n            log_format\n        ):\n            formatter = ColoredLevelFormatter(\n                create_terminal_writer(self._config), log_format, log_date_format\n            )  # type: logging.Formatter\n        else:\n            formatter = logging.Formatter(log_format, log_date_format)\n\n        formatter._style = PercentStyleMultiline(\n            formatter._style._fmt, auto_indent=auto_indent\n        )\n\n        return formatter\n\n    def _setup_cli_logging(self):\n        config = self._config\n        terminal_reporter = config.pluginmanager.get_plugin(\"terminalreporter\")\n        if terminal_reporter is None:\n            # terminal reporter is disabled e.g. by pytest-xdist.\n            return\n\n        capture_manager = config.pluginmanager.get_plugin(\"capturemanager\")\n        # if capturemanager plugin is disabled, live logging still works.\n        log_cli_handler = _LiveLoggingStreamHandler(terminal_reporter, capture_manager)\n\n        log_cli_formatter = self._create_formatter(\n            get_option_ini(config, \"log_cli_format\", \"log_format\"),\n            get_option_ini(config, \"log_cli_date_format\", \"log_date_format\"),\n            get_option_ini(config, \"log_auto_indent\"),\n        )\n\n        log_cli_level = get_log_level_for_setting(config, \"log_cli_level\", \"log_level\")\n        self.log_cli_handler = log_cli_handler\n        self.live_logs_context = lambda: catching_logs(\n            log_cli_handler, formatter=log_cli_formatter, level=log_cli_level\n        )\n\n    def set_log_path(self, fname):\n        \"\"\"Public method, which can set filename parameter for\n        Logging.FileHandler(). Also creates parent directory if\n        it does not exist.\n\n        .. warning::\n            Please considered as an experimental API.\n        \"\"\"\n        fname = Path(fname)\n\n        if not fname.is_absolute():\n            fname = Path(self._config.rootdir, fname)\n\n        if not fname.parent.exists():\n            fname.parent.mkdir(exist_ok=True, parents=True)\n\n        self.log_file_handler = logging.FileHandler(\n            str(fname), mode=\"w\", encoding=\"UTF-8\"\n        )\n        self.log_file_handler.setFormatter(self.log_file_formatter)\n\n    def _log_cli_enabled(self):\n        \"\"\"Return True if log_cli should be considered enabled, either explicitly\n        or because --log-cli-level was given in the command-line.\n        \"\"\"\n        return self._config.getoption(\n            \"--log-cli-level\"\n        ) is not None or self._config.getini(\"log_cli\")\n\n    @pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_collection(self) -> Generator[None, None, None]:\n        with self.live_logs_context():\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(\"collection\")\n\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield\n            else:\n                yield\n\n    @contextmanager\n    def _runtest_for(self, item, when):\n        with self._runtest_for_main(item, when):\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield\n            else:\n                yield\n\n    @contextmanager\n    def _runtest_for_main(\n        self, item: nodes.Item, when: str\n    ) -> Generator[None, None, None]:\n        \"\"\"Implements the internals of pytest_runtest_xxx() hook.\"\"\"\n        with catching_logs(\n            LogCaptureHandler(), formatter=self.formatter, level=self.log_level\n        ) as log_handler:\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(when)\n\n            if item is None:\n                yield  # run the test\n                return\n\n            if not hasattr(item, \"catch_log_handlers\"):\n                item.catch_log_handlers = {}  # type: ignore[attr-defined]  # noqa: F821\n            item.catch_log_handlers[when] = log_handler  # type: ignore[attr-defined]  # noqa: F821\n            item.catch_log_handler = log_handler  # type: ignore[attr-defined]  # noqa: F821\n            try:\n                yield  # run test\n            finally:\n                if when == \"teardown\":\n                    del item.catch_log_handler  # type: ignore[attr-defined]  # noqa: F821\n                    del item.catch_log_handlers  # type: ignore[attr-defined]  # noqa: F821\n\n            if self.print_logs:\n                # Add a captured log section to the report.\n                log = log_handler.stream.getvalue().strip()\n                item.add_report_section(when, \"log\", log)\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_setup(self, item):\n        with self._runtest_for(item, \"setup\"):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_call(self, item):\n        with self._runtest_for(item, \"call\"):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_teardown(self, item):\n        with self._runtest_for(item, \"teardown\"):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_logstart(self):\n        if self.log_cli_handler:\n            self.log_cli_handler.reset()\n        with self._runtest_for(None, \"start\"):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_logfinish(self):\n        with self._runtest_for(None, \"finish\"):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_logreport(self):\n        with self._runtest_for(None, \"logreport\"):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_sessionfinish(self):\n        with self.live_logs_context():\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(\"sessionfinish\")\n            if self.log_file_handler is not None:\n                try:\n                    with catching_logs(\n                        self.log_file_handler, level=self.log_file_level\n                    ):\n                        yield\n                finally:\n                    # Close the FileHandler explicitly.\n                    # (logging.shutdown might have lost the weakref?!)\n                    self.log_file_handler.close()\n            else:\n                yield\n\n    @pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_sessionstart(self):\n        with self.live_logs_context():\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(\"sessionstart\")\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield\n            else:\n                yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtestloop(self, session):\n        \"\"\"Runs all collected test items.\"\"\"\n\n        if session.config.option.collectonly:\n            yield\n            return\n\n        if self._log_cli_enabled() and self._config.getoption(\"verbose\") < 1:\n            # setting verbose flag is needed to avoid messy test progress output\n            self._config.option.verbose = 1\n\n        with self.live_logs_context():\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield  # run all the tests\n            else:\n                yield  # run all the tests"}, {"id": "_pytest.logging.LoggingPlugin.__init__", "kind": "function", "range": [485, 4, 533, 37, 16499, 18529], "file_path": "src/_pytest/logging.py", "content": "def __init__(self, config: Config) -> None:\n        \"\"\"Creates a new plugin to capture log messages.\n\n        The formatter can be safely shared across all handlers so\n        create a single one for the entire test session here.\n        \"\"\"\n        self._config = config\n\n        self.print_logs = get_option_ini(config, \"log_print\")\n        if not self.print_logs:\n            from _pytest.warnings import _issue_warning_captured\n            from _pytest.deprecated import NO_PRINT_LOGS\n\n            _issue_warning_captured(NO_PRINT_LOGS, self._config.hook, stacklevel=2)\n\n        self.formatter = self._create_formatter(\n            get_option_ini(config, \"log_format\"),\n            get_option_ini(config, \"log_date_format\"),\n            get_option_ini(config, \"log_auto_indent\"),\n        )\n        self.log_level = get_log_level_for_setting(config, \"log_level\")\n\n        self.log_file_level = get_log_level_for_setting(config, \"log_file_level\")\n        self.log_file_format = get_option_ini(config, \"log_file_format\", \"log_format\")\n        self.log_file_date_format = get_option_ini(\n            config, \"log_file_date_format\", \"log_date_format\"\n        )\n        self.log_file_formatter = logging.Formatter(\n            self.log_file_format, datefmt=self.log_file_date_format\n        )\n\n        log_file = get_option_ini(config, \"log_file\")\n        if log_file:\n            self.log_file_handler = logging.FileHandler(\n                log_file, mode=\"w\", encoding=\"UTF-8\"\n            )  # type: Optional[logging.FileHandler]\n            self.log_file_handler.setFormatter(self.log_file_formatter)\n        else:\n            self.log_file_handler = None\n\n        self.log_cli_handler = None\n\n        self.live_logs_context = lambda: nullcontext()\n        # Note that the lambda for the live_logs_context is needed because\n        # live_logs_context can otherwise not be entered multiple times due\n        # to limitations of contextlib.contextmanager.\n\n        if self._log_cli_enabled():\n            self._setup_cli_logging()"}, {"id": "_pytest.logging.LoggingPlugin._create_formatter", "kind": "function", "range": [535, 4, 551, 24, 18535, 19247], "file_path": "src/_pytest/logging.py", "content": "def _create_formatter(self, log_format, log_date_format, auto_indent):\n        # color option doesn't exist if terminal plugin is disabled\n        color = getattr(self._config.option, \"color\", \"no\")\n        if color != \"no\" and ColoredLevelFormatter.LEVELNAME_FMT_REGEX.search(\n            log_format\n        ):\n            formatter = ColoredLevelFormatter(\n                create_terminal_writer(self._config), log_format, log_date_format\n            )  # type: logging.Formatter\n        else:\n            formatter = logging.Formatter(log_format, log_date_format)\n\n        formatter._style = PercentStyleMultiline(\n            formatter._style._fmt, auto_indent=auto_indent\n        )\n\n        return formatter"}, {"id": "_pytest.logging.LoggingPlugin._setup_cli_logging", "kind": "function", "range": [553, 4, 574, 9, 19253, 20298], "file_path": "src/_pytest/logging.py", "content": "def _setup_cli_logging(self):\n        config = self._config\n        terminal_reporter = config.pluginmanager.get_plugin(\"terminalreporter\")\n        if terminal_reporter is None:\n            # terminal reporter is disabled e.g. by pytest-xdist.\n            return\n\n        capture_manager = config.pluginmanager.get_plugin(\"capturemanager\")\n        # if capturemanager plugin is disabled, live logging still works.\n        log_cli_handler = _LiveLoggingStreamHandler(terminal_reporter, capture_manager)\n\n        log_cli_formatter = self._create_formatter(\n            get_option_ini(config, \"log_cli_format\", \"log_format\"),\n            get_option_ini(config, \"log_cli_date_format\", \"log_date_format\"),\n            get_option_ini(config, \"log_auto_indent\"),\n        )\n\n        log_cli_level = get_log_level_for_setting(config, \"log_cli_level\", \"log_level\")\n        self.log_cli_handler = log_cli_handler\n        self.live_logs_context = lambda: catching_logs(\n            log_cli_handler, formatter=log_cli_formatter, level=log_cli_level\n        )"}, {"id": "_pytest.logging.LoggingPlugin.set_log_path", "kind": "function", "range": [576, 4, 595, 67, 20304, 20977], "file_path": "src/_pytest/logging.py", "content": "def set_log_path(self, fname):\n        \"\"\"Public method, which can set filename parameter for\n        Logging.FileHandler(). Also creates parent directory if\n        it does not exist.\n\n        .. warning::\n            Please considered as an experimental API.\n        \"\"\"\n        fname = Path(fname)\n\n        if not fname.is_absolute():\n            fname = Path(self._config.rootdir, fname)\n\n        if not fname.parent.exists():\n            fname.parent.mkdir(exist_ok=True, parents=True)\n\n        self.log_file_handler = logging.FileHandler(\n            str(fname), mode=\"w\", encoding=\"UTF-8\"\n        )\n        self.log_file_handler.setFormatter(self.log_file_formatter)"}, {"id": "_pytest.logging.LoggingPlugin._log_cli_enabled", "kind": "function", "range": [597, 4, 603, 55, 20983, 21295], "file_path": "src/_pytest/logging.py", "content": "def _log_cli_enabled(self):\n        \"\"\"Return True if log_cli should be considered enabled, either explicitly\n        or because --log-cli-level was given in the command-line.\n        \"\"\"\n        return self._config.getoption(\n            \"--log-cli-level\"\n        ) is not None or self._config.getini(\"log_cli\")"}, {"id": "_pytest.logging.LoggingPlugin.pytest_collection", "kind": "function", "range": [605, 4, 615, 21, 21301, 21753], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_collection(self) -> Generator[None, None, None]:\n        with self.live_logs_context():\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(\"collection\")\n\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield\n            else:\n                yield"}, {"id": "_pytest.logging.LoggingPlugin._runtest_for", "kind": "function", "range": [617, 4, 624, 21, 21759, 22065], "file_path": "src/_pytest/logging.py", "content": "@contextmanager\n    def _runtest_for(self, item, when):\n        with self._runtest_for_main(item, when):\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield\n            else:\n                yield"}, {"id": "_pytest.logging.LoggingPlugin._runtest_for_main", "kind": "function", "range": [626, 4, 655, 57, 22071, 23420], "file_path": "src/_pytest/logging.py", "content": "@contextmanager\n    def _runtest_for_main(\n        self, item: nodes.Item, when: str\n    ) -> Generator[None, None, None]:\n        \"\"\"Implements the internals of pytest_runtest_xxx() hook.\"\"\"\n        with catching_logs(\n            LogCaptureHandler(), formatter=self.formatter, level=self.log_level\n        ) as log_handler:\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(when)\n\n            if item is None:\n                yield  # run the test\n                return\n\n            if not hasattr(item, \"catch_log_handlers\"):\n                item.catch_log_handlers = {}  # type: ignore[attr-defined]  # noqa: F821\n            item.catch_log_handlers[when] = log_handler  # type: ignore[attr-defined]  # noqa: F821\n            item.catch_log_handler = log_handler  # type: ignore[attr-defined]  # noqa: F821\n            try:\n                yield  # run test\n            finally:\n                if when == \"teardown\":\n                    del item.catch_log_handler  # type: ignore[attr-defined]  # noqa: F821\n                    del item.catch_log_handlers  # type: ignore[attr-defined]  # noqa: F821\n\n            if self.print_logs:\n                # Add a captured log section to the report.\n                log = log_handler.stream.getvalue().strip()\n                item.add_report_section(when, \"log\", log)"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtest_setup", "kind": "function", "range": [657, 4, 660, 17, 23426, 23567], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_setup(self, item):\n        with self._runtest_for(item, \"setup\"):\n            yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtest_call", "kind": "function", "range": [662, 4, 665, 17, 23573, 23712], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_call(self, item):\n        with self._runtest_for(item, \"call\"):\n            yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtest_teardown", "kind": "function", "range": [667, 4, 670, 17, 23718, 23865], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_teardown(self, item):\n        with self._runtest_for(item, \"teardown\"):\n            yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtest_logstart", "kind": "function", "range": [672, 4, 677, 17, 23871, 24083], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_logstart(self):\n        if self.log_cli_handler:\n            self.log_cli_handler.reset()\n        with self._runtest_for(None, \"start\"):\n            yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtest_logfinish", "kind": "function", "range": [679, 4, 682, 17, 24089, 24229], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_logfinish(self):\n        with self._runtest_for(None, \"finish\"):\n            yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtest_logreport", "kind": "function", "range": [684, 4, 687, 17, 24235, 24378], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_logreport(self):\n        with self._runtest_for(None, \"logreport\"):\n            yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_sessionfinish", "kind": "function", "range": [689, 4, 705, 21, 24384, 25087], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_sessionfinish(self):\n        with self.live_logs_context():\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(\"sessionfinish\")\n            if self.log_file_handler is not None:\n                try:\n                    with catching_logs(\n                        self.log_file_handler, level=self.log_file_level\n                    ):\n                        yield\n                finally:\n                    # Close the FileHandler explicitly.\n                    # (logging.shutdown might have lost the weakref?!)\n                    self.log_file_handler.close()\n            else:\n                yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_sessionstart", "kind": "function", "range": [707, 4, 716, 21, 25093, 25517], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_sessionstart(self):\n        with self.live_logs_context():\n            if self.log_cli_handler:\n                self.log_cli_handler.set_when(\"sessionstart\")\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield\n            else:\n                yield"}, {"id": "_pytest.logging.LoggingPlugin.pytest_runtestloop", "kind": "function", "range": [718, 4, 735, 42, 25523, 26217], "file_path": "src/_pytest/logging.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtestloop(self, session):\n        \"\"\"Runs all collected test items.\"\"\"\n\n        if session.config.option.collectonly:\n            yield\n            return\n\n        if self._log_cli_enabled() and self._config.getoption(\"verbose\") < 1:\n            # setting verbose flag is needed to avoid messy test progress output\n            self._config.option.verbose = 1\n\n        with self.live_logs_context():\n            if self.log_file_handler is not None:\n                with catching_logs(self.log_file_handler, level=self.log_file_level):\n                    yield  # run all the tests\n            else:\n                yield  # run all the tests"}, {"id": "_pytest.logging._LiveLoggingStreamHandler", "kind": "class", "range": [738, 0, 786, 52, 26220, 28188], "file_path": "src/_pytest/logging.py", "content": "class _LiveLoggingStreamHandler(logging.StreamHandler):\n    \"\"\"\n    Custom StreamHandler used by the live logging feature: it will write a newline before the first log message\n    in each test.\n\n    During live logging we must also explicitly disable stdout/stderr capturing otherwise it will get captured\n    and won't appear in the terminal.\n    \"\"\"\n\n    def __init__(self, terminal_reporter, capture_manager):\n        \"\"\"\n        :param _pytest.terminal.TerminalReporter terminal_reporter:\n        :param _pytest.capture.CaptureManager capture_manager:\n        \"\"\"\n        logging.StreamHandler.__init__(self, stream=terminal_reporter)\n        self.capture_manager = capture_manager\n        self.reset()\n        self.set_when(None)\n        self._test_outcome_written = False\n\n    def reset(self):\n        \"\"\"Reset the handler; should be called before the start of each test\"\"\"\n        self._first_record_emitted = False\n\n    def set_when(self, when):\n        \"\"\"Prepares for the given test phase (setup/call/teardown)\"\"\"\n        self._when = when\n        self._section_name_shown = False\n        if when == \"start\":\n            self._test_outcome_written = False\n\n    def emit(self, record):\n        ctx_manager = (\n            self.capture_manager.global_and_fixture_disabled()\n            if self.capture_manager\n            else nullcontext()\n        )\n        with ctx_manager:\n            if not self._first_record_emitted:\n                self.stream.write(\"\\n\")\n                self._first_record_emitted = True\n            elif self._when in (\"teardown\", \"finish\"):\n                if not self._test_outcome_written:\n                    self._test_outcome_written = True\n                    self.stream.write(\"\\n\")\n            if not self._section_name_shown and self._when:\n                self.stream.section(\"live log \" + self._when, sep=\"-\", bold=True)\n                self._section_name_shown = True\n            logging.StreamHandler.emit(self, record)"}, {"id": "_pytest.logging._LiveLoggingStreamHandler.__init__", "kind": "function", "range": [747, 4, 756, 42, 26577, 26997], "file_path": "src/_pytest/logging.py", "content": "def __init__(self, terminal_reporter, capture_manager):\n        \"\"\"\n        :param _pytest.terminal.TerminalReporter terminal_reporter:\n        :param _pytest.capture.CaptureManager capture_manager:\n        \"\"\"\n        logging.StreamHandler.__init__(self, stream=terminal_reporter)\n        self.capture_manager = capture_manager\n        self.reset()\n        self.set_when(None)\n        self._test_outcome_written = False"}, {"id": "_pytest.logging._LiveLoggingStreamHandler.reset", "kind": "function", "range": [758, 4, 760, 42, 27003, 27142], "file_path": "src/_pytest/logging.py", "content": "def reset(self):\n        \"\"\"Reset the handler; should be called before the start of each test\"\"\"\n        self._first_record_emitted = False"}, {"id": "_pytest.logging._LiveLoggingStreamHandler.set_when", "kind": "function", "range": [762, 4, 767, 46, 27148, 27385], "file_path": "src/_pytest/logging.py", "content": "def set_when(self, when):\n        \"\"\"Prepares for the given test phase (setup/call/teardown)\"\"\"\n        self._when = when\n        self._section_name_shown = False\n        if when == \"start\":\n            self._test_outcome_written = False"}, {"id": "_pytest.logging._LiveLoggingStreamHandler.emit", "kind": "function", "range": [769, 4, 786, 52, 27391, 28188], "file_path": "src/_pytest/logging.py", "content": "def emit(self, record):\n        ctx_manager = (\n            self.capture_manager.global_and_fixture_disabled()\n            if self.capture_manager\n            else nullcontext()\n        )\n        with ctx_manager:\n            if not self._first_record_emitted:\n                self.stream.write(\"\\n\")\n                self._first_record_emitted = True\n            elif self._when in (\"teardown\", \"finish\"):\n                if not self._test_outcome_written:\n                    self._test_outcome_written = True\n                    self.stream.write(\"\\n\")\n            if not self._section_name_shown and self._when:\n                self.stream.section(\"live log \" + self._when, sep=\"-\", bold=True)\n                self._section_name_shown = True\n            logging.StreamHandler.emit(self, record)"}, {"id": "_pytest.unittest.pytest_pycollect_makeitem", "kind": "function", "range": [20, 0, 28, 66, 595, 948], "file_path": "src/_pytest/unittest.py", "content": "def pytest_pycollect_makeitem(collector, name, obj):\n    # has unittest been imported and is obj a subclass of its TestCase?\n    try:\n        if not issubclass(obj, sys.modules[\"unittest\"].TestCase):\n            return\n    except Exception:\n        return\n    # yes, so let's collect it\n    return UnitTestCase.from_parent(collector, name=name, obj=obj)"}, {"id": "_pytest.unittest.UnitTestCase", "kind": "class", "range": [31, 0, 80, 54, 951, 2907], "file_path": "src/_pytest/unittest.py", "content": "class UnitTestCase(Class):\n    # marker for fixturemanger.getfixtureinfo()\n    # to declare that our children do not support funcargs\n    nofuncargs = True\n\n    def collect(self):\n        from unittest import TestLoader\n\n        cls = self.obj\n        if not getattr(cls, \"__test__\", True):\n            return\n\n        skipped = getattr(cls, \"__unittest_skip__\", False)\n        if not skipped:\n            self._inject_setup_teardown_fixtures(cls)\n            self._inject_setup_class_fixture()\n\n        self.session._fixturemanager.parsefactories(self, unittest=True)\n        loader = TestLoader()\n        foundsomething = False\n        for name in loader.getTestCaseNames(self.obj):\n            x = getattr(self.obj, name)\n            if not getattr(x, \"__test__\", True):\n                continue\n            funcobj = getimfunc(x)\n            yield TestCaseFunction.from_parent(self, name=name, callobj=funcobj)\n            foundsomething = True\n\n        if not foundsomething:\n            runtest = getattr(self.obj, \"runTest\", None)\n            if runtest is not None:\n                ut = sys.modules.get(\"twisted.trial.unittest\", None)\n                if ut is None or runtest != ut.TestCase.runTest:\n                    # TODO: callobj consistency\n                    yield TestCaseFunction.from_parent(self, name=\"runTest\")\n\n    def _inject_setup_teardown_fixtures(self, cls):\n        \"\"\"Injects a hidden auto-use fixture to invoke setUpClass/setup_method and corresponding\n        teardown functions (#517)\"\"\"\n        class_fixture = _make_xunit_fixture(\n            cls, \"setUpClass\", \"tearDownClass\", scope=\"class\", pass_self=False\n        )\n        if class_fixture:\n            cls.__pytest_class_setup = class_fixture\n\n        method_fixture = _make_xunit_fixture(\n            cls, \"setup_method\", \"teardown_method\", scope=\"function\", pass_self=True\n        )\n        if method_fixture:\n            cls.__pytest_method_setup = method_fixture"}, {"id": "_pytest.unittest.UnitTestCase.nofuncargs", "kind": "variable", "range": [34, 4, 34, 21, 1089, 1106], "file_path": "src/_pytest/unittest.py", "content": "nofuncargs = True"}, {"id": "_pytest.unittest.UnitTestCase.collect", "kind": "function", "range": [36, 4, 65, 76, 1112, 2283], "file_path": "src/_pytest/unittest.py", "content": "def collect(self):\n        from unittest import TestLoader\n\n        cls = self.obj\n        if not getattr(cls, \"__test__\", True):\n            return\n\n        skipped = getattr(cls, \"__unittest_skip__\", False)\n        if not skipped:\n            self._inject_setup_teardown_fixtures(cls)\n            self._inject_setup_class_fixture()\n\n        self.session._fixturemanager.parsefactories(self, unittest=True)\n        loader = TestLoader()\n        foundsomething = False\n        for name in loader.getTestCaseNames(self.obj):\n            x = getattr(self.obj, name)\n            if not getattr(x, \"__test__\", True):\n                continue\n            funcobj = getimfunc(x)\n            yield TestCaseFunction.from_parent(self, name=name, callobj=funcobj)\n            foundsomething = True\n\n        if not foundsomething:\n            runtest = getattr(self.obj, \"runTest\", None)\n            if runtest is not None:\n                ut = sys.modules.get(\"twisted.trial.unittest\", None)\n                if ut is None or runtest != ut.TestCase.runTest:\n                    # TODO: callobj consistency\n                    yield TestCaseFunction.from_parent(self, name=\"runTest\")"}, {"id": "_pytest.unittest.UnitTestCase._inject_setup_teardown_fixtures", "kind": "function", "range": [67, 4, 80, 54, 2289, 2907], "file_path": "src/_pytest/unittest.py", "content": "def _inject_setup_teardown_fixtures(self, cls):\n        \"\"\"Injects a hidden auto-use fixture to invoke setUpClass/setup_method and corresponding\n        teardown functions (#517)\"\"\"\n        class_fixture = _make_xunit_fixture(\n            cls, \"setUpClass\", \"tearDownClass\", scope=\"class\", pass_self=False\n        )\n        if class_fixture:\n            cls.__pytest_class_setup = class_fixture\n\n        method_fixture = _make_xunit_fixture(\n            cls, \"setup_method\", \"teardown_method\", scope=\"function\", pass_self=True\n        )\n        if method_fixture:\n            cls.__pytest_method_setup = method_fixture"}, {"id": "_pytest.unittest._make_xunit_fixture", "kind": "function", "range": [83, 0, 106, 18, 2910, 3683], "file_path": "src/_pytest/unittest.py", "content": "def _make_xunit_fixture(obj, setup_name, teardown_name, scope, pass_self):\n    setup = getattr(obj, setup_name, None)\n    teardown = getattr(obj, teardown_name, None)\n    if setup is None and teardown is None:\n        return None\n\n    @pytest.fixture(scope=scope, autouse=True)\n    def fixture(self, request):\n        if getattr(self, \"__unittest_skip__\", None):\n            reason = self.__unittest_skip_why__\n            pytest.skip(reason)\n        if setup is not None:\n            if pass_self:\n                setup(self, request.function)\n            else:\n                setup()\n        yield\n        if teardown is not None:\n            if pass_self:\n                teardown(self, request.function)\n            else:\n                teardown()\n\n    return fixture"}, {"id": "_pytest.unittest.TestCaseFunction", "kind": "class", "range": [109, 0, 240, 41, 3686, 8712], "file_path": "src/_pytest/unittest.py", "content": "class TestCaseFunction(Function):\n    nofuncargs = True\n    _excinfo = None\n    _testcase = None\n\n    def setup(self):\n        # a bound method to be called during teardown() if set (see 'runtest()')\n        self._explicit_tearDown = None\n        self._testcase = self.parent.obj(self.name)\n        self._obj = getattr(self._testcase, self.name)\n        if hasattr(self, \"_request\"):\n            self._request._fillfixtures()\n\n    def teardown(self):\n        if self._explicit_tearDown is not None:\n            self._explicit_tearDown()\n            self._explicit_tearDown = None\n        self._testcase = None\n        self._obj = None\n\n    def startTest(self, testcase):\n        pass\n\n    def _addexcinfo(self, rawexcinfo):\n        # unwrap potential exception info (see twisted trial support below)\n        rawexcinfo = getattr(rawexcinfo, \"_rawexcinfo\", rawexcinfo)\n        try:\n            excinfo = _pytest._code.ExceptionInfo(rawexcinfo)\n            # invoke the attributes to trigger storing the traceback\n            # trial causes some issue there\n            excinfo.value\n            excinfo.traceback\n        except TypeError:\n            try:\n                try:\n                    values = traceback.format_exception(*rawexcinfo)\n                    values.insert(\n                        0,\n                        \"NOTE: Incompatible Exception Representation, \"\n                        \"displaying natively:\\n\\n\",\n                    )\n                    fail(\"\".join(values), pytrace=False)\n                except (fail.Exception, KeyboardInterrupt):\n                    raise\n                except:  # noqa\n                    fail(\n                        \"ERROR: Unknown Incompatible Exception \"\n                        \"representation:\\n%r\" % (rawexcinfo,),\n                        pytrace=False,\n                    )\n            except KeyboardInterrupt:\n                raise\n            except fail.Exception:\n                excinfo = _pytest._code.ExceptionInfo.from_current()\n        self.__dict__.setdefault(\"_excinfo\", []).append(excinfo)\n\n    def addError(self, testcase, rawexcinfo):\n        try:\n            if isinstance(rawexcinfo[1], exit.Exception):\n                exit(rawexcinfo[1].msg)\n        except TypeError:\n            pass\n        self._addexcinfo(rawexcinfo)\n\n    def addFailure(self, testcase, rawexcinfo):\n        self._addexcinfo(rawexcinfo)\n\n    def addSkip(self, testcase, reason):\n        try:\n            skip(reason)\n        except skip.Exception:\n            self._store[skipped_by_mark_key] = True\n            self._addexcinfo(sys.exc_info())\n\n    def addExpectedFailure(self, testcase, rawexcinfo, reason=\"\"):\n        try:\n            xfail(str(reason))\n        except xfail.Exception:\n            self._addexcinfo(sys.exc_info())\n\n    def addUnexpectedSuccess(self, testcase, reason=\"\"):\n        self._store[unexpectedsuccess_key] = reason\n\n    def addSuccess(self, testcase):\n        pass\n\n    def stopTest(self, testcase):\n        pass\n\n    def _expecting_failure(self, test_method) -> bool:\n        \"\"\"Return True if the given unittest method (or the entire class) is marked\n        with @expectedFailure\"\"\"\n        expecting_failure_method = getattr(\n            test_method, \"__unittest_expecting_failure__\", False\n        )\n        expecting_failure_class = getattr(self, \"__unittest_expecting_failure__\", False)\n        return bool(expecting_failure_class or expecting_failure_method)\n\n    def runtest(self):\n        from _pytest.debugging import maybe_wrap_pytest_function_for_tracing\n\n        maybe_wrap_pytest_function_for_tracing(self)\n\n        # let the unittest framework handle async functions\n        if is_async_function(self.obj):\n            self._testcase(self)\n        else:\n            # when --pdb is given, we want to postpone calling tearDown() otherwise\n            # when entering the pdb prompt, tearDown() would have probably cleaned up\n            # instance variables, which makes it difficult to debug\n            # arguably we could always postpone tearDown(), but this changes the moment where the\n            # TestCase instance interacts with the results object, so better to only do it\n            # when absolutely needed\n            if self.config.getoption(\"usepdb\"):\n                self._explicit_tearDown = self._testcase.tearDown\n                setattr(self._testcase, \"tearDown\", lambda *args: None)\n\n            # we need to update the actual bound method with self.obj, because\n            # wrap_pytest_function_for_tracing replaces self.obj by a wrapper\n            setattr(self._testcase, self.name, self.obj)\n            try:\n                self._testcase(result=self)\n            finally:\n                delattr(self._testcase, self.name)\n\n    def _prunetraceback(self, excinfo):\n        Function._prunetraceback(self, excinfo)\n        traceback = excinfo.traceback.filter(\n            lambda x: not x.frame.f_globals.get(\"__unittest\")\n        )\n        if traceback:\n            excinfo.traceback = traceback"}, {"id": "_pytest.unittest.TestCaseFunction.nofuncargs", "kind": "variable", "range": [110, 4, 110, 21, 3724, 3741], "file_path": "src/_pytest/unittest.py", "content": "nofuncargs = True"}, {"id": "_pytest.unittest.TestCaseFunction._excinfo", "kind": "variable", "range": [111, 4, 111, 19, 3746, 3761], "file_path": "src/_pytest/unittest.py", "content": "_excinfo = None"}, {"id": "_pytest.unittest.TestCaseFunction._testcase", "kind": "variable", "range": [112, 4, 112, 20, 3766, 3782], "file_path": "src/_pytest/unittest.py", "content": "_testcase = None"}, {"id": "_pytest.unittest.TestCaseFunction.setup", "kind": "function", "range": [114, 4, 120, 41, 3788, 4111], "file_path": "src/_pytest/unittest.py", "content": "def setup(self):\n        # a bound method to be called during teardown() if set (see 'runtest()')\n        self._explicit_tearDown = None\n        self._testcase = self.parent.obj(self.name)\n        self._obj = getattr(self._testcase, self.name)\n        if hasattr(self, \"_request\"):\n            self._request._fillfixtures()"}, {"id": "_pytest.unittest.TestCaseFunction.teardown", "kind": "function", "range": [122, 4, 127, 24, 4117, 4320], "file_path": "src/_pytest/unittest.py", "content": "def teardown(self):\n        if self._explicit_tearDown is not None:\n            self._explicit_tearDown()\n            self._explicit_tearDown = None\n        self._testcase = None\n        self._obj = None"}, {"id": "_pytest.unittest.TestCaseFunction.startTest", "kind": "function", "range": [129, 4, 130, 12, 4326, 4369], "file_path": "src/_pytest/unittest.py", "content": "def startTest(self, testcase):\n        pass"}, {"id": "_pytest.unittest.TestCaseFunction._addexcinfo", "kind": "function", "range": [132, 4, 163, 64, 4375, 5757], "file_path": "src/_pytest/unittest.py", "content": "def _addexcinfo(self, rawexcinfo):\n        # unwrap potential exception info (see twisted trial support below)\n        rawexcinfo = getattr(rawexcinfo, \"_rawexcinfo\", rawexcinfo)\n        try:\n            excinfo = _pytest._code.ExceptionInfo(rawexcinfo)\n            # invoke the attributes to trigger storing the traceback\n            # trial causes some issue there\n            excinfo.value\n            excinfo.traceback\n        except TypeError:\n            try:\n                try:\n                    values = traceback.format_exception(*rawexcinfo)\n                    values.insert(\n                        0,\n                        \"NOTE: Incompatible Exception Representation, \"\n                        \"displaying natively:\\n\\n\",\n                    )\n                    fail(\"\".join(values), pytrace=False)\n                except (fail.Exception, KeyboardInterrupt):\n                    raise\n                except:  # noqa\n                    fail(\n                        \"ERROR: Unknown Incompatible Exception \"\n                        \"representation:\\n%r\" % (rawexcinfo,),\n                        pytrace=False,\n                    )\n            except KeyboardInterrupt:\n                raise\n            except fail.Exception:\n                excinfo = _pytest._code.ExceptionInfo.from_current()\n        self.__dict__.setdefault(\"_excinfo\", []).append(excinfo)"}, {"id": "_pytest.unittest.TestCaseFunction.addError", "kind": "function", "range": [165, 4, 171, 36, 5763, 5995], "file_path": "src/_pytest/unittest.py", "content": "def addError(self, testcase, rawexcinfo):\n        try:\n            if isinstance(rawexcinfo[1], exit.Exception):\n                exit(rawexcinfo[1].msg)\n        except TypeError:\n            pass\n        self._addexcinfo(rawexcinfo)"}, {"id": "_pytest.unittest.TestCaseFunction.addFailure", "kind": "function", "range": [173, 4, 174, 36, 6001, 6081], "file_path": "src/_pytest/unittest.py", "content": "def addFailure(self, testcase, rawexcinfo):\n        self._addexcinfo(rawexcinfo)"}, {"id": "_pytest.unittest.TestCaseFunction.addSkip", "kind": "function", "range": [176, 4, 181, 44, 6087, 6289], "file_path": "src/_pytest/unittest.py", "content": "def addSkip(self, testcase, reason):\n        try:\n            skip(reason)\n        except skip.Exception:\n            self._store[skipped_by_mark_key] = True\n            self._addexcinfo(sys.exc_info())"}, {"id": "_pytest.unittest.TestCaseFunction.addExpectedFailure", "kind": "function", "range": [183, 4, 187, 44, 6295, 6478], "file_path": "src/_pytest/unittest.py", "content": "def addExpectedFailure(self, testcase, rawexcinfo, reason=\"\"):\n        try:\n            xfail(str(reason))\n        except xfail.Exception:\n            self._addexcinfo(sys.exc_info())"}, {"id": "_pytest.unittest.TestCaseFunction.addUnexpectedSuccess", "kind": "function", "range": [189, 4, 190, 51, 6484, 6588], "file_path": "src/_pytest/unittest.py", "content": "def addUnexpectedSuccess(self, testcase, reason=\"\"):\n        self._store[unexpectedsuccess_key] = reason"}, {"id": "_pytest.unittest.TestCaseFunction.addSuccess", "kind": "function", "range": [192, 4, 193, 12, 6594, 6638], "file_path": "src/_pytest/unittest.py", "content": "def addSuccess(self, testcase):\n        pass"}, {"id": "_pytest.unittest.TestCaseFunction.stopTest", "kind": "function", "range": [195, 4, 196, 12, 6644, 6686], "file_path": "src/_pytest/unittest.py", "content": "def stopTest(self, testcase):\n        pass"}, {"id": "_pytest.unittest.TestCaseFunction._expecting_failure", "kind": "function", "range": [198, 4, 205, 72, 6692, 7140], "file_path": "src/_pytest/unittest.py", "content": "def _expecting_failure(self, test_method) -> bool:\n        \"\"\"Return True if the given unittest method (or the entire class) is marked\n        with @expectedFailure\"\"\"\n        expecting_failure_method = getattr(\n            test_method, \"__unittest_expecting_failure__\", False\n        )\n        expecting_failure_class = getattr(self, \"__unittest_expecting_failure__\", False)\n        return bool(expecting_failure_class or expecting_failure_method)"}, {"id": "_pytest.unittest.TestCaseFunction.runtest", "kind": "function", "range": [207, 4, 232, 50, 7146, 8441], "file_path": "src/_pytest/unittest.py", "content": "def runtest(self):\n        from _pytest.debugging import maybe_wrap_pytest_function_for_tracing\n\n        maybe_wrap_pytest_function_for_tracing(self)\n\n        # let the unittest framework handle async functions\n        if is_async_function(self.obj):\n            self._testcase(self)\n        else:\n            # when --pdb is given, we want to postpone calling tearDown() otherwise\n            # when entering the pdb prompt, tearDown() would have probably cleaned up\n            # instance variables, which makes it difficult to debug\n            # arguably we could always postpone tearDown(), but this changes the moment where the\n            # TestCase instance interacts with the results object, so better to only do it\n            # when absolutely needed\n            if self.config.getoption(\"usepdb\"):\n                self._explicit_tearDown = self._testcase.tearDown\n                setattr(self._testcase, \"tearDown\", lambda *args: None)\n\n            # we need to update the actual bound method with self.obj, because\n            # wrap_pytest_function_for_tracing replaces self.obj by a wrapper\n            setattr(self._testcase, self.name, self.obj)\n            try:\n                self._testcase(result=self)\n            finally:\n                delattr(self._testcase, self.name)"}, {"id": "_pytest.unittest.TestCaseFunction._prunetraceback", "kind": "function", "range": [234, 4, 240, 41, 8447, 8712], "file_path": "src/_pytest/unittest.py", "content": "def _prunetraceback(self, excinfo):\n        Function._prunetraceback(self, excinfo)\n        traceback = excinfo.traceback.filter(\n            lambda x: not x.frame.f_globals.get(\"__unittest\")\n        )\n        if traceback:\n            excinfo.traceback = traceback"}, {"id": "_pytest.unittest.pytest_runtest_makereport", "kind": "function", "range": [243, 0, 259, 36, 8715, 9345], "file_path": "src/_pytest/unittest.py", "content": "@hookimpl(tryfirst=True)\ndef pytest_runtest_makereport(item, call):\n    if isinstance(item, TestCaseFunction):\n        if item._excinfo:\n            call.excinfo = item._excinfo.pop(0)\n            try:\n                del call.result\n            except AttributeError:\n                pass\n\n    unittest = sys.modules.get(\"unittest\")\n    if unittest and call.excinfo and call.excinfo.errisinstance(unittest.SkipTest):\n        # let's substitute the excinfo with a pytest.skip one\n        call2 = CallInfo.from_call(\n            lambda: pytest.skip(str(call.excinfo.value)), call.when\n        )\n        call.excinfo = call2.excinfo"}, {"id": "_pytest.unittest.pytest_runtest_protocol", "kind": "function", "range": [265, 0, 292, 13, 9374, 10403], "file_path": "src/_pytest/unittest.py", "content": "@hookimpl(hookwrapper=True)\ndef pytest_runtest_protocol(item):\n    if isinstance(item, TestCaseFunction) and \"twisted.trial.unittest\" in sys.modules:\n        ut = sys.modules[\"twisted.python.failure\"]\n        Failure__init__ = ut.Failure.__init__\n        check_testcase_implements_trial_reporter()\n\n        def excstore(\n            self, exc_value=None, exc_type=None, exc_tb=None, captureVars=None\n        ):\n            if exc_value is None:\n                self._rawexcinfo = sys.exc_info()\n            else:\n                if exc_type is None:\n                    exc_type = type(exc_value)\n                self._rawexcinfo = (exc_type, exc_value, exc_tb)\n            try:\n                Failure__init__(\n                    self, exc_value, exc_type, exc_tb, captureVars=captureVars\n                )\n            except TypeError:\n                Failure__init__(self, exc_value, exc_type, exc_tb)\n\n        ut.Failure.__init__ = excstore\n        yield\n        ut.Failure.__init__ = Failure__init__\n    else:\n        yield"}, {"id": "_pytest.unittest.check_testcase_implements_trial_reporter", "kind": "function", "range": [295, 0, 302, 18, 10406, 10651], "file_path": "src/_pytest/unittest.py", "content": "def check_testcase_implements_trial_reporter(done=[]):\n    if done:\n        return\n    from zope.interface import classImplements\n    from twisted.trial.itrial import IReporter\n\n    classImplements(TestCaseFunction, IReporter)\n    done.append(1)"}, {"id": "_pytest.runner.pytest_addoption", "kind": "function", "range": [34, 0, 43, 5, 933, 1244], "file_path": "src/_pytest/runner.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"terminal reporting\", \"reporting\", after=\"general\")\n    group.addoption(\n        \"--durations\",\n        action=\"store\",\n        type=int,\n        default=None,\n        metavar=\"N\",\n        help=\"show N slowest setup/test durations (N=0 for all).\",\n    )"}, {"id": "_pytest.runner.pytest_terminal_summary", "kind": "function", "range": [46, 0, 75, 86, 1247, 2281], "file_path": "src/_pytest/runner.py", "content": "def pytest_terminal_summary(terminalreporter):\n    durations = terminalreporter.config.option.durations\n    verbose = terminalreporter.config.getvalue(\"verbose\")\n    if durations is None:\n        return\n    tr = terminalreporter\n    dlist = []\n    for replist in tr.stats.values():\n        for rep in replist:\n            if hasattr(rep, \"duration\"):\n                dlist.append(rep)\n    if not dlist:\n        return\n    dlist.sort(key=lambda x: x.duration)\n    dlist.reverse()\n    if not durations:\n        tr.write_sep(\"=\", \"slowest durations\")\n    else:\n        tr.write_sep(\"=\", \"slowest %s durations\" % durations)\n        dlist = dlist[:durations]\n\n    for i, rep in enumerate(dlist):\n        if verbose < 2 and rep.duration < 0.005:\n            tr.write_line(\"\")\n            tr.write_line(\n                \"(%s durations < 0.005s hidden.  Use -vv to show these durations.)\"\n                % (len(dlist) - i)\n            )\n            break\n        tr.write_line(\"{:02.2f}s {:<8} {}\".format(rep.duration, rep.when, rep.nodeid))"}, {"id": "_pytest.runner.pytest_sessionstart", "kind": "function", "range": [78, 0, 79, 38, 2284, 2356], "file_path": "src/_pytest/runner.py", "content": "def pytest_sessionstart(session):\n    session._setupstate = SetupState()"}, {"id": "_pytest.runner.pytest_sessionfinish", "kind": "function", "range": [82, 0, 83, 38, 2359, 2432], "file_path": "src/_pytest/runner.py", "content": "def pytest_sessionfinish(session):\n    session._setupstate.teardown_all()"}, {"id": "_pytest.runner.pytest_runtest_protocol", "kind": "function", "range": [86, 0, 90, 15, 2435, 2707], "file_path": "src/_pytest/runner.py", "content": "def pytest_runtest_protocol(item, nextitem):\n    item.ihook.pytest_runtest_logstart(nodeid=item.nodeid, location=item.location)\n    runtestprotocol(item, nextitem=nextitem)\n    item.ihook.pytest_runtest_logfinish(nodeid=item.nodeid, location=item.location)\n    return True"}, {"id": "_pytest.runner.runtestprotocol", "kind": "function", "range": [93, 0, 110, 18, 2710, 3437], "file_path": "src/_pytest/runner.py", "content": "def runtestprotocol(item, log=True, nextitem=None):\n    hasrequest = hasattr(item, \"_request\")\n    if hasrequest and not item._request:\n        item._initrequest()\n    rep = call_and_report(item, \"setup\", log)\n    reports = [rep]\n    if rep.passed:\n        if item.config.getoption(\"setupshow\", False):\n            show_test_item(item)\n        if not item.config.getoption(\"setuponly\", False):\n            reports.append(call_and_report(item, \"call\", log))\n    reports.append(call_and_report(item, \"teardown\", log, nextitem=nextitem))\n    # after all teardown hooks have been called\n    # want funcargs and request info to go away\n    if hasrequest:\n        item._request = False\n        item.funcargs = None\n    return reports"}, {"id": "_pytest.runner.show_test_item", "kind": "function", "range": [113, 0, 121, 73, 3440, 3804], "file_path": "src/_pytest/runner.py", "content": "def show_test_item(item):\n    \"\"\"Show test function, parameters and the fixtures of the test item.\"\"\"\n    tw = item.config.get_terminal_writer()\n    tw.line()\n    tw.write(\" \" * 8)\n    tw.write(item.nodeid)\n    used_fixtures = sorted(getattr(item, \"fixturenames\", []))\n    if used_fixtures:\n        tw.write(\" (fixtures used: {})\".format(\", \".join(used_fixtures)))"}, {"id": "_pytest.runner.pytest_runtest_setup", "kind": "function", "range": [124, 0, 126, 42, 3807, 3925], "file_path": "src/_pytest/runner.py", "content": "def pytest_runtest_setup(item):\n    _update_current_test_var(item, \"setup\")\n    item.session._setupstate.prepare(item)"}, {"id": "_pytest.runner.pytest_runtest_call", "kind": "function", "range": [129, 0, 146, 15, 3928, 4449], "file_path": "src/_pytest/runner.py", "content": "def pytest_runtest_call(item):\n    _update_current_test_var(item, \"call\")\n    try:\n        del sys.last_type\n        del sys.last_value\n        del sys.last_traceback\n    except AttributeError:\n        pass\n    try:\n        item.runtest()\n    except Exception as e:\n        # Store trace info to allow postmortem debugging\n        sys.last_type = type(e)\n        sys.last_value = e\n        assert e.__traceback__ is not None\n        # Skip *this* frame\n        sys.last_traceback = e.__traceback__.tb_next\n        raise e"}, {"id": "_pytest.runner.pytest_runtest_teardown", "kind": "function", "range": [149, 0, 152, 40, 4452, 4644], "file_path": "src/_pytest/runner.py", "content": "def pytest_runtest_teardown(item, nextitem):\n    _update_current_test_var(item, \"teardown\")\n    item.session._setupstate.teardown_exact(item, nextitem)\n    _update_current_test_var(item, None)"}, {"id": "_pytest.runner._update_current_test_var", "kind": "function", "range": [155, 0, 168, 32, 4647, 5170], "file_path": "src/_pytest/runner.py", "content": "def _update_current_test_var(item, when):\n    \"\"\"\n    Update :envvar:`PYTEST_CURRENT_TEST` to reflect the current item and stage.\n\n    If ``when`` is None, delete ``PYTEST_CURRENT_TEST`` from the environment.\n    \"\"\"\n    var_name = \"PYTEST_CURRENT_TEST\"\n    if when:\n        value = \"{} ({})\".format(item.nodeid, when)\n        # don't allow null bytes on environment variables (see #2644, #2957)\n        value = value.replace(\"\\x00\", \"(null)\")\n        os.environ[var_name] = value\n    else:\n        os.environ.pop(var_name)"}, {"id": "_pytest.runner.pytest_report_teststatus", "kind": "function", "range": [171, 0, 179, 29, 5173, 5495], "file_path": "src/_pytest/runner.py", "content": "def pytest_report_teststatus(report):\n    if report.when in (\"setup\", \"teardown\"):\n        if report.failed:\n            #      category, shortletter, verbose-word\n            return \"error\", \"E\", \"ERROR\"\n        elif report.skipped:\n            return \"skipped\", \"s\", \"SKIPPED\"\n        else:\n            return \"\", \"\", \"\""}, {"id": "_pytest.runner.call_and_report", "kind": "function", "range": [186, 0, 196, 17, 5519, 5961], "file_path": "src/_pytest/runner.py", "content": "def call_and_report(\n    item, when: \"Literal['setup', 'call', 'teardown']\", log=True, **kwds\n):\n    call = call_runtest_hook(item, when, **kwds)\n    hook = item.ihook\n    report = hook.pytest_runtest_makereport(item=item, call=call)\n    if log:\n        hook.pytest_runtest_logreport(report=report)\n    if check_interactive_exception(call, report):\n        hook.pytest_exception_interact(node=item, call=call, report=report)\n    return report"}, {"id": "_pytest.runner.check_interactive_exception", "kind": "function", "range": [199, 0, 204, 5, 5964, 6184], "file_path": "src/_pytest/runner.py", "content": "def check_interactive_exception(call, report):\n    return call.excinfo and not (\n        hasattr(report, \"wasxfail\")\n        or call.excinfo.errisinstance(Skipped)\n        or call.excinfo.errisinstance(bdb.BdbQuit)\n    )"}, {"id": "_pytest.runner.call_runtest_hook", "kind": "function", "range": [207, 0, 221, 5, 6187, 6832], "file_path": "src/_pytest/runner.py", "content": "def call_runtest_hook(item, when: \"Literal['setup', 'call', 'teardown']\", **kwds):\n    if when == \"setup\":\n        ihook = item.ihook.pytest_runtest_setup\n    elif when == \"call\":\n        ihook = item.ihook.pytest_runtest_call\n    elif when == \"teardown\":\n        ihook = item.ihook.pytest_runtest_teardown\n    else:\n        assert False, \"Unhandled runtest hook case: {}\".format(when)\n    reraise = (Exit,)  # type: Tuple[Type[BaseException], ...]\n    if not item.config.getoption(\"usepdb\", False):\n        reraise += (KeyboardInterrupt,)\n    return CallInfo.from_call(\n        lambda: ihook(item=item, **kwds), when=when, reraise=reraise\n    )"}, {"id": "_pytest.runner.CallInfo", "kind": "class", "range": [224, 0, 280, 82, 6835, 8894], "file_path": "src/_pytest/runner.py", "content": "@attr.s(repr=False)\nclass CallInfo:\n    \"\"\" Result/Exception info a function invocation.\n\n    :param result: The return value of the call, if it didn't raise. Can only be accessed\n        if excinfo is None.\n    :param Optional[ExceptionInfo] excinfo: The captured exception of the call, if it raised.\n    :param float start: The system time when the call started, in seconds since the epoch.\n    :param float stop: The system time when the call ended, in seconds since the epoch.\n    :param float duration: The call duration, in seconds.\n    :param str when: The context of invocation: \"setup\", \"call\", \"teardown\", ...\n    \"\"\"\n\n    _result = attr.ib()\n    excinfo = attr.ib(type=Optional[ExceptionInfo])\n    start = attr.ib(type=float)\n    stop = attr.ib(type=float)\n    duration = attr.ib(type=float)\n    when = attr.ib(type=str)\n\n    @property\n    def result(self):\n        if self.excinfo is not None:\n            raise AttributeError(\"{!r} has no valid result\".format(self))\n        return self._result\n\n    @classmethod\n    def from_call(cls, func, when, reraise=None) -> \"CallInfo\":\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        excinfo = None\n        start = time()\n        precise_start = perf_counter()\n        try:\n            result = func()\n        except:  # noqa\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and excinfo.errisinstance(reraise):\n                raise\n            result = None\n        # use the perf counter\n        precise_stop = perf_counter()\n        duration = precise_stop - precise_start\n        stop = time()\n        return cls(\n            start=start,\n            stop=stop,\n            duration=duration,\n            when=when,\n            result=result,\n            excinfo=excinfo,\n        )\n\n    def __repr__(self):\n        if self.excinfo is None:\n            return \"<CallInfo when={!r} result: {!r}>\".format(self.when, self._result)\n        return \"<CallInfo when={!r} excinfo={!r}>\".format(self.when, self.excinfo)"}, {"id": "_pytest.runner.CallInfo._result", "kind": "variable", "range": [237, 4, 237, 23, 7468, 7487], "file_path": "src/_pytest/runner.py", "content": "_result = attr.ib()"}, {"id": "_pytest.runner.CallInfo.excinfo", "kind": "variable", "range": [238, 4, 238, 51, 7492, 7539], "file_path": "src/_pytest/runner.py", "content": "excinfo = attr.ib(type=Optional[ExceptionInfo])"}, {"id": "_pytest.runner.CallInfo.start", "kind": "variable", "range": [239, 4, 239, 31, 7544, 7571], "file_path": "src/_pytest/runner.py", "content": "start = attr.ib(type=float)"}, {"id": "_pytest.runner.CallInfo.stop", "kind": "variable", "range": [240, 4, 240, 30, 7576, 7602], "file_path": "src/_pytest/runner.py", "content": "stop = attr.ib(type=float)"}, {"id": "_pytest.runner.CallInfo.duration", "kind": "variable", "range": [241, 4, 241, 34, 7607, 7637], "file_path": "src/_pytest/runner.py", "content": "duration = attr.ib(type=float)"}, {"id": "_pytest.runner.CallInfo.when", "kind": "variable", "range": [242, 4, 242, 28, 7642, 7666], "file_path": "src/_pytest/runner.py", "content": "when = attr.ib(type=str)"}, {"id": "_pytest.runner.CallInfo.result", "kind": "function", "range": [244, 4, 248, 27, 7672, 7842], "file_path": "src/_pytest/runner.py", "content": "@property\n    def result(self):\n        if self.excinfo is not None:\n            raise AttributeError(\"{!r} has no valid result\".format(self))\n        return self._result"}, {"id": "_pytest.runner.CallInfo.from_call", "kind": "function", "range": [250, 4, 275, 9, 7848, 8666], "file_path": "src/_pytest/runner.py", "content": "@classmethod\n    def from_call(cls, func, when, reraise=None) -> \"CallInfo\":\n        #: context of invocation: one of \"setup\", \"call\",\n        #: \"teardown\", \"memocollect\"\n        excinfo = None\n        start = time()\n        precise_start = perf_counter()\n        try:\n            result = func()\n        except:  # noqa\n            excinfo = ExceptionInfo.from_current()\n            if reraise is not None and excinfo.errisinstance(reraise):\n                raise\n            result = None\n        # use the perf counter\n        precise_stop = perf_counter()\n        duration = precise_stop - precise_start\n        stop = time()\n        return cls(\n            start=start,\n            stop=stop,\n            duration=duration,\n            when=when,\n            result=result,\n            excinfo=excinfo,\n        )"}, {"id": "_pytest.runner.CallInfo.__repr__", "kind": "function", "range": [277, 4, 280, 82, 8672, 8894], "file_path": "src/_pytest/runner.py", "content": "def __repr__(self):\n        if self.excinfo is None:\n            return \"<CallInfo when={!r} result: {!r}>\".format(self.when, self._result)\n        return \"<CallInfo when={!r} excinfo={!r}>\".format(self.when, self.excinfo)"}, {"id": "_pytest.runner.pytest_runtest_makereport", "kind": "function", "range": [283, 0, 284, 52, 8897, 8992], "file_path": "src/_pytest/runner.py", "content": "def pytest_runtest_makereport(item, call):\n    return TestReport.from_item_and_call(item, call)"}, {"id": "_pytest.runner.pytest_make_collect_report", "kind": "function", "range": [287, 0, 315, 14, 8995, 10237], "file_path": "src/_pytest/runner.py", "content": "def pytest_make_collect_report(collector: Collector) -> CollectReport:\n    call = CallInfo.from_call(lambda: list(collector.collect()), \"collect\")\n    longrepr = None\n    if not call.excinfo:\n        outcome = \"passed\"\n    else:\n        skip_exceptions = [Skipped]\n        unittest = sys.modules.get(\"unittest\")\n        if unittest is not None:\n            # Type ignored because unittest is loaded dynamically.\n            skip_exceptions.append(unittest.SkipTest)  # type: ignore\n        if call.excinfo.errisinstance(tuple(skip_exceptions)):\n            outcome = \"skipped\"\n            r_ = collector._repr_failure_py(call.excinfo, \"line\")\n            assert isinstance(r_, ExceptionChainRepr), repr(r_)\n            r = r_.reprcrash\n            assert r\n            longrepr = (str(r.path), r.lineno, r.message)\n        else:\n            outcome = \"failed\"\n            errorinfo = collector.repr_failure(call.excinfo)\n            if not hasattr(errorinfo, \"toterminal\"):\n                errorinfo = CollectErrorRepr(errorinfo)\n            longrepr = errorinfo\n    rep = CollectReport(\n        collector.nodeid, outcome, longrepr, getattr(call, \"result\", None)\n    )\n    rep.call = call  # type: ignore # see collect_one_node\n    return rep"}, {"id": "_pytest.runner.SetupState", "kind": "class", "range": [318, 0, 400, 23, 10240, 13201], "file_path": "src/_pytest/runner.py", "content": "class SetupState:\n    \"\"\" shared state for setting up/tearing down test items or collectors. \"\"\"\n\n    def __init__(self):\n        self.stack = []  # type: List[Node]\n        self._finalizers = {}  # type: Dict[Node, List[Callable[[], None]]]\n\n    def addfinalizer(self, finalizer, colitem):\n        \"\"\" attach a finalizer to the given colitem. \"\"\"\n        assert colitem and not isinstance(colitem, tuple)\n        assert callable(finalizer)\n        # assert colitem in self.stack  # some unit tests don't setup stack :/\n        self._finalizers.setdefault(colitem, []).append(finalizer)\n\n    def _pop_and_teardown(self):\n        colitem = self.stack.pop()\n        self._teardown_with_finalization(colitem)\n\n    def _callfinalizers(self, colitem):\n        finalizers = self._finalizers.pop(colitem, None)\n        exc = None\n        while finalizers:\n            fin = finalizers.pop()\n            try:\n                fin()\n            except TEST_OUTCOME as e:\n                # XXX Only first exception will be seen by user,\n                #     ideally all should be reported.\n                if exc is None:\n                    exc = e\n        if exc:\n            raise exc\n\n    def _teardown_with_finalization(self, colitem):\n        self._callfinalizers(colitem)\n        colitem.teardown()\n        for colitem in self._finalizers:\n            assert colitem in self.stack\n\n    def teardown_all(self):\n        while self.stack:\n            self._pop_and_teardown()\n        for key in list(self._finalizers):\n            self._teardown_with_finalization(key)\n        assert not self._finalizers\n\n    def teardown_exact(self, item, nextitem):\n        needed_collectors = nextitem and nextitem.listchain() or []\n        self._teardown_towards(needed_collectors)\n\n    def _teardown_towards(self, needed_collectors):\n        exc = None\n        while self.stack:\n            if self.stack == needed_collectors[: len(self.stack)]:\n                break\n            try:\n                self._pop_and_teardown()\n            except TEST_OUTCOME as e:\n                # XXX Only first exception will be seen by user,\n                #     ideally all should be reported.\n                if exc is None:\n                    exc = e\n        if exc:\n            raise exc\n\n    def prepare(self, colitem):\n        \"\"\" setup objects along the collector chain to the test-method\n            and teardown previously setup objects.\"\"\"\n        needed_collectors = colitem.listchain()\n        self._teardown_towards(needed_collectors)\n\n        # check if the last collection node has raised an error\n        for col in self.stack:\n            if hasattr(col, \"_prepare_exc\"):\n                exc = col._prepare_exc\n                raise exc\n        for col in needed_collectors[len(self.stack) :]:\n            self.stack.append(col)\n            try:\n                col.setup()\n            except TEST_OUTCOME as e:\n                col._prepare_exc = e\n                raise e"}, {"id": "_pytest.runner.SetupState.__init__", "kind": "function", "range": [321, 4, 323, 75, 10342, 10481], "file_path": "src/_pytest/runner.py", "content": "def __init__(self):\n        self.stack = []  # type: List[Node]\n        self._finalizers = {}  # type: Dict[Node, List[Callable[[], None]]]"}, {"id": "_pytest.runner.SetupState.addfinalizer", "kind": "function", "range": [325, 4, 330, 66, 10487, 10826], "file_path": "src/_pytest/runner.py", "content": "def addfinalizer(self, finalizer, colitem):\n        \"\"\" attach a finalizer to the given colitem. \"\"\"\n        assert colitem and not isinstance(colitem, tuple)\n        assert callable(finalizer)\n        # assert colitem in self.stack  # some unit tests don't setup stack :/\n        self._finalizers.setdefault(colitem, []).append(finalizer)"}, {"id": "_pytest.runner.SetupState._pop_and_teardown", "kind": "function", "range": [332, 4, 334, 49, 10832, 10945], "file_path": "src/_pytest/runner.py", "content": "def _pop_and_teardown(self):\n        colitem = self.stack.pop()\n        self._teardown_with_finalization(colitem)"}, {"id": "_pytest.runner.SetupState._callfinalizers", "kind": "function", "range": [336, 4, 349, 21, 10951, 11417], "file_path": "src/_pytest/runner.py", "content": "def _callfinalizers(self, colitem):\n        finalizers = self._finalizers.pop(colitem, None)\n        exc = None\n        while finalizers:\n            fin = finalizers.pop()\n            try:\n                fin()\n            except TEST_OUTCOME as e:\n                # XXX Only first exception will be seen by user,\n                #     ideally all should be reported.\n                if exc is None:\n                    exc = e\n        if exc:\n            raise exc"}, {"id": "_pytest.runner.SetupState._teardown_with_finalization", "kind": "function", "range": [351, 4, 355, 40, 11423, 11617], "file_path": "src/_pytest/runner.py", "content": "def _teardown_with_finalization(self, colitem):\n        self._callfinalizers(colitem)\n        colitem.teardown()\n        for colitem in self._finalizers:\n            assert colitem in self.stack"}, {"id": "_pytest.runner.SetupState.teardown_all", "kind": "function", "range": [357, 4, 362, 35, 11623, 11838], "file_path": "src/_pytest/runner.py", "content": "def teardown_all(self):\n        while self.stack:\n            self._pop_and_teardown()\n        for key in list(self._finalizers):\n            self._teardown_with_finalization(key)\n        assert not self._finalizers"}, {"id": "_pytest.runner.SetupState.teardown_exact", "kind": "function", "range": [364, 4, 366, 49, 11844, 12003], "file_path": "src/_pytest/runner.py", "content": "def teardown_exact(self, item, nextitem):\n        needed_collectors = nextitem and nextitem.listchain() or []\n        self._teardown_towards(needed_collectors)"}, {"id": "_pytest.runner.SetupState._teardown_towards", "kind": "function", "range": [368, 4, 381, 21, 12009, 12503], "file_path": "src/_pytest/runner.py", "content": "def _teardown_towards(self, needed_collectors):\n        exc = None\n        while self.stack:\n            if self.stack == needed_collectors[: len(self.stack)]:\n                break\n            try:\n                self._pop_and_teardown()\n            except TEST_OUTCOME as e:\n                # XXX Only first exception will be seen by user,\n                #     ideally all should be reported.\n                if exc is None:\n                    exc = e\n        if exc:\n            raise exc"}, {"id": "_pytest.runner.SetupState.prepare", "kind": "function", "range": [383, 4, 400, 23, 12509, 13201], "file_path": "src/_pytest/runner.py", "content": "def prepare(self, colitem):\n        \"\"\" setup objects along the collector chain to the test-method\n            and teardown previously setup objects.\"\"\"\n        needed_collectors = colitem.listchain()\n        self._teardown_towards(needed_collectors)\n\n        # check if the last collection node has raised an error\n        for col in self.stack:\n            if hasattr(col, \"_prepare_exc\"):\n                exc = col._prepare_exc\n                raise exc\n        for col in needed_collectors[len(self.stack) :]:\n            self.stack.append(col)\n            try:\n                col.setup()\n            except TEST_OUTCOME as e:\n                col._prepare_exc = e\n                raise e"}, {"id": "_pytest.runner.collect_one_node", "kind": "function", "range": [403, 0, 410, 14, 13204, 13571], "file_path": "src/_pytest/runner.py", "content": "def collect_one_node(collector):\n    ihook = collector.ihook\n    ihook.pytest_collectstart(collector=collector)\n    rep = ihook.pytest_make_collect_report(collector=collector)\n    call = rep.__dict__.pop(\"call\", None)\n    if call and check_interactive_exception(call, rep):\n        ihook.pytest_exception_interact(node=collector, call=call, report=rep)\n    return rep"}, {"id": "_pytest.helpconfig.HelpAction", "kind": "class", "range": [11, 0, 35, 27, 175, 1165], "file_path": "src/_pytest/helpconfig.py", "content": "class HelpAction(Action):\n    \"\"\"This is an argparse Action that will raise an exception in\n    order to skip the rest of the argument parsing when --help is passed.\n    This prevents argparse from quitting due to missing required arguments\n    when any are defined, for example by ``pytest_addoption``.\n    This is similar to the way that the builtin argparse --help option is\n    implemented by raising SystemExit.\n    \"\"\"\n\n    def __init__(self, option_strings, dest=None, default=False, help=None):\n        super().__init__(\n            option_strings=option_strings,\n            dest=dest,\n            const=True,\n            default=default,\n            nargs=0,\n            help=help,\n        )\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, self.const)\n\n        # We should only skip the rest of the parsing after preparse is done\n        if getattr(parser._parser, \"after_preparse\", False):\n            raise PrintHelp"}, {"id": "_pytest.helpconfig.HelpAction.__init__", "kind": "function", "range": [20, 4, 28, 9, 605, 876], "file_path": "src/_pytest/helpconfig.py", "content": "def __init__(self, option_strings, dest=None, default=False, help=None):\n        super().__init__(\n            option_strings=option_strings,\n            dest=dest,\n            const=True,\n            default=default,\n            nargs=0,\n            help=help,\n        )"}, {"id": "_pytest.helpconfig.HelpAction.__call__", "kind": "function", "range": [30, 4, 35, 27, 882, 1165], "file_path": "src/_pytest/helpconfig.py", "content": "def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, self.const)\n\n        # We should only skip the rest of the parsing after preparse is done\n        if getattr(parser._parser, \"after_preparse\", False):\n            raise PrintHelp"}, {"id": "_pytest.helpconfig.pytest_addoption", "kind": "function", "range": [38, 0, 83, 5, 1168, 2498], "file_path": "src/_pytest/helpconfig.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"debugconfig\")\n    group.addoption(\n        \"--version\",\n        \"-V\",\n        action=\"store_true\",\n        help=\"display pytest version and information about plugins.\",\n    )\n    group._addoption(\n        \"-h\",\n        \"--help\",\n        action=HelpAction,\n        dest=\"help\",\n        help=\"show help message and configuration info\",\n    )\n    group._addoption(\n        \"-p\",\n        action=\"append\",\n        dest=\"plugins\",\n        default=[],\n        metavar=\"name\",\n        help=\"early-load given plugin module name or entry point (multi-allowed). \"\n        \"To avoid loading of plugins, use the `no:` prefix, e.g. \"\n        \"`no:doctest`.\",\n    )\n    group.addoption(\n        \"--traceconfig\",\n        \"--trace-config\",\n        action=\"store_true\",\n        default=False,\n        help=\"trace considerations of conftest.py files.\",\n    )\n    group.addoption(\n        \"--debug\",\n        action=\"store_true\",\n        dest=\"debug\",\n        default=False,\n        help=\"store internal tracing debug information in 'pytestdebug.log'.\",\n    )\n    group._addoption(\n        \"-o\",\n        \"--override-ini\",\n        dest=\"override_ini\",\n        action=\"append\",\n        help='override ini option with \"option=value\" style, e.g. `-o xfail_strict=True -o cache_dir=cache`.',\n    )"}, {"id": "_pytest.helpconfig.pytest_cmdline_parse", "kind": "function", "range": [86, 0, 114, 41, 2501, 3533], "file_path": "src/_pytest/helpconfig.py", "content": "@pytest.hookimpl(hookwrapper=True)\ndef pytest_cmdline_parse():\n    outcome = yield\n    config = outcome.get_result()\n    if config.option.debug:\n        path = os.path.abspath(\"pytestdebug.log\")\n        debugfile = open(path, \"w\")\n        debugfile.write(\n            \"versions pytest-%s, py-%s, \"\n            \"python-%s\\ncwd=%s\\nargs=%s\\n\\n\"\n            % (\n                pytest.__version__,\n                py.__version__,\n                \".\".join(map(str, sys.version_info)),\n                os.getcwd(),\n                config.invocation_params.args,\n            )\n        )\n        config.trace.root.setwriter(debugfile.write)\n        undo_tracing = config.pluginmanager.enable_tracing()\n        sys.stderr.write(\"writing pytestdebug information to %s\\n\" % path)\n\n        def unset_tracing():\n            debugfile.close()\n            sys.stderr.write(\"wrote pytestdebug information to %s\\n\" % debugfile.name)\n            config.trace.root.setwriter(None)\n            undo_tracing()\n\n        config.add_cleanup(unset_tracing)"}, {"id": "_pytest.helpconfig.showversion", "kind": "function", "range": [117, 0, 126, 41, 3536, 3849], "file_path": "src/_pytest/helpconfig.py", "content": "def showversion(config):\n    sys.stderr.write(\n        \"This is pytest version {}, imported from {}\\n\".format(\n            pytest.__version__, pytest.__file__\n        )\n    )\n    plugininfo = getpluginversioninfo(config)\n    if plugininfo:\n        for line in plugininfo:\n            sys.stderr.write(line + \"\\n\")"}, {"id": "_pytest.helpconfig.pytest_cmdline_main", "kind": "function", "range": [129, 0, 137, 16, 3852, 4098], "file_path": "src/_pytest/helpconfig.py", "content": "def pytest_cmdline_main(config):\n    if config.option.version:\n        showversion(config)\n        return 0\n    elif config.option.help:\n        config._do_configure()\n        showhelp(config)\n        config._ensure_unconfigure()\n        return 0"}, {"id": "_pytest.helpconfig.showhelp", "kind": "function", "range": [140, 0, 207, 10, 4101, 6489], "file_path": "src/_pytest/helpconfig.py", "content": "def showhelp(config):\n    import textwrap\n\n    reporter = config.pluginmanager.get_plugin(\"terminalreporter\")\n    tw = reporter._tw\n    tw.write(config._parser.optparser.format_help())\n    tw.line()\n    tw.line(\n        \"[pytest] ini-options in the first pytest.ini|tox.ini|setup.cfg file found:\"\n    )\n    tw.line()\n\n    columns = tw.fullwidth  # costly call\n    indent_len = 24  # based on argparse's max_help_position=24\n    indent = \" \" * indent_len\n    for name in config._parser._ininames:\n        help, type, default = config._parser._inidict[name]\n        if type is None:\n            type = \"string\"\n        spec = \"{} ({}):\".format(name, type)\n        tw.write(\"  %s\" % spec)\n        spec_len = len(spec)\n        if spec_len > (indent_len - 3):\n            # Display help starting at a new line.\n            tw.line()\n            helplines = textwrap.wrap(\n                help,\n                columns,\n                initial_indent=indent,\n                subsequent_indent=indent,\n                break_on_hyphens=False,\n            )\n\n            for line in helplines:\n                tw.line(line)\n        else:\n            # Display help starting after the spec, following lines indented.\n            tw.write(\" \" * (indent_len - spec_len - 2))\n            wrapped = textwrap.wrap(help, columns - indent_len, break_on_hyphens=False)\n\n            tw.line(wrapped[0])\n            for line in wrapped[1:]:\n                tw.line(indent + line)\n\n    tw.line()\n    tw.line(\"environment variables:\")\n    vars = [\n        (\"PYTEST_ADDOPTS\", \"extra command line options\"),\n        (\"PYTEST_PLUGINS\", \"comma-separated plugins to load during startup\"),\n        (\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\", \"set to disable plugin auto-loading\"),\n        (\"PYTEST_DEBUG\", \"set to enable debug tracing of pytest's internals\"),\n    ]\n    for name, help in vars:\n        tw.line(\"  {:<24} {}\".format(name, help))\n    tw.line()\n    tw.line()\n\n    tw.line(\"to see available markers type: pytest --markers\")\n    tw.line(\"to see available fixtures type: pytest --fixtures\")\n    tw.line(\n        \"(shown according to specified file_or_dir or current dir \"\n        \"if not specified; fixtures with leading '_' are only shown \"\n        \"with the '-v' option\"\n    )\n\n    for warningreport in reporter.stats.get(\"warnings\", []):\n        tw.line(\"warning : \" + warningreport.message, red=True)\n    return"}, {"id": "_pytest.helpconfig.conftest_options", "kind": "variable", "range": [210, 0, 210, 71, 6492, 6563], "file_path": "src/_pytest/helpconfig.py", "content": "conftest_options = [(\"pytest_plugins\", \"list of plugin names to load\")]"}, {"id": "_pytest.helpconfig.getpluginversioninfo", "kind": "function", "range": [213, 0, 222, 16, 6566, 6988], "file_path": "src/_pytest/helpconfig.py", "content": "def getpluginversioninfo(config):\n    lines = []\n    plugininfo = config.pluginmanager.list_plugin_distinfo()\n    if plugininfo:\n        lines.append(\"setuptools registered plugins:\")\n        for plugin, dist in plugininfo:\n            loc = getattr(plugin, \"__file__\", repr(plugin))\n            content = \"{}-{} at {}\".format(dist.project_name, dist.version, loc)\n            lines.append(\"  \" + content)\n    return lines"}, {"id": "_pytest.helpconfig.pytest_report_header", "kind": "function", "range": [225, 0, 245, 16, 6991, 7686], "file_path": "src/_pytest/helpconfig.py", "content": "def pytest_report_header(config):\n    lines = []\n    if config.option.debug or config.option.traceconfig:\n        lines.append(\n            \"using: pytest-{} pylib-{}\".format(pytest.__version__, py.__version__)\n        )\n\n        verinfo = getpluginversioninfo(config)\n        if verinfo:\n            lines.extend(verinfo)\n\n    if config.option.traceconfig:\n        lines.append(\"active plugins:\")\n        items = config.pluginmanager.list_name_plugin()\n        for name, plugin in items:\n            if hasattr(plugin, \"__file__\"):\n                r = plugin.__file__\n            else:\n                r = repr(plugin)\n            lines.append(\"    {:<20}: {}\".format(name, r))\n    return lines"}, {"id": "_pytest.pastebin.pastebinfile_key", "kind": "variable", "range": [8, 0, 8, 40, 164, 204], "file_path": "src/_pytest/pastebin.py", "content": "pastebinfile_key = StoreKey[IO[bytes]]()"}, {"id": "_pytest.pastebin.pytest_addoption", "kind": "function", "range": [11, 0, 21, 5, 207, 535], "file_path": "src/_pytest/pastebin.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"terminal reporting\")\n    group._addoption(\n        \"--pastebin\",\n        metavar=\"mode\",\n        action=\"store\",\n        dest=\"pastebin\",\n        default=None,\n        choices=[\"failed\", \"all\"],\n        help=\"send failed|all info to bpaste.net pastebin service.\",\n    )"}, {"id": "_pytest.pastebin.pytest_configure", "kind": "function", "range": [24, 0, 42, 36, 538, 1352], "file_path": "src/_pytest/pastebin.py", "content": "@pytest.hookimpl(trylast=True)\ndef pytest_configure(config):\n    if config.option.pastebin == \"all\":\n        tr = config.pluginmanager.getplugin(\"terminalreporter\")\n        # if no terminal reporter plugin is present, nothing we can do here;\n        # this can happen when this function executes in a slave node\n        # when using pytest-xdist, for example\n        if tr is not None:\n            # pastebin file will be utf-8 encoded binary file\n            config._store[pastebinfile_key] = tempfile.TemporaryFile(\"w+b\")\n            oldwrite = tr._tw.write\n\n            def tee_write(s, **kwargs):\n                oldwrite(s, **kwargs)\n                if isinstance(s, str):\n                    s = s.encode(\"utf-8\")\n                config._store[pastebinfile_key].write(s)\n\n            tr._tw.write = tee_write"}, {"id": "_pytest.pastebin.pytest_unconfigure", "kind": "function", "range": [45, 0, 59, 65, 1355, 2035], "file_path": "src/_pytest/pastebin.py", "content": "def pytest_unconfigure(config):\n    if pastebinfile_key in config._store:\n        pastebinfile = config._store[pastebinfile_key]\n        # get terminal contents and delete file\n        pastebinfile.seek(0)\n        sessionlog = pastebinfile.read()\n        pastebinfile.close()\n        del config._store[pastebinfile_key]\n        # undo our patching in the terminal reporter\n        tr = config.pluginmanager.getplugin(\"terminalreporter\")\n        del tr._tw.__dict__[\"write\"]\n        # write summary\n        tr.write_sep(\"=\", \"Sending information to Paste Service\")\n        pastebinurl = create_new_paste(sessionlog)\n        tr.write_line(\"pastebin session-log: %s\\n\" % pastebinurl)"}, {"id": "_pytest.pastebin.create_new_paste", "kind": "function", "range": [62, 0, 85, 66, 2038, 2850], "file_path": "src/_pytest/pastebin.py", "content": "def create_new_paste(contents):\n    \"\"\"\n    Creates a new paste using bpaste.net service.\n\n    :contents: paste contents as utf-8 encoded bytes\n    :returns: url to the pasted contents or error message\n    \"\"\"\n    import re\n    from urllib.request import urlopen\n    from urllib.parse import urlencode\n\n    params = {\"code\": contents, \"lexer\": \"text\", \"expiry\": \"1week\"}\n    url = \"https://bpaste.net\"\n    try:\n        response = (\n            urlopen(url, data=urlencode(params).encode(\"ascii\")).read().decode(\"utf-8\")\n        )\n    except OSError as exc_info:  # urllib errors\n        return \"bad response: %s\" % exc_info\n    m = re.search(r'href=\"/raw/(\\w+)\"', response)\n    if m:\n        return \"{}/show/{}\".format(url, m.group(1))\n    else:\n        return \"bad response: invalid format ('\" + response + \"')\""}, {"id": "_pytest.pastebin.pytest_terminal_summary", "kind": "function", "range": [88, 0, 108, 63, 2853, 3703], "file_path": "src/_pytest/pastebin.py", "content": "def pytest_terminal_summary(terminalreporter):\n    import _pytest.config\n\n    if terminalreporter.config.option.pastebin != \"failed\":\n        return\n    tr = terminalreporter\n    if \"failed\" in tr.stats:\n        terminalreporter.write_sep(\"=\", \"Sending information to Paste Service\")\n        for rep in terminalreporter.stats.get(\"failed\"):\n            try:\n                msg = rep.longrepr.reprtraceback.reprentries[-1].reprfileloc\n            except AttributeError:\n                msg = tr._getfailureheadline(rep)\n            tw = _pytest.config.create_terminal_writer(\n                terminalreporter.config, stringio=True\n            )\n            rep.toterminal(tw)\n            s = tw.stringio.getvalue()\n            assert len(s)\n            pastebinurl = create_new_paste(s)\n            tr.write_line(\"{} --> {}\".format(msg, pastebinurl))"}, {"id": "_pytest.compat._T", "kind": "variable", "range": [37, 0, 37, 18, 759, 777], "file_path": "src/_pytest/compat.py", "content": "_T = TypeVar(\"_T\")"}, {"id": "_pytest.compat._S", "kind": "variable", "range": [38, 0, 38, 18, 778, 796], "file_path": "src/_pytest/compat.py", "content": "_S = TypeVar(\"_S\")"}, {"id": "_pytest.compat.NOTSET", "kind": "variable", "range": [41, 0, 41, 17, 799, 816], "file_path": "src/_pytest/compat.py", "content": "NOTSET = object()"}, {"id": "_pytest.compat.MODULE_NOT_FOUND_ERROR", "kind": "variable", "range": [43, 0, 45, 1, 818, 925], "file_path": "src/_pytest/compat.py", "content": "MODULE_NOT_FOUND_ERROR = (\n    \"ModuleNotFoundError\" if sys.version_info[:2] >= (3, 6) else \"ImportError\"\n)"}, {"id": "_pytest.compat._format_args", "kind": "function", "range": [54, 0, 55, 31, 1068, 1150], "file_path": "src/_pytest/compat.py", "content": "def _format_args(func: Callable[..., Any]) -> str:\n    return str(signature(func))"}, {"id": "_pytest.compat.REGEX_TYPE", "kind": "variable", "range": [59, 0, 59, 33, 1212, 1245], "file_path": "src/_pytest/compat.py", "content": "REGEX_TYPE = type(re.compile(\"\"))"}, {"id": "_pytest.compat.is_generator", "kind": "function", "range": [75, 0, 77, 52, 1493, 1633], "file_path": "src/_pytest/compat.py", "content": "def is_generator(func: object) -> bool:\n    genfunc = inspect.isgeneratorfunction(func)\n    return genfunc and not iscoroutinefunction(func)"}, {"id": "_pytest.compat.iscoroutinefunction", "kind": "function", "range": [80, 0, 90, 85, 1636, 2163], "file_path": "src/_pytest/compat.py", "content": "def iscoroutinefunction(func: object) -> bool:\n    \"\"\"\n    Return True if func is a coroutine function (a function defined with async\n    def syntax, and doesn't contain yield), or a function decorated with\n    @asyncio.coroutine.\n\n    Note: copied and modified from Python 3.5's builtin couroutines.py to avoid\n    importing asyncio directly, which in turns also initializes the \"logging\"\n    module as a side-effect (see issue #8).\n    \"\"\"\n    return inspect.iscoroutinefunction(func) or getattr(func, \"_is_coroutine\", False)"}, {"id": "_pytest.compat.is_async_function", "kind": "function", "range": [93, 0, 97, 5, 2166, 2423], "file_path": "src/_pytest/compat.py", "content": "def is_async_function(func: object) -> bool:\n    \"\"\"Return True if the given function seems to be an async function or async generator\"\"\"\n    return iscoroutinefunction(func) or (\n        sys.version_info >= (3, 6) and inspect.isasyncgenfunction(func)\n    )"}, {"id": "_pytest.compat.getlocation", "kind": "function", "range": [100, 0, 108, 37, 2426, 2772], "file_path": "src/_pytest/compat.py", "content": "def getlocation(function, curdir=None) -> str:\n    function = get_real_func(function)\n    fn = py.path.local(inspect.getfile(function))\n    lineno = function.__code__.co_firstlineno\n    if curdir is not None:\n        relfn = fn.relto(curdir)\n        if relfn:\n            return \"%s:%d\" % (relfn, lineno + 1)\n    return \"%s:%d\" % (fn, lineno + 1)"}, {"id": "_pytest.compat.num_mock_patch_args", "kind": "function", "range": [111, 0, 127, 5, 2775, 3337], "file_path": "src/_pytest/compat.py", "content": "def num_mock_patch_args(function) -> int:\n    \"\"\" return number of arguments used up by mock arguments (if any) \"\"\"\n    patchings = getattr(function, \"patchings\", None)\n    if not patchings:\n        return 0\n\n    mock_sentinel = getattr(sys.modules.get(\"mock\"), \"DEFAULT\", object())\n    ut_mock_sentinel = getattr(sys.modules.get(\"unittest.mock\"), \"DEFAULT\", object())\n\n    return len(\n        [\n            p\n            for p in patchings\n            if not p.attribute_name\n            and (p.new is mock_sentinel or p.new is ut_mock_sentinel)\n        ]\n    )"}, {"id": "_pytest.compat.getfuncargnames", "kind": "function", "range": [130, 0, 190, 20, 3340, 5624], "file_path": "src/_pytest/compat.py", "content": "def getfuncargnames(\n    function: Callable[..., Any],\n    *,\n    name: str = \"\",\n    is_method: bool = False,\n    cls: Optional[type] = None\n) -> Tuple[str, ...]:\n    \"\"\"Returns the names of a function's mandatory arguments.\n\n    This should return the names of all function arguments that:\n        * Aren't bound to an instance or type as in instance or class methods.\n        * Don't have default values.\n        * Aren't bound with functools.partial.\n        * Aren't replaced with mocks.\n\n    The is_method and cls arguments indicate that the function should\n    be treated as a bound method even though it's not unless, only in\n    the case of cls, the function is a static method.\n\n    The name parameter should be the original name in which the function was collected.\n    \"\"\"\n    # TODO(RonnyPfannschmidt): This function should be refactored when we\n    # revisit fixtures. The fixture mechanism should ask the node for\n    # the fixture names, and not try to obtain directly from the\n    # function object well after collection has occurred.\n\n    # The parameters attribute of a Signature object contains an\n    # ordered mapping of parameter names to Parameter instances.  This\n    # creates a tuple of the names of the parameters that don't have\n    # defaults.\n    try:\n        parameters = signature(function).parameters\n    except (ValueError, TypeError) as e:\n        fail(\n            \"Could not determine arguments of {!r}: {}\".format(function, e),\n            pytrace=False,\n        )\n\n    arg_names = tuple(\n        p.name\n        for p in parameters.values()\n        if (\n            p.kind is Parameter.POSITIONAL_OR_KEYWORD\n            or p.kind is Parameter.KEYWORD_ONLY\n        )\n        and p.default is Parameter.empty\n    )\n    if not name:\n        name = function.__name__\n\n    # If this function should be treated as a bound method even though\n    # it's passed as an unbound method or function, remove the first\n    # parameter name.\n    if is_method or (\n        cls and not isinstance(cls.__dict__.get(name, None), staticmethod)\n    ):\n        arg_names = arg_names[1:]\n    # Remove any names that will be replaced with mocks.\n    if hasattr(function, \"__wrapped__\"):\n        arg_names = arg_names[num_mock_patch_args(function) :]\n    return arg_names"}, {"id": "_pytest.compat.get_default_arg_names", "kind": "function", "range": [204, 0, 212, 5, 5772, 6252], "file_path": "src/_pytest/compat.py", "content": "def get_default_arg_names(function: Callable[..., Any]) -> Tuple[str, ...]:\n    # Note: this code intentionally mirrors the code at the beginning of getfuncargnames,\n    # to get the arguments which were excluded from its result because they had default values\n    return tuple(\n        p.name\n        for p in signature(function).parameters.values()\n        if p.kind in (Parameter.POSITIONAL_OR_KEYWORD, Parameter.KEYWORD_ONLY)\n        and p.default is not Parameter.empty\n    )"}, {"id": "_pytest.compat._non_printable_ascii_translate_table", "kind": "variable", "range": [215, 0, 217, 1, 6255, 6373], "file_path": "src/_pytest/compat.py", "content": "_non_printable_ascii_translate_table = {\n    i: \"\\\\x{:02x}\".format(i) for i in range(128) if i not in range(32, 127)\n}"}, {"id": "_pytest.compat._translate_non_printable", "kind": "function", "range": [223, 0, 224, 60, 6482, 6587], "file_path": "src/_pytest/compat.py", "content": "def _translate_non_printable(s: str) -> str:\n    return s.translate(_non_printable_ascii_translate_table)"}, {"id": "_pytest.compat.STRING_TYPES", "kind": "variable", "range": [227, 0, 227, 25, 6590, 6615], "file_path": "src/_pytest/compat.py", "content": "STRING_TYPES = bytes, str"}, {"id": "_pytest.compat._bytes_to_ascii", "kind": "function", "range": [230, 0, 231, 50, 6618, 6708], "file_path": "src/_pytest/compat.py", "content": "def _bytes_to_ascii(val: bytes) -> str:\n    return val.decode(\"ascii\", \"backslashreplace\")"}, {"id": "_pytest.compat.ascii_escaped", "kind": "function", "range": [234, 0, 256, 40, 6711, 7495], "file_path": "src/_pytest/compat.py", "content": "def ascii_escaped(val: Union[bytes, str]) -> str:\n    \"\"\"If val is pure ascii, returns it as a str().  Otherwise, escapes\n    bytes objects into a sequence of escaped bytes:\n\n    b'\\xc3\\xb4\\xc5\\xd6' -> '\\\\xc3\\\\xb4\\\\xc5\\\\xd6'\n\n    and escapes unicode objects into a sequence of escaped unicode\n    ids, e.g.:\n\n    '4\\\\nV\\\\U00043efa\\\\x0eMXWB\\\\x1e\\\\u3028\\\\u15fd\\\\xcd\\\\U0007d944'\n\n    note:\n       the obvious \"v.decode('unicode-escape')\" will return\n       valid utf-8 unicode if it finds them in bytes, but we\n       want to return escaped bytes for any byte, even if they match\n       a utf-8 string.\n\n    \"\"\"\n    if isinstance(val, bytes):\n        ret = _bytes_to_ascii(val)\n    else:\n        ret = val.encode(\"unicode_escape\").decode(\"ascii\")\n    return _translate_non_printable(ret)"}, {"id": "_pytest.compat._PytestWrapper", "kind": "class", "range": [259, 0, 268, 19, 7498, 7852], "file_path": "src/_pytest/compat.py", "content": "@attr.s\nclass _PytestWrapper:\n    \"\"\"Dummy wrapper around a function object for internal use only.\n\n    Used to correctly unwrap the underlying function object\n    when we are creating fixtures, because we wrap the function object ourselves with a decorator\n    to issue warnings when the fixture function is called directly.\n    \"\"\"\n\n    obj = attr.ib()"}, {"id": "_pytest.compat._PytestWrapper.obj", "kind": "variable", "range": [268, 4, 268, 19, 7837, 7852], "file_path": "src/_pytest/compat.py", "content": "obj = attr.ib()"}, {"id": "_pytest.compat.get_real_func", "kind": "function", "range": [271, 0, 296, 14, 7855, 8896], "file_path": "src/_pytest/compat.py", "content": "def get_real_func(obj):\n    \"\"\" gets the real function object of the (possibly) wrapped object by\n    functools.wraps or functools.partial.\n    \"\"\"\n    start_obj = obj\n    for i in range(100):\n        # __pytest_wrapped__ is set by @pytest.fixture when wrapping the fixture function\n        # to trigger a warning if it gets called directly instead of by pytest: we don't\n        # want to unwrap further than this otherwise we lose useful wrappings like @mock.patch (#3774)\n        new_obj = getattr(obj, \"__pytest_wrapped__\", None)\n        if isinstance(new_obj, _PytestWrapper):\n            obj = new_obj.obj\n            break\n        new_obj = getattr(obj, \"__wrapped__\", None)\n        if new_obj is None:\n            break\n        obj = new_obj\n    else:\n        raise ValueError(\n            (\"could not find real function of {start}\\nstopped at {current}\").format(\n                start=saferepr(start_obj), current=saferepr(obj)\n            )\n        )\n    if isinstance(obj, functools.partial):\n        obj = obj.func\n    return obj"}, {"id": "_pytest.compat.get_real_method", "kind": "function", "range": [299, 0, 311, 14, 8899, 9406], "file_path": "src/_pytest/compat.py", "content": "def get_real_method(obj, holder):\n    \"\"\"\n    Attempts to obtain the real function object that might be wrapping ``obj``, while at the same time\n    returning a bound method to ``holder`` if the original object was a bound method.\n    \"\"\"\n    try:\n        is_method = hasattr(obj, \"__func__\")\n        obj = get_real_func(obj)\n    except Exception:  # pragma: no cover\n        return obj\n    if is_method and hasattr(obj, \"__get__\") and callable(obj.__get__):\n        obj = obj.__get__(holder)\n    return obj"}, {"id": "_pytest.compat.getimfunc", "kind": "function", "range": [314, 0, 318, 19, 9409, 9514], "file_path": "src/_pytest/compat.py", "content": "def getimfunc(func):\n    try:\n        return func.__func__\n    except AttributeError:\n        return func"}, {"id": "_pytest.compat.safe_getattr", "kind": "function", "range": [321, 0, 332, 22, 9517, 10027], "file_path": "src/_pytest/compat.py", "content": "def safe_getattr(object: Any, name: str, default: Any) -> Any:\n    \"\"\" Like getattr but return default upon any Exception or any OutcomeException.\n\n    Attribute access can potentially fail for 'evil' Python objects.\n    See issue #214.\n    It catches OutcomeException because of #2490 (issue #580), new outcomes are derived from BaseException\n    instead of Exception (for more details check #2707)\n    \"\"\"\n    try:\n        return getattr(object, name, default)\n    except TEST_OUTCOME:\n        return default"}, {"id": "_pytest.compat.safe_isclass", "kind": "function", "range": [335, 0, 340, 20, 10030, 10215], "file_path": "src/_pytest/compat.py", "content": "def safe_isclass(obj: object) -> bool:\n    \"\"\"Ignore any exception via isinstance on Python 3.\"\"\"\n    try:\n        return inspect.isclass(obj)\n    except Exception:\n        return False"}, {"id": "_pytest.terminal.REPORT_COLLECTING_RESOLUTION", "kind": "variable", "range": [37, 0, 37, 34, 867, 901], "file_path": "src/_pytest/terminal.py", "content": "REPORT_COLLECTING_RESOLUTION = 0.5"}, {"id": "_pytest.terminal.KNOWN_TYPES", "kind": "variable", "range": [39, 0, 48, 1, 903, 1040], "file_path": "src/_pytest/terminal.py", "content": "KNOWN_TYPES = (\n    \"failed\",\n    \"passed\",\n    \"skipped\",\n    \"deselected\",\n    \"xfailed\",\n    \"xpassed\",\n    \"warnings\",\n    \"error\",\n)"}, {"id": "_pytest.terminal._REPORTCHARS_DEFAULT", "kind": "variable", "range": [50, 0, 50, 27, 1042, 1069], "file_path": "src/_pytest/terminal.py", "content": "_REPORTCHARS_DEFAULT = \"fE\""}, {"id": "_pytest.terminal.MoreQuietAction", "kind": "class", "range": [53, 0, 75, 60, 1072, 1863], "file_path": "src/_pytest/terminal.py", "content": "class MoreQuietAction(argparse.Action):\n    \"\"\"\n    a modified copy of the argparse count action which counts down and updates\n    the legacy quiet attribute at the same time\n\n    used to unify verbosity handling\n    \"\"\"\n\n    def __init__(self, option_strings, dest, default=None, required=False, help=None):\n        super().__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            default=default,\n            required=required,\n            help=help,\n        )\n\n    def __call__(self, parser, namespace, values, option_string=None):\n        new_count = getattr(namespace, self.dest, 0) - 1\n        setattr(namespace, self.dest, new_count)\n        # todo Deprecate config.quiet\n        namespace.quiet = getattr(namespace, \"quiet\", 0) + 1"}, {"id": "_pytest.terminal.MoreQuietAction.__init__", "kind": "function", "range": [61, 4, 69, 9, 1298, 1586], "file_path": "src/_pytest/terminal.py", "content": "def __init__(self, option_strings, dest, default=None, required=False, help=None):\n        super().__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            default=default,\n            required=required,\n            help=help,\n        )"}, {"id": "_pytest.terminal.MoreQuietAction.__call__", "kind": "function", "range": [71, 4, 75, 60, 1592, 1863], "file_path": "src/_pytest/terminal.py", "content": "def __call__(self, parser, namespace, values, option_string=None):\n        new_count = getattr(namespace, self.dest, 0) - 1\n        setattr(namespace, self.dest, new_count)\n        # todo Deprecate config.quiet\n        namespace.quiet = getattr(namespace, \"quiet\", 0) + 1"}, {"id": "_pytest.terminal.pytest_addoption", "kind": "function", "range": [78, 0, 170, 5, 1866, 4609], "file_path": "src/_pytest/terminal.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"terminal reporting\", \"reporting\", after=\"general\")\n    group._addoption(\n        \"-v\",\n        \"--verbose\",\n        action=\"count\",\n        default=0,\n        dest=\"verbose\",\n        help=\"increase verbosity.\",\n    )\n    group._addoption(\n        \"-q\",\n        \"--quiet\",\n        action=MoreQuietAction,\n        default=0,\n        dest=\"verbose\",\n        help=\"decrease verbosity.\",\n    )\n    group._addoption(\n        \"--verbosity\",\n        dest=\"verbose\",\n        type=int,\n        default=0,\n        help=\"set verbosity. Default is 0.\",\n    )\n    group._addoption(\n        \"-r\",\n        action=\"store\",\n        dest=\"reportchars\",\n        default=_REPORTCHARS_DEFAULT,\n        metavar=\"chars\",\n        help=\"show extra test summary info as specified by chars: (f)ailed, \"\n        \"(E)rror, (s)kipped, (x)failed, (X)passed, \"\n        \"(p)assed, (P)assed with output, (a)ll except passed (p/P), or (A)ll. \"\n        \"(w)arnings are enabled by default (see --disable-warnings), \"\n        \"'N' can be used to reset the list. (default: 'fE').\",\n    )\n    group._addoption(\n        \"--disable-warnings\",\n        \"--disable-pytest-warnings\",\n        default=False,\n        dest=\"disable_warnings\",\n        action=\"store_true\",\n        help=\"disable warnings summary\",\n    )\n    group._addoption(\n        \"-l\",\n        \"--showlocals\",\n        action=\"store_true\",\n        dest=\"showlocals\",\n        default=False,\n        help=\"show locals in tracebacks (disabled by default).\",\n    )\n    group._addoption(\n        \"--tb\",\n        metavar=\"style\",\n        action=\"store\",\n        dest=\"tbstyle\",\n        default=\"auto\",\n        choices=[\"auto\", \"long\", \"short\", \"no\", \"line\", \"native\"],\n        help=\"traceback print mode (auto/long/short/line/native/no).\",\n    )\n    group._addoption(\n        \"--show-capture\",\n        action=\"store\",\n        dest=\"showcapture\",\n        choices=[\"no\", \"stdout\", \"stderr\", \"log\", \"all\"],\n        default=\"all\",\n        help=\"Controls how captured stdout/stderr/log is shown on failed tests. \"\n        \"Default is 'all'.\",\n    )\n    group._addoption(\n        \"--fulltrace\",\n        \"--full-trace\",\n        action=\"store_true\",\n        default=False,\n        help=\"don't cut any tracebacks (default is to cut).\",\n    )\n    group._addoption(\n        \"--color\",\n        metavar=\"color\",\n        action=\"store\",\n        dest=\"color\",\n        default=\"auto\",\n        choices=[\"yes\", \"no\", \"auto\"],\n        help=\"color terminal output (yes/no/auto).\",\n    )\n\n    parser.addini(\n        \"console_output_style\",\n        help='console output: \"classic\", or with additional progress information (\"progress\" (percentage) | \"count\").',\n        default=\"progress\",\n    )"}, {"id": "_pytest.terminal.pytest_configure", "kind": "function", "range": [173, 0, 182, 65, 4612, 5031], "file_path": "src/_pytest/terminal.py", "content": "def pytest_configure(config: Config) -> None:\n    reporter = TerminalReporter(config, sys.stdout)\n    config.pluginmanager.register(reporter, \"terminalreporter\")\n    if config.option.debug or config.option.traceconfig:\n\n        def mywriter(tags, args):\n            msg = \" \".join(map(str, args))\n            reporter.write_line(\"[traceconfig] \" + msg)\n\n        config.trace.root.setprocessor(\"pytest:config\", mywriter)"}, {"id": "_pytest.terminal.getreportopt", "kind": "function", "range": [185, 0, 207, 21, 5034, 5744], "file_path": "src/_pytest/terminal.py", "content": "def getreportopt(config: Config) -> str:\n    reportchars = config.option.reportchars\n\n    old_aliases = {\"F\", \"S\"}\n    reportopts = \"\"\n    for char in reportchars:\n        if char in old_aliases:\n            char = char.lower()\n        if char == \"a\":\n            reportopts = \"sxXEf\"\n        elif char == \"A\":\n            reportopts = \"PpsxXEf\"\n        elif char == \"N\":\n            reportopts = \"\"\n        elif char not in reportopts:\n            reportopts += char\n\n    if not config.option.disable_warnings and \"w\" not in reportopts:\n        reportopts = \"w\" + reportopts\n    elif config.option.disable_warnings and \"w\" in reportopts:\n        reportopts = reportopts.replace(\"w\", \"\")\n\n    return reportopts"}, {"id": "_pytest.terminal.pytest_report_teststatus", "kind": "function", "range": [210, 0, 223, 43, 5747, 6183], "file_path": "src/_pytest/terminal.py", "content": "@pytest.hookimpl(trylast=True)  # after _pytest.runner\ndef pytest_report_teststatus(report: TestReport) -> Tuple[str, str, str]:\n    letter = \"F\"\n    if report.passed:\n        letter = \".\"\n    elif report.skipped:\n        letter = \"s\"\n\n    outcome = report.outcome\n    if report.when in (\"collect\", \"setup\", \"teardown\") and outcome == \"failed\":\n        outcome = \"error\"\n        letter = \"E\"\n\n    return outcome, letter, outcome.upper()"}, {"id": "_pytest.terminal.WarningReport", "kind": "class", "range": [226, 0, 258, 19, 6186, 7430], "file_path": "src/_pytest/terminal.py", "content": "@attr.s\nclass WarningReport:\n    \"\"\"\n    Simple structure to hold warnings information captured by ``pytest_warning_captured``.\n\n    :ivar str message: user friendly message about the warning\n    :ivar str|None nodeid: node id that generated the warning (see ``get_location``).\n    :ivar tuple|py.path.local fslocation:\n        file system location of the source of the warning (see ``get_location``).\n    \"\"\"\n\n    message = attr.ib(type=str)\n    nodeid = attr.ib(type=Optional[str], default=None)\n    fslocation = attr.ib(default=None)\n    count_towards_summary = True\n\n    def get_location(self, config):\n        \"\"\"\n        Returns the more user-friendly information about the location\n        of a warning, or None.\n        \"\"\"\n        if self.nodeid:\n            return self.nodeid\n        if self.fslocation:\n            if isinstance(self.fslocation, tuple) and len(self.fslocation) >= 2:\n                filename, linenum = self.fslocation[:2]\n                relpath = py.path.local(filename).relto(config.invocation_dir)\n                if not relpath:\n                    relpath = str(filename)\n                return \"{}:{}\".format(relpath, linenum)\n            else:\n                return str(self.fslocation)\n        return None"}, {"id": "_pytest.terminal.WarningReport.message", "kind": "variable", "range": [237, 4, 237, 31, 6601, 6628], "file_path": "src/_pytest/terminal.py", "content": "message = attr.ib(type=str)"}, {"id": "_pytest.terminal.WarningReport.nodeid", "kind": "variable", "range": [238, 4, 238, 54, 6633, 6683], "file_path": "src/_pytest/terminal.py", "content": "nodeid = attr.ib(type=Optional[str], default=None)"}, {"id": "_pytest.terminal.WarningReport.fslocation", "kind": "variable", "range": [239, 4, 239, 38, 6688, 6722], "file_path": "src/_pytest/terminal.py", "content": "fslocation = attr.ib(default=None)"}, {"id": "_pytest.terminal.WarningReport.count_towards_summary", "kind": "variable", "range": [240, 4, 240, 32, 6727, 6755], "file_path": "src/_pytest/terminal.py", "content": "count_towards_summary = True"}, {"id": "_pytest.terminal.WarningReport.get_location", "kind": "function", "range": [242, 4, 258, 19, 6761, 7430], "file_path": "src/_pytest/terminal.py", "content": "def get_location(self, config):\n        \"\"\"\n        Returns the more user-friendly information about the location\n        of a warning, or None.\n        \"\"\"\n        if self.nodeid:\n            return self.nodeid\n        if self.fslocation:\n            if isinstance(self.fslocation, tuple) and len(self.fslocation) >= 2:\n                filename, linenum = self.fslocation[:2]\n                relpath = py.path.local(filename).relto(config.invocation_dir)\n                if not relpath:\n                    relpath = str(filename)\n                return \"{}:{}\".format(relpath, linenum)\n            else:\n                return str(self.fslocation)\n        return None"}, {"id": "_pytest.terminal.TerminalReporter", "kind": "class", "range": [261, 0, 1116, 32, 7433, 40530], "file_path": "src/_pytest/terminal.py", "content": "class TerminalReporter:\n    def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]\n\n    @property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw\n\n    @writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value\n\n    def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False\n\n    @property\n    def verbosity(self):\n        return self.config.option.verbose\n\n    @property\n    def showheader(self):\n        return self.verbosity >= 0\n\n    @property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath\n\n    @showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value\n\n    @property\n    def showlongtestinfo(self):\n        return self.verbosity > 0\n\n    def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars\n\n    def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, **markup)\n\n    def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2\n\n    def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None\n\n    def write(self, content, **markup):\n        self._tw.write(content, **markup)\n\n    def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)\n\n    def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)\n\n    def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)\n\n    def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)\n\n    def line(self, msg, **kw):\n        self._tw.line(msg, **kw)\n\n    def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()\n\n    def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1\n\n    def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])\n\n    def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)\n\n    def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)\n\n    def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n        elif self.showfspath:\n            fsid = nodeid.split(\"::\")[0]\n            self.write_fspath_result(fsid, \"\")\n\n    def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            if not running_xdist and self.showfspath:\n                self.write_fspath_result(rep.nodeid, letter, **markup)\n            else:\n                self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2\n\n    @property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected\n\n    def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})\n\n    def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\"\n\n    def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), **{color: True})\n\n    @property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        try:\n            return self._tw.width_of_current_line\n        except AttributeError:\n            # py < 1.6.0\n            return self._tw.chars_on_current_line\n\n    def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", bold=True)\n\n    def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()\n\n    def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)\n\n    @pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)\n\n    def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)\n\n    def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result\n\n    def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        if self.config.getoption(\"collectonly\"):\n            self._printcollecteditems(session.items)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)\n\n    def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()\n\n    def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)\n\n    def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()\n\n    def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )\n\n    def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \"\n\n    def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?\n\n    def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\"\n\n    #\n    # summaries for sessionfinish\n    #\n    def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values\n\n    def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                collections.OrderedDict()\n            )  # type: collections.OrderedDict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = (\n                    collections.OrderedDict()\n                )  # type: collections.OrderedDict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")\n\n    def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]\n\n    def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)\n\n    def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)\n\n    def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)\n\n    def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)\n\n    def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)\n\n    def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)\n\n    def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)\n\n    def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types\n\n    def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color\n\n    def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))\n\n    def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color"}, {"id": "_pytest.terminal.TerminalReporter.__init__", "kind": "function", "range": [262, 4, 284, 71, 7461, 8466], "file_path": "src/_pytest/terminal.py", "content": "def __init__(self, config: Config, file=None) -> None:\n        import _pytest.config\n\n        self.config = config\n        self._numcollected = 0\n        self._session = None  # type: Optional[Session]\n        self._showfspath = None\n\n        self.stats = {}  # type: Dict[str, List[Any]]\n        self._main_color = None  # type: Optional[str]\n        self._known_types = None  # type: Optional[List]\n        self.startdir = config.invocation_dir\n        if file is None:\n            file = sys.stdout\n        self._tw = _pytest.config.create_terminal_writer(config, file)\n        self._screen_width = self._tw.fullwidth\n        self.currentfspath = None  # type: Any\n        self.reportchars = getreportopt(config)\n        self.hasmarkup = self._tw.hasmarkup\n        self.isatty = file.isatty()\n        self._progress_nodeids_reported = set()  # type: Set[str]\n        self._show_progress_info = self._determine_show_progress_info()\n        self._collect_report_last_write = None  # type: Optional[float]"}, {"id": "_pytest.terminal.TerminalReporter.writer", "kind": "function", "range": [286, 4, 289, 23, 8472, 8604], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def writer(self) -> TerminalWriter:\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        return self._tw"}, {"id": "_pytest.terminal.TerminalReporter.writer", "kind": "function", "range": [291, 4, 294, 24, 8610, 8753], "file_path": "src/_pytest/terminal.py", "content": "@writer.setter\n    def writer(self, value: TerminalWriter):\n        warnings.warn(TERMINALWRITER_WRITER, stacklevel=2)\n        self._tw = value"}, {"id": "_pytest.terminal.TerminalReporter._determine_show_progress_info", "kind": "function", "range": [296, 4, 307, 20, 8759, 9342], "file_path": "src/_pytest/terminal.py", "content": "def _determine_show_progress_info(self):\n        \"\"\"Return True if we should display progress information based on the current config\"\"\"\n        # do not show progress if we are not capturing output (#3038)\n        if self.config.getoption(\"capture\", \"no\") == \"no\":\n            return False\n        # do not show progress if we are showing fixture setup/teardown\n        if self.config.getoption(\"setupshow\", False):\n            return False\n        cfg = self.config.getini(\"console_output_style\")\n        if cfg in (\"progress\", \"count\"):\n            return cfg\n        return False"}, {"id": "_pytest.terminal.TerminalReporter.verbosity", "kind": "function", "range": [309, 4, 311, 41, 9348, 9424], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def verbosity(self):\n        return self.config.option.verbose"}, {"id": "_pytest.terminal.TerminalReporter.showheader", "kind": "function", "range": [313, 4, 315, 34, 9430, 9500], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def showheader(self):\n        return self.verbosity >= 0"}, {"id": "_pytest.terminal.TerminalReporter.showfspath", "kind": "function", "range": [317, 4, 321, 31, 9506, 9649], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def showfspath(self):\n        if self._showfspath is None:\n            return self.verbosity >= 0\n        return self._showfspath"}, {"id": "_pytest.terminal.TerminalReporter.showfspath", "kind": "function", "range": [323, 4, 325, 32, 9655, 9739], "file_path": "src/_pytest/terminal.py", "content": "@showfspath.setter\n    def showfspath(self, value):\n        self._showfspath = value"}, {"id": "_pytest.terminal.TerminalReporter.showlongtestinfo", "kind": "function", "range": [327, 4, 329, 33, 9745, 9820], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def showlongtestinfo(self):\n        return self.verbosity > 0"}, {"id": "_pytest.terminal.TerminalReporter.hasopt", "kind": "function", "range": [331, 4, 333, 39, 9826, 9953], "file_path": "src/_pytest/terminal.py", "content": "def hasopt(self, char):\n        char = {\"xfailed\": \"x\", \"skipped\": \"s\"}.get(char, char)\n        return char in self.reportchars"}, {"id": "_pytest.terminal.TerminalReporter.write_fspath_result", "kind": "function", "range": [335, 4, 346, 37, 9959, 10644], "file_path": "src/_pytest/terminal.py", "content": "def write_fspath_result(self, nodeid, res, **markup):\n        fspath = self.config.rootdir.join(nodeid.split(\"::\")[0])\n        # NOTE: explicitly check for None to work around py bug, and for less\n        # overhead in general (https://github.com/pytest-dev/py/pull/207).\n        if self.currentfspath is None or fspath != self.currentfspath:\n            if self.currentfspath is not None and self._show_progress_info:\n                self._write_progress_information_filling_space()\n            self.currentfspath = fspath\n            fspath = self.startdir.bestrelpath(fspath)\n            self._tw.line()\n            self._tw.write(fspath + \" \")\n        self._tw.write(res, **markup)"}, {"id": "_pytest.terminal.TerminalReporter.write_ensure_prefix", "kind": "function", "range": [348, 4, 355, 35, 10650, 10950], "file_path": "src/_pytest/terminal.py", "content": "def write_ensure_prefix(self, prefix, extra=\"\", **kwargs):\n        if self.currentfspath != prefix:\n            self._tw.line()\n            self.currentfspath = prefix\n            self._tw.write(prefix)\n        if extra:\n            self._tw.write(extra, **kwargs)\n            self.currentfspath = -2"}, {"id": "_pytest.terminal.TerminalReporter.ensure_newline", "kind": "function", "range": [357, 4, 360, 37, 10956, 11078], "file_path": "src/_pytest/terminal.py", "content": "def ensure_newline(self):\n        if self.currentfspath:\n            self._tw.line()\n            self.currentfspath = None"}, {"id": "_pytest.terminal.TerminalReporter.write", "kind": "function", "range": [362, 4, 363, 41, 11084, 11161], "file_path": "src/_pytest/terminal.py", "content": "def write(self, content, **markup):\n        self._tw.write(content, **markup)"}, {"id": "_pytest.terminal.TerminalReporter.write_line", "kind": "function", "range": [365, 4, 369, 37, 11167, 11357], "file_path": "src/_pytest/terminal.py", "content": "def write_line(self, line, **markup):\n        if not isinstance(line, str):\n            line = str(line, errors=\"replace\")\n        self.ensure_newline()\n        self._tw.line(line, **markup)"}, {"id": "_pytest.terminal.TerminalReporter.rewrite", "kind": "function", "range": [371, 4, 387, 52, 11363, 11981], "file_path": "src/_pytest/terminal.py", "content": "def rewrite(self, line, **markup):\n        \"\"\"\n        Rewinds the terminal cursor to the beginning and writes the given line.\n\n        :kwarg erase: if True, will also add spaces until the full terminal width to ensure\n            previous lines are properly erased.\n\n        The rest of the keyword arguments are markup instructions.\n        \"\"\"\n        erase = markup.pop(\"erase\", False)\n        if erase:\n            fill_count = self._tw.fullwidth - len(line) - 1\n            fill = \" \" * fill_count\n        else:\n            fill = \"\"\n        line = str(line)\n        self._tw.write(\"\\r\" + line + fill, **markup)"}, {"id": "_pytest.terminal.TerminalReporter.write_sep", "kind": "function", "range": [389, 4, 391, 42, 11987, 12107], "file_path": "src/_pytest/terminal.py", "content": "def write_sep(self, sep, title=None, **markup):\n        self.ensure_newline()\n        self._tw.sep(sep, title, **markup)"}, {"id": "_pytest.terminal.TerminalReporter.section", "kind": "function", "range": [393, 4, 394, 38, 12113, 12192], "file_path": "src/_pytest/terminal.py", "content": "def section(self, title, sep=\"=\", **kw):\n        self._tw.sep(sep, title, **kw)"}, {"id": "_pytest.terminal.TerminalReporter.line", "kind": "function", "range": [396, 4, 397, 32, 12198, 12257], "file_path": "src/_pytest/terminal.py", "content": "def line(self, msg, **kw):\n        self._tw.line(msg, **kw)"}, {"id": "_pytest.terminal.TerminalReporter._add_stats", "kind": "function", "range": [399, 4, 403, 34, 12263, 12495], "file_path": "src/_pytest/terminal.py", "content": "def _add_stats(self, category: str, items: List) -> None:\n        set_main_color = category not in self.stats\n        self.stats.setdefault(category, []).extend(items[:])\n        if set_main_color:\n            self._set_main_color()"}, {"id": "_pytest.terminal.TerminalReporter.pytest_internalerror", "kind": "function", "range": [405, 4, 408, 16, 12501, 12658], "file_path": "src/_pytest/terminal.py", "content": "def pytest_internalerror(self, excrepr):\n        for line in str(excrepr).split(\"\\n\"):\n            self.write_line(\"INTERNALERROR> \" + line)\n        return 1"}, {"id": "_pytest.terminal.TerminalReporter.pytest_warning_captured", "kind": "function", "range": [410, 4, 421, 53, 12664, 13197], "file_path": "src/_pytest/terminal.py", "content": "def pytest_warning_captured(self, warning_message, item):\n        # from _pytest.nodes import get_fslocation_from_item\n        from _pytest.warnings import warning_record_to_str\n\n        fslocation = warning_message.filename, warning_message.lineno\n        message = warning_record_to_str(warning_message)\n\n        nodeid = item.nodeid if item is not None else \"\"\n        warning_report = WarningReport(\n            fslocation=fslocation, message=message, nodeid=nodeid\n        )\n        self._add_stats(\"warnings\", [warning_report])"}, {"id": "_pytest.terminal.TerminalReporter.pytest_plugin_registered", "kind": "function", "range": [423, 4, 429, 32, 13203, 13578], "file_path": "src/_pytest/terminal.py", "content": "def pytest_plugin_registered(self, plugin):\n        if self.config.option.traceconfig:\n            msg = \"PLUGIN registered: {}\".format(plugin)\n            # XXX this event may happen during setup/teardown time\n            #     which unfortunately captures our output here\n            #     which garbles our output if we use self.write_line\n            self.write_line(msg)"}, {"id": "_pytest.terminal.TerminalReporter.pytest_deselected", "kind": "function", "range": [431, 4, 432, 44, 13584, 13664], "file_path": "src/_pytest/terminal.py", "content": "def pytest_deselected(self, items):\n        self._add_stats(\"deselected\", items)"}, {"id": "_pytest.terminal.TerminalReporter.pytest_runtest_logstart", "kind": "function", "range": [434, 4, 442, 46, 13670, 14077], "file_path": "src/_pytest/terminal.py", "content": "def pytest_runtest_logstart(self, nodeid, location):\n        # ensure that the path is printed before the\n        # 1st test of a module starts running\n        if self.showlongtestinfo:\n            line = self._locationline(nodeid, *location)\n            self.write_ensure_prefix(line, \"\")\n        elif self.showfspath:\n            fsid = nodeid.split(\"::\")[0]\n            self.write_fspath_result(fsid, \"\")"}, {"id": "_pytest.terminal.TerminalReporter.pytest_runtest_logreport", "kind": "function", "range": [444, 4, 493, 39, 14083, 16121], "file_path": "src/_pytest/terminal.py", "content": "def pytest_runtest_logreport(self, report: TestReport) -> None:\n        self._tests_ran = True\n        rep = report\n        res = self.config.hook.pytest_report_teststatus(report=rep, config=self.config)\n        category, letter, word = res\n        if isinstance(word, tuple):\n            word, markup = word\n        else:\n            markup = None\n        self._add_stats(category, [rep])\n        if not letter and not word:\n            # probably passed setup/teardown\n            return\n        running_xdist = hasattr(rep, \"node\")\n        if markup is None:\n            was_xfail = hasattr(report, \"wasxfail\")\n            if rep.passed and not was_xfail:\n                markup = {\"green\": True}\n            elif rep.passed and was_xfail:\n                markup = {\"yellow\": True}\n            elif rep.failed:\n                markup = {\"red\": True}\n            elif rep.skipped:\n                markup = {\"yellow\": True}\n            else:\n                markup = {}\n        if self.verbosity <= 0:\n            if not running_xdist and self.showfspath:\n                self.write_fspath_result(rep.nodeid, letter, **markup)\n            else:\n                self._tw.write(letter, **markup)\n        else:\n            self._progress_nodeids_reported.add(rep.nodeid)\n            line = self._locationline(rep.nodeid, *rep.location)\n            if not running_xdist:\n                self.write_ensure_prefix(line, word, **markup)\n                if self._show_progress_info:\n                    self._write_progress_information_filling_space()\n            else:\n                self.ensure_newline()\n                self._tw.write(\"[%s]\" % rep.node.gateway.id)\n                if self._show_progress_info:\n                    self._tw.write(\n                        self._get_progress_information_message() + \" \", cyan=True\n                    )\n                else:\n                    self._tw.write(\" \")\n                self._tw.write(word, **markup)\n                self._tw.write(\" \" + line)\n                self.currentfspath = -2"}, {"id": "_pytest.terminal.TerminalReporter._is_last_item", "kind": "function", "range": [495, 4, 497, 83, 16127, 16249], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def _is_last_item(self):\n        return len(self._progress_nodeids_reported) == self._session.testscollected"}, {"id": "_pytest.terminal.TerminalReporter.pytest_runtest_logfinish", "kind": "function", "range": [499, 4, 518, 68, 16255, 17172], "file_path": "src/_pytest/terminal.py", "content": "def pytest_runtest_logfinish(self, nodeid):\n        assert self._session\n        if self.verbosity <= 0 and self._show_progress_info:\n            if self._show_progress_info == \"count\":\n                num_tests = self._session.testscollected\n                progress_length = len(\" [{}/{}]\".format(str(num_tests), str(num_tests)))\n            else:\n                progress_length = len(\" [100%]\")\n\n            self._progress_nodeids_reported.add(nodeid)\n\n            if self._is_last_item:\n                self._write_progress_information_filling_space()\n            else:\n                main_color, _ = self._get_main_color()\n                w = self._width_of_current_line\n                past_edge = w + progress_length + 1 >= self._screen_width\n                if past_edge:\n                    msg = self._get_progress_information_message()\n                    self._tw.write(msg + \"\\n\", **{main_color: True})"}, {"id": "_pytest.terminal.TerminalReporter._get_progress_information_message", "kind": "function", "range": [520, 4, 535, 28, 17178, 17919], "file_path": "src/_pytest/terminal.py", "content": "def _get_progress_information_message(self) -> str:\n        assert self._session\n        collected = self._session.testscollected\n        if self._show_progress_info == \"count\":\n            if collected:\n                progress = self._progress_nodeids_reported\n                counter_format = \"{{:{}d}}\".format(len(str(collected)))\n                format_string = \" [{}/{{}}]\".format(counter_format)\n                return format_string.format(len(progress), collected)\n            return \" [ {} / {} ]\".format(collected, collected)\n        else:\n            if collected:\n                return \" [{:3d}%]\".format(\n                    len(self._progress_nodeids_reported) * 100 // collected\n                )\n            return \" [100%]\""}, {"id": "_pytest.terminal.TerminalReporter._write_progress_information_filling_space", "kind": "function", "range": [537, 4, 542, 52, 17925, 18209], "file_path": "src/_pytest/terminal.py", "content": "def _write_progress_information_filling_space(self):\n        color, _ = self._get_main_color()\n        msg = self._get_progress_information_message()\n        w = self._width_of_current_line\n        fill = self._tw.fullwidth - w - 1\n        self.write(msg.rjust(fill), **{color: True})"}, {"id": "_pytest.terminal.TerminalReporter._width_of_current_line", "kind": "function", "range": [544, 4, 551, 49, 18215, 18538], "file_path": "src/_pytest/terminal.py", "content": "@property\n    def _width_of_current_line(self):\n        \"\"\"Return the width of current line, using the superior implementation of py-1.6 when available\"\"\"\n        try:\n            return self._tw.width_of_current_line\n        except AttributeError:\n            # py < 1.6.0\n            return self._tw.chars_on_current_line"}, {"id": "_pytest.terminal.TerminalReporter.pytest_collection", "kind": "function", "range": [553, 4, 559, 52, 18544, 18870], "file_path": "src/_pytest/terminal.py", "content": "def pytest_collection(self) -> None:\n        if self.isatty:\n            if self.config.option.verbose >= 0:\n                self.write(\"collecting ... \", bold=True)\n                self._collect_report_last_write = time.time()\n        elif self.config.option.verbose >= 1:\n            self.write(\"collecting ... \", bold=True)"}, {"id": "_pytest.terminal.TerminalReporter.pytest_collectreport", "kind": "function", "range": [561, 4, 569, 33, 18876, 19261], "file_path": "src/_pytest/terminal.py", "content": "def pytest_collectreport(self, report: CollectReport) -> None:\n        if report.failed:\n            self._add_stats(\"error\", [report])\n        elif report.skipped:\n            self._add_stats(\"skipped\", [report])\n        items = [x for x in report.result if isinstance(x, pytest.Item)]\n        self._numcollected += len(items)\n        if self.isatty:\n            self.report_collect()"}, {"id": "_pytest.terminal.TerminalReporter.report_collect", "kind": "function", "range": [571, 4, 609, 33, 19267, 20682], "file_path": "src/_pytest/terminal.py", "content": "def report_collect(self, final=False):\n        if self.config.option.verbose < 0:\n            return\n\n        if not final:\n            # Only write \"collecting\" report every 0.5s.\n            t = time.time()\n            if (\n                self._collect_report_last_write is not None\n                and self._collect_report_last_write > t - REPORT_COLLECTING_RESOLUTION\n            ):\n                return\n            self._collect_report_last_write = t\n\n        errors = len(self.stats.get(\"error\", []))\n        skipped = len(self.stats.get(\"skipped\", []))\n        deselected = len(self.stats.get(\"deselected\", []))\n        selected = self._numcollected - errors - skipped - deselected\n        if final:\n            line = \"collected \"\n        else:\n            line = \"collecting \"\n        line += (\n            str(self._numcollected) + \" item\" + (\"\" if self._numcollected == 1 else \"s\")\n        )\n        if errors:\n            line += \" / %d error%s\" % (errors, \"s\" if errors != 1 else \"\")\n        if deselected:\n            line += \" / %d deselected\" % deselected\n        if skipped:\n            line += \" / %d skipped\" % skipped\n        if self._numcollected > selected > 0:\n            line += \" / %d selected\" % selected\n        if self.isatty:\n            self.rewrite(line, bold=True, erase=True)\n            if final:\n                self.write(\"\\n\")\n        else:\n            self.write_line(line)"}, {"id": "_pytest.terminal.TerminalReporter.pytest_sessionstart", "kind": "function", "range": [611, 4, 637, 50, 20688, 21854], "file_path": "src/_pytest/terminal.py", "content": "@pytest.hookimpl(trylast=True)\n    def pytest_sessionstart(self, session: Session) -> None:\n        self._session = session\n        self._sessionstarttime = time.time()\n        if not self.showheader:\n            return\n        self.write_sep(\"=\", \"test session starts\", bold=True)\n        verinfo = platform.python_version()\n        msg = \"platform {} -- Python {}\".format(sys.platform, verinfo)\n        pypy_version_info = getattr(sys, \"pypy_version_info\", None)\n        if pypy_version_info:\n            verinfo = \".\".join(map(str, pypy_version_info[:3]))\n            msg += \"[pypy-{}-{}]\".format(verinfo, pypy_version_info[3])\n        msg += \", pytest-{}, py-{}, pluggy-{}\".format(\n            pytest.__version__, py.__version__, pluggy.__version__\n        )\n        if (\n            self.verbosity > 0\n            or self.config.option.debug\n            or getattr(self.config.option, \"pastebin\", None)\n        ):\n            msg += \" -- \" + str(sys.executable)\n        self.write_line(msg)\n        lines = self.config.hook.pytest_report_header(\n            config=self.config, startdir=self.startdir\n        )\n        self._write_report_lines_from_hooks(lines)"}, {"id": "_pytest.terminal.TerminalReporter._write_report_lines_from_hooks", "kind": "function", "range": [639, 4, 642, 33, 21860, 22003], "file_path": "src/_pytest/terminal.py", "content": "def _write_report_lines_from_hooks(self, lines):\n        lines.reverse()\n        for line in collapse(lines):\n            self.write_line(line)"}, {"id": "_pytest.terminal.TerminalReporter.pytest_report_header", "kind": "function", "range": [644, 4, 659, 21, 22009, 22664], "file_path": "src/_pytest/terminal.py", "content": "def pytest_report_header(self, config):\n        line = \"rootdir: %s\" % config.rootdir\n\n        if config.inifile:\n            line += \", inifile: \" + config.rootdir.bestrelpath(config.inifile)\n\n        testpaths = config.getini(\"testpaths\")\n        if testpaths and config.args == testpaths:\n            rel_paths = [config.rootdir.bestrelpath(x) for x in testpaths]\n            line += \", testpaths: {}\".format(\", \".join(rel_paths))\n        result = [line]\n\n        plugininfo = config.pluginmanager.list_plugin_distinfo()\n        if plugininfo:\n            result.append(\"plugins: %s\" % \", \".join(_plugin_nameversions(plugininfo)))\n        return result"}, {"id": "_pytest.terminal.TerminalReporter.pytest_collection_finish", "kind": "function", "range": [661, 4, 677, 44, 22670, 23310], "file_path": "src/_pytest/terminal.py", "content": "def pytest_collection_finish(self, session):\n        self.report_collect(True)\n\n        if self.config.getoption(\"collectonly\"):\n            self._printcollecteditems(session.items)\n\n        lines = self.config.hook.pytest_report_collectionfinish(\n            config=self.config, startdir=self.startdir, items=session.items\n        )\n        self._write_report_lines_from_hooks(lines)\n\n        if self.config.getoption(\"collectonly\"):\n            failed = self.stats.get(\"failed\")\n            if failed:\n                self._tw.sep(\"!\", \"collection failures\")\n                for rep in failed:\n                    rep.toterminal(self._tw)"}, {"id": "_pytest.terminal.TerminalReporter._printcollecteditems", "kind": "function", "range": [679, 4, 717, 77, 23316, 25038], "file_path": "src/_pytest/terminal.py", "content": "def _printcollecteditems(self, items):\n        # to print out items and their parent collectors\n        # we take care to leave out Instances aka ()\n        # because later versions are going to get rid of them anyway\n        if self.config.option.verbose < 0:\n            if self.config.option.verbose < -1:\n                counts = {}  # type: Dict[str, int]\n                for item in items:\n                    name = item.nodeid.split(\"::\", 1)[0]\n                    counts[name] = counts.get(name, 0) + 1\n                for name, count in sorted(counts.items()):\n                    self._tw.line(\"%s: %d\" % (name, count))\n            else:\n                for item in items:\n                    self._tw.line(item.nodeid)\n            return\n        stack = []\n        indent = \"\"\n        for item in items:\n            needed_collectors = item.listchain()[1:]  # strip root node\n            while stack:\n                if stack == needed_collectors[: len(stack)]:\n                    break\n                stack.pop()\n            for col in needed_collectors[len(stack) :]:\n                stack.append(col)\n                if col.name == \"()\":  # Skip Instances.\n                    continue\n                indent = (len(stack) - 1) * \"  \"\n                self._tw.line(\"{}{}\".format(indent, col))\n                if self.config.option.verbose >= 1:\n                    try:\n                        obj = col.obj  # type: ignore\n                    except AttributeError:\n                        continue\n                    doc = inspect.getdoc(obj)\n                    if doc:\n                        for line in doc.splitlines():\n                            self._tw.line(\"{}{}\".format(indent + \"  \", line))"}, {"id": "_pytest.terminal.TerminalReporter.pytest_sessionfinish", "kind": "function", "range": [719, 4, 742, 28, 25044, 25991], "file_path": "src/_pytest/terminal.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_sessionfinish(self, session: Session, exitstatus: ExitCode):\n        outcome = yield\n        outcome.get_result()\n        self._tw.line(\"\")\n        summary_exit_codes = (\n            ExitCode.OK,\n            ExitCode.TESTS_FAILED,\n            ExitCode.INTERRUPTED,\n            ExitCode.USAGE_ERROR,\n            ExitCode.NO_TESTS_COLLECTED,\n        )\n        if exitstatus in summary_exit_codes:\n            self.config.hook.pytest_terminal_summary(\n                terminalreporter=self, exitstatus=exitstatus, config=self.config\n            )\n        if session.shouldfail:\n            self.write_sep(\"!\", session.shouldfail, red=True)\n        if exitstatus == ExitCode.INTERRUPTED:\n            self._report_keyboardinterrupt()\n            del self._keyboardinterrupt_memo\n        elif session.shouldstop:\n            self.write_sep(\"!\", session.shouldstop, red=True)\n        self.summary_stats()"}, {"id": "_pytest.terminal.TerminalReporter.pytest_terminal_summary", "kind": "function", "range": [744, 4, 753, 31, 25997, 26340], "file_path": "src/_pytest/terminal.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_terminal_summary(self):\n        self.summary_errors()\n        self.summary_failures()\n        self.summary_warnings()\n        self.summary_passes()\n        yield\n        self.short_test_summary()\n        # Display any extra warnings from teardown here (if any).\n        self.summary_warnings()"}, {"id": "_pytest.terminal.TerminalReporter.pytest_keyboard_interrupt", "kind": "function", "range": [755, 4, 756, 69, 26346, 26461], "file_path": "src/_pytest/terminal.py", "content": "def pytest_keyboard_interrupt(self, excinfo):\n        self._keyboardinterrupt_memo = excinfo.getrepr(funcargs=True)"}, {"id": "_pytest.terminal.TerminalReporter.pytest_unconfigure", "kind": "function", "range": [758, 4, 760, 44, 26467, 26594], "file_path": "src/_pytest/terminal.py", "content": "def pytest_unconfigure(self):\n        if hasattr(self, \"_keyboardinterrupt_memo\"):\n            self._report_keyboardinterrupt()"}, {"id": "_pytest.terminal.TerminalReporter._report_keyboardinterrupt", "kind": "function", "range": [762, 4, 774, 17, 26600, 27128], "file_path": "src/_pytest/terminal.py", "content": "def _report_keyboardinterrupt(self):\n        excrepr = self._keyboardinterrupt_memo\n        msg = excrepr.reprcrash.message\n        self.write_sep(\"!\", msg)\n        if \"KeyboardInterrupt\" in msg:\n            if self.config.option.fulltrace:\n                excrepr.toterminal(self._tw)\n            else:\n                excrepr.reprcrash.toterminal(self._tw)\n                self._tw.line(\n                    \"(to show a full traceback on KeyboardInterrupt use --full-trace)\",\n                    yellow=True,\n                )"}, {"id": "_pytest.terminal.TerminalReporter._locationline", "kind": "function", "range": [776, 4, 796, 24, 27134, 27956], "file_path": "src/_pytest/terminal.py", "content": "def _locationline(self, nodeid, fspath, lineno, domain):\n        def mkrel(nodeid):\n            line = self.config.cwd_relative_nodeid(nodeid)\n            if domain and line.endswith(domain):\n                line = line[: -len(domain)]\n                values = domain.split(\"[\")\n                values[0] = values[0].replace(\".\", \"::\")  # don't replace '.' in params\n                line += \"[\".join(values)\n            return line\n\n        # collect_fspath comes from testid which has a \"/\"-normalized path\n\n        if fspath:\n            res = mkrel(nodeid)\n            if self.verbosity >= 2 and nodeid.split(\"::\")[0] != fspath.replace(\n                \"\\\\\", nodes.SEP\n            ):\n                res += \" <- \" + self.startdir.bestrelpath(fspath)\n        else:\n            res = \"[location]\"\n        return res + \" \""}, {"id": "_pytest.terminal.TerminalReporter._getfailureheadline", "kind": "function", "range": [798, 4, 802, 37, 27962, 28120], "file_path": "src/_pytest/terminal.py", "content": "def _getfailureheadline(self, rep):\n        head_line = rep.head_line\n        if head_line:\n            return head_line\n        return \"test session\"  # XXX?"}, {"id": "_pytest.terminal.TerminalReporter._getcrashline", "kind": "function", "range": [804, 4, 811, 25, 28126, 28370], "file_path": "src/_pytest/terminal.py", "content": "def _getcrashline(self, rep):\n        try:\n            return str(rep.longrepr.reprcrash)\n        except AttributeError:\n            try:\n                return str(rep.longrepr)[:50]\n            except AttributeError:\n                return \"\""}, {"id": "_pytest.terminal.TerminalReporter.getreports", "kind": "function", "range": [816, 4, 821, 21, 28422, 28611], "file_path": "src/_pytest/terminal.py", "content": "def getreports(self, name):\n        values = []\n        for x in self.stats.get(name, []):\n            if not hasattr(x, \"_pdbshown\"):\n                values.append(x)\n        return values"}, {"id": "_pytest.terminal.TerminalReporter.summary_warnings", "kind": "function", "range": [823, 4, 880, 85, 28617, 31154], "file_path": "src/_pytest/terminal.py", "content": "def summary_warnings(self):\n        if self.hasopt(\"w\"):\n            all_warnings = self.stats.get(\n                \"warnings\"\n            )  # type: Optional[List[WarningReport]]\n            if not all_warnings:\n                return\n\n            final = hasattr(self, \"_already_displayed_warnings\")\n            if final:\n                warning_reports = all_warnings[self._already_displayed_warnings :]\n            else:\n                warning_reports = all_warnings\n            self._already_displayed_warnings = len(warning_reports)\n            if not warning_reports:\n                return\n\n            reports_grouped_by_message = (\n                collections.OrderedDict()\n            )  # type: collections.OrderedDict[str, List[WarningReport]]\n            for wr in warning_reports:\n                reports_grouped_by_message.setdefault(wr.message, []).append(wr)\n\n            def collapsed_location_report(reports: List[WarningReport]):\n                locations = []\n                for w in reports:\n                    location = w.get_location(self.config)\n                    if location:\n                        locations.append(location)\n\n                if len(locations) < 10:\n                    return \"\\n\".join(map(str, locations))\n\n                counts_by_filename = (\n                    collections.OrderedDict()\n                )  # type: collections.OrderedDict[str, int]\n                for loc in locations:\n                    key = str(loc).split(\"::\", 1)[0]\n                    counts_by_filename[key] = counts_by_filename.get(key, 0) + 1\n                return \"\\n\".join(\n                    \"{}: {} warning{}\".format(k, v, \"s\" if v > 1 else \"\")\n                    for k, v in counts_by_filename.items()\n                )\n\n            title = \"warnings summary (final)\" if final else \"warnings summary\"\n            self.write_sep(\"=\", title, yellow=True, bold=False)\n            for message, message_reports in reports_grouped_by_message.items():\n                maybe_location = collapsed_location_report(message_reports)\n                if maybe_location:\n                    self._tw.line(maybe_location)\n                    lines = message.splitlines()\n                    indented = \"\\n\".join(\"  \" + x for x in lines)\n                    message = indented.rstrip()\n                else:\n                    message = message.rstrip()\n                self._tw.line(message)\n                self._tw.line()\n            self._tw.line(\"-- Docs: https://docs.pytest.org/en/latest/warnings.html\")"}, {"id": "_pytest.terminal.TerminalReporter.summary_passes", "kind": "function", "range": [882, 4, 894, 62, 31160, 31740], "file_path": "src/_pytest/terminal.py", "content": "def summary_passes(self):\n        if self.config.option.tbstyle != \"no\":\n            if self.hasopt(\"P\"):\n                reports = self.getreports(\"passed\")\n                if not reports:\n                    return\n                self.write_sep(\"=\", \"PASSES\")\n                for rep in reports:\n                    if rep.sections:\n                        msg = self._getfailureheadline(rep)\n                        self.write_sep(\"_\", msg, green=True, bold=True)\n                        self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)"}, {"id": "_pytest.terminal.TerminalReporter._get_teardown_reports", "kind": "function", "range": [896, 4, 901, 9, 31746, 31972], "file_path": "src/_pytest/terminal.py", "content": "def _get_teardown_reports(self, nodeid: str) -> List[TestReport]:\n        return [\n            report\n            for report in self.getreports(\"\")\n            if report.when == \"teardown\" and report.nodeid == nodeid\n        ]"}, {"id": "_pytest.terminal.TerminalReporter._handle_teardown_sections", "kind": "function", "range": [903, 4, 905, 48, 31978, 32142], "file_path": "src/_pytest/terminal.py", "content": "def _handle_teardown_sections(self, nodeid: str) -> None:\n        for report in self._get_teardown_reports(nodeid):\n            self.print_teardown_sections(report)"}, {"id": "_pytest.terminal.TerminalReporter.print_teardown_sections", "kind": "function", "range": [907, 4, 918, 38, 32148, 32654], "file_path": "src/_pytest/terminal.py", "content": "def print_teardown_sections(self, rep: TestReport) -> None:\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            if \"teardown\" in secname:\n                self._tw.sep(\"-\", secname)\n                if content[-1:] == \"\\n\":\n                    content = content[:-1]\n                self._tw.line(content)"}, {"id": "_pytest.terminal.TerminalReporter.summary_failures", "kind": "function", "range": [920, 4, 935, 62, 32660, 33344], "file_path": "src/_pytest/terminal.py", "content": "def summary_failures(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"failed\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"FAILURES\")\n            if self.config.option.tbstyle == \"line\":\n                for rep in reports:\n                    line = self._getcrashline(rep)\n                    self.write_line(line)\n            else:\n                for rep in reports:\n                    msg = self._getfailureheadline(rep)\n                    self.write_sep(\"_\", msg, red=True, bold=True)\n                    self._outrep_summary(rep)\n                    self._handle_teardown_sections(rep.nodeid)"}, {"id": "_pytest.terminal.TerminalReporter.summary_errors", "kind": "function", "range": [937, 4, 950, 41, 33350, 33946], "file_path": "src/_pytest/terminal.py", "content": "def summary_errors(self):\n        if self.config.option.tbstyle != \"no\":\n            reports = self.getreports(\"error\")\n            if not reports:\n                return\n            self.write_sep(\"=\", \"ERRORS\")\n            for rep in self.stats[\"error\"]:\n                msg = self._getfailureheadline(rep)\n                if rep.when == \"collect\":\n                    msg = \"ERROR collecting \" + msg\n                else:\n                    msg = \"ERROR at {} of {}\".format(rep.when, msg)\n                self.write_sep(\"_\", msg, red=True, bold=True)\n                self._outrep_summary(rep)"}, {"id": "_pytest.terminal.TerminalReporter._outrep_summary", "kind": "function", "range": [952, 4, 963, 34, 33952, 34409], "file_path": "src/_pytest/terminal.py", "content": "def _outrep_summary(self, rep):\n        rep.toterminal(self._tw)\n        showcapture = self.config.option.showcapture\n        if showcapture == \"no\":\n            return\n        for secname, content in rep.sections:\n            if showcapture != \"all\" and showcapture not in secname:\n                continue\n            self._tw.sep(\"-\", secname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            self._tw.line(content)"}, {"id": "_pytest.terminal.TerminalReporter.summary_stats", "kind": "function", "range": [965, 4, 1000, 47, 34415, 35784], "file_path": "src/_pytest/terminal.py", "content": "def summary_stats(self):\n        if self.verbosity < -1:\n            return\n\n        session_duration = time.time() - self._sessionstarttime\n        (parts, main_color) = self.build_summary_stats_line()\n        line_parts = []\n\n        display_sep = self.verbosity >= 0\n        if display_sep:\n            fullwidth = self._tw.fullwidth\n        for text, markup in parts:\n            with_markup = self._tw.markup(text, **markup)\n            if display_sep:\n                fullwidth += len(with_markup) - len(text)\n            line_parts.append(with_markup)\n        msg = \", \".join(line_parts)\n\n        main_markup = {main_color: True}\n        duration = \" in {}\".format(format_session_duration(session_duration))\n        duration_with_markup = self._tw.markup(duration, **main_markup)\n        if display_sep:\n            fullwidth += len(duration_with_markup) - len(duration)\n        msg += duration_with_markup\n\n        if display_sep:\n            markup_for_end_sep = self._tw.markup(\"\", **main_markup)\n            if markup_for_end_sep.endswith(\"\\x1b[0m\"):\n                markup_for_end_sep = markup_for_end_sep[:-4]\n            fullwidth += len(markup_for_end_sep)\n            msg += markup_for_end_sep\n\n        if display_sep:\n            self.write_sep(\"=\", msg, fullwidth=fullwidth, **main_markup)\n        else:\n            self.write_line(msg, **main_markup)"}, {"id": "_pytest.terminal.TerminalReporter.short_test_summary", "kind": "function", "range": [1002, 4, 1069, 37, 35790, 38529], "file_path": "src/_pytest/terminal.py", "content": "def short_test_summary(self) -> None:\n        if not self.reportchars:\n            return\n\n        def show_simple(stat, lines: List[str]) -> None:\n            failed = self.stats.get(stat, [])\n            if not failed:\n                return\n            termwidth = self._tw.fullwidth\n            config = self.config\n            for rep in failed:\n                line = _get_line_with_reprcrash_message(config, rep, termwidth)\n                lines.append(line)\n\n        def show_xfailed(lines: List[str]) -> None:\n            xfailed = self.stats.get(\"xfailed\", [])\n            for rep in xfailed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                lines.append(\"{} {}\".format(verbose_word, pos))\n                reason = rep.wasxfail\n                if reason:\n                    lines.append(\"  \" + str(reason))\n\n        def show_xpassed(lines: List[str]) -> None:\n            xpassed = self.stats.get(\"xpassed\", [])\n            for rep in xpassed:\n                verbose_word = rep._get_verbose_word(self.config)\n                pos = _get_pos(self.config, rep)\n                reason = rep.wasxfail\n                lines.append(\"{} {} {}\".format(verbose_word, pos, reason))\n\n        def show_skipped(lines: List[str]) -> None:\n            skipped = self.stats.get(\"skipped\", [])\n            fskips = _folded_skips(self.startdir, skipped) if skipped else []\n            if not fskips:\n                return\n            verbose_word = skipped[0]._get_verbose_word(self.config)\n            for num, fspath, lineno, reason in fskips:\n                if reason.startswith(\"Skipped: \"):\n                    reason = reason[9:]\n                if lineno is not None:\n                    lines.append(\n                        \"%s [%d] %s:%d: %s\"\n                        % (verbose_word, num, fspath, lineno, reason)\n                    )\n                else:\n                    lines.append(\"%s [%d] %s: %s\" % (verbose_word, num, fspath, reason))\n\n        REPORTCHAR_ACTIONS = {\n            \"x\": show_xfailed,\n            \"X\": show_xpassed,\n            \"f\": partial(show_simple, \"failed\"),\n            \"s\": show_skipped,\n            \"p\": partial(show_simple, \"passed\"),\n            \"E\": partial(show_simple, \"error\"),\n        }  # type: Mapping[str, Callable[[List[str]], None]]\n\n        lines = []  # type: List[str]\n        for char in self.reportchars:\n            action = REPORTCHAR_ACTIONS.get(char)\n            if action:  # skipping e.g. \"P\" (passed with output) here.\n                action(lines)\n\n        if lines:\n            self.write_sep(\"=\", \"short test summary info\")\n            for line in lines:\n                self.write_line(line)"}, {"id": "_pytest.terminal.TerminalReporter._get_main_color", "kind": "function", "range": [1071, 4, 1076, 50, 38535, 38833], "file_path": "src/_pytest/terminal.py", "content": "def _get_main_color(self) -> Tuple[str, List[str]]:\n        if self._main_color is None or self._known_types is None or self._is_last_item:\n            self._set_main_color()\n            assert self._main_color\n            assert self._known_types\n        return self._main_color, self._known_types"}, {"id": "_pytest.terminal.TerminalReporter._determine_main_color", "kind": "function", "range": [1078, 4, 1088, 25, 38839, 39287], "file_path": "src/_pytest/terminal.py", "content": "def _determine_main_color(self, unknown_type_seen: bool) -> str:\n        stats = self.stats\n        if \"failed\" in stats or \"error\" in stats:\n            main_color = \"red\"\n        elif \"warnings\" in stats or \"xpassed\" in stats or unknown_type_seen:\n            main_color = \"yellow\"\n        elif \"passed\" in stats or not self._is_last_item:\n            main_color = \"green\"\n        else:\n            main_color = \"yellow\"\n        return main_color"}, {"id": "_pytest.terminal.TerminalReporter._set_main_color", "kind": "function", "range": [1090, 4, 1097, 74, 39293, 39778], "file_path": "src/_pytest/terminal.py", "content": "def _set_main_color(self) -> None:\n        unknown_types = []  # type: List[str]\n        for found_type in self.stats.keys():\n            if found_type:  # setup/teardown reports have an empty key, ignore them\n                if found_type not in KNOWN_TYPES and found_type not in unknown_types:\n                    unknown_types.append(found_type)\n        self._known_types = list(KNOWN_TYPES) + unknown_types\n        self._main_color = self._determine_main_color(bool(unknown_types))"}, {"id": "_pytest.terminal.TerminalReporter.build_summary_stats_line", "kind": "function", "range": [1099, 4, 1116, 32, 39784, 40530], "file_path": "src/_pytest/terminal.py", "content": "def build_summary_stats_line(self) -> Tuple[List[Tuple[str, Dict[str, bool]]], str]:\n        main_color, known_types = self._get_main_color()\n\n        parts = []\n        for key in known_types:\n            reports = self.stats.get(key, None)\n            if reports:\n                count = sum(\n                    1 for rep in reports if getattr(rep, \"count_towards_summary\", True)\n                )\n                color = _color_for_type.get(key, _color_for_type_default)\n                markup = {color: True, \"bold\": color == main_color}\n                parts.append((\"%d %s\" % _make_plural(count, key), markup))\n\n        if not parts:\n            parts = [(\"no tests ran\", {_color_for_type_default: True})]\n\n        return parts, main_color"}, {"id": "_pytest.terminal._get_pos", "kind": "function", "range": [1119, 0, 1121, 17, 40533, 40629], "file_path": "src/_pytest/terminal.py", "content": "def _get_pos(config, rep):\n    nodeid = config.cwd_relative_nodeid(rep.nodeid)\n    return nodeid"}, {"id": "_pytest.terminal._get_line_with_reprcrash_message", "kind": "function", "range": [1124, 0, 1159, 15, 40632, 41763], "file_path": "src/_pytest/terminal.py", "content": "def _get_line_with_reprcrash_message(config, rep, termwidth):\n    \"\"\"Get summary line for a report, trying to add reprcrash message.\"\"\"\n    from wcwidth import wcswidth\n\n    verbose_word = rep._get_verbose_word(config)\n    pos = _get_pos(config, rep)\n\n    line = \"{} {}\".format(verbose_word, pos)\n    len_line = wcswidth(line)\n    ellipsis, len_ellipsis = \"...\", 3\n    if len_line > termwidth - len_ellipsis:\n        # No space for an additional message.\n        return line\n\n    try:\n        msg = rep.longrepr.reprcrash.message\n    except AttributeError:\n        pass\n    else:\n        # Only use the first line.\n        i = msg.find(\"\\n\")\n        if i != -1:\n            msg = msg[:i]\n        len_msg = wcswidth(msg)\n\n        sep, len_sep = \" - \", 3\n        max_len_msg = termwidth - len_line - len_sep\n        if max_len_msg >= len_ellipsis:\n            if len_msg > max_len_msg:\n                max_len_msg -= len_ellipsis\n                msg = msg[:max_len_msg]\n                while wcswidth(msg) > max_len_msg:\n                    msg = msg[:-1]\n                msg += ellipsis\n            line += sep + msg\n    return line"}, {"id": "_pytest.terminal._folded_skips", "kind": "function", "range": [1162, 0, 1185, 17, 41766, 42727], "file_path": "src/_pytest/terminal.py", "content": "def _folded_skips(startdir, skipped):\n    d = {}\n    for event in skipped:\n        assert len(event.longrepr) == 3, (event, event.longrepr)\n        fspath, lineno, reason = event.longrepr\n        # For consistency, report all fspaths in relative form.\n        fspath = startdir.bestrelpath(py.path.local(fspath))\n        keywords = getattr(event, \"keywords\", {})\n        # folding reports with global pytestmark variable\n        # this is workaround, because for now we cannot identify the scope of a skip marker\n        # TODO: revisit after marks scope would be fixed\n        if (\n            event.when == \"setup\"\n            and \"skip\" in keywords\n            and \"pytestmark\" not in keywords\n        ):\n            key = (fspath, None, reason)\n        else:\n            key = (fspath, lineno, reason)\n        d.setdefault(key, []).append(event)\n    values = []\n    for key, events in d.items():\n        values.append((len(events),) + key)\n    return values"}, {"id": "_pytest.terminal._color_for_type", "kind": "variable", "range": [1188, 0, 1193, 1, 42730, 42841], "file_path": "src/_pytest/terminal.py", "content": "_color_for_type = {\n    \"failed\": \"red\",\n    \"error\": \"red\",\n    \"warnings\": \"yellow\",\n    \"passed\": \"green\",\n}"}, {"id": "_pytest.terminal._color_for_type_default", "kind": "variable", "range": [1194, 0, 1194, 34, 42842, 42876], "file_path": "src/_pytest/terminal.py", "content": "_color_for_type_default = \"yellow\""}, {"id": "_pytest.terminal._make_plural", "kind": "function", "range": [1197, 0, 1207, 52, 42879, 43330], "file_path": "src/_pytest/terminal.py", "content": "def _make_plural(count, noun):\n    # No need to pluralize words such as `failed` or `passed`.\n    if noun not in [\"error\", \"warnings\"]:\n        return count, noun\n\n    # The `warnings` key is plural. To avoid API breakage, we keep it that way but\n    # set it to singular here so we can determine plurality in the same way as we do\n    # for `error`.\n    noun = noun.replace(\"warnings\", \"warning\")\n\n    return count, noun + \"s\" if count != 1 else noun"}, {"id": "_pytest.terminal._plugin_nameversions", "kind": "function", "range": [1210, 0, 1222, 17, 43333, 43866], "file_path": "src/_pytest/terminal.py", "content": "def _plugin_nameversions(plugininfo) -> List[str]:\n    values = []  # type: List[str]\n    for plugin, dist in plugininfo:\n        # gets us name and version!\n        name = \"{dist.project_name}-{dist.version}\".format(dist=dist)\n        # questionable convenience, but it keeps things short\n        if name.startswith(\"pytest-\"):\n            name = name[7:]\n        # we decided to print python package names\n        # they can have more than one plugin\n        if name not in values:\n            values.append(name)\n    return values"}, {"id": "_pytest.terminal.format_session_duration", "kind": "function", "range": [1225, 0, 1231, 49, 43869, 44187], "file_path": "src/_pytest/terminal.py", "content": "def format_session_duration(seconds: float) -> str:\n    \"\"\"Format the given seconds in a human readable manner to show in the final summary\"\"\"\n    if seconds < 60:\n        return \"{:.2f}s\".format(seconds)\n    else:\n        dt = datetime.timedelta(seconds=int(seconds))\n        return \"{:.2f}s ({})\".format(seconds, dt)"}, {"id": "_pytest.config._PluggyPlugin", "kind": "variable", "range": [53, 0, 53, 22, 1370, 1392], "file_path": "src/_pytest/config/__init__.py", "content": "_PluggyPlugin = object"}, {"id": "_pytest.config.hookimpl", "kind": "variable", "range": [60, 0, 60, 35, 1600, 1635], "file_path": "src/_pytest/config/__init__.py", "content": "hookimpl = HookimplMarker(\"pytest\")"}, {"id": "_pytest.config.hookspec", "kind": "variable", "range": [61, 0, 61, 35, 1636, 1671], "file_path": "src/_pytest/config/__init__.py", "content": "hookspec = HookspecMarker(\"pytest\")"}, {"id": "_pytest.config.ExitCode", "kind": "class", "range": [64, 0, 84, 26, 1674, 2153], "file_path": "src/_pytest/config/__init__.py", "content": "class ExitCode(enum.IntEnum):\n    \"\"\"\n    .. versionadded:: 5.0\n\n    Encodes the valid exit codes by pytest.\n\n    Currently users and plugins may supply other exit codes as well.\n    \"\"\"\n\n    #: tests passed\n    OK = 0\n    #: tests failed\n    TESTS_FAILED = 1\n    #: pytest was interrupted\n    INTERRUPTED = 2\n    #: an internal error got in the way\n    INTERNAL_ERROR = 3\n    #: pytest was misused\n    USAGE_ERROR = 4\n    #: pytest couldn't find tests\n    NO_TESTS_COLLECTED = 5"}, {"id": "_pytest.config.ExitCode.OK", "kind": "variable", "range": [74, 4, 74, 10, 1886, 1892], "file_path": "src/_pytest/config/__init__.py", "content": "OK = 0"}, {"id": "_pytest.config.ExitCode.TESTS_FAILED", "kind": "variable", "range": [76, 4, 76, 20, 1917, 1933], "file_path": "src/_pytest/config/__init__.py", "content": "TESTS_FAILED = 1"}, {"id": "_pytest.config.ExitCode.INTERRUPTED", "kind": "variable", "range": [78, 4, 78, 19, 1968, 1983], "file_path": "src/_pytest/config/__init__.py", "content": "INTERRUPTED = 2"}, {"id": "_pytest.config.ExitCode.INTERNAL_ERROR", "kind": "variable", "range": [80, 4, 80, 22, 2028, 2046], "file_path": "src/_pytest/config/__init__.py", "content": "INTERNAL_ERROR = 3"}, {"id": "_pytest.config.ExitCode.USAGE_ERROR", "kind": "variable", "range": [82, 4, 82, 19, 2077, 2092], "file_path": "src/_pytest/config/__init__.py", "content": "USAGE_ERROR = 4"}, {"id": "_pytest.config.ExitCode.NO_TESTS_COLLECTED", "kind": "variable", "range": [84, 4, 84, 26, 2131, 2153], "file_path": "src/_pytest/config/__init__.py", "content": "NO_TESTS_COLLECTED = 5"}, {"id": "_pytest.config.ConftestImportFailure", "kind": "class", "range": [87, 0, 91, 88, 2156, 2396], "file_path": "src/_pytest/config/__init__.py", "content": "class ConftestImportFailure(Exception):\n    def __init__(self, path, excinfo):\n        Exception.__init__(self, path, excinfo)\n        self.path = path\n        self.excinfo = excinfo  # type: Tuple[Type[Exception], Exception, TracebackType]"}, {"id": "_pytest.config.ConftestImportFailure.__init__", "kind": "function", "range": [88, 4, 91, 88, 2200, 2396], "file_path": "src/_pytest/config/__init__.py", "content": "def __init__(self, path, excinfo):\n        Exception.__init__(self, path, excinfo)\n        self.path = path\n        self.excinfo = excinfo  # type: Tuple[Type[Exception], Exception, TracebackType]"}, {"id": "_pytest.config.main", "kind": "function", "range": [94, 0, 136, 35, 2399, 4001], "file_path": "src/_pytest/config/__init__.py", "content": "def main(args=None, plugins=None) -> Union[int, ExitCode]:\n    \"\"\" return exit code, after performing an in-process test run.\n\n    :arg args: list of command line arguments.\n\n    :arg plugins: list of plugin objects to be auto-registered during\n                  initialization.\n    \"\"\"\n    try:\n        try:\n            config = _prepareconfig(args, plugins)\n        except ConftestImportFailure as e:\n            exc_info = ExceptionInfo(e.excinfo)\n            tw = TerminalWriter(sys.stderr)\n            tw.line(\n                \"ImportError while loading conftest '{e.path}'.\".format(e=e), red=True\n            )\n            exc_info.traceback = exc_info.traceback.filter(filter_traceback)\n            exc_repr = (\n                exc_info.getrepr(style=\"short\", chain=False)\n                if exc_info.traceback\n                else exc_info.exconly()\n            )\n            formatted_tb = str(exc_repr)\n            for line in formatted_tb.splitlines():\n                tw.line(line.rstrip(), red=True)\n            return ExitCode.USAGE_ERROR\n        else:\n            try:\n                ret = config.hook.pytest_cmdline_main(\n                    config=config\n                )  # type: Union[ExitCode, int]\n                try:\n                    return ExitCode(ret)\n                except ValueError:\n                    return ret\n            finally:\n                config._ensure_unconfigure()\n    except UsageError as e:\n        tw = TerminalWriter(sys.stderr)\n        for msg in e.args:\n            tw.line(\"ERROR: {}\\n\".format(msg), red=True)\n        return ExitCode.USAGE_ERROR"}, {"id": "_pytest.config.cmdline", "kind": "class", "range": [139, 0, 140, 29, 4004, 4075], "file_path": "src/_pytest/config/__init__.py", "content": "class cmdline:  # compatibility namespace\n    main = staticmethod(main)"}, {"id": "_pytest.config.cmdline.main", "kind": "variable", "range": [140, 4, 140, 29, 4050, 4075], "file_path": "src/_pytest/config/__init__.py", "content": "main = staticmethod(main)"}, {"id": "_pytest.config.filename_arg", "kind": "function", "range": [143, 0, 151, 15, 4078, 4363], "file_path": "src/_pytest/config/__init__.py", "content": "def filename_arg(path, optname):\n    \"\"\" Argparse type validator for filename arguments.\n\n    :path: path of filename\n    :optname: name of the option\n    \"\"\"\n    if os.path.isdir(path):\n        raise UsageError(\"{} must be a filename, given: {}\".format(optname, path))\n    return path"}, {"id": "_pytest.config.directory_arg", "kind": "function", "range": [154, 0, 162, 15, 4366, 4658], "file_path": "src/_pytest/config/__init__.py", "content": "def directory_arg(path, optname):\n    \"\"\"Argparse type validator for directory arguments.\n\n    :path: path of directory\n    :optname: name of the option\n    \"\"\"\n    if not os.path.isdir(path):\n        raise UsageError(\"{} must be a directory, given: {}\".format(optname, path))\n    return path"}, {"id": "_pytest.config.essential_plugins", "kind": "variable", "range": [166, 0, 172, 1, 4720, 4831], "file_path": "src/_pytest/config/__init__.py", "content": "essential_plugins = (\n    \"mark\",\n    \"main\",\n    \"runner\",\n    \"fixtures\",\n    \"helpconfig\",  # Provides -p.\n)"}, {"id": "_pytest.config.default_plugins", "kind": "variable", "range": [174, 0, 199, 1, 4833, 5268], "file_path": "src/_pytest/config/__init__.py", "content": "default_plugins = essential_plugins + (\n    \"python\",\n    \"terminal\",\n    \"debugging\",\n    \"unittest\",\n    \"capture\",\n    \"skipping\",\n    \"tmpdir\",\n    \"monkeypatch\",\n    \"recwarn\",\n    \"pastebin\",\n    \"nose\",\n    \"assertion\",\n    \"junitxml\",\n    \"resultlog\",\n    \"doctest\",\n    \"cacheprovider\",\n    \"freeze_support\",\n    \"setuponly\",\n    \"setupplan\",\n    \"stepwise\",\n    \"warnings\",\n    \"logging\",\n    \"reports\",\n    \"faulthandler\",\n)"}, {"id": "_pytest.config.builtin_plugins", "kind": "variable", "range": [201, 0, 201, 38, 5270, 5308], "file_path": "src/_pytest/config/__init__.py", "content": "builtin_plugins = set(default_plugins)"}, {"id": "_pytest.config.get_config", "kind": "function", "range": [205, 0, 221, 17, 5343, 5891], "file_path": "src/_pytest/config/__init__.py", "content": "def get_config(args=None, plugins=None):\n    # subsequent calls to main will create a fresh instance\n    pluginmanager = PytestPluginManager()\n    config = Config(\n        pluginmanager,\n        invocation_params=Config.InvocationParams(\n            args=args or (), plugins=plugins, dir=Path().resolve()\n        ),\n    )\n\n    if args is not None:\n        # Handle any \"-p no:plugin\" args.\n        pluginmanager.consider_preparse(args, exclude_only=True)\n\n    for spec in default_plugins:\n        pluginmanager.import_plugin(spec)\n    return config"}, {"id": "_pytest.config.get_plugin_manager", "kind": "function", "range": [224, 0, 233, 37, 5894, 6218], "file_path": "src/_pytest/config/__init__.py", "content": "def get_plugin_manager():\n    \"\"\"\n    Obtain a new instance of the\n    :py:class:`_pytest.config.PytestPluginManager`, with default plugins\n    already loaded.\n\n    This function can be used by integration with other tools, like hooking\n    into pytest to run tests into an IDE.\n    \"\"\"\n    return get_config().pluginmanager"}, {"id": "_pytest.config._prepareconfig", "kind": "function", "range": [236, 0, 261, 13, 6221, 7130], "file_path": "src/_pytest/config/__init__.py", "content": "def _prepareconfig(\n    args: Optional[Union[py.path.local, List[str]]] = None, plugins=None\n):\n    if args is None:\n        args = sys.argv[1:]\n    elif isinstance(args, py.path.local):\n        args = [str(args)]\n    elif not isinstance(args, list):\n        msg = \"`args` parameter expected to be a list of strings, got: {!r} (type: {})\"\n        raise TypeError(msg.format(args, type(args)))\n\n    config = get_config(args, plugins)\n    pluginmanager = config.pluginmanager\n    try:\n        if plugins:\n            for plugin in plugins:\n                if isinstance(plugin, str):\n                    pluginmanager.consider_pluginarg(plugin)\n                else:\n                    pluginmanager.register(plugin)\n        return pluginmanager.hook.pytest_cmdline_parse(\n            pluginmanager=pluginmanager, args=args\n        )\n    except BaseException:\n        config._ensure_unconfigure()\n        raise"}, {"id": "_pytest.config._fail_on_non_top_pytest_plugins", "kind": "function", "range": [264, 0, 274, 61, 7133, 7716], "file_path": "src/_pytest/config/__init__.py", "content": "def _fail_on_non_top_pytest_plugins(conftestpath, confcutdir):\n    msg = (\n        \"Defining 'pytest_plugins' in a non-top-level conftest is no longer supported:\\n\"\n        \"It affects the entire test suite instead of just below the conftest as expected.\\n\"\n        \"  {}\\n\"\n        \"Please move it to a top level conftest file at the rootdir:\\n\"\n        \"  {}\\n\"\n        \"For more information, visit:\\n\"\n        \"  https://docs.pytest.org/en/latest/deprecations.html#pytest-plugins-in-non-top-level-conftest-files\"\n    )\n    fail(msg.format(conftestpath, confcutdir), pytrace=False)"}, {"id": "_pytest.config.PytestPluginManager", "kind": "class", "range": [277, 0, 630, 39, 7719, 21400], "file_path": "src/_pytest/config/__init__.py", "content": "class PytestPluginManager(PluginManager):\n    \"\"\"\n    Overwrites :py:class:`pluggy.PluginManager <pluggy.PluginManager>` to add pytest-specific\n    functionality:\n\n    * loading plugins from the command line, ``PYTEST_PLUGINS`` env variable and\n      ``pytest_plugins`` global variables found in plugins being loaded;\n    * ``conftest.py`` loading during start-up;\n    \"\"\"\n\n    def __init__(self):\n        import _pytest.assertion\n\n        super().__init__(\"pytest\")\n        # The objects are module objects, only used generically.\n        self._conftest_plugins = set()  # type: Set[object]\n\n        # state related to local conftest plugins\n        # Maps a py.path.local to a list of module objects.\n        self._dirpath2confmods = {}  # type: Dict[Any, List[object]]\n        # Maps a py.path.local to a module object.\n        self._conftestpath2mod = {}  # type: Dict[Any, object]\n        self._confcutdir = None\n        self._noconftest = False\n        # Set of py.path.local's.\n        self._duplicatepaths = set()  # type: Set[Any]\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err = sys.stderr\n            encoding = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()), mode=err.mode, buffering=1, encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook = _pytest.assertion.DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage\n        self._configured = False\n\n    def parse_hookimpl_opts(self, plugin, name):\n        # pytest hooks are always prefixed with pytest_\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073)\n        if not name.startswith(\"pytest_\"):\n            return\n        # ignore names which can not be hooks\n        if name == \"pytest_plugins\":\n            return\n\n        method = getattr(plugin, name)\n        opts = super().parse_hookimpl_opts(plugin, name)\n\n        # consider only actual functions for hooks (#3775)\n        if not inspect.isroutine(method):\n            return\n\n        # collect unmarked hooks as long as they have the `pytest_' prefix\n        if opts is None and name.startswith(\"pytest_\"):\n            opts = {}\n        if opts is not None:\n            # TODO: DeprecationWarning, people should use hookimpl\n            # https://github.com/pytest-dev/pytest/issues/4562\n            known_marks = {m.name for m in getattr(method, \"pytestmark\", [])}\n\n            for name in (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\"):\n                opts.setdefault(name, hasattr(method, name) or name in known_marks)\n        return opts\n\n    def parse_hookspec_opts(self, module_or_class, name):\n        opts = super().parse_hookspec_opts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n\n            if name.startswith(\"pytest_\"):\n                # todo: deprecate hookspec hacks\n                # https://github.com/pytest-dev/pytest/issues/4562\n                known_marks = {m.name for m in getattr(method, \"pytestmark\", [])}\n                opts = {\n                    \"firstresult\": hasattr(method, \"firstresult\")\n                    or \"firstresult\" in known_marks,\n                    \"historic\": hasattr(method, \"historic\")\n                    or \"historic\" in known_marks,\n                }\n        return opts\n\n    def register(self, plugin, name=None):\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return\n        ret = super().register(plugin, name)\n        if ret:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=dict(plugin=plugin, manager=self)\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return ret\n\n    def getplugin(self, name):\n        # support deprecated naming because plugins (xdist e.g.) use it\n        return self.get_plugin(name)\n\n    def hasplugin(self, name):\n        \"\"\"Return True if the plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))\n\n    def pytest_configure(self, config):\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible.\",\n        )\n        self._configured = True\n\n    #\n    # internal API for local conftest plugin handling\n    #\n    def _set_initial_conftests(self, namespace):\n        \"\"\" load initial conftest files given a preparsed \"namespace\".\n            As conftest files may add their own command line options\n            which have arguments ('--my-opt somepath') we might get some\n            false positives.  All builtin and 3rd party plugins will have\n            been loaded, however, so common options will not confuse our logic\n            here.\n        \"\"\"\n        current = py.path.local()\n        self._confcutdir = (\n            current.join(namespace.confcutdir, abs=True)\n            if namespace.confcutdir\n            else None\n        )\n        self._noconftest = namespace.noconftest\n        self._using_pyargs = namespace.pyargs\n        testpaths = namespace.file_or_dir\n        foundanchor = False\n        for path in testpaths:\n            path = str(path)\n            # remove node-id syntax\n            i = path.find(\"::\")\n            if i != -1:\n                path = path[:i]\n            anchor = current.join(path, abs=1)\n            if exists(anchor):  # we found some file object\n                self._try_load_conftest(anchor)\n                foundanchor = True\n        if not foundanchor:\n            self._try_load_conftest(current)\n\n    def _try_load_conftest(self, anchor):\n        self._getconftestmodules(anchor)\n        # let's also consider test* subdirs\n        if anchor.check(dir=1):\n            for x in anchor.listdir(\"test*\"):\n                if x.check(dir=1):\n                    self._getconftestmodules(x)\n\n    @lru_cache(maxsize=128)\n    def _getconftestmodules(self, path):\n        if self._noconftest:\n            return []\n\n        if path.isfile():\n            directory = path.dirpath()\n        else:\n            directory = path\n\n        # XXX these days we may rather want to use config.rootdir\n        # and allow users to opt into looking into the rootdir parent\n        # directories instead of requiring to specify confcutdir\n        clist = []\n        for parent in directory.realpath().parts():\n            if self._confcutdir and self._confcutdir.relto(parent):\n                continue\n            conftestpath = parent.join(\"conftest.py\")\n            if conftestpath.isfile():\n                mod = self._importconftest(conftestpath)\n                clist.append(mod)\n        self._dirpath2confmods[directory] = clist\n        return clist\n\n    def _rget_with_confmod(self, name, path):\n        modules = self._getconftestmodules(path)\n        for mod in reversed(modules):\n            try:\n                return mod, getattr(mod, name)\n            except AttributeError:\n                continue\n        raise KeyError(name)\n\n    def _importconftest(self, conftestpath):\n        # Use a resolved Path object as key to avoid loading the same conftest twice\n        # with build systems that create build directories containing\n        # symlinks to actual files.\n        # Using Path().resolve() is better than py.path.realpath because\n        # it resolves to the correct path/drive in case-insensitive file systems (#5792)\n        key = Path(str(conftestpath)).resolve()\n        try:\n            return self._conftestpath2mod[key]\n        except KeyError:\n            pkgpath = conftestpath.pypkgpath()\n            if pkgpath is None:\n                _ensure_removed_sysmodule(conftestpath.purebasename)\n            try:\n                mod = conftestpath.pyimport()\n                if (\n                    hasattr(mod, \"pytest_plugins\")\n                    and self._configured\n                    and not self._using_pyargs\n                ):\n                    _fail_on_non_top_pytest_plugins(conftestpath, self._confcutdir)\n            except Exception:\n                raise ConftestImportFailure(conftestpath, sys.exc_info())\n\n            self._conftest_plugins.add(mod)\n            self._conftestpath2mod[key] = mod\n            dirpath = conftestpath.dirpath()\n            if dirpath in self._dirpath2confmods:\n                for path, mods in self._dirpath2confmods.items():\n                    if path and path.relto(dirpath) or path == dirpath:\n                        assert mod not in mods\n                        mods.append(mod)\n            self.trace(\"loading conftestmodule {!r}\".format(mod))\n            self.consider_conftest(mod)\n            return mod\n\n    #\n    # API for bootstrapping plugin loading\n    #\n    #\n\n    def consider_preparse(self, args, *, exclude_only=False):\n        i = 0\n        n = len(args)\n        while i < n:\n            opt = args[i]\n            i += 1\n            if isinstance(opt, str):\n                if opt == \"-p\":\n                    try:\n                        parg = args[i]\n                    except IndexError:\n                        return\n                    i += 1\n                elif opt.startswith(\"-p\"):\n                    parg = opt[2:]\n                else:\n                    continue\n                if exclude_only and not parg.startswith(\"no:\"):\n                    continue\n                self.consider_pluginarg(parg)\n\n    def consider_pluginarg(self, arg):\n        if arg.startswith(\"no:\"):\n            name = arg[3:]\n            if name in essential_plugins:\n                raise UsageError(\"plugin %s cannot be disabled\" % name)\n\n            # PR #4304 : remove stepwise if cacheprovider is blocked\n            if name == \"cacheprovider\":\n                self.set_blocked(\"stepwise\")\n                self.set_blocked(\"pytest_stepwise\")\n\n            self.set_blocked(name)\n            if not name.startswith(\"pytest_\"):\n                self.set_blocked(\"pytest_\" + name)\n        else:\n            name = arg\n            # Unblock the plugin.  None indicates that it has been blocked.\n            # There is no interface with pluggy for this.\n            if self._name2plugin.get(name, -1) is None:\n                del self._name2plugin[name]\n            if not name.startswith(\"pytest_\"):\n                if self._name2plugin.get(\"pytest_\" + name, -1) is None:\n                    del self._name2plugin[\"pytest_\" + name]\n            self.import_plugin(arg, consider_entry_points=True)\n\n    def consider_conftest(self, conftestmodule):\n        self.register(conftestmodule, name=conftestmodule.__file__)\n\n    def consider_env(self):\n        self._import_plugin_specs(os.environ.get(\"PYTEST_PLUGINS\"))\n\n    def consider_module(self, mod):\n        self._import_plugin_specs(getattr(mod, \"pytest_plugins\", []))\n\n    def _import_plugin_specs(self, spec):\n        plugins = _get_plugin_specs_as_list(spec)\n        for import_spec in plugins:\n            self.import_plugin(import_spec)\n\n    def import_plugin(self, modname, consider_entry_points=False):\n        \"\"\"\n        Imports a plugin with ``modname``. If ``consider_entry_points`` is True, entry point\n        names are also considered to find a plugin.\n        \"\"\"\n        # most often modname refers to builtin modules, e.g. \"pytester\",\n        # \"terminal\" or \"capture\".  Those plugins are registered under their\n        # basename for historic purposes but must be imported with the\n        # _pytest prefix.\n        assert isinstance(modname, str), (\n            \"module name as text required, got %r\" % modname\n        )\n        modname = str(modname)\n        if self.is_blocked(modname) or self.get_plugin(modname) is not None:\n            return\n\n        importspec = \"_pytest.\" + modname if modname in builtin_plugins else modname\n        self.rewrite_hook.mark_rewrite(importspec)\n\n        if consider_entry_points:\n            loaded = self.load_setuptools_entrypoints(\"pytest11\", name=modname)\n            if loaded:\n                return\n\n        try:\n            __import__(importspec)\n        except ImportError as e:\n            raise ImportError(\n                'Error importing plugin \"{}\": {}'.format(modname, str(e.args[0]))\n            ).with_traceback(e.__traceback__)\n\n        except Skipped as e:\n            from _pytest.warnings import _issue_warning_captured\n\n            _issue_warning_captured(\n                PytestConfigWarning(\"skipped plugin {!r}: {}\".format(modname, e.msg)),\n                self.hook,\n                stacklevel=2,\n            )\n        else:\n            mod = sys.modules[importspec]\n            self.register(mod, modname)"}, {"id": "_pytest.config.PytestPluginManager.__init__", "kind": "function", "range": [287, 4, 321, 32, 8097, 9507], "file_path": "src/_pytest/config/__init__.py", "content": "def __init__(self):\n        import _pytest.assertion\n\n        super().__init__(\"pytest\")\n        # The objects are module objects, only used generically.\n        self._conftest_plugins = set()  # type: Set[object]\n\n        # state related to local conftest plugins\n        # Maps a py.path.local to a list of module objects.\n        self._dirpath2confmods = {}  # type: Dict[Any, List[object]]\n        # Maps a py.path.local to a module object.\n        self._conftestpath2mod = {}  # type: Dict[Any, object]\n        self._confcutdir = None\n        self._noconftest = False\n        # Set of py.path.local's.\n        self._duplicatepaths = set()  # type: Set[Any]\n\n        self.add_hookspecs(_pytest.hookspec)\n        self.register(self)\n        if os.environ.get(\"PYTEST_DEBUG\"):\n            err = sys.stderr\n            encoding = getattr(err, \"encoding\", \"utf8\")\n            try:\n                err = open(\n                    os.dup(err.fileno()), mode=err.mode, buffering=1, encoding=encoding,\n                )\n            except Exception:\n                pass\n            self.trace.root.setwriter(err.write)\n            self.enable_tracing()\n\n        # Config._consider_importhook will set a real object if required.\n        self.rewrite_hook = _pytest.assertion.DummyRewriteHook()\n        # Used to know when we are importing conftests after the pytest_configure stage\n        self._configured = False"}, {"id": "_pytest.config.PytestPluginManager.parse_hookimpl_opts", "kind": "function", "range": [323, 4, 350, 19, 9513, 10664], "file_path": "src/_pytest/config/__init__.py", "content": "def parse_hookimpl_opts(self, plugin, name):\n        # pytest hooks are always prefixed with pytest_\n        # so we avoid accessing possibly non-readable attributes\n        # (see issue #1073)\n        if not name.startswith(\"pytest_\"):\n            return\n        # ignore names which can not be hooks\n        if name == \"pytest_plugins\":\n            return\n\n        method = getattr(plugin, name)\n        opts = super().parse_hookimpl_opts(plugin, name)\n\n        # consider only actual functions for hooks (#3775)\n        if not inspect.isroutine(method):\n            return\n\n        # collect unmarked hooks as long as they have the `pytest_' prefix\n        if opts is None and name.startswith(\"pytest_\"):\n            opts = {}\n        if opts is not None:\n            # TODO: DeprecationWarning, people should use hookimpl\n            # https://github.com/pytest-dev/pytest/issues/4562\n            known_marks = {m.name for m in getattr(method, \"pytestmark\", [])}\n\n            for name in (\"tryfirst\", \"trylast\", \"optionalhook\", \"hookwrapper\"):\n                opts.setdefault(name, hasattr(method, name) or name in known_marks)\n        return opts"}, {"id": "_pytest.config.PytestPluginManager.parse_hookspec_opts", "kind": "function", "range": [352, 4, 367, 19, 10670, 11400], "file_path": "src/_pytest/config/__init__.py", "content": "def parse_hookspec_opts(self, module_or_class, name):\n        opts = super().parse_hookspec_opts(module_or_class, name)\n        if opts is None:\n            method = getattr(module_or_class, name)\n\n            if name.startswith(\"pytest_\"):\n                # todo: deprecate hookspec hacks\n                # https://github.com/pytest-dev/pytest/issues/4562\n                known_marks = {m.name for m in getattr(method, \"pytestmark\", [])}\n                opts = {\n                    \"firstresult\": hasattr(method, \"firstresult\")\n                    or \"firstresult\" in known_marks,\n                    \"historic\": hasattr(method, \"historic\")\n                    or \"historic\" in known_marks,\n                }\n        return opts"}, {"id": "_pytest.config.PytestPluginManager.register", "kind": "function", "range": [369, 4, 388, 18, 11406, 12142], "file_path": "src/_pytest/config/__init__.py", "content": "def register(self, plugin, name=None):\n        if name in _pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS:\n            warnings.warn(\n                PytestConfigWarning(\n                    \"{} plugin has been merged into the core, \"\n                    \"please remove it from your requirements.\".format(\n                        name.replace(\"_\", \"-\")\n                    )\n                )\n            )\n            return\n        ret = super().register(plugin, name)\n        if ret:\n            self.hook.pytest_plugin_registered.call_historic(\n                kwargs=dict(plugin=plugin, manager=self)\n            )\n\n            if isinstance(plugin, types.ModuleType):\n                self.consider_module(plugin)\n        return ret"}, {"id": "_pytest.config.PytestPluginManager.getplugin", "kind": "function", "range": [390, 4, 392, 36, 12148, 12283], "file_path": "src/_pytest/config/__init__.py", "content": "def getplugin(self, name):\n        # support deprecated naming because plugins (xdist e.g.) use it\n        return self.get_plugin(name)"}, {"id": "_pytest.config.PytestPluginManager.hasplugin", "kind": "function", "range": [394, 4, 396, 42, 12289, 12433], "file_path": "src/_pytest/config/__init__.py", "content": "def hasplugin(self, name):\n        \"\"\"Return True if the plugin with the given name is registered.\"\"\"\n        return bool(self.get_plugin(name))"}, {"id": "_pytest.config.PytestPluginManager.pytest_configure", "kind": "function", "range": [398, 4, 411, 31, 12439, 13071], "file_path": "src/_pytest/config/__init__.py", "content": "def pytest_configure(self, config):\n        # XXX now that the pluginmanager exposes hookimpl(tryfirst...)\n        # we should remove tryfirst/trylast as markers\n        config.addinivalue_line(\n            \"markers\",\n            \"tryfirst: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it first/as early as possible.\",\n        )\n        config.addinivalue_line(\n            \"markers\",\n            \"trylast: mark a hook implementation function such that the \"\n            \"plugin machinery will try to call it last/as late as possible.\",\n        )\n        self._configured = True"}, {"id": "_pytest.config.PytestPluginManager._set_initial_conftests", "kind": "function", "range": [416, 4, 445, 44, 13143, 14382], "file_path": "src/_pytest/config/__init__.py", "content": "def _set_initial_conftests(self, namespace):\n        \"\"\" load initial conftest files given a preparsed \"namespace\".\n            As conftest files may add their own command line options\n            which have arguments ('--my-opt somepath') we might get some\n            false positives.  All builtin and 3rd party plugins will have\n            been loaded, however, so common options will not confuse our logic\n            here.\n        \"\"\"\n        current = py.path.local()\n        self._confcutdir = (\n            current.join(namespace.confcutdir, abs=True)\n            if namespace.confcutdir\n            else None\n        )\n        self._noconftest = namespace.noconftest\n        self._using_pyargs = namespace.pyargs\n        testpaths = namespace.file_or_dir\n        foundanchor = False\n        for path in testpaths:\n            path = str(path)\n            # remove node-id syntax\n            i = path.find(\"::\")\n            if i != -1:\n                path = path[:i]\n            anchor = current.join(path, abs=1)\n            if exists(anchor):  # we found some file object\n                self._try_load_conftest(anchor)\n                foundanchor = True\n        if not foundanchor:\n            self._try_load_conftest(current)"}, {"id": "_pytest.config.PytestPluginManager._try_load_conftest", "kind": "function", "range": [447, 4, 453, 47, 14388, 14671], "file_path": "src/_pytest/config/__init__.py", "content": "def _try_load_conftest(self, anchor):\n        self._getconftestmodules(anchor)\n        # let's also consider test* subdirs\n        if anchor.check(dir=1):\n            for x in anchor.listdir(\"test*\"):\n                if x.check(dir=1):\n                    self._getconftestmodules(x)"}, {"id": "_pytest.config.PytestPluginManager._getconftestmodules", "kind": "function", "range": [455, 4, 477, 20, 14677, 15521], "file_path": "src/_pytest/config/__init__.py", "content": "@lru_cache(maxsize=128)\n    def _getconftestmodules(self, path):\n        if self._noconftest:\n            return []\n\n        if path.isfile():\n            directory = path.dirpath()\n        else:\n            directory = path\n\n        # XXX these days we may rather want to use config.rootdir\n        # and allow users to opt into looking into the rootdir parent\n        # directories instead of requiring to specify confcutdir\n        clist = []\n        for parent in directory.realpath().parts():\n            if self._confcutdir and self._confcutdir.relto(parent):\n                continue\n            conftestpath = parent.join(\"conftest.py\")\n            if conftestpath.isfile():\n                mod = self._importconftest(conftestpath)\n                clist.append(mod)\n        self._dirpath2confmods[directory] = clist\n        return clist"}, {"id": "_pytest.config.PytestPluginManager._rget_with_confmod", "kind": "function", "range": [479, 4, 486, 28, 15527, 15808], "file_path": "src/_pytest/config/__init__.py", "content": "def _rget_with_confmod(self, name, path):\n        modules = self._getconftestmodules(path)\n        for mod in reversed(modules):\n            try:\n                return mod, getattr(mod, name)\n            except AttributeError:\n                continue\n        raise KeyError(name)"}, {"id": "_pytest.config.PytestPluginManager._importconftest", "kind": "function", "range": [488, 4, 522, 22, 15814, 17459], "file_path": "src/_pytest/config/__init__.py", "content": "def _importconftest(self, conftestpath):\n        # Use a resolved Path object as key to avoid loading the same conftest twice\n        # with build systems that create build directories containing\n        # symlinks to actual files.\n        # Using Path().resolve() is better than py.path.realpath because\n        # it resolves to the correct path/drive in case-insensitive file systems (#5792)\n        key = Path(str(conftestpath)).resolve()\n        try:\n            return self._conftestpath2mod[key]\n        except KeyError:\n            pkgpath = conftestpath.pypkgpath()\n            if pkgpath is None:\n                _ensure_removed_sysmodule(conftestpath.purebasename)\n            try:\n                mod = conftestpath.pyimport()\n                if (\n                    hasattr(mod, \"pytest_plugins\")\n                    and self._configured\n                    and not self._using_pyargs\n                ):\n                    _fail_on_non_top_pytest_plugins(conftestpath, self._confcutdir)\n            except Exception:\n                raise ConftestImportFailure(conftestpath, sys.exc_info())\n\n            self._conftest_plugins.add(mod)\n            self._conftestpath2mod[key] = mod\n            dirpath = conftestpath.dirpath()\n            if dirpath in self._dirpath2confmods:\n                for path, mods in self._dirpath2confmods.items():\n                    if path and path.relto(dirpath) or path == dirpath:\n                        assert mod not in mods\n                        mods.append(mod)\n            self.trace(\"loading conftestmodule {!r}\".format(mod))\n            self.consider_conftest(mod)\n            return mod"}, {"id": "_pytest.config.PytestPluginManager.consider_preparse", "kind": "function", "range": [529, 4, 548, 45, 17527, 18184], "file_path": "src/_pytest/config/__init__.py", "content": "def consider_preparse(self, args, *, exclude_only=False):\n        i = 0\n        n = len(args)\n        while i < n:\n            opt = args[i]\n            i += 1\n            if isinstance(opt, str):\n                if opt == \"-p\":\n                    try:\n                        parg = args[i]\n                    except IndexError:\n                        return\n                    i += 1\n                elif opt.startswith(\"-p\"):\n                    parg = opt[2:]\n                else:\n                    continue\n                if exclude_only and not parg.startswith(\"no:\"):\n                    continue\n                self.consider_pluginarg(parg)"}, {"id": "_pytest.config.PytestPluginManager.consider_pluginarg", "kind": "function", "range": [550, 4, 573, 63, 18190, 19254], "file_path": "src/_pytest/config/__init__.py", "content": "def consider_pluginarg(self, arg):\n        if arg.startswith(\"no:\"):\n            name = arg[3:]\n            if name in essential_plugins:\n                raise UsageError(\"plugin %s cannot be disabled\" % name)\n\n            # PR #4304 : remove stepwise if cacheprovider is blocked\n            if name == \"cacheprovider\":\n                self.set_blocked(\"stepwise\")\n                self.set_blocked(\"pytest_stepwise\")\n\n            self.set_blocked(name)\n            if not name.startswith(\"pytest_\"):\n                self.set_blocked(\"pytest_\" + name)\n        else:\n            name = arg\n            # Unblock the plugin.  None indicates that it has been blocked.\n            # There is no interface with pluggy for this.\n            if self._name2plugin.get(name, -1) is None:\n                del self._name2plugin[name]\n            if not name.startswith(\"pytest_\"):\n                if self._name2plugin.get(\"pytest_\" + name, -1) is None:\n                    del self._name2plugin[\"pytest_\" + name]\n            self.import_plugin(arg, consider_entry_points=True)"}, {"id": "_pytest.config.PytestPluginManager.consider_conftest", "kind": "function", "range": [575, 4, 576, 67, 19260, 19372], "file_path": "src/_pytest/config/__init__.py", "content": "def consider_conftest(self, conftestmodule):\n        self.register(conftestmodule, name=conftestmodule.__file__)"}, {"id": "_pytest.config.PytestPluginManager.consider_env", "kind": "function", "range": [578, 4, 579, 67, 19378, 19469], "file_path": "src/_pytest/config/__init__.py", "content": "def consider_env(self):\n        self._import_plugin_specs(os.environ.get(\"PYTEST_PLUGINS\"))"}, {"id": "_pytest.config.PytestPluginManager.consider_module", "kind": "function", "range": [581, 4, 582, 69, 19475, 19576], "file_path": "src/_pytest/config/__init__.py", "content": "def consider_module(self, mod):\n        self._import_plugin_specs(getattr(mod, \"pytest_plugins\", []))"}, {"id": "_pytest.config.PytestPluginManager._import_plugin_specs", "kind": "function", "range": [584, 4, 587, 43, 19582, 19749], "file_path": "src/_pytest/config/__init__.py", "content": "def _import_plugin_specs(self, spec):\n        plugins = _get_plugin_specs_as_list(spec)\n        for import_spec in plugins:\n            self.import_plugin(import_spec)"}, {"id": "_pytest.config.PytestPluginManager.import_plugin", "kind": "function", "range": [589, 4, 630, 39, 19755, 21400], "file_path": "src/_pytest/config/__init__.py", "content": "def import_plugin(self, modname, consider_entry_points=False):\n        \"\"\"\n        Imports a plugin with ``modname``. If ``consider_entry_points`` is True, entry point\n        names are also considered to find a plugin.\n        \"\"\"\n        # most often modname refers to builtin modules, e.g. \"pytester\",\n        # \"terminal\" or \"capture\".  Those plugins are registered under their\n        # basename for historic purposes but must be imported with the\n        # _pytest prefix.\n        assert isinstance(modname, str), (\n            \"module name as text required, got %r\" % modname\n        )\n        modname = str(modname)\n        if self.is_blocked(modname) or self.get_plugin(modname) is not None:\n            return\n\n        importspec = \"_pytest.\" + modname if modname in builtin_plugins else modname\n        self.rewrite_hook.mark_rewrite(importspec)\n\n        if consider_entry_points:\n            loaded = self.load_setuptools_entrypoints(\"pytest11\", name=modname)\n            if loaded:\n                return\n\n        try:\n            __import__(importspec)\n        except ImportError as e:\n            raise ImportError(\n                'Error importing plugin \"{}\": {}'.format(modname, str(e.args[0]))\n            ).with_traceback(e.__traceback__)\n\n        except Skipped as e:\n            from _pytest.warnings import _issue_warning_captured\n\n            _issue_warning_captured(\n                PytestConfigWarning(\"skipped plugin {!r}: {}\".format(modname, e.msg)),\n                self.hook,\n                stacklevel=2,\n            )\n        else:\n            mod = sys.modules[importspec]\n            self.register(mod, modname)"}, {"id": "_pytest.config._get_plugin_specs_as_list", "kind": "function", "range": [633, 0, 650, 13, 21403, 22175], "file_path": "src/_pytest/config/__init__.py", "content": "def _get_plugin_specs_as_list(specs):\n    \"\"\"\n    Parses a list of \"plugin specs\" and returns a list of plugin names.\n\n    Plugin specs can be given as a list of strings separated by \",\" or already as a list/tuple in\n    which case it is returned as a list. Specs can also be `None` in which case an\n    empty list is returned.\n    \"\"\"\n    if specs is not None and not isinstance(specs, types.ModuleType):\n        if isinstance(specs, str):\n            specs = specs.split(\",\") if specs else []\n        if not isinstance(specs, (list, tuple)):\n            raise UsageError(\n                \"Plugin specs must be a ','-separated string or a \"\n                \"list/tuple of strings for plugin names. Given: %r\" % specs\n            )\n        return list(specs)\n    return []"}, {"id": "_pytest.config._ensure_removed_sysmodule", "kind": "function", "range": [653, 0, 657, 12, 22178, 22293], "file_path": "src/_pytest/config/__init__.py", "content": "def _ensure_removed_sysmodule(modname):\n    try:\n        del sys.modules[modname]\n    except KeyError:\n        pass"}, {"id": "_pytest.config.Notset", "kind": "class", "range": [660, 0, 662, 25, 22296, 22359], "file_path": "src/_pytest/config/__init__.py", "content": "class Notset:\n    def __repr__(self):\n        return \"<NOTSET>\""}, {"id": "_pytest.config.Notset.__repr__", "kind": "function", "range": [661, 4, 662, 25, 22314, 22359], "file_path": "src/_pytest/config/__init__.py", "content": "def __repr__(self):\n        return \"<NOTSET>\""}, {"id": "_pytest.config.notset", "kind": "variable", "range": [665, 0, 665, 17, 22362, 22379], "file_path": "src/_pytest/config/__init__.py", "content": "notset = Notset()"}, {"id": "_pytest.config._iter_rewritable_modules", "kind": "function", "range": [668, 0, 728, 66, 22382, 24820], "file_path": "src/_pytest/config/__init__.py", "content": "def _iter_rewritable_modules(package_files):\n    \"\"\"\n    Given an iterable of file names in a source distribution, return the \"names\" that should\n    be marked for assertion rewrite (for example the package \"pytest_mock/__init__.py\" should\n    be added as \"pytest_mock\" in the assertion rewrite mechanism.\n\n    This function has to deal with dist-info based distributions and egg based distributions\n    (which are still very much in use for \"editable\" installs).\n\n    Here are the file names as seen in a dist-info based distribution:\n\n        pytest_mock/__init__.py\n        pytest_mock/_version.py\n        pytest_mock/plugin.py\n        pytest_mock.egg-info/PKG-INFO\n\n    Here are the file names as seen in an egg based distribution:\n\n        src/pytest_mock/__init__.py\n        src/pytest_mock/_version.py\n        src/pytest_mock/plugin.py\n        src/pytest_mock.egg-info/PKG-INFO\n        LICENSE\n        setup.py\n\n    We have to take in account those two distribution flavors in order to determine which\n    names should be considered for assertion rewriting.\n\n    More information:\n        https://github.com/pytest-dev/pytest-mock/issues/167\n    \"\"\"\n    package_files = list(package_files)\n    seen_some = False\n    for fn in package_files:\n        is_simple_module = \"/\" not in fn and fn.endswith(\".py\")\n        is_package = fn.count(\"/\") == 1 and fn.endswith(\"__init__.py\")\n        if is_simple_module:\n            module_name, _ = os.path.splitext(fn)\n            # we ignore \"setup.py\" at the root of the distribution\n            if module_name != \"setup\":\n                seen_some = True\n                yield module_name\n        elif is_package:\n            package_name = os.path.dirname(fn)\n            seen_some = True\n            yield package_name\n\n    if not seen_some:\n        # at this point we did not find any packages or modules suitable for assertion\n        # rewriting, so we try again by stripping the first path component (to account for\n        # \"src\" based source trees for example)\n        # this approach lets us have the common case continue to be fast, as egg-distributions\n        # are rarer\n        new_package_files = []\n        for fn in package_files:\n            parts = fn.split(\"/\")\n            new_fn = \"/\".join(parts[1:])\n            if new_fn:\n                new_package_files.append(new_fn)\n        if new_package_files:\n            yield from _iter_rewritable_modules(new_package_files)"}, {"id": "_pytest.config.Config", "kind": "class", "range": [731, 0, 1184, 46, 24823, 41979], "file_path": "src/_pytest/config/__init__.py", "content": "class Config:\n    \"\"\"\n    Access to configuration values, pluginmanager and plugin hooks.\n\n    :param PytestPluginManager pluginmanager:\n\n    :param InvocationParams invocation_params:\n        Object containing the parameters regarding the ``pytest.main``\n        invocation.\n    \"\"\"\n\n    @attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\"\n\n    def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]\n\n    @property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))\n\n    def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)\n\n    def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))\n\n    def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()\n\n    def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw\n\n    def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self\n\n    def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()\n\n    def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid\n\n    @classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config\n\n    def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)\n\n    @hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)\n\n    def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()\n\n    def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)\n\n    def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)\n\n    def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args\n\n    def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise\n\n    def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )\n\n    def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass\n\n    def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline\n\n    def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val\n\n    def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value\n\n    def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values\n\n    def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value\n\n    def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))\n\n    def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)\n\n    def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)"}, {"id": "_pytest.config.Config.InvocationParams", "kind": "class", "range": [742, 4, 763, 65, 25112, 25882], "file_path": "src/_pytest/config/__init__.py", "content": "@attr.s(frozen=True)\n    class InvocationParams:\n        \"\"\"Holds parameters passed during ``pytest.main()``\n\n        The object attributes are read-only.\n\n        .. versionadded:: 5.1\n\n        .. note::\n\n            Note that the environment variable ``PYTEST_ADDOPTS`` and the ``addopts``\n            ini option are handled by pytest, not being included in the ``args`` attribute.\n\n            Plugins accessing ``InvocationParams`` must be aware of that.\n        \"\"\"\n\n        args = attr.ib(converter=tuple)\n        \"\"\"tuple of command-line arguments as passed to ``pytest.main()``.\"\"\"\n        plugins = attr.ib()\n        \"\"\"list of extra plugins, might be `None`.\"\"\"\n        dir = attr.ib(type=Path)\n        \"\"\"directory where ``pytest.main()`` was invoked from.\"\"\""}, {"id": "_pytest.config.Config.InvocationParams.args", "kind": "variable", "range": [758, 8, 758, 39, 25592, 25623], "file_path": "src/_pytest/config/__init__.py", "content": "args = attr.ib(converter=tuple)"}, {"id": "_pytest.config.Config.InvocationParams.plugins", "kind": "variable", "range": [760, 8, 760, 27, 25710, 25729], "file_path": "src/_pytest/config/__init__.py", "content": "plugins = attr.ib()"}, {"id": "_pytest.config.Config.InvocationParams.dir", "kind": "variable", "range": [762, 8, 762, 32, 25792, 25816], "file_path": "src/_pytest/config/__init__.py", "content": "dir = attr.ib(type=Path)"}, {"id": "_pytest.config.Config.__init__", "kind": "function", "range": [765, 4, 813, 54, 25888, 27668], "file_path": "src/_pytest/config/__init__.py", "content": "def __init__(\n        self,\n        pluginmanager: PytestPluginManager,\n        *,\n        invocation_params: Optional[InvocationParams] = None\n    ) -> None:\n        from .argparsing import Parser, FILE_OR_DIR\n\n        if invocation_params is None:\n            invocation_params = self.InvocationParams(\n                args=(), plugins=None, dir=Path().resolve()\n            )\n\n        self.option = argparse.Namespace()\n        \"\"\"access to command line option as attributes.\n\n          :type: argparse.Namespace\"\"\"\n\n        self.invocation_params = invocation_params\n\n        _a = FILE_OR_DIR\n        self._parser = Parser(\n            usage=\"%(prog)s [options] [{}] [{}] [...]\".format(_a, _a),\n            processopt=self._processopt,\n        )\n        self.pluginmanager = pluginmanager\n        \"\"\"the plugin manager handles plugin registration and hook invocation.\n\n          :type: PytestPluginManager\"\"\"\n\n        self.trace = self.pluginmanager.trace.root.get(\"config\")\n        self.hook = self.pluginmanager.hook\n        self._inicache = {}  # type: Dict[str, Any]\n        self._override_ini = ()  # type: Sequence[str]\n        self._opt2dest = {}  # type: Dict[str, str]\n        self._cleanup = []  # type: List[Callable[[], None]]\n        # A place where plugins can store information on the config for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n        self.pluginmanager.register(self, \"pytestconfig\")\n        self._configured = False\n        self.hook.pytest_addoption.call_historic(\n            kwargs=dict(parser=self._parser, pluginmanager=self.pluginmanager)\n        )\n\n        if TYPE_CHECKING:\n            from _pytest.cacheprovider import Cache\n\n            self.cache = None  # type: Optional[Cache]"}, {"id": "_pytest.config.Config.invocation_dir", "kind": "function", "range": [815, 4, 818, 61, 27674, 27812], "file_path": "src/_pytest/config/__init__.py", "content": "@property\n    def invocation_dir(self):\n        \"\"\"Backward compatibility\"\"\"\n        return py.path.local(str(self.invocation_params.dir))"}, {"id": "_pytest.config.Config.add_cleanup", "kind": "function", "range": [820, 4, 823, 34, 27818, 28018], "file_path": "src/_pytest/config/__init__.py", "content": "def add_cleanup(self, func):\n        \"\"\" Add a function to be called when the config object gets out of\n        use (usually coninciding with pytest_unconfigure).\"\"\"\n        self._cleanup.append(func)"}, {"id": "_pytest.config.Config._do_configure", "kind": "function", "range": [825, 4, 830, 78, 28024, 28280], "file_path": "src/_pytest/config/__init__.py", "content": "def _do_configure(self):\n        assert not self._configured\n        self._configured = True\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"default\")\n            self.hook.pytest_configure.call_historic(kwargs=dict(config=self))"}, {"id": "_pytest.config.Config._ensure_unconfigure", "kind": "function", "range": [832, 4, 839, 17, 28286, 28579], "file_path": "src/_pytest/config/__init__.py", "content": "def _ensure_unconfigure(self):\n        if self._configured:\n            self._configured = False\n            self.hook.pytest_unconfigure(config=self)\n            self.hook.pytest_configure._call_history = []\n        while self._cleanup:\n            fin = self._cleanup.pop()\n            fin()"}, {"id": "_pytest.config.Config.get_terminal_writer", "kind": "function", "range": [841, 4, 842, 68, 28585, 28684], "file_path": "src/_pytest/config/__init__.py", "content": "def get_terminal_writer(self):\n        return self.pluginmanager.get_plugin(\"terminalreporter\")._tw"}, {"id": "_pytest.config.Config.pytest_cmdline_parse", "kind": "function", "range": [844, 4, 866, 19, 28690, 29533], "file_path": "src/_pytest/config/__init__.py", "content": "def pytest_cmdline_parse(self, pluginmanager, args):\n        try:\n            self.parse(args)\n        except UsageError:\n\n            # Handle --version and --help here in a minimal fashion.\n            # This gets done via helpconfig normally, but its\n            # pytest_cmdline_main is not called in case of errors.\n            if getattr(self.option, \"version\", False) or \"--version\" in args:\n                from _pytest.helpconfig import showversion\n\n                showversion(self)\n            elif (\n                getattr(self.option, \"help\", False) or \"--help\" in args or \"-h\" in args\n            ):\n                self._parser._getparser().print_help()\n                sys.stdout.write(\n                    \"\\nNOTE: displaying only minimal help due to UsageError.\\n\\n\"\n                )\n\n            raise\n\n        return self"}, {"id": "_pytest.config.Config.notify_exception", "kind": "function", "range": [868, 4, 880, 34, 29539, 30102], "file_path": "src/_pytest/config/__init__.py", "content": "def notify_exception(self, excinfo, option=None):\n        if option and getattr(option, \"fulltrace\", False):\n            style = \"long\"\n        else:\n            style = \"native\"\n        excrepr = excinfo.getrepr(\n            funcargs=True, showlocals=getattr(option, \"showlocals\", False), style=style\n        )\n        res = self.hook.pytest_internalerror(excrepr=excrepr, excinfo=excinfo)\n        if not any(res):\n            for line in str(excrepr).split(\"\\n\"):\n                sys.stderr.write(\"INTERNALERROR> %s\\n\" % line)\n                sys.stderr.flush()"}, {"id": "_pytest.config.Config.cwd_relative_nodeid", "kind": "function", "range": [882, 4, 887, 21, 30108, 30401], "file_path": "src/_pytest/config/__init__.py", "content": "def cwd_relative_nodeid(self, nodeid):\n        # nodeid's are relative to the rootpath, compute relative to cwd\n        if self.invocation_dir != self.rootdir:\n            fullpath = self.rootdir.join(nodeid)\n            nodeid = self.invocation_dir.bestrelpath(fullpath)\n        return nodeid"}, {"id": "_pytest.config.Config.fromdictargs", "kind": "function", "range": [889, 4, 897, 21, 30407, 30762], "file_path": "src/_pytest/config/__init__.py", "content": "@classmethod\n    def fromdictargs(cls, option_dict, args):\n        \"\"\" constructor usable for subprocesses. \"\"\"\n        config = get_config(args)\n        config.option.__dict__.update(option_dict)\n        config.parse(args, addopts=False)\n        for x in config.option.plugins:\n            config.pluginmanager.consider_pluginarg(x)\n        return config"}, {"id": "_pytest.config.Config._processopt", "kind": "function", "range": [899, 4, 905, 59, 30768, 31061], "file_path": "src/_pytest/config/__init__.py", "content": "def _processopt(self, opt: \"Argument\") -> None:\n        for name in opt._short_opts + opt._long_opts:\n            self._opt2dest[name] = opt.dest\n\n        if hasattr(opt, \"default\"):\n            if not hasattr(self.option, opt.dest):\n                setattr(self.option, opt.dest, opt.default)"}, {"id": "_pytest.config.Config.pytest_load_initial_conftests", "kind": "function", "range": [907, 4, 909, 84, 31067, 31234], "file_path": "src/_pytest/config/__init__.py", "content": "@hookimpl(trylast=True)\n    def pytest_load_initial_conftests(self, early_config):\n        self.pluginmanager._set_initial_conftests(early_config.known_args_namespace)"}, {"id": "_pytest.config.Config._initini", "kind": "function", "range": [911, 4, 926, 50, 31240, 31977], "file_path": "src/_pytest/config/__init__.py", "content": "def _initini(self, args: Sequence[str]) -> None:\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(\n            args, namespace=copy.copy(self.option)\n        )\n        r = determine_setup(\n            ns.inifilename,\n            ns.file_or_dir + unknown_args,\n            rootdir_cmd_arg=ns.rootdir or None,\n            config=self,\n        )\n        self.rootdir, self.inifile, self.inicfg = r\n        self._parser.extra_info[\"rootdir\"] = self.rootdir\n        self._parser.extra_info[\"inifile\"] = self.inifile\n        self._parser.addini(\"addopts\", \"extra command line options\", \"args\")\n        self._parser.addini(\"minversion\", \"minimally required pytest version\")\n        self._override_ini = ns.override_ini or ()"}, {"id": "_pytest.config.Config._consider_importhook", "kind": "function", "range": [928, 4, 946, 43, 31983, 32751], "file_path": "src/_pytest/config/__init__.py", "content": "def _consider_importhook(self, args: Sequence[str]) -> None:\n        \"\"\"Install the PEP 302 import hook if using assertion rewriting.\n\n        Needs to parse the --assert=<mode> option from the commandline\n        and find all the installed plugins to mark them for rewriting\n        by the importhook.\n        \"\"\"\n        ns, unknown_args = self._parser.parse_known_and_unknown_args(args)\n        mode = getattr(ns, \"assertmode\", \"plain\")\n        if mode == \"rewrite\":\n            import _pytest.assertion\n\n            try:\n                hook = _pytest.assertion.install_importhook(self)\n            except SystemError:\n                mode = \"plain\"\n            else:\n                self._mark_plugins_for_rewrite(hook)\n        _warn_about_missing_assertion(mode)"}, {"id": "_pytest.config.Config._mark_plugins_for_rewrite", "kind": "function", "range": [948, 4, 968, 35, 32757, 33510], "file_path": "src/_pytest/config/__init__.py", "content": "def _mark_plugins_for_rewrite(self, hook):\n        \"\"\"\n        Given an importhook, mark for rewrite any top-level\n        modules or packages in the distribution package for\n        all pytest plugins.\n        \"\"\"\n        self.pluginmanager.rewrite_hook = hook\n\n        if os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # We don't autoload from setuptools entry points, no need to continue.\n            return\n\n        package_files = (\n            str(file)\n            for dist in importlib_metadata.distributions()\n            if any(ep.group == \"pytest11\" for ep in dist.entry_points)\n            for file in dist.files or []\n        )\n\n        for name in _iter_rewritable_modules(package_files):\n            hook.mark_rewrite(name)"}, {"id": "_pytest.config.Config._validate_args", "kind": "function", "range": [970, 4, 980, 19, 33516, 33919], "file_path": "src/_pytest/config/__init__.py", "content": "def _validate_args(self, args: List[str], via: str) -> List[str]:\n        \"\"\"Validate known args.\"\"\"\n        self._parser._config_source_hint = via  # type: ignore\n        try:\n            self._parser.parse_known_and_unknown_args(\n                args, namespace=copy.copy(self.option)\n            )\n        finally:\n            del self._parser._config_source_hint  # type: ignore\n\n        return args"}, {"id": "_pytest.config.Config._preparse", "kind": "function", "range": [982, 4, 1028, 21, 33925, 35963], "file_path": "src/_pytest/config/__init__.py", "content": "def _preparse(self, args: List[str], addopts: bool = True) -> None:\n        if addopts:\n            env_addopts = os.environ.get(\"PYTEST_ADDOPTS\", \"\")\n            if len(env_addopts):\n                args[:] = (\n                    self._validate_args(shlex.split(env_addopts), \"via PYTEST_ADDOPTS\")\n                    + args\n                )\n        self._initini(args)\n        if addopts:\n            args[:] = (\n                self._validate_args(self.getini(\"addopts\"), \"via addopts config\") + args\n            )\n\n        self._checkversion()\n        self._consider_importhook(args)\n        self.pluginmanager.consider_preparse(args, exclude_only=False)\n        if not os.environ.get(\"PYTEST_DISABLE_PLUGIN_AUTOLOAD\"):\n            # Don't autoload from setuptools entry point. Only explicitly specified\n            # plugins are going to be loaded.\n            self.pluginmanager.load_setuptools_entrypoints(\"pytest11\")\n        self.pluginmanager.consider_env()\n        self.known_args_namespace = ns = self._parser.parse_known_args(\n            args, namespace=copy.copy(self.option)\n        )\n        if self.known_args_namespace.confcutdir is None and self.inifile:\n            confcutdir = py.path.local(self.inifile).dirname\n            self.known_args_namespace.confcutdir = confcutdir\n        try:\n            self.hook.pytest_load_initial_conftests(\n                early_config=self, args=args, parser=self._parser\n            )\n        except ConftestImportFailure as e:\n            if ns.help or ns.version:\n                # we don't want to prevent --help/--version to work\n                # so just let is pass and print a warning at the end\n                from _pytest.warnings import _issue_warning_captured\n\n                _issue_warning_captured(\n                    PytestConfigWarning(\n                        \"could not load initial conftests: {}\".format(e.path)\n                    ),\n                    self.hook,\n                    stacklevel=2,\n                )\n            else:\n                raise"}, {"id": "_pytest.config.Config._checkversion", "kind": "function", "range": [1030, 4, 1044, 17, 35969, 36505], "file_path": "src/_pytest/config/__init__.py", "content": "def _checkversion(self):\n        import pytest\n\n        minver = self.inicfg.get(\"minversion\", None)\n        if minver:\n            if Version(minver) > Version(pytest.__version__):\n                raise pytest.UsageError(\n                    \"%s:%d: requires pytest-%s, actual pytest-%s'\"\n                    % (\n                        self.inicfg.config.path,\n                        self.inicfg.lineof(\"minversion\"),\n                        minver,\n                        pytest.__version__,\n                    )\n                )"}, {"id": "_pytest.config.Config.parse", "kind": "function", "range": [1046, 4, 1069, 16, 36511, 37504], "file_path": "src/_pytest/config/__init__.py", "content": "def parse(self, args: List[str], addopts: bool = True) -> None:\n        # parse given cmdline arguments into this config object.\n        assert not hasattr(\n            self, \"args\"\n        ), \"can only parse cmdline args at most once per Config object\"\n        self.hook.pytest_addhooks.call_historic(\n            kwargs=dict(pluginmanager=self.pluginmanager)\n        )\n        self._preparse(args, addopts=addopts)\n        # XXX deprecated hook:\n        self.hook.pytest_cmdline_preparse(config=self, args=args)\n        self._parser.after_preparse = True  # type: ignore\n        try:\n            args = self._parser.parse_setoption(\n                args, self.option, namespace=self.option\n            )\n            if not args:\n                if self.invocation_dir == self.rootdir:\n                    args = self.getini(\"testpaths\")\n                if not args:\n                    args = [str(self.invocation_dir)]\n            self.args = args\n        except PrintHelp:\n            pass"}, {"id": "_pytest.config.Config.addinivalue_line", "kind": "function", "range": [1071, 4, 1077, 57, 37510, 37862], "file_path": "src/_pytest/config/__init__.py", "content": "def addinivalue_line(self, name, line):\n        \"\"\" add a line to an ini-file option. The option must have been\n        declared but might not yet be set in which case the line becomes the\n        the first line in its value. \"\"\"\n        x = self.getini(name)\n        assert isinstance(x, list)\n        x.append(line)  # modifies the cached list inline"}, {"id": "_pytest.config.Config.getini", "kind": "function", "range": [1079, 4, 1088, 22, 37868, 38342], "file_path": "src/_pytest/config/__init__.py", "content": "def getini(self, name: str):\n        \"\"\" return configuration value from an :ref:`ini file <inifiles>`. If the\n        specified name hasn't been registered through a prior\n        :py:func:`parser.addini <_pytest.config.argparsing.Parser.addini>`\n        call (usually from a plugin), a ValueError is raised. \"\"\"\n        try:\n            return self._inicache[name]\n        except KeyError:\n            self._inicache[name] = val = self._getini(name)\n            return val"}, {"id": "_pytest.config.Config._getini", "kind": "function", "range": [1090, 4, 1119, 24, 38348, 39483], "file_path": "src/_pytest/config/__init__.py", "content": "def _getini(self, name: str) -> Any:\n        try:\n            description, type, default = self._parser._inidict[name]\n        except KeyError:\n            raise ValueError(\"unknown configuration value: {!r}\".format(name))\n        value = self._get_override_ini_value(name)\n        if value is None:\n            try:\n                value = self.inicfg[name]\n            except KeyError:\n                if default is not None:\n                    return default\n                if type is None:\n                    return \"\"\n                return []\n        if type == \"pathlist\":\n            dp = py.path.local(self.inicfg.config.path).dirpath()\n            values = []\n            for relpath in shlex.split(value):\n                values.append(dp.join(relpath, abs=True))\n            return values\n        elif type == \"args\":\n            return shlex.split(value)\n        elif type == \"linelist\":\n            return [t for t in map(lambda x: x.strip(), value.split(\"\\n\")) if t]\n        elif type == \"bool\":\n            return bool(_strtobool(value.strip()))\n        else:\n            assert type is None\n            return value"}, {"id": "_pytest.config.Config._getconftest_pathlist", "kind": "function", "range": [1121, 4, 1133, 21, 39489, 40018], "file_path": "src/_pytest/config/__init__.py", "content": "def _getconftest_pathlist(self, name, path):\n        try:\n            mod, relroots = self.pluginmanager._rget_with_confmod(name, path)\n        except KeyError:\n            return None\n        modpath = py.path.local(mod.__file__).dirpath()\n        values = []\n        for relroot in relroots:\n            if not isinstance(relroot, py.path.local):\n                relroot = relroot.replace(\"/\", py.path.local.sep)\n                relroot = modpath.join(relroot, abs=True)\n            values.append(relroot)\n        return values"}, {"id": "_pytest.config.Config._get_override_ini_value", "kind": "function", "range": [1135, 4, 1152, 20, 40024, 40772], "file_path": "src/_pytest/config/__init__.py", "content": "def _get_override_ini_value(self, name: str) -> Optional[str]:\n        value = None\n        # override_ini is a list of \"ini=value\" options\n        # always use the last item if multiple values are set for same ini-name,\n        # e.g. -o foo=bar1 -o foo=bar2 will set foo to bar2\n        for ini_config in self._override_ini:\n            try:\n                key, user_ini_value = ini_config.split(\"=\", 1)\n            except ValueError:\n                raise UsageError(\n                    \"-o/--override-ini expects option=value style (got: {!r}).\".format(\n                        ini_config\n                    )\n                )\n            else:\n                if key == name:\n                    value = user_ini_value\n        return value"}, {"id": "_pytest.config.Config.getoption", "kind": "function", "range": [1154, 4, 1176, 65, 40778, 41705], "file_path": "src/_pytest/config/__init__.py", "content": "def getoption(self, name: str, default=notset, skip: bool = False):\n        \"\"\" return command line option value.\n\n        :arg name: name of the option.  You may also specify\n            the literal ``--OPT`` option instead of the \"dest\" option name.\n        :arg default: default value if no option of that name exists.\n        :arg skip: if True raise pytest.skip if option does not exists\n            or has a None value.\n        \"\"\"\n        name = self._opt2dest.get(name, name)\n        try:\n            val = getattr(self.option, name)\n            if val is None and skip:\n                raise AttributeError(name)\n            return val\n        except AttributeError:\n            if default is not notset:\n                return default\n            if skip:\n                import pytest\n\n                pytest.skip(\"no {!r} option found\".format(name))\n            raise ValueError(\"no option named {!r}\".format(name))"}, {"id": "_pytest.config.Config.getvalue", "kind": "function", "range": [1178, 4, 1180, 35, 41711, 41829], "file_path": "src/_pytest/config/__init__.py", "content": "def getvalue(self, name, path=None):\n        \"\"\" (deprecated, use getoption()) \"\"\"\n        return self.getoption(name)"}, {"id": "_pytest.config.Config.getvalueorskip", "kind": "function", "range": [1182, 4, 1184, 46, 41835, 41979], "file_path": "src/_pytest/config/__init__.py", "content": "def getvalueorskip(self, name, path=None):\n        \"\"\" (deprecated, use getoption(skip=True)) \"\"\"\n        return self.getoption(name, skip=True)"}, {"id": "_pytest.config._assertion_supported", "kind": "function", "range": [1187, 0, 1193, 20, 41982, 42117], "file_path": "src/_pytest/config/__init__.py", "content": "def _assertion_supported():\n    try:\n        assert False\n    except AssertionError:\n        return True\n    else:\n        return False"}, {"id": "_pytest.config._warn_about_missing_assertion", "kind": "function", "range": [1196, 0, 1211, 13, 42120, 42743], "file_path": "src/_pytest/config/__init__.py", "content": "def _warn_about_missing_assertion(mode):\n    if not _assertion_supported():\n        if mode == \"plain\":\n            sys.stderr.write(\n                \"WARNING: ASSERTIONS ARE NOT EXECUTED\"\n                \" and FAILING TESTS WILL PASS.  Are you\"\n                \" using python -O?\"\n            )\n        else:\n            sys.stderr.write(\n                \"WARNING: assertions not in test modules or\"\n                \" plugins will be ignored\"\n                \" because assert statements are not executed \"\n                \"by the underlying Python interpreter \"\n                \"(are you using python -O?)\\n\"\n            )"}, {"id": "_pytest.config.create_terminal_writer", "kind": "function", "range": [1214, 0, 1224, 13, 42746, 43233], "file_path": "src/_pytest/config/__init__.py", "content": "def create_terminal_writer(config: Config, *args, **kwargs) -> TerminalWriter:\n    \"\"\"Create a TerminalWriter instance configured according to the options\n    in the config object. Every code which requires a TerminalWriter object\n    and has access to a config object should use this function.\n    \"\"\"\n    tw = TerminalWriter(*args, **kwargs)\n    if config.option.color == \"yes\":\n        tw.hasmarkup = True\n    if config.option.color == \"no\":\n        tw.hasmarkup = False\n    return tw"}, {"id": "_pytest.config._strtobool", "kind": "function", "range": [1227, 0, 1242, 64, 43236, 43791], "file_path": "src/_pytest/config/__init__.py", "content": "def _strtobool(val):\n    \"\"\"Convert a string representation of truth to true (1) or false (0).\n\n    True values are 'y', 'yes', 't', 'true', 'on', and '1'; false values\n    are 'n', 'no', 'f', 'false', 'off', and '0'.  Raises ValueError if\n    'val' is anything else.\n\n    .. note:: copied from distutils.util\n    \"\"\"\n    val = val.lower()\n    if val in (\"y\", \"yes\", \"t\", \"true\", \"on\", \"1\"):\n        return 1\n    elif val in (\"n\", \"no\", \"f\", \"false\", \"off\", \"0\"):\n        return 0\n    else:\n        raise ValueError(\"invalid truth value {!r}\".format(val))"}, {"id": "_pytest.config.exists", "kind": "function", "range": [17, 0, 21, 20, 320, 430], "file_path": "src/_pytest/config/findpaths.py", "content": "def exists(path, ignore=OSError):\n    try:\n        return path.check()\n    except ignore:\n        return False"}, {"id": "_pytest.config.getcfg", "kind": "function", "range": [24, 0, 62, 27, 433, 2052], "file_path": "src/_pytest/config/findpaths.py", "content": "def getcfg(args, config=None):\n    \"\"\"\n    Search the list of arguments for a valid ini-file for pytest,\n    and return a tuple of (rootdir, inifile, cfg-dict).\n\n    note: config is optional and used only to issue warnings explicitly (#2891).\n    \"\"\"\n    inibasenames = [\"pytest.ini\", \"tox.ini\", \"setup.cfg\"]\n    args = [x for x in args if not str(x).startswith(\"-\")]\n    if not args:\n        args = [py.path.local()]\n    for arg in args:\n        arg = py.path.local(arg)\n        for base in arg.parts(reverse=True):\n            for inibasename in inibasenames:\n                p = base.join(inibasename)\n                if exists(p):\n                    try:\n                        iniconfig = py.iniconfig.IniConfig(p)\n                    except py.iniconfig.ParseError as exc:\n                        raise UsageError(str(exc))\n\n                    if (\n                        inibasename == \"setup.cfg\"\n                        and \"tool:pytest\" in iniconfig.sections\n                    ):\n                        return base, p, iniconfig[\"tool:pytest\"]\n                    elif \"pytest\" in iniconfig.sections:\n                        if inibasename == \"setup.cfg\" and config is not None:\n\n                            fail(\n                                CFG_PYTEST_SECTION.format(filename=inibasename),\n                                pytrace=False,\n                            )\n                        return base, p, iniconfig[\"pytest\"]\n                    elif inibasename == \"pytest.ini\":\n                        # allowed to be empty\n                        return base, p, {}\n    return None, None, None"}, {"id": "_pytest.config.get_common_ancestor", "kind": "function", "range": [65, 0, 85, 26, 2055, 2839], "file_path": "src/_pytest/config/findpaths.py", "content": "def get_common_ancestor(paths: Iterable[py.path.local]) -> py.path.local:\n    common_ancestor = None\n    for path in paths:\n        if not path.exists():\n            continue\n        if common_ancestor is None:\n            common_ancestor = path\n        else:\n            if path.relto(common_ancestor) or path == common_ancestor:\n                continue\n            elif common_ancestor.relto(path):\n                common_ancestor = path\n            else:\n                shared = path.common(common_ancestor)\n                if shared is not None:\n                    common_ancestor = shared\n    if common_ancestor is None:\n        common_ancestor = py.path.local()\n    elif common_ancestor.isfile():\n        common_ancestor = common_ancestor.dirpath()\n    return common_ancestor"}, {"id": "_pytest.config.get_dirs_from_args", "kind": "function", "range": [88, 0, 107, 80, 2842, 3486], "file_path": "src/_pytest/config/findpaths.py", "content": "def get_dirs_from_args(args: Iterable[str]) -> List[py.path.local]:\n    def is_option(x: str) -> bool:\n        return x.startswith(\"-\")\n\n    def get_file_part_from_node_id(x: str) -> str:\n        return x.split(\"::\")[0]\n\n    def get_dir_from_path(path: py.path.local) -> py.path.local:\n        if path.isdir():\n            return path\n        return py.path.local(path.dirname)\n\n    # These look like paths but may not exist\n    possible_paths = (\n        py.path.local(get_file_part_from_node_id(arg))\n        for arg in args\n        if not is_option(arg)\n    )\n\n    return [get_dir_from_path(path) for path in possible_paths if path.exists()]"}, {"id": "_pytest.config.CFG_PYTEST_SECTION", "kind": "variable", "range": [110, 0, 110, 116, 3489, 3605], "file_path": "src/_pytest/config/findpaths.py", "content": "CFG_PYTEST_SECTION = \"[pytest] section in {filename} files is no longer supported, change to [tool:pytest] instead.\""}, {"id": "_pytest.config.determine_setup", "kind": "function", "range": [113, 0, 166, 41, 3608, 5876], "file_path": "src/_pytest/config/findpaths.py", "content": "def determine_setup(\n    inifile: Optional[str],\n    args: List[str],\n    rootdir_cmd_arg: Optional[str] = None,\n    config: Optional[\"Config\"] = None,\n) -> Tuple[py.path.local, Optional[str], Any]:\n    dirs = get_dirs_from_args(args)\n    if inifile:\n        iniconfig = py.iniconfig.IniConfig(inifile)\n        is_cfg_file = str(inifile).endswith(\".cfg\")\n        sections = [\"tool:pytest\", \"pytest\"] if is_cfg_file else [\"pytest\"]\n        for section in sections:\n            try:\n                inicfg = iniconfig[\n                    section\n                ]  # type: Optional[py.iniconfig._SectionWrapper]\n                if is_cfg_file and section == \"pytest\" and config is not None:\n                    fail(\n                        CFG_PYTEST_SECTION.format(filename=str(inifile)), pytrace=False\n                    )\n                break\n            except KeyError:\n                inicfg = None\n        if rootdir_cmd_arg is None:\n            rootdir = get_common_ancestor(dirs)\n    else:\n        ancestor = get_common_ancestor(dirs)\n        rootdir, inifile, inicfg = getcfg([ancestor], config=config)\n        if rootdir is None and rootdir_cmd_arg is None:\n            for possible_rootdir in ancestor.parts(reverse=True):\n                if possible_rootdir.join(\"setup.py\").exists():\n                    rootdir = possible_rootdir\n                    break\n            else:\n                if dirs != [ancestor]:\n                    rootdir, inifile, inicfg = getcfg(dirs, config=config)\n                if rootdir is None:\n                    if config is not None:\n                        cwd = config.invocation_dir\n                    else:\n                        cwd = py.path.local()\n                    rootdir = get_common_ancestor([cwd, ancestor])\n                    is_fs_root = os.path.splitdrive(str(rootdir))[1] == \"/\"\n                    if is_fs_root:\n                        rootdir = ancestor\n    if rootdir_cmd_arg:\n        rootdir = py.path.local(os.path.expandvars(rootdir_cmd_arg))\n        if not rootdir.isdir():\n            raise UsageError(\n                \"Directory '{}' not found. Check your '--rootdir' option.\".format(\n                    rootdir\n                )\n            )\n    return rootdir, inifile, inicfg or {}"}, {"id": "_pytest.config.UsageError", "kind": "class", "range": [0, 0, 1, 46, 0, 75], "file_path": "src/_pytest/config/exceptions.py", "content": "class UsageError(Exception):\n    \"\"\" error in pytest usage or invocation\"\"\""}, {"id": "_pytest.config.PrintHelp", "kind": "class", "range": [4, 0, 8, 8, 78, 228], "file_path": "src/_pytest/config/exceptions.py", "content": "class PrintHelp(Exception):\n    \"\"\"Raised when pytest should print it's help to skip the rest of the\n    argument parsing and validation.\"\"\"\n\n    pass"}, {"id": "_pytest.config.FILE_OR_DIR", "kind": "variable", "range": [24, 0, 24, 27, 537, 564], "file_path": "src/_pytest/config/argparsing.py", "content": "FILE_OR_DIR = \"file_or_dir\""}, {"id": "_pytest.config.Parser", "kind": "class", "range": [27, 0, 178, 35, 567, 6553], "file_path": "src/_pytest/config/argparsing.py", "content": "class Parser:\n    \"\"\" Parser for command line arguments and ini-file values.\n\n    :ivar extra_info: dict of generic param -> value to display in case\n        there's an error processing the command line arguments.\n    \"\"\"\n\n    prog = None  # type: Optional[str]\n\n    def __init__(\n        self,\n        usage: Optional[str] = None,\n        processopt: Optional[Callable[[\"Argument\"], None]] = None,\n    ) -> None:\n        self._anonymous = OptionGroup(\"custom options\", parser=self)\n        self._groups = []  # type: List[OptionGroup]\n        self._processopt = processopt\n        self._usage = usage\n        self._inidict = {}  # type: Dict[str, Tuple[str, Optional[str], Any]]\n        self._ininames = []  # type: List[str]\n        self.extra_info = {}  # type: Dict[str, Any]\n\n    def processoption(self, option: \"Argument\") -> None:\n        if self._processopt:\n            if option.dest:\n                self._processopt(option)\n\n    def getgroup(\n        self, name: str, description: str = \"\", after: Optional[str] = None\n    ) -> \"OptionGroup\":\n        \"\"\" get (or create) a named option Group.\n\n        :name: name of the option group.\n        :description: long description for --help output.\n        :after: name of other group, used for ordering --help output.\n\n        The returned group object has an ``addoption`` method with the same\n        signature as :py:func:`parser.addoption\n        <_pytest.config.argparsing.Parser.addoption>` but will be shown in the\n        respective group in the output of ``pytest. --help``.\n        \"\"\"\n        for group in self._groups:\n            if group.name == name:\n                return group\n        group = OptionGroup(name, description, parser=self)\n        i = 0\n        for i, grp in enumerate(self._groups):\n            if grp.name == after:\n                break\n        self._groups.insert(i + 1, group)\n        return group\n\n    def addoption(self, *opts: str, **attrs: Any) -> None:\n        \"\"\" register a command line option.\n\n        :opts: option names, can be short or long options.\n        :attrs: same attributes which the ``add_argument()`` function of the\n           `argparse library\n           <https://docs.python.org/library/argparse.html>`_\n           accepts.\n\n        After command line parsing options are available on the pytest config\n        object via ``config.option.NAME`` where ``NAME`` is usually set\n        by passing a ``dest`` attribute, for example\n        ``addoption(\"--long\", dest=\"NAME\", ...)``.\n        \"\"\"\n        self._anonymous.addoption(*opts, **attrs)\n\n    def parse(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> argparse.Namespace:\n        from _pytest._argcomplete import try_argcomplete\n\n        self.optparser = self._getparser()\n        try_argcomplete(self.optparser)\n        strargs = [str(x) if isinstance(x, py.path.local) else x for x in args]\n        return self.optparser.parse_args(strargs, namespace=namespace)\n\n    def _getparser(self) -> \"MyOptionParser\":\n        from _pytest._argcomplete import filescompleter\n\n        optparser = MyOptionParser(self, self.extra_info, prog=self.prog)\n        groups = self._groups + [self._anonymous]\n        for group in groups:\n            if group.options:\n                desc = group.description or group.name\n                arggroup = optparser.add_argument_group(desc)\n                for option in group.options:\n                    n = option.names()\n                    a = option.attrs()\n                    arggroup.add_argument(*n, **a)\n        file_or_dir_arg = optparser.add_argument(FILE_OR_DIR, nargs=\"*\")\n        # bash like autocompletion for dirs (appending '/')\n        # Type ignored because typeshed doesn't know about argcomplete.\n        file_or_dir_arg.completer = filescompleter  # type: ignore\n        return optparser\n\n    def parse_setoption(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        option: argparse.Namespace,\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> List[str]:\n        parsedoption = self.parse(args, namespace=namespace)\n        for name, value in parsedoption.__dict__.items():\n            setattr(option, name, value)\n        return cast(List[str], getattr(parsedoption, FILE_OR_DIR))\n\n    def parse_known_args(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> argparse.Namespace:\n        \"\"\"parses and returns a namespace object with known arguments at this\n        point.\n        \"\"\"\n        return self.parse_known_and_unknown_args(args, namespace=namespace)[0]\n\n    def parse_known_and_unknown_args(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> Tuple[argparse.Namespace, List[str]]:\n        \"\"\"parses and returns a namespace object with known arguments, and\n        the remaining arguments unknown at this point.\n        \"\"\"\n        optparser = self._getparser()\n        strargs = [str(x) if isinstance(x, py.path.local) else x for x in args]\n        return optparser.parse_known_args(strargs, namespace=namespace)\n\n    def addini(\n        self,\n        name: str,\n        help: str,\n        type: Optional[\"Literal['pathlist', 'args', 'linelist', 'bool']\"] = None,\n        default=None,\n    ) -> None:\n        \"\"\" register an ini-file option.\n\n        :name: name of the ini-variable\n        :type: type of the variable, can be ``pathlist``, ``args``, ``linelist``\n               or ``bool``.\n        :default: default value if no ini-file option exists but is queried.\n\n        The value of ini-variables can be retrieved via a call to\n        :py:func:`config.getini(name) <_pytest.config.Config.getini>`.\n        \"\"\"\n        assert type in (None, \"pathlist\", \"args\", \"linelist\", \"bool\")\n        self._inidict[name] = (help, type, default)\n        self._ininames.append(name)"}, {"id": "_pytest.config.Parser.prog", "kind": "variable", "range": [34, 4, 34, 15, 794, 805], "file_path": "src/_pytest/config/argparsing.py", "content": "prog = None"}, {"id": "_pytest.config.Parser.__init__", "kind": "function", "range": [36, 4, 47, 52, 834, 1346], "file_path": "src/_pytest/config/argparsing.py", "content": "def __init__(\n        self,\n        usage: Optional[str] = None,\n        processopt: Optional[Callable[[\"Argument\"], None]] = None,\n    ) -> None:\n        self._anonymous = OptionGroup(\"custom options\", parser=self)\n        self._groups = []  # type: List[OptionGroup]\n        self._processopt = processopt\n        self._usage = usage\n        self._inidict = {}  # type: Dict[str, Tuple[str, Optional[str], Any]]\n        self._ininames = []  # type: List[str]\n        self.extra_info = {}  # type: Dict[str, Any]"}, {"id": "_pytest.config.Parser.processoption", "kind": "function", "range": [49, 4, 52, 40, 1352, 1502], "file_path": "src/_pytest/config/argparsing.py", "content": "def processoption(self, option: \"Argument\") -> None:\n        if self._processopt:\n            if option.dest:\n                self._processopt(option)"}, {"id": "_pytest.config.Parser.getgroup", "kind": "function", "range": [54, 4, 77, 20, 1508, 2458], "file_path": "src/_pytest/config/argparsing.py", "content": "def getgroup(\n        self, name: str, description: str = \"\", after: Optional[str] = None\n    ) -> \"OptionGroup\":\n        \"\"\" get (or create) a named option Group.\n\n        :name: name of the option group.\n        :description: long description for --help output.\n        :after: name of other group, used for ordering --help output.\n\n        The returned group object has an ``addoption`` method with the same\n        signature as :py:func:`parser.addoption\n        <_pytest.config.argparsing.Parser.addoption>` but will be shown in the\n        respective group in the output of ``pytest. --help``.\n        \"\"\"\n        for group in self._groups:\n            if group.name == name:\n                return group\n        group = OptionGroup(name, description, parser=self)\n        i = 0\n        for i, grp in enumerate(self._groups):\n            if grp.name == after:\n                break\n        self._groups.insert(i + 1, group)\n        return group"}, {"id": "_pytest.config.Parser.addoption", "kind": "function", "range": [79, 4, 93, 49, 2464, 3126], "file_path": "src/_pytest/config/argparsing.py", "content": "def addoption(self, *opts: str, **attrs: Any) -> None:\n        \"\"\" register a command line option.\n\n        :opts: option names, can be short or long options.\n        :attrs: same attributes which the ``add_argument()`` function of the\n           `argparse library\n           <https://docs.python.org/library/argparse.html>`_\n           accepts.\n\n        After command line parsing options are available on the pytest config\n        object via ``config.option.NAME`` where ``NAME`` is usually set\n        by passing a ``dest`` attribute, for example\n        ``addoption(\"--long\", dest=\"NAME\", ...)``.\n        \"\"\"\n        self._anonymous.addoption(*opts, **attrs)"}, {"id": "_pytest.config.Parser.parse", "kind": "function", "range": [95, 4, 105, 70, 3132, 3584], "file_path": "src/_pytest/config/argparsing.py", "content": "def parse(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> argparse.Namespace:\n        from _pytest._argcomplete import try_argcomplete\n\n        self.optparser = self._getparser()\n        try_argcomplete(self.optparser)\n        strargs = [str(x) if isinstance(x, py.path.local) else x for x in args]\n        return self.optparser.parse_args(strargs, namespace=namespace)"}, {"id": "_pytest.config.Parser._getparser", "kind": "function", "range": [107, 4, 124, 24, 3590, 4459], "file_path": "src/_pytest/config/argparsing.py", "content": "def _getparser(self) -> \"MyOptionParser\":\n        from _pytest._argcomplete import filescompleter\n\n        optparser = MyOptionParser(self, self.extra_info, prog=self.prog)\n        groups = self._groups + [self._anonymous]\n        for group in groups:\n            if group.options:\n                desc = group.description or group.name\n                arggroup = optparser.add_argument_group(desc)\n                for option in group.options:\n                    n = option.names()\n                    a = option.attrs()\n                    arggroup.add_argument(*n, **a)\n        file_or_dir_arg = optparser.add_argument(FILE_OR_DIR, nargs=\"*\")\n        # bash like autocompletion for dirs (appending '/')\n        # Type ignored because typeshed doesn't know about argcomplete.\n        file_or_dir_arg.completer = filescompleter  # type: ignore\n        return optparser"}, {"id": "_pytest.config.Parser.parse_setoption", "kind": "function", "range": [126, 4, 135, 66, 4465, 4889], "file_path": "src/_pytest/config/argparsing.py", "content": "def parse_setoption(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        option: argparse.Namespace,\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> List[str]:\n        parsedoption = self.parse(args, namespace=namespace)\n        for name, value in parsedoption.__dict__.items():\n            setattr(option, name, value)\n        return cast(List[str], getattr(parsedoption, FILE_OR_DIR))"}, {"id": "_pytest.config.Parser.parse_known_args", "kind": "function", "range": [137, 4, 145, 78, 4895, 5250], "file_path": "src/_pytest/config/argparsing.py", "content": "def parse_known_args(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> argparse.Namespace:\n        \"\"\"parses and returns a namespace object with known arguments at this\n        point.\n        \"\"\"\n        return self.parse_known_and_unknown_args(args, namespace=namespace)[0]"}, {"id": "_pytest.config.Parser.parse_known_and_unknown_args", "kind": "function", "range": [147, 4, 157, 71, 5256, 5789], "file_path": "src/_pytest/config/argparsing.py", "content": "def parse_known_and_unknown_args(\n        self,\n        args: Sequence[Union[str, py.path.local]],\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> Tuple[argparse.Namespace, List[str]]:\n        \"\"\"parses and returns a namespace object with known arguments, and\n        the remaining arguments unknown at this point.\n        \"\"\"\n        optparser = self._getparser()\n        strargs = [str(x) if isinstance(x, py.path.local) else x for x in args]\n        return optparser.parse_known_args(strargs, namespace=namespace)"}, {"id": "_pytest.config.Parser.addini", "kind": "function", "range": [159, 4, 178, 35, 5795, 6553], "file_path": "src/_pytest/config/argparsing.py", "content": "def addini(\n        self,\n        name: str,\n        help: str,\n        type: Optional[\"Literal['pathlist', 'args', 'linelist', 'bool']\"] = None,\n        default=None,\n    ) -> None:\n        \"\"\" register an ini-file option.\n\n        :name: name of the ini-variable\n        :type: type of the variable, can be ``pathlist``, ``args``, ``linelist``\n               or ``bool``.\n        :default: default value if no ini-file option exists but is queried.\n\n        The value of ini-variables can be retrieved via a call to\n        :py:func:`config.getini(name) <_pytest.config.Config.getini>`.\n        \"\"\"\n        assert type in (None, \"pathlist\", \"args\", \"linelist\", \"bool\")\n        self._inidict[name] = (help, type, default)\n        self._ininames.append(name)"}, {"id": "_pytest.config.ArgumentError", "kind": "class", "range": [181, 0, 195, 27, 6556, 6996], "file_path": "src/_pytest/config/argparsing.py", "content": "class ArgumentError(Exception):\n    \"\"\"\n    Raised if an Argument instance is created with invalid or\n    inconsistent arguments.\n    \"\"\"\n\n    def __init__(self, msg: str, option: Union[\"Argument\", str]) -> None:\n        self.msg = msg\n        self.option_id = str(option)\n\n    def __str__(self) -> str:\n        if self.option_id:\n            return \"option {}: {}\".format(self.option_id, self.msg)\n        else:\n            return self.msg"}, {"id": "_pytest.config.ArgumentError.__init__", "kind": "function", "range": [187, 4, 189, 36, 6699, 6828], "file_path": "src/_pytest/config/argparsing.py", "content": "def __init__(self, msg: str, option: Union[\"Argument\", str]) -> None:\n        self.msg = msg\n        self.option_id = str(option)"}, {"id": "_pytest.config.ArgumentError.__str__", "kind": "function", "range": [191, 4, 195, 27, 6834, 6996], "file_path": "src/_pytest/config/argparsing.py", "content": "def __str__(self) -> str:\n        if self.option_id:\n            return \"option {}: {}\".format(self.option_id, self.msg)\n        else:\n            return self.msg"}, {"id": "_pytest.config.Argument", "kind": "class", "range": [198, 0, 328, 53, 6999, 12298], "file_path": "src/_pytest/config/argparsing.py", "content": "class Argument:\n    \"\"\"class that mimics the necessary behaviour of optparse.Option\n\n    it's currently a least effort implementation\n    and ignoring choices and integer prefixes\n    https://docs.python.org/3/library/optparse.html#optparse-standard-option-types\n    \"\"\"\n\n    _typ_map = {\"int\": int, \"string\": str, \"float\": float, \"complex\": complex}\n\n    def __init__(self, *names: str, **attrs: Any) -> None:\n        \"\"\"store parms in private vars for use in add_argument\"\"\"\n        self._attrs = attrs\n        self._short_opts = []  # type: List[str]\n        self._long_opts = []  # type: List[str]\n        if \"%default\" in (attrs.get(\"help\") or \"\"):\n            warnings.warn(\n                'pytest now uses argparse. \"%default\" should be'\n                ' changed to \"%(default)s\" ',\n                DeprecationWarning,\n                stacklevel=3,\n            )\n        try:\n            typ = attrs[\"type\"]\n        except KeyError:\n            pass\n        else:\n            # this might raise a keyerror as well, don't want to catch that\n            if isinstance(typ, str):\n                if typ == \"choice\":\n                    warnings.warn(\n                        \"`type` argument to addoption() is the string %r.\"\n                        \" For choices this is optional and can be omitted, \"\n                        \" but when supplied should be a type (for example `str` or `int`).\"\n                        \" (options: %s)\" % (typ, names),\n                        DeprecationWarning,\n                        stacklevel=4,\n                    )\n                    # argparse expects a type here take it from\n                    # the type of the first element\n                    attrs[\"type\"] = type(attrs[\"choices\"][0])\n                else:\n                    warnings.warn(\n                        \"`type` argument to addoption() is the string %r, \"\n                        \" but when supplied should be a type (for example `str` or `int`).\"\n                        \" (options: %s)\" % (typ, names),\n                        DeprecationWarning,\n                        stacklevel=4,\n                    )\n                    attrs[\"type\"] = Argument._typ_map[typ]\n                # used in test_parseopt -> test_parse_defaultgetter\n                self.type = attrs[\"type\"]\n            else:\n                self.type = typ\n        try:\n            # attribute existence is tested in Config._processopt\n            self.default = attrs[\"default\"]\n        except KeyError:\n            pass\n        self._set_opt_strings(names)\n        dest = attrs.get(\"dest\")  # type: Optional[str]\n        if dest:\n            self.dest = dest\n        elif self._long_opts:\n            self.dest = self._long_opts[0][2:].replace(\"-\", \"_\")\n        else:\n            try:\n                self.dest = self._short_opts[0][1:]\n            except IndexError:\n                self.dest = \"???\"  # Needed for the error repr.\n                raise ArgumentError(\"need a long or short option\", self)\n\n    def names(self) -> List[str]:\n        return self._short_opts + self._long_opts\n\n    def attrs(self) -> Mapping[str, Any]:\n        # update any attributes set by processopt\n        attrs = \"default dest help\".split()\n        attrs.append(self.dest)\n        for attr in attrs:\n            try:\n                self._attrs[attr] = getattr(self, attr)\n            except AttributeError:\n                pass\n        if self._attrs.get(\"help\"):\n            a = self._attrs[\"help\"]\n            a = a.replace(\"%default\", \"%(default)s\")\n            # a = a.replace('%prog', '%(prog)s')\n            self._attrs[\"help\"] = a\n        return self._attrs\n\n    def _set_opt_strings(self, opts: Sequence[str]) -> None:\n        \"\"\"directly from optparse\n\n        might not be necessary as this is passed to argparse later on\"\"\"\n        for opt in opts:\n            if len(opt) < 2:\n                raise ArgumentError(\n                    \"invalid option string %r: \"\n                    \"must be at least two characters long\" % opt,\n                    self,\n                )\n            elif len(opt) == 2:\n                if not (opt[0] == \"-\" and opt[1] != \"-\"):\n                    raise ArgumentError(\n                        \"invalid short option string %r: \"\n                        \"must be of the form -x, (x any non-dash char)\" % opt,\n                        self,\n                    )\n                self._short_opts.append(opt)\n            else:\n                if not (opt[0:2] == \"--\" and opt[2] != \"-\"):\n                    raise ArgumentError(\n                        \"invalid long option string %r: \"\n                        \"must start with --, followed by non-dash\" % opt,\n                        self,\n                    )\n                self._long_opts.append(opt)\n\n    def __repr__(self) -> str:\n        args = []  # type: List[str]\n        if self._short_opts:\n            args += [\"_short_opts: \" + repr(self._short_opts)]\n        if self._long_opts:\n            args += [\"_long_opts: \" + repr(self._long_opts)]\n        args += [\"dest: \" + repr(self.dest)]\n        if hasattr(self, \"type\"):\n            args += [\"type: \" + repr(self.type)]\n        if hasattr(self, \"default\"):\n            args += [\"default: \" + repr(self.default)]\n        return \"Argument({})\".format(\", \".join(args))"}, {"id": "_pytest.config.Argument._typ_map", "kind": "variable", "range": [206, 4, 206, 78, 7275, 7349], "file_path": "src/_pytest/config/argparsing.py", "content": "_typ_map = {\"int\": int, \"string\": str, \"float\": float, \"complex\": complex}"}, {"id": "_pytest.config.Argument.__init__", "kind": "function", "range": [208, 4, 268, 72, 7355, 9993], "file_path": "src/_pytest/config/argparsing.py", "content": "def __init__(self, *names: str, **attrs: Any) -> None:\n        \"\"\"store parms in private vars for use in add_argument\"\"\"\n        self._attrs = attrs\n        self._short_opts = []  # type: List[str]\n        self._long_opts = []  # type: List[str]\n        if \"%default\" in (attrs.get(\"help\") or \"\"):\n            warnings.warn(\n                'pytest now uses argparse. \"%default\" should be'\n                ' changed to \"%(default)s\" ',\n                DeprecationWarning,\n                stacklevel=3,\n            )\n        try:\n            typ = attrs[\"type\"]\n        except KeyError:\n            pass\n        else:\n            # this might raise a keyerror as well, don't want to catch that\n            if isinstance(typ, str):\n                if typ == \"choice\":\n                    warnings.warn(\n                        \"`type` argument to addoption() is the string %r.\"\n                        \" For choices this is optional and can be omitted, \"\n                        \" but when supplied should be a type (for example `str` or `int`).\"\n                        \" (options: %s)\" % (typ, names),\n                        DeprecationWarning,\n                        stacklevel=4,\n                    )\n                    # argparse expects a type here take it from\n                    # the type of the first element\n                    attrs[\"type\"] = type(attrs[\"choices\"][0])\n                else:\n                    warnings.warn(\n                        \"`type` argument to addoption() is the string %r, \"\n                        \" but when supplied should be a type (for example `str` or `int`).\"\n                        \" (options: %s)\" % (typ, names),\n                        DeprecationWarning,\n                        stacklevel=4,\n                    )\n                    attrs[\"type\"] = Argument._typ_map[typ]\n                # used in test_parseopt -> test_parse_defaultgetter\n                self.type = attrs[\"type\"]\n            else:\n                self.type = typ\n        try:\n            # attribute existence is tested in Config._processopt\n            self.default = attrs[\"default\"]\n        except KeyError:\n            pass\n        self._set_opt_strings(names)\n        dest = attrs.get(\"dest\")  # type: Optional[str]\n        if dest:\n            self.dest = dest\n        elif self._long_opts:\n            self.dest = self._long_opts[0][2:].replace(\"-\", \"_\")\n        else:\n            try:\n                self.dest = self._short_opts[0][1:]\n            except IndexError:\n                self.dest = \"???\"  # Needed for the error repr.\n                raise ArgumentError(\"need a long or short option\", self)"}, {"id": "_pytest.config.Argument.names", "kind": "function", "range": [270, 4, 271, 49, 9999, 10078], "file_path": "src/_pytest/config/argparsing.py", "content": "def names(self) -> List[str]:\n        return self._short_opts + self._long_opts"}, {"id": "_pytest.config.Argument.attrs", "kind": "function", "range": [273, 4, 287, 26, 10084, 10640], "file_path": "src/_pytest/config/argparsing.py", "content": "def attrs(self) -> Mapping[str, Any]:\n        # update any attributes set by processopt\n        attrs = \"default dest help\".split()\n        attrs.append(self.dest)\n        for attr in attrs:\n            try:\n                self._attrs[attr] = getattr(self, attr)\n            except AttributeError:\n                pass\n        if self._attrs.get(\"help\"):\n            a = self._attrs[\"help\"]\n            a = a.replace(\"%default\", \"%(default)s\")\n            # a = a.replace('%prog', '%(prog)s')\n            self._attrs[\"help\"] = a\n        return self._attrs"}, {"id": "_pytest.config.Argument._set_opt_strings", "kind": "function", "range": [289, 4, 315, 43, 10646, 11774], "file_path": "src/_pytest/config/argparsing.py", "content": "def _set_opt_strings(self, opts: Sequence[str]) -> None:\n        \"\"\"directly from optparse\n\n        might not be necessary as this is passed to argparse later on\"\"\"\n        for opt in opts:\n            if len(opt) < 2:\n                raise ArgumentError(\n                    \"invalid option string %r: \"\n                    \"must be at least two characters long\" % opt,\n                    self,\n                )\n            elif len(opt) == 2:\n                if not (opt[0] == \"-\" and opt[1] != \"-\"):\n                    raise ArgumentError(\n                        \"invalid short option string %r: \"\n                        \"must be of the form -x, (x any non-dash char)\" % opt,\n                        self,\n                    )\n                self._short_opts.append(opt)\n            else:\n                if not (opt[0:2] == \"--\" and opt[2] != \"-\"):\n                    raise ArgumentError(\n                        \"invalid long option string %r: \"\n                        \"must start with --, followed by non-dash\" % opt,\n                        self,\n                    )\n                self._long_opts.append(opt)"}, {"id": "_pytest.config.Argument.__repr__", "kind": "function", "range": [317, 4, 328, 53, 11780, 12298], "file_path": "src/_pytest/config/argparsing.py", "content": "def __repr__(self) -> str:\n        args = []  # type: List[str]\n        if self._short_opts:\n            args += [\"_short_opts: \" + repr(self._short_opts)]\n        if self._long_opts:\n            args += [\"_long_opts: \" + repr(self._long_opts)]\n        args += [\"dest: \" + repr(self.dest)]\n        if hasattr(self, \"type\"):\n            args += [\"type: \" + repr(self.type)]\n        if hasattr(self, \"default\"):\n            args += [\"default: \" + repr(self.default)]\n        return \"Argument({})\".format(\", \".join(args))"}, {"id": "_pytest.config.OptionGroup", "kind": "class", "range": [331, 0, 367, 35, 12301, 13862], "file_path": "src/_pytest/config/argparsing.py", "content": "class OptionGroup:\n    def __init__(\n        self, name: str, description: str = \"\", parser: Optional[Parser] = None\n    ) -> None:\n        self.name = name\n        self.description = description\n        self.options = []  # type: List[Argument]\n        self.parser = parser\n\n    def addoption(self, *optnames: str, **attrs: Any) -> None:\n        \"\"\" add an option to this group.\n\n        if a shortened version of a long option is specified it will\n        be suppressed in the help. addoption('--twowords', '--two-words')\n        results in help showing '--two-words' only, but --twowords gets\n        accepted **and** the automatic destination is in args.twowords\n        \"\"\"\n        conflict = set(optnames).intersection(\n            name for opt in self.options for name in opt.names()\n        )\n        if conflict:\n            raise ValueError(\"option names %s already added\" % conflict)\n        option = Argument(*optnames, **attrs)\n        self._addoption_instance(option, shortupper=False)\n\n    def _addoption(self, *optnames: str, **attrs: Any) -> None:\n        option = Argument(*optnames, **attrs)\n        self._addoption_instance(option, shortupper=True)\n\n    def _addoption_instance(self, option: \"Argument\", shortupper: bool = False) -> None:\n        if not shortupper:\n            for opt in option._short_opts:\n                if opt[0] == \"-\" and opt[1].islower():\n                    raise ValueError(\"lowercase shortoptions reserved\")\n        if self.parser:\n            self.parser.processoption(option)\n        self.options.append(option)"}, {"id": "_pytest.config.OptionGroup.__init__", "kind": "function", "range": [332, 4, 338, 28, 12324, 12575], "file_path": "src/_pytest/config/argparsing.py", "content": "def __init__(\n        self, name: str, description: str = \"\", parser: Optional[Parser] = None\n    ) -> None:\n        self.name = name\n        self.description = description\n        self.options = []  # type: List[Argument]\n        self.parser = parser"}, {"id": "_pytest.config.OptionGroup.addoption", "kind": "function", "range": [340, 4, 354, 58, 12581, 13300], "file_path": "src/_pytest/config/argparsing.py", "content": "def addoption(self, *optnames: str, **attrs: Any) -> None:\n        \"\"\" add an option to this group.\n\n        if a shortened version of a long option is specified it will\n        be suppressed in the help. addoption('--twowords', '--two-words')\n        results in help showing '--two-words' only, but --twowords gets\n        accepted **and** the automatic destination is in args.twowords\n        \"\"\"\n        conflict = set(optnames).intersection(\n            name for opt in self.options for name in opt.names()\n        )\n        if conflict:\n            raise ValueError(\"option names %s already added\" % conflict)\n        option = Argument(*optnames, **attrs)\n        self._addoption_instance(option, shortupper=False)"}, {"id": "_pytest.config.OptionGroup._addoption", "kind": "function", "range": [356, 4, 358, 57, 13306, 13469], "file_path": "src/_pytest/config/argparsing.py", "content": "def _addoption(self, *optnames: str, **attrs: Any) -> None:\n        option = Argument(*optnames, **attrs)\n        self._addoption_instance(option, shortupper=True)"}, {"id": "_pytest.config.OptionGroup._addoption_instance", "kind": "function", "range": [360, 4, 367, 35, 13475, 13862], "file_path": "src/_pytest/config/argparsing.py", "content": "def _addoption_instance(self, option: \"Argument\", shortupper: bool = False) -> None:\n        if not shortupper:\n            for opt in option._short_opts:\n                if opt[0] == \"-\" and opt[1].islower():\n                    raise ValueError(\"lowercase shortoptions reserved\")\n        if self.parser:\n            self.parser.processoption(option)\n        self.options.append(option)"}, {"id": "_pytest.config.MyOptionParser", "kind": "class", "range": [370, 0, 454, 41, 13865, 17743], "file_path": "src/_pytest/config/argparsing.py", "content": "class MyOptionParser(argparse.ArgumentParser):\n    def __init__(\n        self,\n        parser: Parser,\n        extra_info: Optional[Dict[str, Any]] = None,\n        prog: Optional[str] = None,\n    ) -> None:\n        self._parser = parser\n        argparse.ArgumentParser.__init__(\n            self,\n            prog=prog,\n            usage=parser._usage,\n            add_help=False,\n            formatter_class=DropShorterLongHelpFormatter,\n            allow_abbrev=False,\n        )\n        # extra_info is a dict of (param -> value) to display if there's\n        # an usage error to provide more contextual information to the user\n        self.extra_info = extra_info if extra_info else {}\n\n    def error(self, message: str) -> \"NoReturn\":\n        \"\"\"Transform argparse error message into UsageError.\"\"\"\n        msg = \"{}: error: {}\".format(self.prog, message)\n\n        if hasattr(self._parser, \"_config_source_hint\"):\n            # Type ignored because the attribute is set dynamically.\n            msg = \"{} ({})\".format(msg, self._parser._config_source_hint)  # type: ignore\n\n        raise UsageError(self.format_usage() + msg)\n\n    # Type ignored because typeshed has a very complex type in the superclass.\n    def parse_args(  # type: ignore\n        self,\n        args: Optional[Sequence[str]] = None,\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> argparse.Namespace:\n        \"\"\"allow splitting of positional arguments\"\"\"\n        parsed, unrecognized = self.parse_known_args(args, namespace)\n        if unrecognized:\n            for arg in unrecognized:\n                if arg and arg[0] == \"-\":\n                    lines = [\"unrecognized arguments: %s\" % (\" \".join(unrecognized))]\n                    for k, v in sorted(self.extra_info.items()):\n                        lines.append(\"  {}: {}\".format(k, v))\n                    self.error(\"\\n\".join(lines))\n            getattr(parsed, FILE_OR_DIR).extend(unrecognized)\n        return parsed\n\n    if sys.version_info[:2] < (3, 9):  # pragma: no cover\n        # Backport of https://github.com/python/cpython/pull/14316 so we can\n        # disable long --argument abbreviations without breaking short flags.\n        def _parse_optional(\n            self, arg_string: str\n        ) -> Optional[Tuple[Optional[argparse.Action], str, Optional[str]]]:\n            if not arg_string:\n                return None\n            if not arg_string[0] in self.prefix_chars:\n                return None\n            if arg_string in self._option_string_actions:\n                action = self._option_string_actions[arg_string]\n                return action, arg_string, None\n            if len(arg_string) == 1:\n                return None\n            if \"=\" in arg_string:\n                option_string, explicit_arg = arg_string.split(\"=\", 1)\n                if option_string in self._option_string_actions:\n                    action = self._option_string_actions[option_string]\n                    return action, option_string, explicit_arg\n            if self.allow_abbrev or not arg_string.startswith(\"--\"):\n                option_tuples = self._get_option_tuples(arg_string)\n                if len(option_tuples) > 1:\n                    msg = gettext(\n                        \"ambiguous option: %(option)s could match %(matches)s\"\n                    )\n                    options = \", \".join(option for _, option, _ in option_tuples)\n                    self.error(msg % {\"option\": arg_string, \"matches\": options})\n                elif len(option_tuples) == 1:\n                    (option_tuple,) = option_tuples\n                    return option_tuple\n            if self._negative_number_matcher.match(arg_string):\n                if not self._has_negative_number_optionals:\n                    return None\n            if \" \" in arg_string:\n                return None\n            return None, arg_string, None"}, {"id": "_pytest.config.MyOptionParser.__init__", "kind": "function", "range": [371, 4, 388, 58, 13916, 14553], "file_path": "src/_pytest/config/argparsing.py", "content": "def __init__(\n        self,\n        parser: Parser,\n        extra_info: Optional[Dict[str, Any]] = None,\n        prog: Optional[str] = None,\n    ) -> None:\n        self._parser = parser\n        argparse.ArgumentParser.__init__(\n            self,\n            prog=prog,\n            usage=parser._usage,\n            add_help=False,\n            formatter_class=DropShorterLongHelpFormatter,\n            allow_abbrev=False,\n        )\n        # extra_info is a dict of (param -> value) to display if there's\n        # an usage error to provide more contextual information to the user\n        self.extra_info = extra_info if extra_info else {}"}, {"id": "_pytest.config.MyOptionParser.error", "kind": "function", "range": [390, 4, 398, 51, 14559, 14994], "file_path": "src/_pytest/config/argparsing.py", "content": "def error(self, message: str) -> \"NoReturn\":\n        \"\"\"Transform argparse error message into UsageError.\"\"\"\n        msg = \"{}: error: {}\".format(self.prog, message)\n\n        if hasattr(self._parser, \"_config_source_hint\"):\n            # Type ignored because the attribute is set dynamically.\n            msg = \"{} ({})\".format(msg, self._parser._config_source_hint)  # type: ignore\n\n        raise UsageError(self.format_usage() + msg)"}, {"id": "_pytest.config.MyOptionParser.parse_args", "kind": "function", "range": [401, 4, 416, 21, 15079, 15829], "file_path": "src/_pytest/config/argparsing.py", "content": "def parse_args(  # type: ignore\n        self,\n        args: Optional[Sequence[str]] = None,\n        namespace: Optional[argparse.Namespace] = None,\n    ) -> argparse.Namespace:\n        \"\"\"allow splitting of positional arguments\"\"\"\n        parsed, unrecognized = self.parse_known_args(args, namespace)\n        if unrecognized:\n            for arg in unrecognized:\n                if arg and arg[0] == \"-\":\n                    lines = [\"unrecognized arguments: %s\" % (\" \".join(unrecognized))]\n                    for k, v in sorted(self.extra_info.items()):\n                        lines.append(\"  {}: {}\".format(k, v))\n                    self.error(\"\\n\".join(lines))\n            getattr(parsed, FILE_OR_DIR).extend(unrecognized)\n        return parsed"}, {"id": "_pytest.config.DropShorterLongHelpFormatter", "kind": "class", "range": [457, 0, 509, 42, 17746, 20247], "file_path": "src/_pytest/config/argparsing.py", "content": "class DropShorterLongHelpFormatter(argparse.HelpFormatter):\n    \"\"\"shorten help for long options that differ only in extra hyphens\n\n    - collapse **long** options that are the same except for extra hyphens\n    - shortcut if there are only two options and one of them is a short one\n    - cache result on action object as this is called at least 2 times\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Use more accurate terminal width via pylib.\"\"\"\n        if \"width\" not in kwargs:\n            kwargs[\"width\"] = py.io.get_terminal_width()\n        super().__init__(*args, **kwargs)\n\n    def _format_action_invocation(self, action: argparse.Action) -> str:\n        orgstr = argparse.HelpFormatter._format_action_invocation(self, action)\n        if orgstr and orgstr[0] != \"-\":  # only optional arguments\n            return orgstr\n        res = getattr(\n            action, \"_formatted_action_invocation\", None\n        )  # type: Optional[str]\n        if res:\n            return res\n        options = orgstr.split(\", \")\n        if len(options) == 2 and (len(options[0]) == 2 or len(options[1]) == 2):\n            # a shortcut for '-h, --help' or '--abc', '-a'\n            action._formatted_action_invocation = orgstr  # type: ignore\n            return orgstr\n        return_list = []\n        short_long = {}  # type: Dict[str, str]\n        for option in options:\n            if len(option) == 2 or option[2] == \" \":\n                continue\n            if not option.startswith(\"--\"):\n                raise ArgumentError(\n                    'long optional argument without \"--\": [%s]' % (option), option\n                )\n            xxoption = option[2:]\n            shortened = xxoption.replace(\"-\", \"\")\n            if shortened not in short_long or len(short_long[shortened]) < len(\n                xxoption\n            ):\n                short_long[shortened] = xxoption\n        # now short_long has been filled out to the longest with dashes\n        # **and** we keep the right option ordering from add_argument\n        for option in options:\n            if len(option) == 2 or option[2] == \" \":\n                return_list.append(option)\n            if option[2:] == short_long.get(option.replace(\"-\", \"\")):\n                return_list.append(option.replace(\" \", \"=\", 1))\n        formatted_action_invocation = \", \".join(return_list)\n        action._formatted_action_invocation = formatted_action_invocation  # type: ignore\n        return formatted_action_invocation"}, {"id": "_pytest.config.DropShorterLongHelpFormatter.__init__", "kind": "function", "range": [465, 4, 469, 41, 18113, 18358], "file_path": "src/_pytest/config/argparsing.py", "content": "def __init__(self, *args: Any, **kwargs: Any) -> None:\n        \"\"\"Use more accurate terminal width via pylib.\"\"\"\n        if \"width\" not in kwargs:\n            kwargs[\"width\"] = py.io.get_terminal_width()\n        super().__init__(*args, **kwargs)"}, {"id": "_pytest.config.DropShorterLongHelpFormatter._format_action_invocation", "kind": "function", "range": [471, 4, 509, 42, 18364, 20247], "file_path": "src/_pytest/config/argparsing.py", "content": "def _format_action_invocation(self, action: argparse.Action) -> str:\n        orgstr = argparse.HelpFormatter._format_action_invocation(self, action)\n        if orgstr and orgstr[0] != \"-\":  # only optional arguments\n            return orgstr\n        res = getattr(\n            action, \"_formatted_action_invocation\", None\n        )  # type: Optional[str]\n        if res:\n            return res\n        options = orgstr.split(\", \")\n        if len(options) == 2 and (len(options[0]) == 2 or len(options[1]) == 2):\n            # a shortcut for '-h, --help' or '--abc', '-a'\n            action._formatted_action_invocation = orgstr  # type: ignore\n            return orgstr\n        return_list = []\n        short_long = {}  # type: Dict[str, str]\n        for option in options:\n            if len(option) == 2 or option[2] == \" \":\n                continue\n            if not option.startswith(\"--\"):\n                raise ArgumentError(\n                    'long optional argument without \"--\": [%s]' % (option), option\n                )\n            xxoption = option[2:]\n            shortened = xxoption.replace(\"-\", \"\")\n            if shortened not in short_long or len(short_long[shortened]) < len(\n                xxoption\n            ):\n                short_long[shortened] = xxoption\n        # now short_long has been filled out to the longest with dashes\n        # **and** we keep the right option ordering from add_argument\n        for option in options:\n            if len(option) == 2 or option[2] == \" \":\n                return_list.append(option)\n            if option[2:] == short_long.get(option.replace(\"-\", \"\")):\n                return_list.append(option.replace(\" \", \"=\", 1))\n        formatted_action_invocation = \", \".join(return_list)\n        action._formatted_action_invocation = formatted_action_invocation  # type: ignore\n        return formatted_action_invocation"}, {"id": "_pytest.warnings._setoption", "kind": "function", "range": [9, 0, 30, 66, 144, 929], "file_path": "src/_pytest/warnings.py", "content": "def _setoption(wmod, arg):\n    \"\"\"\n    Copy of the warning._setoption function but does not escape arguments.\n    \"\"\"\n    parts = arg.split(\":\")\n    if len(parts) > 5:\n        raise wmod._OptionError(\"too many fields (max 5): {!r}\".format(arg))\n    while len(parts) < 5:\n        parts.append(\"\")\n    action, message, category, module, lineno = [s.strip() for s in parts]\n    action = wmod._getaction(action)\n    category = wmod._getcategory(category)\n    if lineno:\n        try:\n            lineno = int(lineno)\n            if lineno < 0:\n                raise ValueError\n        except (ValueError, OverflowError):\n            raise wmod._OptionError(\"invalid lineno {!r}\".format(lineno))\n    else:\n        lineno = 0\n    wmod.filterwarnings(action, message, category, module, lineno)"}, {"id": "_pytest.warnings.pytest_addoption", "kind": "function", "range": [33, 0, 47, 5, 932, 1390], "file_path": "src/_pytest/warnings.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"pytest-warnings\")\n    group.addoption(\n        \"-W\",\n        \"--pythonwarnings\",\n        action=\"append\",\n        help=\"set which warnings to report, see -W option of python itself.\",\n    )\n    parser.addini(\n        \"filterwarnings\",\n        type=\"linelist\",\n        help=\"Each line specifies a pattern for \"\n        \"warnings.filterwarnings. \"\n        \"Processed after -W/--pythonwarnings.\",\n    )"}, {"id": "_pytest.warnings.pytest_configure", "kind": "function", "range": [50, 0, 55, 5, 1393, 1643], "file_path": "src/_pytest/warnings.py", "content": "def pytest_configure(config):\n    config.addinivalue_line(\n        \"markers\",\n        \"filterwarnings(warning): add a warning filter to the given test. \"\n        \"see https://docs.pytest.org/en/latest/warnings.html#pytest-mark-filterwarnings \",\n    )"}, {"id": "_pytest.warnings.catch_warnings_for_item", "kind": "function", "range": [58, 0, 96, 13, 1646, 3222], "file_path": "src/_pytest/warnings.py", "content": "@contextmanager\ndef catch_warnings_for_item(config, ihook, when, item):\n    \"\"\"\n    Context manager that catches warnings generated in the contained execution block.\n\n    ``item`` can be None if we are not in the context of an item execution.\n\n    Each warning captured triggers the ``pytest_warning_captured`` hook.\n    \"\"\"\n    cmdline_filters = config.getoption(\"pythonwarnings\") or []\n    inifilters = config.getini(\"filterwarnings\")\n    with warnings.catch_warnings(record=True) as log:\n        # mypy can't infer that record=True means log is not None; help it.\n        assert log is not None\n\n        if not sys.warnoptions:\n            # if user is not explicitly configuring warning filters, show deprecation warnings by default (#2908)\n            warnings.filterwarnings(\"always\", category=DeprecationWarning)\n            warnings.filterwarnings(\"always\", category=PendingDeprecationWarning)\n\n        # filters should have this precedence: mark, cmdline options, ini\n        # filters should be applied in the inverse order of precedence\n        for arg in inifilters:\n            _setoption(warnings, arg)\n\n        for arg in cmdline_filters:\n            warnings._setoption(arg)\n\n        if item is not None:\n            for mark in item.iter_markers(name=\"filterwarnings\"):\n                for arg in mark.args:\n                    _setoption(warnings, arg)\n\n        yield\n\n        for warning_message in log:\n            ihook.pytest_warning_captured.call_historic(\n                kwargs=dict(warning_message=warning_message, when=when, item=item)\n            )"}, {"id": "_pytest.warnings.warning_record_to_str", "kind": "function", "range": [99, 0, 109, 14, 3225, 3567], "file_path": "src/_pytest/warnings.py", "content": "def warning_record_to_str(warning_message):\n    \"\"\"Convert a warnings.WarningMessage to a string.\"\"\"\n    warn_msg = warning_message.message\n    msg = warnings.formatwarning(\n        warn_msg,\n        warning_message.category,\n        warning_message.filename,\n        warning_message.lineno,\n        warning_message.line,\n    )\n    return msg"}, {"id": "_pytest.warnings.pytest_runtest_protocol", "kind": "function", "range": [112, 0, 117, 13, 3570, 3781], "file_path": "src/_pytest/warnings.py", "content": "@pytest.hookimpl(hookwrapper=True, tryfirst=True)\ndef pytest_runtest_protocol(item):\n    with catch_warnings_for_item(\n        config=item.config, ihook=item.ihook, when=\"runtest\", item=item\n    ):\n        yield"}, {"id": "_pytest.warnings.pytest_collection", "kind": "function", "range": [120, 0, 126, 13, 3784, 4056], "file_path": "src/_pytest/warnings.py", "content": "@pytest.hookimpl(hookwrapper=True, tryfirst=True)\ndef pytest_collection(session: Session) -> Generator[None, None, None]:\n    config = session.config\n    with catch_warnings_for_item(\n        config=config, ihook=config.hook, when=\"collect\", item=None\n    ):\n        yield"}, {"id": "_pytest.warnings.pytest_terminal_summary", "kind": "function", "range": [129, 0, 135, 13, 4059, 4299], "file_path": "src/_pytest/warnings.py", "content": "@pytest.hookimpl(hookwrapper=True)\ndef pytest_terminal_summary(terminalreporter):\n    config = terminalreporter.config\n    with catch_warnings_for_item(\n        config=config, ihook=config.hook, when=\"config\", item=None\n    ):\n        yield"}, {"id": "_pytest.warnings.pytest_sessionfinish", "kind": "function", "range": [138, 0, 144, 13, 4302, 4521], "file_path": "src/_pytest/warnings.py", "content": "@pytest.hookimpl(hookwrapper=True)\ndef pytest_sessionfinish(session):\n    config = session.config\n    with catch_warnings_for_item(\n        config=config, ihook=config.hook, when=\"config\", item=None\n    ):\n        yield"}, {"id": "_pytest.warnings._issue_warning_captured", "kind": "function", "range": [147, 0, 168, 5, 4524, 5628], "file_path": "src/_pytest/warnings.py", "content": "def _issue_warning_captured(warning, hook, stacklevel):\n    \"\"\"\n    This function should be used instead of calling ``warnings.warn`` directly when we are in the \"configure\" stage:\n    at this point the actual options might not have been set, so we manually trigger the pytest_warning_captured\n    hook so we can display these warnings in the terminal. This is a hack until we can sort out #2891.\n\n    :param warning: the warning instance.\n    :param hook: the hook caller\n    :param stacklevel: stacklevel forwarded to warnings.warn\n    \"\"\"\n    with warnings.catch_warnings(record=True) as records:\n        warnings.simplefilter(\"always\", type(warning))\n        warnings.warn(warning, stacklevel=stacklevel)\n    # Mypy can't infer that record=True means records is not None; help it.\n    assert records is not None\n    frame = sys._getframe(stacklevel - 1)\n    location = frame.f_code.co_filename, frame.f_lineno, frame.f_code.co_name\n    hook.pytest_warning_captured.call_historic(\n        kwargs=dict(\n            warning_message=records[0], when=\"config\", item=None, location=location\n        )\n    )"}, {"id": "_pytest.deprecated.DEPRECATED_EXTERNAL_PLUGINS", "kind": "variable", "range": [16, 0, 20, 1, 700, 808], "file_path": "src/_pytest/deprecated.py", "content": "DEPRECATED_EXTERNAL_PLUGINS = {\n    \"pytest_catchlog\",\n    \"pytest_capturelog\",\n    \"pytest_faulthandler\",\n}"}, {"id": "_pytest.deprecated.FUNCARGNAMES", "kind": "variable", "range": [22, 0, 25, 1, 810, 979], "file_path": "src/_pytest/deprecated.py", "content": "FUNCARGNAMES = PytestDeprecationWarning(\n    \"The `funcargnames` attribute was an alias for `fixturenames`, \"\n    \"since pytest 2.3 - use the newer attribute instead.\"\n)"}, {"id": "_pytest.deprecated.FILLFUNCARGS", "kind": "variable", "range": [27, 0, 30, 1, 981, 1171], "file_path": "src/_pytest/deprecated.py", "content": "FILLFUNCARGS = PytestDeprecationWarning(\n    \"The `_fillfuncargs` function is deprecated, use \"\n    \"function._request._fillfixtures() instead if you cannot avoid reaching into internals.\"\n)"}, {"id": "_pytest.deprecated.RESULT_LOG", "kind": "variable", "range": [32, 0, 35, 1, 1173, 1399], "file_path": "src/_pytest/deprecated.py", "content": "RESULT_LOG = PytestDeprecationWarning(\n    \"--result-log is deprecated, please try the new pytest-reportlog plugin.\\n\"\n    \"See https://docs.pytest.org/en/latest/deprecations.html#result-log-result-log for more information.\"\n)"}, {"id": "_pytest.deprecated.FIXTURE_POSITIONAL_ARGUMENTS", "kind": "variable", "range": [37, 0, 40, 1, 1401, 1591], "file_path": "src/_pytest/deprecated.py", "content": "FIXTURE_POSITIONAL_ARGUMENTS = PytestDeprecationWarning(\n    \"Passing arguments to pytest.fixture() as positional arguments is deprecated - pass them \"\n    \"as a keyword argument instead.\"\n)"}, {"id": "_pytest.deprecated.NODE_USE_FROM_PARENT", "kind": "variable", "range": [42, 0, 48, 1, 1593, 1898], "file_path": "src/_pytest/deprecated.py", "content": "NODE_USE_FROM_PARENT = UnformattedWarning(\n    PytestDeprecationWarning,\n    \"Direct construction of {name} has been deprecated, please use {name}.from_parent.\\n\"\n    \"See \"\n    \"https://docs.pytest.org/en/latest/deprecations.html#node-construction-changed-to-node-from-parent\"\n    \" for more details.\",\n)"}, {"id": "_pytest.deprecated.JUNIT_XML_DEFAULT_FAMILY", "kind": "variable", "range": [50, 0, 54, 1, 1900, 2173], "file_path": "src/_pytest/deprecated.py", "content": "JUNIT_XML_DEFAULT_FAMILY = PytestDeprecationWarning(\n    \"The 'junit_family' default value will change to 'xunit2' in pytest 6.0. See:\\n\"\n    \"  https://docs.pytest.org/en/latest/deprecations.html#junit-family-default-value-change-to-xunit2\\n\"\n    \"for more information.\"\n)"}, {"id": "_pytest.deprecated.NO_PRINT_LOGS", "kind": "variable", "range": [56, 0, 59, 1, 2175, 2338], "file_path": "src/_pytest/deprecated.py", "content": "NO_PRINT_LOGS = PytestDeprecationWarning(\n    \"--no-print-logs is deprecated and scheduled for removal in pytest 6.0.\\n\"\n    \"Please use --show-capture instead.\"\n)"}, {"id": "_pytest.deprecated.COLLECT_DIRECTORY_HOOK", "kind": "variable", "range": [61, 0, 64, 1, 2340, 2529], "file_path": "src/_pytest/deprecated.py", "content": "COLLECT_DIRECTORY_HOOK = PytestDeprecationWarning(\n    \"The pytest_collect_directory hook is not working.\\n\"\n    \"Please use collect_ignore in conftests or pytest_collection_modifyitems.\"\n)"}, {"id": "_pytest.deprecated.PYTEST_COLLECT_MODULE", "kind": "variable", "range": [66, 0, 70, 1, 2531, 2701], "file_path": "src/_pytest/deprecated.py", "content": "PYTEST_COLLECT_MODULE = UnformattedWarning(\n    PytestDeprecationWarning,\n    \"pytest.collect.{name} was moved to pytest.{name}\\n\"\n    \"Please update to the new name.\",\n)"}, {"id": "_pytest.deprecated.TERMINALWRITER_WRITER", "kind": "variable", "range": [73, 0, 76, 1, 2704, 2975], "file_path": "src/_pytest/deprecated.py", "content": "TERMINALWRITER_WRITER = PytestDeprecationWarning(\n    \"The TerminalReporter.writer attribute is deprecated, use TerminalReporter._tw instead at your own risk.\\n\"\n    \"See https://docs.pytest.org/en/latest/deprecations.html#terminalreporter-writer for more information.\"\n)"}, {"id": "_pytest.recwarn.recwarn", "kind": "function", "range": [22, 0, 32, 18, 529, 872], "file_path": "src/_pytest/recwarn.py", "content": "@yield_fixture\ndef recwarn():\n    \"\"\"Return a :class:`WarningsRecorder` instance that records all warnings emitted by test functions.\n\n    See http://docs.python.org/library/warnings.html for information\n    on warning categories.\n    \"\"\"\n    wrec = WarningsRecorder()\n    with wrec:\n        warnings.simplefilter(\"default\")\n        yield wrec"}, {"id": "_pytest.recwarn.deprecated_call", "kind": "function", "range": [35, 0, 54, 82, 875, 1684], "file_path": "src/_pytest/recwarn.py", "content": "def deprecated_call(func=None, *args, **kwargs):\n    \"\"\"context manager that can be used to ensure a block of code triggers a\n    ``DeprecationWarning`` or ``PendingDeprecationWarning``::\n\n        >>> import warnings\n        >>> def api_call_v2():\n        ...     warnings.warn('use v3 of this api', DeprecationWarning)\n        ...     return 200\n\n        >>> with deprecated_call():\n        ...    assert api_call_v2() == 200\n\n    ``deprecated_call`` can also be used by passing a function and ``*args`` and ``*kwargs``,\n    in which case it will ensure calling ``func(*args, **kwargs)`` produces one of the warnings\n    types above.\n    \"\"\"\n    __tracebackhide__ = True\n    if func is not None:\n        args = (func,) + args\n    return warns((DeprecationWarning, PendingDeprecationWarning), *args, **kwargs)"}, {"id": "_pytest.recwarn.warns", "kind": "function", "range": [57, 0, 63, 31, 1687, 1904], "file_path": "src/_pytest/recwarn.py", "content": "@overload\ndef warns(\n    expected_warning: Optional[Union[\"Type[Warning]\", Tuple[\"Type[Warning]\", ...]]],\n    *,\n    match: \"Optional[Union[str, Pattern]]\" = ...\n) -> \"WarningsChecker\":\n    raise NotImplementedError()"}, {"id": "_pytest.recwarn.warns", "kind": "function", "range": [66, 0, 74, 31, 1907, 2193], "file_path": "src/_pytest/recwarn.py", "content": "@overload  # noqa: F811\ndef warns(  # noqa: F811\n    expected_warning: Optional[Union[\"Type[Warning]\", Tuple[\"Type[Warning]\", ...]]],\n    func: Callable,\n    *args: Any,\n    match: Optional[Union[str, \"Pattern\"]] = ...,\n    **kwargs: Any\n) -> Union[Any]:\n    raise NotImplementedError()"}, {"id": "_pytest.recwarn.warns", "kind": "function", "range": [77, 0, 129, 44, 2196, 4303], "file_path": "src/_pytest/recwarn.py", "content": "def warns(  # noqa: F811\n    expected_warning: Optional[Union[\"Type[Warning]\", Tuple[\"Type[Warning]\", ...]]],\n    *args: Any,\n    match: Optional[Union[str, \"Pattern\"]] = None,\n    **kwargs: Any\n) -> Union[\"WarningsChecker\", Any]:\n    r\"\"\"Assert that code raises a particular class of warning.\n\n    Specifically, the parameter ``expected_warning`` can be a warning class or\n    sequence of warning classes, and the inside the ``with`` block must issue a warning of that class or\n    classes.\n\n    This helper produces a list of :class:`warnings.WarningMessage` objects,\n    one for each warning raised.\n\n    This function can be used as a context manager, or any of the other ways\n    ``pytest.raises`` can be used::\n\n        >>> with warns(RuntimeWarning):\n        ...    warnings.warn(\"my warning\", RuntimeWarning)\n\n    In the context manager form you may use the keyword argument ``match`` to assert\n    that the exception matches a text or regex::\n\n        >>> with warns(UserWarning, match='must be 0 or None'):\n        ...     warnings.warn(\"value must be 0 or None\", UserWarning)\n\n        >>> with warns(UserWarning, match=r'must be \\d+$'):\n        ...     warnings.warn(\"value must be 42\", UserWarning)\n\n        >>> with warns(UserWarning, match=r'must be \\d+$'):\n        ...     warnings.warn(\"this is not here\", UserWarning)\n        Traceback (most recent call last):\n          ...\n        Failed: DID NOT WARN. No warnings of type ...UserWarning... was emitted...\n\n    \"\"\"\n    __tracebackhide__ = True\n    if not args:\n        if kwargs:\n            msg = \"Unexpected keyword arguments passed to pytest.warns: \"\n            msg += \", \".join(sorted(kwargs))\n            msg += \"\\nUse context-manager form instead?\"\n            raise TypeError(msg)\n        return WarningsChecker(expected_warning, match_expr=match)\n    else:\n        func = args[0]\n        if not callable(func):\n            raise TypeError(\n                \"{!r} object (type: {}) must be callable\".format(func, type(func))\n            )\n        with WarningsChecker(expected_warning):\n            return func(*args[1:], **kwargs)"}, {"id": "_pytest.recwarn.WarningsRecorder", "kind": "class", "range": [132, 0, 199, 29, 4306, 6722], "file_path": "src/_pytest/recwarn.py", "content": "class WarningsRecorder(warnings.catch_warnings):\n    \"\"\"A context manager to record raised warnings.\n\n    Adapted from `warnings.catch_warnings`.\n    \"\"\"\n\n    def __init__(self):\n        super().__init__(record=True)\n        self._entered = False\n        self._list = []  # type: List[warnings.WarningMessage]\n\n    @property\n    def list(self) -> List[\"warnings.WarningMessage\"]:\n        \"\"\"The list of recorded warnings.\"\"\"\n        return self._list\n\n    def __getitem__(self, i: int) -> \"warnings.WarningMessage\":\n        \"\"\"Get a recorded warning by index.\"\"\"\n        return self._list[i]\n\n    def __iter__(self) -> Iterator[\"warnings.WarningMessage\"]:\n        \"\"\"Iterate through the recorded warnings.\"\"\"\n        return iter(self._list)\n\n    def __len__(self) -> int:\n        \"\"\"The number of recorded warnings.\"\"\"\n        return len(self._list)\n\n    def pop(self, cls: \"Type[Warning]\" = Warning) -> \"warnings.WarningMessage\":\n        \"\"\"Pop the first recorded warning, raise exception if not exists.\"\"\"\n        for i, w in enumerate(self._list):\n            if issubclass(w.category, cls):\n                return self._list.pop(i)\n        __tracebackhide__ = True\n        raise AssertionError(\"%r not found in warning list\" % cls)\n\n    def clear(self) -> None:\n        \"\"\"Clear the list of recorded warnings.\"\"\"\n        self._list[:] = []\n\n    # Type ignored because it doesn't exactly warnings.catch_warnings.__enter__\n    # -- it returns a List but we only emulate one.\n    def __enter__(self) -> \"WarningsRecorder\":  # type: ignore\n        if self._entered:\n            __tracebackhide__ = True\n            raise RuntimeError(\"Cannot enter %r twice\" % self)\n        _list = super().__enter__()\n        # record=True means it's None.\n        assert _list is not None\n        self._list = _list\n        warnings.simplefilter(\"always\")\n        return self\n\n    def __exit__(\n        self,\n        exc_type: Optional[\"Type[BaseException]\"],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        if not self._entered:\n            __tracebackhide__ = True\n            raise RuntimeError(\"Cannot exit %r without entering first\" % self)\n\n        super().__exit__(exc_type, exc_val, exc_tb)\n\n        # Built-in catch_warnings does not reset entered state so we do it\n        # manually here for this context manager to become reusable.\n        self._entered = False"}, {"id": "_pytest.recwarn.WarningsRecorder.__init__", "kind": "function", "range": [138, 4, 141, 62, 4465, 4615], "file_path": "src/_pytest/recwarn.py", "content": "def __init__(self):\n        super().__init__(record=True)\n        self._entered = False\n        self._list = []  # type: List[warnings.WarningMessage]"}, {"id": "_pytest.recwarn.WarningsRecorder.list", "kind": "function", "range": [143, 4, 146, 25, 4621, 4756], "file_path": "src/_pytest/recwarn.py", "content": "@property\n    def list(self) -> List[\"warnings.WarningMessage\"]:\n        \"\"\"The list of recorded warnings.\"\"\"\n        return self._list"}, {"id": "_pytest.recwarn.WarningsRecorder.__getitem__", "kind": "function", "range": [148, 4, 150, 28, 4762, 4897], "file_path": "src/_pytest/recwarn.py", "content": "def __getitem__(self, i: int) -> \"warnings.WarningMessage\":\n        \"\"\"Get a recorded warning by index.\"\"\"\n        return self._list[i]"}, {"id": "_pytest.recwarn.WarningsRecorder.__iter__", "kind": "function", "range": [152, 4, 154, 31, 4903, 5046], "file_path": "src/_pytest/recwarn.py", "content": "def __iter__(self) -> Iterator[\"warnings.WarningMessage\"]:\n        \"\"\"Iterate through the recorded warnings.\"\"\"\n        return iter(self._list)"}, {"id": "_pytest.recwarn.WarningsRecorder.__len__", "kind": "function", "range": [156, 4, 158, 30, 5052, 5155], "file_path": "src/_pytest/recwarn.py", "content": "def __len__(self) -> int:\n        \"\"\"The number of recorded warnings.\"\"\"\n        return len(self._list)"}, {"id": "_pytest.recwarn.WarningsRecorder.pop", "kind": "function", "range": [160, 4, 166, 66, 5161, 5541], "file_path": "src/_pytest/recwarn.py", "content": "def pop(self, cls: \"Type[Warning]\" = Warning) -> \"warnings.WarningMessage\":\n        \"\"\"Pop the first recorded warning, raise exception if not exists.\"\"\"\n        for i, w in enumerate(self._list):\n            if issubclass(w.category, cls):\n                return self._list.pop(i)\n        __tracebackhide__ = True\n        raise AssertionError(\"%r not found in warning list\" % cls)"}, {"id": "_pytest.recwarn.WarningsRecorder.clear", "kind": "function", "range": [168, 4, 170, 26, 5547, 5649], "file_path": "src/_pytest/recwarn.py", "content": "def clear(self) -> None:\n        \"\"\"Clear the list of recorded warnings.\"\"\"\n        self._list[:] = []"}, {"id": "_pytest.recwarn.WarningsRecorder.__enter__", "kind": "function", "range": [174, 4, 183, 19, 5787, 6166], "file_path": "src/_pytest/recwarn.py", "content": "def __enter__(self) -> \"WarningsRecorder\":  # type: ignore\n        if self._entered:\n            __tracebackhide__ = True\n            raise RuntimeError(\"Cannot enter %r twice\" % self)\n        _list = super().__enter__()\n        # record=True means it's None.\n        assert _list is not None\n        self._list = _list\n        warnings.simplefilter(\"always\")\n        return self"}, {"id": "_pytest.recwarn.WarningsRecorder.__exit__", "kind": "function", "range": [185, 4, 199, 29, 6172, 6722], "file_path": "src/_pytest/recwarn.py", "content": "def __exit__(\n        self,\n        exc_type: Optional[\"Type[BaseException]\"],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        if not self._entered:\n            __tracebackhide__ = True\n            raise RuntimeError(\"Cannot exit %r without entering first\" % self)\n\n        super().__exit__(exc_type, exc_val, exc_tb)\n\n        # Built-in catch_warnings does not reset entered state so we do it\n        # manually here for this context manager to become reusable.\n        self._entered = False"}, {"id": "_pytest.recwarn.WarningsChecker", "kind": "class", "range": [202, 0, 263, 25, 6725, 9330], "file_path": "src/_pytest/recwarn.py", "content": "class WarningsChecker(WarningsRecorder):\n    def __init__(\n        self,\n        expected_warning: Optional[\n            Union[\"Type[Warning]\", Tuple[\"Type[Warning]\", ...]]\n        ] = None,\n        match_expr: Optional[Union[str, \"Pattern\"]] = None,\n    ) -> None:\n        super().__init__()\n\n        msg = \"exceptions must be derived from Warning, not %s\"\n        if expected_warning is None:\n            expected_warning_tup = None\n        elif isinstance(expected_warning, tuple):\n            for exc in expected_warning:\n                if not issubclass(exc, Warning):\n                    raise TypeError(msg % type(exc))\n            expected_warning_tup = expected_warning\n        elif issubclass(expected_warning, Warning):\n            expected_warning_tup = (expected_warning,)\n        else:\n            raise TypeError(msg % type(expected_warning))\n\n        self.expected_warning = expected_warning_tup\n        self.match_expr = match_expr\n\n    def __exit__(\n        self,\n        exc_type: Optional[\"Type[BaseException]\"],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        super().__exit__(exc_type, exc_val, exc_tb)\n\n        __tracebackhide__ = True\n\n        # only check if we're not currently handling an exception\n        if exc_type is None and exc_val is None and exc_tb is None:\n            if self.expected_warning is not None:\n                if not any(issubclass(r.category, self.expected_warning) for r in self):\n                    __tracebackhide__ = True\n                    fail(\n                        \"DID NOT WARN. No warnings of type {} was emitted. \"\n                        \"The list of emitted warnings is: {}.\".format(\n                            self.expected_warning, [each.message for each in self]\n                        )\n                    )\n                elif self.match_expr is not None:\n                    for r in self:\n                        if issubclass(r.category, self.expected_warning):\n                            if re.compile(self.match_expr).search(str(r.message)):\n                                break\n                    else:\n                        fail(\n                            \"DID NOT WARN. No warnings of type {} matching\"\n                            \" ('{}') was emitted. The list of emitted warnings\"\n                            \" is: {}.\".format(\n                                self.expected_warning,\n                                self.match_expr,\n                                [each.message for each in self],\n                            )\n                        )"}, {"id": "_pytest.recwarn.WarningsChecker.__init__", "kind": "function", "range": [203, 4, 226, 36, 6770, 7674], "file_path": "src/_pytest/recwarn.py", "content": "def __init__(\n        self,\n        expected_warning: Optional[\n            Union[\"Type[Warning]\", Tuple[\"Type[Warning]\", ...]]\n        ] = None,\n        match_expr: Optional[Union[str, \"Pattern\"]] = None,\n    ) -> None:\n        super().__init__()\n\n        msg = \"exceptions must be derived from Warning, not %s\"\n        if expected_warning is None:\n            expected_warning_tup = None\n        elif isinstance(expected_warning, tuple):\n            for exc in expected_warning:\n                if not issubclass(exc, Warning):\n                    raise TypeError(msg % type(exc))\n            expected_warning_tup = expected_warning\n        elif issubclass(expected_warning, Warning):\n            expected_warning_tup = (expected_warning,)\n        else:\n            raise TypeError(msg % type(expected_warning))\n\n        self.expected_warning = expected_warning_tup\n        self.match_expr = match_expr"}, {"id": "_pytest.recwarn.WarningsChecker.__exit__", "kind": "function", "range": [228, 4, 263, 25, 7680, 9330], "file_path": "src/_pytest/recwarn.py", "content": "def __exit__(\n        self,\n        exc_type: Optional[\"Type[BaseException]\"],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> None:\n        super().__exit__(exc_type, exc_val, exc_tb)\n\n        __tracebackhide__ = True\n\n        # only check if we're not currently handling an exception\n        if exc_type is None and exc_val is None and exc_tb is None:\n            if self.expected_warning is not None:\n                if not any(issubclass(r.category, self.expected_warning) for r in self):\n                    __tracebackhide__ = True\n                    fail(\n                        \"DID NOT WARN. No warnings of type {} was emitted. \"\n                        \"The list of emitted warnings is: {}.\".format(\n                            self.expected_warning, [each.message for each in self]\n                        )\n                    )\n                elif self.match_expr is not None:\n                    for r in self:\n                        if issubclass(r.category, self.expected_warning):\n                            if re.compile(self.match_expr).search(str(r.message)):\n                                break\n                    else:\n                        fail(\n                            \"DID NOT WARN. No warnings of type {} matching\"\n                            \" ('{}') was emitted. The list of emitted warnings\"\n                            \" is: {}.\".format(\n                                self.expected_warning,\n                                self.match_expr,\n                                [each.message for each in self],\n                            )\n                        )"}, {"id": "_pytest.mark.MarkMapping", "kind": "class", "range": [16, 0, 29, 42, 313, 705], "file_path": "src/_pytest/mark/legacy.py", "content": "@attr.s\nclass MarkMapping:\n    \"\"\"Provides a local mapping for markers where item access\n    resolves to True if the marker is present. \"\"\"\n\n    own_mark_names = attr.ib()\n\n    @classmethod\n    def from_item(cls, item):\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)\n\n    def __getitem__(self, name):\n        return name in self.own_mark_names"}, {"id": "_pytest.mark.MarkMapping.own_mark_names", "kind": "variable", "range": [21, 4, 21, 30, 458, 484], "file_path": "src/_pytest/mark/legacy.py", "content": "own_mark_names = attr.ib()"}, {"id": "_pytest.mark.MarkMapping.from_item", "kind": "function", "range": [23, 4, 26, 30, 490, 628], "file_path": "src/_pytest/mark/legacy.py", "content": "@classmethod\n    def from_item(cls, item):\n        mark_names = {mark.name for mark in item.iter_markers()}\n        return cls(mark_names)"}, {"id": "_pytest.mark.MarkMapping.__getitem__", "kind": "function", "range": [28, 4, 29, 42, 634, 705], "file_path": "src/_pytest/mark/legacy.py", "content": "def __getitem__(self, name):\n        return name in self.own_mark_names"}, {"id": "_pytest.mark.KeywordMapping", "kind": "class", "range": [32, 0, 76, 20, 708, 2154], "file_path": "src/_pytest/mark/legacy.py", "content": "@attr.s\nclass KeywordMapping:\n    \"\"\"Provides a local mapping for keywords.\n    Given a list of names, map any substring of one of these names to True.\n    \"\"\"\n\n    _names = attr.ib(type=Set[str])\n\n    @classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMapping\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for item in item.listchain():\n            if not isinstance(item, pytest.Instance):\n                mapped_names.add(item.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"function\", None)\n        if function_obj:\n            mapped_names.update(function_obj.__dict__)\n\n        # add the markers to the keywords as we no longer handle them correctly\n        mapped_names.update(mark.name for mark in item.iter_markers())\n\n        return cls(mapped_names)\n\n    def __getitem__(self, subname: str) -> bool:\n        \"\"\"Return whether subname is included within stored names.\n\n        The string inclusion check is case-insensitive.\n\n        \"\"\"\n        subname = subname.lower()\n        names = (name.lower() for name in self._names)\n\n        for name in names:\n            if subname in name:\n                return True\n        return False"}, {"id": "_pytest.mark.KeywordMapping._names", "kind": "variable", "range": [38, 4, 38, 35, 873, 904], "file_path": "src/_pytest/mark/legacy.py", "content": "_names = attr.ib(type=Set[str])"}, {"id": "_pytest.mark.KeywordMapping.from_item", "kind": "function", "range": [40, 4, 62, 32, 910, 1769], "file_path": "src/_pytest/mark/legacy.py", "content": "@classmethod\n    def from_item(cls, item: \"Item\") -> \"KeywordMapping\":\n        mapped_names = set()\n\n        # Add the names of the current item and any parent items\n        import pytest\n\n        for item in item.listchain():\n            if not isinstance(item, pytest.Instance):\n                mapped_names.add(item.name)\n\n        # Add the names added as extra keywords to current or parent items\n        mapped_names.update(item.listextrakeywords())\n\n        # Add the names attached to the current function through direct assignment\n        function_obj = getattr(item, \"function\", None)\n        if function_obj:\n            mapped_names.update(function_obj.__dict__)\n\n        # add the markers to the keywords as we no longer handle them correctly\n        mapped_names.update(mark.name for mark in item.iter_markers())\n\n        return cls(mapped_names)"}, {"id": "_pytest.mark.KeywordMapping.__getitem__", "kind": "function", "range": [64, 4, 76, 20, 1775, 2154], "file_path": "src/_pytest/mark/legacy.py", "content": "def __getitem__(self, subname: str) -> bool:\n        \"\"\"Return whether subname is included within stored names.\n\n        The string inclusion check is case-insensitive.\n\n        \"\"\"\n        subname = subname.lower()\n        names = (name.lower() for name in self._names)\n\n        for name in names:\n            if subname in name:\n                return True\n        return False"}, {"id": "_pytest.mark.python_keywords_allowed_list", "kind": "variable", "range": [79, 0, 79, 51, 2157, 2208], "file_path": "src/_pytest/mark/legacy.py", "content": "python_keywords_allowed_list = [\"or\", \"and\", \"not\"]"}, {"id": "_pytest.mark.matchmark", "kind": "function", "range": [82, 0, 87, 80, 2211, 2499], "file_path": "src/_pytest/mark/legacy.py", "content": "def matchmark(colitem, markexpr):\n    \"\"\"Tries to match on any marker names, attached to the given colitem.\"\"\"\n    try:\n        return eval(markexpr, {}, MarkMapping.from_item(colitem))\n    except Exception:\n        raise UsageError(\"Wrong expression passed to '-m': {}\".format(markexpr))"}, {"id": "_pytest.mark.matchkeyword", "kind": "function", "range": [90, 0, 115, 83, 2502, 3680], "file_path": "src/_pytest/mark/legacy.py", "content": "def matchkeyword(colitem, keywordexpr):\n    \"\"\"Tries to match given keyword expression to given collector item.\n\n    Will match on the name of colitem, including the names of its parents.\n    Only matches names of items which are either a :class:`Class` or a\n    :class:`Function`.\n    Additionally, matches on names in the 'extra_keyword_matches' set of\n    any item, as well as names directly assigned to test functions.\n    \"\"\"\n    mapping = KeywordMapping.from_item(colitem)\n    if \" \" not in keywordexpr:\n        # special case to allow for simple \"-k pass\" and \"-k 1.3\"\n        return mapping[keywordexpr]\n    elif keywordexpr.startswith(\"not \") and \" \" not in keywordexpr[4:]:\n        return not mapping[keywordexpr[4:]]\n    for kwd in keywordexpr.split():\n        if keyword.iskeyword(kwd) and kwd not in python_keywords_allowed_list:\n            raise UsageError(\n                \"Python keyword '{}' not accepted in expressions passed to '-k'\".format(\n                    kwd\n                )\n            )\n    try:\n        return eval(keywordexpr, {}, mapping)\n    except Exception:\n        raise UsageError(\"Wrong expression passed to '-k': {}\".format(keywordexpr))"}, {"id": "_pytest.mark.__all__", "kind": "variable", "range": [17, 0, 17, 83, 583, 666], "file_path": "src/_pytest/mark/__init__.py", "content": "__all__ = [\"Mark\", \"MarkDecorator\", \"MarkGenerator\", \"get_empty_parameterset_mark\"]"}, {"id": "_pytest.mark.old_mark_config_key", "kind": "variable", "range": [20, 0, 20, 50, 669, 719], "file_path": "src/_pytest/mark/__init__.py", "content": "old_mark_config_key = StoreKey[Optional[Config]]()"}, {"id": "_pytest.mark.param", "kind": "function", "range": [23, 0, 40, 44, 722, 1440], "file_path": "src/_pytest/mark/__init__.py", "content": "def param(*values, **kw):\n    \"\"\"Specify a parameter in `pytest.mark.parametrize`_ calls or\n    :ref:`parametrized fixtures <fixture-parametrize-marks>`.\n\n    .. code-block:: python\n\n        @pytest.mark.parametrize(\n            \"test_input,expected\",\n            [(\"3+5\", 8), pytest.param(\"6*9\", 42, marks=pytest.mark.xfail),],\n        )\n        def test_eval(test_input, expected):\n            assert eval(test_input) == expected\n\n    :param values: variable args of the values of the parameter set, in order.\n    :keyword marks: a single mark or a list of marks to be applied to this parameter set.\n    :keyword str id: the id to attribute to this parameter set.\n    \"\"\"\n    return ParameterSet.param(*values, **kw)"}, {"id": "_pytest.mark.pytest_addoption", "kind": "function", "range": [43, 0, 82, 86, 1443, 3042], "file_path": "src/_pytest/mark/__init__.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"-k\",\n        action=\"store\",\n        dest=\"keyword\",\n        default=\"\",\n        metavar=\"EXPRESSION\",\n        help=\"only run tests which match the given substring expression. \"\n        \"An expression is a python evaluatable expression \"\n        \"where all names are substring-matched against test names \"\n        \"and their parent classes. Example: -k 'test_method or test_\"\n        \"other' matches all test functions and classes whose name \"\n        \"contains 'test_method' or 'test_other', while -k 'not test_method' \"\n        \"matches those that don't contain 'test_method' in their names. \"\n        \"-k 'not test_method and not test_other' will eliminate the matches. \"\n        \"Additionally keywords are matched to classes and functions \"\n        \"containing extra names in their 'extra_keyword_matches' set, \"\n        \"as well as functions which have names assigned directly to them. \"\n        \"The matching is case-insensitive.\",\n    )\n\n    group._addoption(\n        \"-m\",\n        action=\"store\",\n        dest=\"markexpr\",\n        default=\"\",\n        metavar=\"MARKEXPR\",\n        help=\"only run tests matching given mark expression.  \"\n        \"example: -m 'mark1 and not mark2'.\",\n    )\n\n    group.addoption(\n        \"--markers\",\n        action=\"store_true\",\n        help=\"show markers (builtin, plugin and per-project ones).\",\n    )\n\n    parser.addini(\"markers\", \"markers for test functions\", \"linelist\")\n    parser.addini(EMPTY_PARAMETERSET_OPTION, \"default marker for empty parametersets\")"}, {"id": "_pytest.mark.pytest_cmdline_main", "kind": "function", "range": [85, 0, 100, 16, 3045, 3578], "file_path": "src/_pytest/mark/__init__.py", "content": "@hookimpl(tryfirst=True)\ndef pytest_cmdline_main(config):\n    import _pytest.config\n\n    if config.option.markers:\n        config._do_configure()\n        tw = _pytest.config.create_terminal_writer(config)\n        for line in config.getini(\"markers\"):\n            parts = line.split(\":\", 1)\n            name = parts[0]\n            rest = parts[1] if len(parts) == 2 else \"\"\n            tw.write(\"@pytest.mark.%s:\" % name, bold=True)\n            tw.line(rest)\n            tw.line()\n        config._ensure_unconfigure()\n        return 0"}, {"id": "_pytest.mark.deselect_by_keyword", "kind": "function", "range": [103, 0, 127, 28, 3581, 4306], "file_path": "src/_pytest/mark/__init__.py", "content": "def deselect_by_keyword(items, config):\n    keywordexpr = config.option.keyword.lstrip()\n    if not keywordexpr:\n        return\n\n    if keywordexpr.startswith(\"-\"):\n        keywordexpr = \"not \" + keywordexpr[1:]\n    selectuntil = False\n    if keywordexpr[-1:] == \":\":\n        selectuntil = True\n        keywordexpr = keywordexpr[:-1]\n\n    remaining = []\n    deselected = []\n    for colitem in items:\n        if keywordexpr and not matchkeyword(colitem, keywordexpr):\n            deselected.append(colitem)\n        else:\n            if selectuntil:\n                keywordexpr = None\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining"}, {"id": "_pytest.mark.deselect_by_mark", "kind": "function", "range": [130, 0, 145, 28, 4309, 4713], "file_path": "src/_pytest/mark/__init__.py", "content": "def deselect_by_mark(items, config):\n    matchexpr = config.option.markexpr\n    if not matchexpr:\n        return\n\n    remaining = []\n    deselected = []\n    for item in items:\n        if matchmark(item, matchexpr):\n            remaining.append(item)\n        else:\n            deselected.append(item)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining"}, {"id": "_pytest.mark.pytest_collection_modifyitems", "kind": "function", "range": [148, 0, 150, 35, 4716, 4840], "file_path": "src/_pytest/mark/__init__.py", "content": "def pytest_collection_modifyitems(items, config):\n    deselect_by_keyword(items, config)\n    deselect_by_mark(items, config)"}, {"id": "_pytest.mark.pytest_configure", "kind": "function", "range": [153, 0, 163, 9, 4843, 5294], "file_path": "src/_pytest/mark/__init__.py", "content": "def pytest_configure(config):\n    config._store[old_mark_config_key] = MARK_GEN._config\n    MARK_GEN._config = config\n\n    empty_parameterset = config.getini(EMPTY_PARAMETERSET_OPTION)\n\n    if empty_parameterset not in (\"skip\", \"xfail\", \"fail_at_collect\", None, \"\"):\n        raise UsageError(\n            \"{!s} must be one of skip, xfail or fail_at_collect\"\n            \" but it is {!r}\".format(EMPTY_PARAMETERSET_OPTION, empty_parameterset)\n        )"}, {"id": "_pytest.mark.pytest_unconfigure", "kind": "function", "range": [166, 0, 167, 67, 5297, 5396], "file_path": "src/_pytest/mark/__init__.py", "content": "def pytest_unconfigure(config):\n    MARK_GEN._config = config._store.get(old_mark_config_key, None)"}, {"id": "_pytest.mark.evalcache_key", "kind": "variable", "range": [13, 0, 13, 42, 237, 279], "file_path": "src/_pytest/mark/evaluate.py", "content": "evalcache_key = StoreKey[Dict[str, Any]]()"}, {"id": "_pytest.mark.cached_eval", "kind": "function", "range": [16, 0, 26, 16, 282, 679], "file_path": "src/_pytest/mark/evaluate.py", "content": "def cached_eval(config: Config, expr: str, d: Dict[str, object]) -> Any:\n    default = {}  # type: Dict[str, object]\n    evalcache = config._store.setdefault(evalcache_key, default)\n    try:\n        return evalcache[expr]\n    except KeyError:\n        import _pytest._code\n\n        exprcode = _pytest._code.compile(expr, mode=\"eval\")\n        evalcache[expr] = x = eval(exprcode, d)\n        return x"}, {"id": "_pytest.mark.MarkEvaluator", "kind": "class", "range": [29, 0, 129, 19, 682, 4202], "file_path": "src/_pytest/mark/evaluate.py", "content": "class MarkEvaluator:\n    def __init__(self, item, name):\n        self.item = item\n        self._marks = None\n        self._mark = None\n        self._mark_name = name\n\n    def __bool__(self):\n        # don't cache here to prevent staleness\n        return bool(self._get_marks())\n\n    def wasvalid(self):\n        return not hasattr(self, \"exc\")\n\n    def _get_marks(self):\n        return list(self.item.iter_markers(name=self._mark_name))\n\n    def invalidraise(self, exc):\n        raises = self.get(\"raises\")\n        if not raises:\n            return\n        return not isinstance(exc, raises)\n\n    def istrue(self):\n        try:\n            return self._istrue()\n        except TEST_OUTCOME:\n            self.exc = sys.exc_info()\n            if isinstance(self.exc[1], SyntaxError):\n                # TODO: Investigate why SyntaxError.offset is Optional, and if it can be None here.\n                assert self.exc[1].offset is not None\n                msg = [\" \" * (self.exc[1].offset + 4) + \"^\"]\n                msg.append(\"SyntaxError: invalid syntax\")\n            else:\n                msg = traceback.format_exception_only(*self.exc[:2])\n            fail(\n                \"Error evaluating %r expression\\n\"\n                \"    %s\\n\"\n                \"%s\" % (self._mark_name, self.expr, \"\\n\".join(msg)),\n                pytrace=False,\n            )\n\n    def _getglobals(self):\n        d = {\"os\": os, \"sys\": sys, \"platform\": platform, \"config\": self.item.config}\n        if hasattr(self.item, \"obj\"):\n            d.update(self.item.obj.__globals__)\n        return d\n\n    def _istrue(self):\n        if hasattr(self, \"result\"):\n            return self.result\n        self._marks = self._get_marks()\n\n        if self._marks:\n            self.result = False\n            for mark in self._marks:\n                self._mark = mark\n                if \"condition\" in mark.kwargs:\n                    args = (mark.kwargs[\"condition\"],)\n                else:\n                    args = mark.args\n\n                for expr in args:\n                    self.expr = expr\n                    if isinstance(expr, str):\n                        d = self._getglobals()\n                        result = cached_eval(self.item.config, expr, d)\n                    else:\n                        if \"reason\" not in mark.kwargs:\n                            # XXX better be checked at collection time\n                            msg = (\n                                \"you need to specify reason=STRING \"\n                                \"when using booleans as conditions.\"\n                            )\n                            fail(msg)\n                        result = bool(expr)\n                    if result:\n                        self.result = True\n                        self.reason = mark.kwargs.get(\"reason\", None)\n                        self.expr = expr\n                        return self.result\n\n                if not args:\n                    self.result = True\n                    self.reason = mark.kwargs.get(\"reason\", None)\n                    return self.result\n        return False\n\n    def get(self, attr, default=None):\n        if self._mark is None:\n            return default\n        return self._mark.kwargs.get(attr, default)\n\n    def getexplanation(self):\n        expl = getattr(self, \"reason\", None) or self.get(\"reason\", None)\n        if not expl:\n            if not hasattr(self, \"expr\"):\n                return \"\"\n            else:\n                return \"condition: \" + str(self.expr)\n        return expl"}, {"id": "_pytest.mark.MarkEvaluator.__init__", "kind": "function", "range": [30, 4, 34, 30, 707, 847], "file_path": "src/_pytest/mark/evaluate.py", "content": "def __init__(self, item, name):\n        self.item = item\n        self._marks = None\n        self._mark = None\n        self._mark_name = name"}, {"id": "_pytest.mark.MarkEvaluator.__bool__", "kind": "function", "range": [36, 4, 38, 38, 853, 959], "file_path": "src/_pytest/mark/evaluate.py", "content": "def __bool__(self):\n        # don't cache here to prevent staleness\n        return bool(self._get_marks())"}, {"id": "_pytest.mark.MarkEvaluator.wasvalid", "kind": "function", "range": [40, 4, 41, 39, 965, 1024], "file_path": "src/_pytest/mark/evaluate.py", "content": "def wasvalid(self):\n        return not hasattr(self, \"exc\")"}, {"id": "_pytest.mark.MarkEvaluator._get_marks", "kind": "function", "range": [43, 4, 44, 65, 1030, 1117], "file_path": "src/_pytest/mark/evaluate.py", "content": "def _get_marks(self):\n        return list(self.item.iter_markers(name=self._mark_name))"}, {"id": "_pytest.mark.MarkEvaluator.invalidraise", "kind": "function", "range": [46, 4, 50, 42, 1123, 1272], "file_path": "src/_pytest/mark/evaluate.py", "content": "def invalidraise(self, exc):\n        raises = self.get(\"raises\")\n        if not raises:\n            return\n        return not isinstance(exc, raises)"}, {"id": "_pytest.mark.MarkEvaluator.istrue", "kind": "function", "range": [52, 4, 69, 13, 1278, 2032], "file_path": "src/_pytest/mark/evaluate.py", "content": "def istrue(self):\n        try:\n            return self._istrue()\n        except TEST_OUTCOME:\n            self.exc = sys.exc_info()\n            if isinstance(self.exc[1], SyntaxError):\n                # TODO: Investigate why SyntaxError.offset is Optional, and if it can be None here.\n                assert self.exc[1].offset is not None\n                msg = [\" \" * (self.exc[1].offset + 4) + \"^\"]\n                msg.append(\"SyntaxError: invalid syntax\")\n            else:\n                msg = traceback.format_exception_only(*self.exc[:2])\n            fail(\n                \"Error evaluating %r expression\\n\"\n                \"    %s\\n\"\n                \"%s\" % (self._mark_name, self.expr, \"\\n\".join(msg)),\n                pytrace=False,\n            )"}, {"id": "_pytest.mark.MarkEvaluator._getglobals", "kind": "function", "range": [71, 4, 75, 16, 2038, 2248], "file_path": "src/_pytest/mark/evaluate.py", "content": "def _getglobals(self):\n        d = {\"os\": os, \"sys\": sys, \"platform\": platform, \"config\": self.item.config}\n        if hasattr(self.item, \"obj\"):\n            d.update(self.item.obj.__globals__)\n        return d"}, {"id": "_pytest.mark.MarkEvaluator._istrue", "kind": "function", "range": [77, 4, 115, 20, 2254, 3767], "file_path": "src/_pytest/mark/evaluate.py", "content": "def _istrue(self):\n        if hasattr(self, \"result\"):\n            return self.result\n        self._marks = self._get_marks()\n\n        if self._marks:\n            self.result = False\n            for mark in self._marks:\n                self._mark = mark\n                if \"condition\" in mark.kwargs:\n                    args = (mark.kwargs[\"condition\"],)\n                else:\n                    args = mark.args\n\n                for expr in args:\n                    self.expr = expr\n                    if isinstance(expr, str):\n                        d = self._getglobals()\n                        result = cached_eval(self.item.config, expr, d)\n                    else:\n                        if \"reason\" not in mark.kwargs:\n                            # XXX better be checked at collection time\n                            msg = (\n                                \"you need to specify reason=STRING \"\n                                \"when using booleans as conditions.\"\n                            )\n                            fail(msg)\n                        result = bool(expr)\n                    if result:\n                        self.result = True\n                        self.reason = mark.kwargs.get(\"reason\", None)\n                        self.expr = expr\n                        return self.result\n\n                if not args:\n                    self.result = True\n                    self.reason = mark.kwargs.get(\"reason\", None)\n                    return self.result\n        return False"}, {"id": "_pytest.mark.MarkEvaluator.get", "kind": "function", "range": [117, 4, 120, 51, 3773, 3917], "file_path": "src/_pytest/mark/evaluate.py", "content": "def get(self, attr, default=None):\n        if self._mark is None:\n            return default\n        return self._mark.kwargs.get(attr, default)"}, {"id": "_pytest.mark.MarkEvaluator.getexplanation", "kind": "function", "range": [122, 4, 129, 19, 3923, 4202], "file_path": "src/_pytest/mark/evaluate.py", "content": "def getexplanation(self):\n        expl = getattr(self, \"reason\", None) or self.get(\"reason\", None)\n        if not expl:\n            if not hasattr(self, \"expr\"):\n                return \"\"\n            else:\n                return \"condition: \" + str(self.expr)\n        return expl"}, {"id": "_pytest.mark.EMPTY_PARAMETERSET_OPTION", "kind": "variable", "range": [22, 0, 22, 54, 550, 604], "file_path": "src/_pytest/mark/structures.py", "content": "EMPTY_PARAMETERSET_OPTION = \"empty_parameter_set_mark\""}, {"id": "_pytest.mark.istestfunc", "kind": "function", "range": [25, 0, 29, 5, 607, 745], "file_path": "src/_pytest/mark/structures.py", "content": "def istestfunc(func):\n    return (\n        hasattr(func, \"__call__\")\n        and getattr(func, \"__name__\", \"<lambda>\") != \"<lambda>\"\n    )"}, {"id": "_pytest.mark.get_empty_parameterset_mark", "kind": "function", "range": [32, 0, 55, 30, 748, 1552], "file_path": "src/_pytest/mark/structures.py", "content": "def get_empty_parameterset_mark(config, argnames, func):\n    from ..nodes import Collector\n\n    requested_mark = config.getini(EMPTY_PARAMETERSET_OPTION)\n    if requested_mark in (\"\", None, \"skip\"):\n        mark = MARK_GEN.skip\n    elif requested_mark == \"xfail\":\n        mark = MARK_GEN.xfail(run=False)\n    elif requested_mark == \"fail_at_collect\":\n        f_name = func.__name__\n        _, lineno = getfslineno(func)\n        raise Collector.CollectError(\n            \"Empty parameter set in '%s' at line %d\" % (f_name, lineno + 1)\n        )\n    else:\n        raise LookupError(requested_mark)\n    fs, lineno = getfslineno(func)\n    reason = \"got empty parameter set %r, function %s at %s:%d\" % (\n        argnames,\n        func.__name__,\n        fs,\n        lineno,\n    )\n    return mark(reason=reason)"}, {"id": "_pytest.mark.ParameterSet", "kind": "class", "range": [58, 0, 141, 35, 1555, 4900], "file_path": "src/_pytest/mark/structures.py", "content": "class ParameterSet(namedtuple(\"ParameterSet\", \"values, marks, id\")):\n    @classmethod\n    def param(cls, *values, marks=(), id=None):\n        if isinstance(marks, MarkDecorator):\n            marks = (marks,)\n        else:\n            assert isinstance(marks, (tuple, list, set))\n\n        if id is not None:\n            if not isinstance(id, str):\n                raise TypeError(\n                    \"Expected id to be a string, got {}: {!r}\".format(type(id), id)\n                )\n            id = ascii_escaped(id)\n        return cls(values, marks, id)\n\n    @classmethod\n    def extract_from(cls, parameterset, force_tuple=False):\n        \"\"\"\n        :param parameterset:\n            a legacy style parameterset that may or may not be a tuple,\n            and may or may not be wrapped into a mess of mark objects\n\n        :param force_tuple:\n            enforce tuple wrapping so single argument tuple values\n            don't get decomposed and break tests\n        \"\"\"\n\n        if isinstance(parameterset, cls):\n            return parameterset\n        if force_tuple:\n            return cls.param(parameterset)\n        else:\n            return cls(parameterset, marks=[], id=None)\n\n    @staticmethod\n    def _parse_parametrize_args(argnames, argvalues, *args, **kwargs):\n        if not isinstance(argnames, (tuple, list)):\n            argnames = [x.strip() for x in argnames.split(\",\") if x.strip()]\n            force_tuple = len(argnames) == 1\n        else:\n            force_tuple = False\n        return argnames, force_tuple\n\n    @staticmethod\n    def _parse_parametrize_parameters(argvalues, force_tuple):\n        return [\n            ParameterSet.extract_from(x, force_tuple=force_tuple) for x in argvalues\n        ]\n\n    @classmethod\n    def _for_parametrize(cls, argnames, argvalues, func, config, function_definition):\n        argnames, force_tuple = cls._parse_parametrize_args(argnames, argvalues)\n        parameters = cls._parse_parametrize_parameters(argvalues, force_tuple)\n        del argvalues\n\n        if parameters:\n            # check all parameter sets have the correct number of values\n            for param in parameters:\n                if len(param.values) != len(argnames):\n                    msg = (\n                        '{nodeid}: in \"parametrize\" the number of names ({names_len}):\\n'\n                        \"  {names}\\n\"\n                        \"must be equal to the number of values ({values_len}):\\n\"\n                        \"  {values}\"\n                    )\n                    fail(\n                        msg.format(\n                            nodeid=function_definition.nodeid,\n                            values=param.values,\n                            names=argnames,\n                            names_len=len(argnames),\n                            values_len=len(param.values),\n                        ),\n                        pytrace=False,\n                    )\n        else:\n            # empty parameter set (likely computed at runtime): create a single\n            # parameter set with NOTSET values, with the \"empty parameter set\" mark applied to it\n            mark = get_empty_parameterset_mark(config, argnames, func)\n            parameters.append(\n                ParameterSet(values=(NOTSET,) * len(argnames), marks=[mark], id=None)\n            )\n        return argnames, parameters"}, {"id": "_pytest.mark.ParameterSet.param", "kind": "function", "range": [59, 4, 72, 37, 1628, 2109], "file_path": "src/_pytest/mark/structures.py", "content": "@classmethod\n    def param(cls, *values, marks=(), id=None):\n        if isinstance(marks, MarkDecorator):\n            marks = (marks,)\n        else:\n            assert isinstance(marks, (tuple, list, set))\n\n        if id is not None:\n            if not isinstance(id, str):\n                raise TypeError(\n                    \"Expected id to be a string, got {}: {!r}\".format(type(id), id)\n                )\n            id = ascii_escaped(id)\n        return cls(values, marks, id)"}, {"id": "_pytest.mark.ParameterSet.extract_from", "kind": "function", "range": [74, 4, 91, 55, 2115, 2739], "file_path": "src/_pytest/mark/structures.py", "content": "@classmethod\n    def extract_from(cls, parameterset, force_tuple=False):\n        \"\"\"\n        :param parameterset:\n            a legacy style parameterset that may or may not be a tuple,\n            and may or may not be wrapped into a mess of mark objects\n\n        :param force_tuple:\n            enforce tuple wrapping so single argument tuple values\n            don't get decomposed and break tests\n        \"\"\"\n\n        if isinstance(parameterset, cls):\n            return parameterset\n        if force_tuple:\n            return cls.param(parameterset)\n        else:\n            return cls(parameterset, marks=[], id=None)"}, {"id": "_pytest.mark.ParameterSet._parse_parametrize_args", "kind": "function", "range": [93, 4, 100, 36, 2745, 3086], "file_path": "src/_pytest/mark/structures.py", "content": "@staticmethod\n    def _parse_parametrize_args(argnames, argvalues, *args, **kwargs):\n        if not isinstance(argnames, (tuple, list)):\n            argnames = [x.strip() for x in argnames.split(\",\") if x.strip()]\n            force_tuple = len(argnames) == 1\n        else:\n            force_tuple = False\n        return argnames, force_tuple"}, {"id": "_pytest.mark.ParameterSet._parse_parametrize_parameters", "kind": "function", "range": [102, 4, 106, 9, 3092, 3280], "file_path": "src/_pytest/mark/structures.py", "content": "@staticmethod\n    def _parse_parametrize_parameters(argvalues, force_tuple):\n        return [\n            ParameterSet.extract_from(x, force_tuple=force_tuple) for x in argvalues\n        ]"}, {"id": "_pytest.mark.ParameterSet._for_parametrize", "kind": "function", "range": [108, 4, 141, 35, 3286, 4900], "file_path": "src/_pytest/mark/structures.py", "content": "@classmethod\n    def _for_parametrize(cls, argnames, argvalues, func, config, function_definition):\n        argnames, force_tuple = cls._parse_parametrize_args(argnames, argvalues)\n        parameters = cls._parse_parametrize_parameters(argvalues, force_tuple)\n        del argvalues\n\n        if parameters:\n            # check all parameter sets have the correct number of values\n            for param in parameters:\n                if len(param.values) != len(argnames):\n                    msg = (\n                        '{nodeid}: in \"parametrize\" the number of names ({names_len}):\\n'\n                        \"  {names}\\n\"\n                        \"must be equal to the number of values ({values_len}):\\n\"\n                        \"  {values}\"\n                    )\n                    fail(\n                        msg.format(\n                            nodeid=function_definition.nodeid,\n                            values=param.values,\n                            names=argnames,\n                            names_len=len(argnames),\n                            values_len=len(param.values),\n                        ),\n                        pytrace=False,\n                    )\n        else:\n            # empty parameter set (likely computed at runtime): create a single\n            # parameter set with NOTSET values, with the \"empty parameter set\" mark applied to it\n            mark = get_empty_parameterset_mark(config, argnames, func)\n            parameters.append(\n                ParameterSet(values=(NOTSET,) * len(argnames), marks=[mark], id=None)\n            )\n        return argnames, parameters"}, {"id": "_pytest.mark.Mark", "kind": "class", "range": [144, 0, 188, 9, 4903, 6399], "file_path": "src/_pytest/mark/structures.py", "content": "@attr.s(frozen=True)\nclass Mark:\n    #: Name of the mark.\n    name = attr.ib(type=str)\n    #: Positional arguments of the mark decorator.\n    args = attr.ib(type=Tuple[Any, ...])\n    #: Keyword arguments of the mark decorator.\n    kwargs = attr.ib(type=Mapping[str, Any])\n\n    #: Source Mark for ids with parametrize Marks.\n    _param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)\n    #: Resolved/generated ids with parametrize Marks.\n    _param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )\n\n    def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4\n\n    def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )"}, {"id": "_pytest.mark.Mark.name", "kind": "variable", "range": [147, 4, 147, 28, 4965, 4989], "file_path": "src/_pytest/mark/structures.py", "content": "name = attr.ib(type=str)"}, {"id": "_pytest.mark.Mark.args", "kind": "variable", "range": [149, 4, 149, 40, 5045, 5081], "file_path": "src/_pytest/mark/structures.py", "content": "args = attr.ib(type=Tuple[Any, ...])"}, {"id": "_pytest.mark.Mark.kwargs", "kind": "variable", "range": [151, 4, 151, 44, 5134, 5174], "file_path": "src/_pytest/mark/structures.py", "content": "kwargs = attr.ib(type=Mapping[str, Any])"}, {"id": "_pytest.mark.Mark._param_ids_from", "kind": "variable", "range": [154, 4, 154, 78, 5231, 5305], "file_path": "src/_pytest/mark/structures.py", "content": "_param_ids_from = attr.ib(type=Optional[\"Mark\"], default=None, repr=False)"}, {"id": "_pytest.mark.Mark._param_ids_generated", "kind": "variable", "range": [156, 4, 158, 5, 5364, 5464], "file_path": "src/_pytest/mark/structures.py", "content": "_param_ids_generated = attr.ib(\n        type=Optional[Sequence[str]], default=None, repr=False\n    )"}, {"id": "_pytest.mark.Mark._has_param_ids", "kind": "function", "range": [160, 4, 161, 58, 5470, 5562], "file_path": "src/_pytest/mark/structures.py", "content": "def _has_param_ids(self) -> bool:\n        return \"ids\" in self.kwargs or len(self.args) >= 4"}, {"id": "_pytest.mark.Mark.combined_with", "kind": "function", "range": [163, 4, 188, 9, 5568, 6399], "file_path": "src/_pytest/mark/structures.py", "content": "def combined_with(self, other: \"Mark\") -> \"Mark\":\n        \"\"\"Return a new Mark which is a combination of this\n        Mark and another Mark.\n\n        Combines by appending args and merging kwargs.\n\n        :param other: The mark to combine with.\n        :type other: Mark\n        :rtype: Mark\n        \"\"\"\n        assert self.name == other.name\n\n        # Remember source of ids with parametrize Marks.\n        param_ids_from = None  # type: Optional[Mark]\n        if self.name == \"parametrize\":\n            if other._has_param_ids():\n                param_ids_from = other\n            elif self._has_param_ids():\n                param_ids_from = self\n\n        return Mark(\n            self.name,\n            self.args + other.args,\n            dict(self.kwargs, **other.kwargs),\n            param_ids_from=param_ids_from,\n        )"}, {"id": "_pytest.mark.MarkDecorator", "kind": "class", "range": [191, 0, 270, 46, 6402, 9225], "file_path": "src/_pytest/mark/structures.py", "content": "@attr.s\nclass MarkDecorator:\n    \"\"\"A decorator for applying a mark on test functions and classes.\n\n    MarkDecorators are created with ``pytest.mark``::\n\n        mark1 = pytest.mark.NAME              # Simple MarkDecorator\n        mark2 = pytest.mark.NAME(name1=value) # Parametrized MarkDecorator\n\n    and can then be applied as decorators to test functions::\n\n        @mark2\n        def test_function():\n            pass\n\n    When a MarkDecorator is called it does the following:\n\n    1. If called with a single class as its only positional argument and no\n       additional keyword arguments, it attaches the mark to the class so it\n       gets applied automatically to all test cases found in that class.\n\n    2. If called with a single function as its only positional argument and\n       no additional keyword arguments, it attaches the mark to the function,\n       containing all the arguments already stored internally in the\n       MarkDecorator.\n\n    3. When called in any other case, it returns a new MarkDecorator instance\n       with the original MarkDecorator's content updated with the arguments\n       passed to this call.\n\n    Note: The rules above prevent MarkDecorators from storing only a single\n    function or class reference as their positional argument with no\n    additional keyword or positional arguments. You can work around this by\n    using `with_args()`.\n    \"\"\"\n\n    mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))\n\n    @property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name\n\n    @property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args\n\n    @property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs\n\n    @property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)\n\n    def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)\n\n    def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))\n\n    def __call__(self, *args: object, **kwargs: object):\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)"}, {"id": "_pytest.mark.MarkDecorator.mark", "kind": "variable", "range": [227, 4, 227, 74, 7801, 7871], "file_path": "src/_pytest/mark/structures.py", "content": "mark = attr.ib(type=Mark, validator=attr.validators.instance_of(Mark))"}, {"id": "_pytest.mark.MarkDecorator.name", "kind": "function", "range": [229, 4, 232, 29, 7877, 7978], "file_path": "src/_pytest/mark/structures.py", "content": "@property\n    def name(self) -> str:\n        \"\"\"Alias for mark.name.\"\"\"\n        return self.mark.name"}, {"id": "_pytest.mark.MarkDecorator.args", "kind": "function", "range": [234, 4, 237, 29, 7984, 8097], "file_path": "src/_pytest/mark/structures.py", "content": "@property\n    def args(self) -> Tuple[Any, ...]:\n        \"\"\"Alias for mark.args.\"\"\"\n        return self.mark.args"}, {"id": "_pytest.mark.MarkDecorator.kwargs", "kind": "function", "range": [239, 4, 242, 31, 8103, 8224], "file_path": "src/_pytest/mark/structures.py", "content": "@property\n    def kwargs(self) -> Mapping[str, Any]:\n        \"\"\"Alias for mark.kwargs.\"\"\"\n        return self.mark.kwargs"}, {"id": "_pytest.mark.MarkDecorator.markname", "kind": "function", "range": [244, 4, 246, 69, 8230, 8340], "file_path": "src/_pytest/mark/structures.py", "content": "@property\n    def markname(self) -> str:\n        return self.name  # for backward-compat (2.4.1 had this attr)"}, {"id": "_pytest.mark.MarkDecorator.__repr__", "kind": "function", "range": [248, 4, 249, 55, 8346, 8428], "file_path": "src/_pytest/mark/structures.py", "content": "def __repr__(self) -> str:\n        return \"<MarkDecorator {!r}>\".format(self.mark)"}, {"id": "_pytest.mark.MarkDecorator.with_args", "kind": "function", "range": [251, 4, 260, 60, 8434, 8840], "file_path": "src/_pytest/mark/structures.py", "content": "def with_args(self, *args: object, **kwargs: object) -> \"MarkDecorator\":\n        \"\"\"Return a MarkDecorator with extra arguments added.\n\n        Unlike calling the MarkDecorator, with_args() can be used even\n        if the sole argument is a callable/class.\n\n        :return: MarkDecorator\n        \"\"\"\n        mark = Mark(self.name, args, kwargs)\n        return self.__class__(self.mark.combined_with(mark))"}, {"id": "_pytest.mark.MarkDecorator.__call__", "kind": "function", "range": [262, 4, 270, 46, 8846, 9225], "file_path": "src/_pytest/mark/structures.py", "content": "def __call__(self, *args: object, **kwargs: object):\n        \"\"\"Call the MarkDecorator.\"\"\"\n        if args and not kwargs:\n            func = args[0]\n            is_class = inspect.isclass(func)\n            if len(args) == 1 and (istestfunc(func) or is_class):\n                store_mark(func, self.mark)\n                return func\n        return self.with_args(*args, **kwargs)"}, {"id": "_pytest.mark.get_unpacked_marks", "kind": "function", "range": [273, 0, 280, 41, 9228, 9492], "file_path": "src/_pytest/mark/structures.py", "content": "def get_unpacked_marks(obj):\n    \"\"\"\n    obtain the unpacked marks that are stored on an object\n    \"\"\"\n    mark_list = getattr(obj, \"pytestmark\", [])\n    if not isinstance(mark_list, list):\n        mark_list = [mark_list]\n    return normalize_mark_list(mark_list)"}, {"id": "_pytest.mark.normalize_mark_list", "kind": "function", "range": [283, 0, 296, 56, 9495, 10031], "file_path": "src/_pytest/mark/structures.py", "content": "def normalize_mark_list(mark_list: Iterable[Union[Mark, MarkDecorator]]) -> List[Mark]:\n    \"\"\"\n    normalizes marker decorating helpers to mark objects\n\n    :type mark_list: List[Union[Mark, Markdecorator]]\n    :rtype: List[Mark]\n    \"\"\"\n    extracted = [\n        getattr(mark, \"mark\", mark) for mark in mark_list\n    ]  # unpack MarkDecorator\n    for mark in extracted:\n        if not isinstance(mark, Mark):\n            raise TypeError(\"got {!r} instead of Mark\".format(mark))\n    return [x for x in extracted if isinstance(x, Mark)]"}, {"id": "_pytest.mark.store_mark", "kind": "function", "range": [299, 0, 307, 53, 10034, 10386], "file_path": "src/_pytest/mark/structures.py", "content": "def store_mark(obj, mark: Mark) -> None:\n    \"\"\"Store a Mark on an object.\n\n    This is used to implement the Mark declarations/decorators correctly.\n    \"\"\"\n    assert isinstance(mark, Mark), mark\n    # Always reassign name to avoid updating pytestmark in a reference that\n    # was only borrowed.\n    obj.pytestmark = get_unpacked_marks(obj) + [mark]"}, {"id": "_pytest.mark.MarkGenerator", "kind": "class", "range": [310, 0, 366, 48, 10389, 12758], "file_path": "src/_pytest/mark/structures.py", "content": "class MarkGenerator:\n    \"\"\"Factory for :class:`MarkDecorator` objects - exposed as\n    a ``pytest.mark`` singleton instance.\n\n    Example::\n\n         import pytest\n\n         @pytest.mark.slowtest\n         def test_function():\n            pass\n\n    applies a 'slowtest' :class:`Mark` on ``test_function``.\n    \"\"\"\n\n    _config = None\n    _markers = set()  # type: Set[str]\n\n    def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/latest/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))"}, {"id": "_pytest.mark.MarkGenerator._config", "kind": "variable", "range": [325, 4, 325, 18, 10708, 10722], "file_path": "src/_pytest/mark/structures.py", "content": "_config = None"}, {"id": "_pytest.mark.MarkGenerator._markers", "kind": "variable", "range": [326, 4, 326, 20, 10727, 10743], "file_path": "src/_pytest/mark/structures.py", "content": "_markers = set()"}, {"id": "_pytest.mark.MarkGenerator.__getattr__", "kind": "function", "range": [328, 4, 366, 48, 10767, 12758], "file_path": "src/_pytest/mark/structures.py", "content": "def __getattr__(self, name: str) -> MarkDecorator:\n        if name[0] == \"_\":\n            raise AttributeError(\"Marker name must NOT start with underscore\")\n\n        if self._config is not None:\n            # We store a set of markers as a performance optimisation - if a mark\n            # name is in the set we definitely know it, but a mark may be known and\n            # not in the set.  We therefore start by updating the set!\n            if name not in self._markers:\n                for line in self._config.getini(\"markers\"):\n                    # example lines: \"skipif(condition): skip the given test if...\"\n                    # or \"hypothesis: tests which use Hypothesis\", so to get the\n                    # marker name we split on both `:` and `(`.\n                    marker = line.split(\":\")[0].split(\"(\")[0].strip()\n                    self._markers.add(marker)\n\n            # If the name is not in the set of known marks after updating,\n            # then it really is time to issue a warning or an error.\n            if name not in self._markers:\n                if self._config.option.strict_markers:\n                    fail(\n                        \"{!r} not found in `markers` configuration option\".format(name),\n                        pytrace=False,\n                    )\n\n                # Raise a specific error for common misspellings of \"parametrize\".\n                if name in [\"parameterize\", \"parametrise\", \"parameterise\"]:\n                    __tracebackhide__ = True\n                    fail(\"Unknown '{}' mark, did you mean 'parametrize'?\".format(name))\n\n                warnings.warn(\n                    \"Unknown pytest.mark.%s - is this a typo?  You can register \"\n                    \"custom marks to avoid this warning - for details, see \"\n                    \"https://docs.pytest.org/en/latest/mark.html\" % name,\n                    PytestUnknownMarkWarning,\n                    2,\n                )\n\n        return MarkDecorator(Mark(name, (), {}))"}, {"id": "_pytest.mark.MARK_GEN", "kind": "variable", "range": [369, 0, 369, 26, 12761, 12787], "file_path": "src/_pytest/mark/structures.py", "content": "MARK_GEN = MarkGenerator()"}, {"id": "_pytest.mark.NodeKeywords", "kind": "class", "range": [372, 0, 406, 61, 12790, 13720], "file_path": "src/_pytest/mark/structures.py", "content": "class NodeKeywords(MutableMapping):\n    def __init__(self, node):\n        self.node = node\n        self.parent = node.parent\n        self._markers = {node.name: True}\n\n    def __getitem__(self, key):\n        try:\n            return self._markers[key]\n        except KeyError:\n            if self.parent is None:\n                raise\n            return self.parent.keywords[key]\n\n    def __setitem__(self, key, value):\n        self._markers[key] = value\n\n    def __delitem__(self, key):\n        raise ValueError(\"cannot delete key in keywords dict\")\n\n    def __iter__(self):\n        seen = self._seen()\n        return iter(seen)\n\n    def _seen(self):\n        seen = set(self._markers)\n        if self.parent is not None:\n            seen.update(self.parent.keywords)\n        return seen\n\n    def __len__(self):\n        return len(self._seen())\n\n    def __repr__(self):\n        return \"<NodeKeywords for node {}>\".format(self.node)"}, {"id": "_pytest.mark.NodeKeywords.__init__", "kind": "function", "range": [373, 4, 376, 41, 12830, 12956], "file_path": "src/_pytest/mark/structures.py", "content": "def __init__(self, node):\n        self.node = node\n        self.parent = node.parent\n        self._markers = {node.name: True}"}, {"id": "_pytest.mark.NodeKeywords.__getitem__", "kind": "function", "range": [378, 4, 384, 44, 12962, 13168], "file_path": "src/_pytest/mark/structures.py", "content": "def __getitem__(self, key):\n        try:\n            return self._markers[key]\n        except KeyError:\n            if self.parent is None:\n                raise\n            return self.parent.keywords[key]"}, {"id": "_pytest.mark.NodeKeywords.__setitem__", "kind": "function", "range": [386, 4, 387, 34, 13174, 13243], "file_path": "src/_pytest/mark/structures.py", "content": "def __setitem__(self, key, value):\n        self._markers[key] = value"}, {"id": "_pytest.mark.NodeKeywords.__delitem__", "kind": "function", "range": [389, 4, 390, 62, 13249, 13339], "file_path": "src/_pytest/mark/structures.py", "content": "def __delitem__(self, key):\n        raise ValueError(\"cannot delete key in keywords dict\")"}, {"id": "_pytest.mark.NodeKeywords.__iter__", "kind": "function", "range": [392, 4, 394, 25, 13345, 13418], "file_path": "src/_pytest/mark/structures.py", "content": "def __iter__(self):\n        seen = self._seen()\n        return iter(seen)"}, {"id": "_pytest.mark.NodeKeywords._seen", "kind": "function", "range": [396, 4, 400, 19, 13424, 13576], "file_path": "src/_pytest/mark/structures.py", "content": "def _seen(self):\n        seen = set(self._markers)\n        if self.parent is not None:\n            seen.update(self.parent.keywords)\n        return seen"}, {"id": "_pytest.mark.NodeKeywords.__len__", "kind": "function", "range": [402, 4, 403, 32, 13582, 13633], "file_path": "src/_pytest/mark/structures.py", "content": "def __len__(self):\n        return len(self._seen())"}, {"id": "_pytest.mark.NodeKeywords.__repr__", "kind": "function", "range": [405, 4, 406, 61, 13639, 13720], "file_path": "src/_pytest/mark/structures.py", "content": "def __repr__(self):\n        return \"<NodeKeywords for node {}>\".format(self.node)"}, {"id": "_pytest.tmpdir.TempPathFactory", "kind": "class", "range": [19, 0, 102, 16, 453, 3759], "file_path": "src/_pytest/tmpdir.py", "content": "@attr.s\nclass TempPathFactory:\n    \"\"\"Factory for temporary directories under the common base temp directory.\n\n    The base directory can be configured using the ``--basetemp`` option.\"\"\"\n\n    _given_basetemp = attr.ib(\n        type=Path,\n        # using os.path.abspath() to get absolute path instead of resolve() as it\n        # does not work the same in all platforms (see #4427)\n        # Path.absolute() exists, but it is not public (see https://bugs.python.org/issue25012)\n        # Ignore type because of https://github.com/python/mypy/issues/6172.\n        converter=attr.converters.optional(\n            lambda p: Path(os.path.abspath(str(p)))  # type: ignore\n        ),\n    )\n    _trace = attr.ib()\n    _basetemp = attr.ib(type=Optional[Path], default=None)\n\n    @classmethod\n    def from_config(cls, config) -> \"TempPathFactory\":\n        \"\"\"\n        :param config: a pytest configuration\n        \"\"\"\n        return cls(\n            given_basetemp=config.option.basetemp, trace=config.trace.get(\"tmpdir\")\n        )\n\n    def _ensure_relative_to_basetemp(self, basename: str):\n        basename = os.path.normpath(basename)\n        if (self.getbasetemp() / basename).resolve().parent != self.getbasetemp():\n            raise ValueError(\n                \"{} is not a normalized and relative path\".format(basename)\n            )\n        return basename\n\n    def mktemp(self, basename: str, numbered: bool = True) -> Path:\n        \"\"\"Creates a new temporary directory managed by the factory.\n\n        :param basename:\n            Directory base name, must be a relative path.\n\n        :param numbered:\n            If ``True``, ensure the directory is unique by adding a numbered\n            suffix greater than any existing one: ``basename=\"foo-\"`` and ``numbered=True``\n            means that this function will create directories named ``\"foo-0\"``,\n            ``\"foo-1\"``, ``\"foo-2\"`` and so on.\n\n        :return:\n            The path to the new directory.\n        \"\"\"\n        basename = self._ensure_relative_to_basetemp(basename)\n        if not numbered:\n            p = self.getbasetemp().joinpath(basename)\n            p.mkdir()\n        else:\n            p = make_numbered_dir(root=self.getbasetemp(), prefix=basename)\n            self._trace(\"mktemp\", p)\n        return p\n\n    def getbasetemp(self) -> Path:\n        \"\"\" return base temporary directory. \"\"\"\n        if self._basetemp is not None:\n            return self._basetemp\n\n        if self._given_basetemp is not None:\n            basetemp = self._given_basetemp\n            ensure_reset_dir(basetemp)\n            basetemp = basetemp.resolve()\n        else:\n            from_env = os.environ.get(\"PYTEST_DEBUG_TEMPROOT\")\n            temproot = Path(from_env or tempfile.gettempdir()).resolve()\n            user = get_user() or \"unknown\"\n            # use a sub-directory in the temproot to speed-up\n            # make_numbered_dir() call\n            rootdir = temproot.joinpath(\"pytest-of-{}\".format(user))\n            rootdir.mkdir(exist_ok=True)\n            basetemp = make_numbered_dir_with_cleanup(\n                prefix=\"pytest-\", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT\n            )\n        assert basetemp is not None, basetemp\n        self._basetemp = t = basetemp\n        self._trace(\"new basetemp\", t)\n        return t"}, {"id": "_pytest.tmpdir.TempPathFactory._given_basetemp", "kind": "variable", "range": [25, 4, 34, 5, 646, 1137], "file_path": "src/_pytest/tmpdir.py", "content": "_given_basetemp = attr.ib(\n        type=Path,\n        # using os.path.abspath() to get absolute path instead of resolve() as it\n        # does not work the same in all platforms (see #4427)\n        # Path.absolute() exists, but it is not public (see https://bugs.python.org/issue25012)\n        # Ignore type because of https://github.com/python/mypy/issues/6172.\n        converter=attr.converters.optional(\n            lambda p: Path(os.path.abspath(str(p)))  # type: ignore\n        ),\n    )"}, {"id": "_pytest.tmpdir.TempPathFactory._trace", "kind": "variable", "range": [35, 4, 35, 22, 1142, 1160], "file_path": "src/_pytest/tmpdir.py", "content": "_trace = attr.ib()"}, {"id": "_pytest.tmpdir.TempPathFactory._basetemp", "kind": "variable", "range": [36, 4, 36, 58, 1165, 1219], "file_path": "src/_pytest/tmpdir.py", "content": "_basetemp = attr.ib(type=Optional[Path], default=None)"}, {"id": "_pytest.tmpdir.TempPathFactory.from_config", "kind": "function", "range": [38, 4, 45, 9, 1225, 1476], "file_path": "src/_pytest/tmpdir.py", "content": "@classmethod\n    def from_config(cls, config) -> \"TempPathFactory\":\n        \"\"\"\n        :param config: a pytest configuration\n        \"\"\"\n        return cls(\n            given_basetemp=config.option.basetemp, trace=config.trace.get(\"tmpdir\")\n        )"}, {"id": "_pytest.tmpdir.TempPathFactory._ensure_relative_to_basetemp", "kind": "function", "range": [47, 4, 53, 23, 1482, 1809], "file_path": "src/_pytest/tmpdir.py", "content": "def _ensure_relative_to_basetemp(self, basename: str):\n        basename = os.path.normpath(basename)\n        if (self.getbasetemp() / basename).resolve().parent != self.getbasetemp():\n            raise ValueError(\n                \"{} is not a normalized and relative path\".format(basename)\n            )\n        return basename"}, {"id": "_pytest.tmpdir.TempPathFactory.mktemp", "kind": "function", "range": [55, 4, 77, 16, 1815, 2735], "file_path": "src/_pytest/tmpdir.py", "content": "def mktemp(self, basename: str, numbered: bool = True) -> Path:\n        \"\"\"Creates a new temporary directory managed by the factory.\n\n        :param basename:\n            Directory base name, must be a relative path.\n\n        :param numbered:\n            If ``True``, ensure the directory is unique by adding a numbered\n            suffix greater than any existing one: ``basename=\"foo-\"`` and ``numbered=True``\n            means that this function will create directories named ``\"foo-0\"``,\n            ``\"foo-1\"``, ``\"foo-2\"`` and so on.\n\n        :return:\n            The path to the new directory.\n        \"\"\"\n        basename = self._ensure_relative_to_basetemp(basename)\n        if not numbered:\n            p = self.getbasetemp().joinpath(basename)\n            p.mkdir()\n        else:\n            p = make_numbered_dir(root=self.getbasetemp(), prefix=basename)\n            self._trace(\"mktemp\", p)\n        return p"}, {"id": "_pytest.tmpdir.TempPathFactory.getbasetemp", "kind": "function", "range": [79, 4, 102, 16, 2741, 3759], "file_path": "src/_pytest/tmpdir.py", "content": "def getbasetemp(self) -> Path:\n        \"\"\" return base temporary directory. \"\"\"\n        if self._basetemp is not None:\n            return self._basetemp\n\n        if self._given_basetemp is not None:\n            basetemp = self._given_basetemp\n            ensure_reset_dir(basetemp)\n            basetemp = basetemp.resolve()\n        else:\n            from_env = os.environ.get(\"PYTEST_DEBUG_TEMPROOT\")\n            temproot = Path(from_env or tempfile.gettempdir()).resolve()\n            user = get_user() or \"unknown\"\n            # use a sub-directory in the temproot to speed-up\n            # make_numbered_dir() call\n            rootdir = temproot.joinpath(\"pytest-of-{}\".format(user))\n            rootdir.mkdir(exist_ok=True)\n            basetemp = make_numbered_dir_with_cleanup(\n                prefix=\"pytest-\", root=rootdir, keep=3, lock_timeout=LOCK_TIMEOUT\n            )\n        assert basetemp is not None, basetemp\n        self._basetemp = t = basetemp\n        self._trace(\"new basetemp\", t)\n        return t"}, {"id": "_pytest.tmpdir.TempdirFactory", "kind": "class", "range": [105, 0, 122, 75, 3762, 4428], "file_path": "src/_pytest/tmpdir.py", "content": "@attr.s\nclass TempdirFactory:\n    \"\"\"\n    backward comptibility wrapper that implements\n    :class:``py.path.local`` for :class:``TempPathFactory``\n    \"\"\"\n\n    _tmppath_factory = attr.ib(type=TempPathFactory)\n\n    def mktemp(self, basename: str, numbered: bool = True) -> py.path.local:\n        \"\"\"\n        Same as :meth:`TempPathFactory.mkdir`, but returns a ``py.path.local`` object.\n        \"\"\"\n        return py.path.local(self._tmppath_factory.mktemp(basename, numbered).resolve())\n\n    def getbasetemp(self):\n        \"\"\"backward compat wrapper for ``_tmppath_factory.getbasetemp``\"\"\"\n        return py.path.local(self._tmppath_factory.getbasetemp().resolve())"}, {"id": "_pytest.tmpdir.TempdirFactory._tmppath_factory", "kind": "variable", "range": [112, 4, 112, 52, 3923, 3971], "file_path": "src/_pytest/tmpdir.py", "content": "_tmppath_factory = attr.ib(type=TempPathFactory)"}, {"id": "_pytest.tmpdir.TempdirFactory.mktemp", "kind": "function", "range": [114, 4, 118, 88, 3977, 4249], "file_path": "src/_pytest/tmpdir.py", "content": "def mktemp(self, basename: str, numbered: bool = True) -> py.path.local:\n        \"\"\"\n        Same as :meth:`TempPathFactory.mkdir`, but returns a ``py.path.local`` object.\n        \"\"\"\n        return py.path.local(self._tmppath_factory.mktemp(basename, numbered).resolve())"}, {"id": "_pytest.tmpdir.TempdirFactory.getbasetemp", "kind": "function", "range": [120, 4, 122, 75, 4255, 4428], "file_path": "src/_pytest/tmpdir.py", "content": "def getbasetemp(self):\n        \"\"\"backward compat wrapper for ``_tmppath_factory.getbasetemp``\"\"\"\n        return py.path.local(self._tmppath_factory.getbasetemp().resolve())"}, {"id": "_pytest.tmpdir.get_user", "kind": "function", "range": [125, 0, 134, 19, 4431, 4705], "file_path": "src/_pytest/tmpdir.py", "content": "def get_user() -> Optional[str]:\n    \"\"\"Return the current user name, or None if getuser() does not work\n    in the current environment (see #1010).\n    \"\"\"\n    import getpass\n\n    try:\n        return getpass.getuser()\n    except (ImportError, KeyError):\n        return None"}, {"id": "_pytest.tmpdir.pytest_configure", "kind": "function", "range": [137, 0, 149, 58, 4708, 5308], "file_path": "src/_pytest/tmpdir.py", "content": "def pytest_configure(config) -> None:\n    \"\"\"Create a TempdirFactory and attach it to the config object.\n\n    This is to comply with existing plugins which expect the handler to be\n    available at pytest_configure time, but ideally should be moved entirely\n    to the tmpdir_factory session fixture.\n    \"\"\"\n    mp = MonkeyPatch()\n    tmppath_handler = TempPathFactory.from_config(config)\n    t = TempdirFactory(tmppath_handler)\n    config._cleanup.append(mp.undo)\n    mp.setattr(config, \"_tmp_path_factory\", tmppath_handler, raising=False)\n    mp.setattr(config, \"_tmpdirhandler\", t, raising=False)"}, {"id": "_pytest.tmpdir.tmpdir_factory", "kind": "function", "range": [152, 0, 157, 56, 5311, 5608], "file_path": "src/_pytest/tmpdir.py", "content": "@pytest.fixture(scope=\"session\")\ndef tmpdir_factory(request: FixtureRequest) -> TempdirFactory:\n    \"\"\"Return a :class:`_pytest.tmpdir.TempdirFactory` instance for the test session.\n    \"\"\"\n    # Set dynamically by pytest_configure() above.\n    return request.config._tmpdirhandler  # type: ignore"}, {"id": "_pytest.tmpdir.tmp_path_factory", "kind": "function", "range": [160, 0, 165, 59, 5611, 5915], "file_path": "src/_pytest/tmpdir.py", "content": "@pytest.fixture(scope=\"session\")\ndef tmp_path_factory(request: FixtureRequest) -> TempPathFactory:\n    \"\"\"Return a :class:`_pytest.tmpdir.TempPathFactory` instance for the test session.\n    \"\"\"\n    # Set dynamically by pytest_configure() above.\n    return request.config._tmp_path_factory  # type: ignore"}, {"id": "_pytest.tmpdir._mk_tmp", "kind": "function", "range": [168, 0, 173, 46, 5918, 6144], "file_path": "src/_pytest/tmpdir.py", "content": "def _mk_tmp(request: FixtureRequest, factory: TempPathFactory) -> Path:\n    name = request.node.name\n    name = re.sub(r\"[\\W]\", \"_\", name)\n    MAXVAL = 30\n    name = name[:MAXVAL]\n    return factory.mktemp(name, numbered=True)"}, {"id": "_pytest.tmpdir.tmpdir", "kind": "function", "range": [176, 0, 186, 34, 6147, 6529], "file_path": "src/_pytest/tmpdir.py", "content": "@pytest.fixture\ndef tmpdir(tmp_path):\n    \"\"\"Return a temporary directory path object\n    which is unique to each test function invocation,\n    created as a sub directory of the base temporary\n    directory.  The returned object is a `py.path.local`_\n    path object.\n\n    .. _`py.path.local`: https://py.readthedocs.io/en/latest/path.html\n    \"\"\"\n    return py.path.local(tmp_path)"}, {"id": "_pytest.tmpdir.tmp_path", "kind": "function", "range": [189, 0, 202, 45, 6532, 6978], "file_path": "src/_pytest/tmpdir.py", "content": "@pytest.fixture\ndef tmp_path(request: FixtureRequest, tmp_path_factory: TempPathFactory) -> Path:\n    \"\"\"Return a temporary directory path object\n    which is unique to each test function invocation,\n    created as a sub directory of the base temporary\n    directory.  The returned object is a :class:`pathlib.Path`\n    object.\n\n    .. note::\n\n        in python < 3.6 this is a pathlib2.Path\n    \"\"\"\n\n    return _mk_tmp(request, tmp_path_factory)"}, {"id": "_pytest.__init__.__all__", "kind": "variable", "range": [0, 0, 0, 25, 0, 25], "file_path": "src/_pytest/__init__.py", "content": "__all__ = [\"__version__\"]"}, {"id": "_pytest._code.Code", "kind": "class", "range": [48, 0, 117, 41, 1185, 3598], "file_path": "src/_pytest/_code/code.py", "content": "class Code:\n    \"\"\" wrapper around Python code objects \"\"\"\n\n    def __init__(self, rawcode) -> None:\n        if not hasattr(rawcode, \"co_filename\"):\n            rawcode = getrawcode(rawcode)\n        if not isinstance(rawcode, CodeType):\n            raise TypeError(\"not a code object: {!r}\".format(rawcode))\n        self.filename = rawcode.co_filename\n        self.firstlineno = rawcode.co_firstlineno - 1\n        self.name = rawcode.co_name\n        self.raw = rawcode\n\n    def __eq__(self, other):\n        return self.raw == other.raw\n\n    # Ignore type because of https://github.com/python/mypy/issues/4266.\n    __hash__ = None  # type: ignore\n\n    def __ne__(self, other):\n        return not self == other\n\n    @property\n    def path(self) -> Union[py.path.local, str]:\n        \"\"\" return a path object pointing to source code (or a str in case\n        of OSError / non-existing file).\n        \"\"\"\n        if not self.raw.co_filename:\n            return \"\"\n        try:\n            p = py.path.local(self.raw.co_filename)\n            # maybe don't try this checking\n            if not p.check():\n                raise OSError(\"py.path check failed.\")\n            return p\n        except OSError:\n            # XXX maybe try harder like the weird logic\n            # in the standard lib [linecache.updatecache] does?\n            return self.raw.co_filename\n\n    @property\n    def fullsource(self) -> Optional[\"Source\"]:\n        \"\"\" return a _pytest._code.Source object for the full source file of the code\n        \"\"\"\n        from _pytest._code import source\n\n        full, _ = source.findsource(self.raw)\n        return full\n\n    def source(self) -> \"Source\":\n        \"\"\" return a _pytest._code.Source object for the code object's source only\n        \"\"\"\n        # return source only for that part of code\n        import _pytest._code\n\n        return _pytest._code.Source(self.raw)\n\n    def getargs(self, var: bool = False) -> Tuple[str, ...]:\n        \"\"\" return a tuple with the argument names for the code object\n\n            if 'var' is set True also return the names of the variable and\n            keyword arguments when present\n        \"\"\"\n        # handfull shortcut for getting args\n        raw = self.raw\n        argcount = raw.co_argcount\n        if var:\n            argcount += raw.co_flags & CO_VARARGS\n            argcount += raw.co_flags & CO_VARKEYWORDS\n        return raw.co_varnames[:argcount]"}, {"id": "_pytest._code.Code.__init__", "kind": "function", "range": [51, 4, 59, 26, 1249, 1653], "file_path": "src/_pytest/_code/code.py", "content": "def __init__(self, rawcode) -> None:\n        if not hasattr(rawcode, \"co_filename\"):\n            rawcode = getrawcode(rawcode)\n        if not isinstance(rawcode, CodeType):\n            raise TypeError(\"not a code object: {!r}\".format(rawcode))\n        self.filename = rawcode.co_filename\n        self.firstlineno = rawcode.co_firstlineno - 1\n        self.name = rawcode.co_name\n        self.raw = rawcode"}, {"id": "_pytest._code.Code.__eq__", "kind": "function", "range": [61, 4, 62, 36, 1659, 1720], "file_path": "src/_pytest/_code/code.py", "content": "def __eq__(self, other):\n        return self.raw == other.raw"}, {"id": "_pytest._code.Code.__hash__", "kind": "variable", "range": [65, 4, 65, 19, 1799, 1814], "file_path": "src/_pytest/_code/code.py", "content": "__hash__ = None"}, {"id": "_pytest._code.Code.__ne__", "kind": "function", "range": [67, 4, 68, 32, 1836, 1893], "file_path": "src/_pytest/_code/code.py", "content": "def __ne__(self, other):\n        return not self == other"}, {"id": "_pytest._code.Code.path", "kind": "function", "range": [70, 4, 86, 39, 1899, 2543], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def path(self) -> Union[py.path.local, str]:\n        \"\"\" return a path object pointing to source code (or a str in case\n        of OSError / non-existing file).\n        \"\"\"\n        if not self.raw.co_filename:\n            return \"\"\n        try:\n            p = py.path.local(self.raw.co_filename)\n            # maybe don't try this checking\n            if not p.check():\n                raise OSError(\"py.path check failed.\")\n            return p\n        except OSError:\n            # XXX maybe try harder like the weird logic\n            # in the standard lib [linecache.updatecache] does?\n            return self.raw.co_filename"}, {"id": "_pytest._code.Code.fullsource", "kind": "function", "range": [88, 4, 95, 19, 2549, 2812], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def fullsource(self) -> Optional[\"Source\"]:\n        \"\"\" return a _pytest._code.Source object for the full source file of the code\n        \"\"\"\n        from _pytest._code import source\n\n        full, _ = source.findsource(self.raw)\n        return full"}, {"id": "_pytest._code.Code.source", "kind": "function", "range": [97, 4, 103, 45, 2818, 3069], "file_path": "src/_pytest/_code/code.py", "content": "def source(self) -> \"Source\":\n        \"\"\" return a _pytest._code.Source object for the code object's source only\n        \"\"\"\n        # return source only for that part of code\n        import _pytest._code\n\n        return _pytest._code.Source(self.raw)"}, {"id": "_pytest._code.Code.getargs", "kind": "function", "range": [105, 4, 117, 41, 3075, 3598], "file_path": "src/_pytest/_code/code.py", "content": "def getargs(self, var: bool = False) -> Tuple[str, ...]:\n        \"\"\" return a tuple with the argument names for the code object\n\n            if 'var' is set True also return the names of the variable and\n            keyword arguments when present\n        \"\"\"\n        # handfull shortcut for getting args\n        raw = self.raw\n        argcount = raw.co_argcount\n        if var:\n            argcount += raw.co_flags & CO_VARARGS\n            argcount += raw.co_flags & CO_VARKEYWORDS\n        return raw.co_varnames[:argcount]"}, {"id": "_pytest._code.Frame", "kind": "class", "range": [120, 0, 180, 21, 3601, 5519], "file_path": "src/_pytest/_code/code.py", "content": "class Frame:\n    \"\"\"Wrapper around a Python frame holding f_locals and f_globals\n    in which expressions can be evaluated.\"\"\"\n\n    def __init__(self, frame: FrameType) -> None:\n        self.lineno = frame.f_lineno - 1\n        self.f_globals = frame.f_globals\n        self.f_locals = frame.f_locals\n        self.raw = frame\n        self.code = Code(frame.f_code)\n\n    @property\n    def statement(self) -> \"Source\":\n        \"\"\" statement this frame is at \"\"\"\n        import _pytest._code\n\n        if self.code.fullsource is None:\n            return _pytest._code.Source(\"\")\n        return self.code.fullsource.getstatement(self.lineno)\n\n    def eval(self, code, **vars):\n        \"\"\" evaluate 'code' in the frame\n\n            'vars' are optional additional local variables\n\n            returns the result of the evaluation\n        \"\"\"\n        f_locals = self.f_locals.copy()\n        f_locals.update(vars)\n        return eval(code, self.f_globals, f_locals)\n\n    def exec_(self, code, **vars) -> None:\n        \"\"\" exec 'code' in the frame\n\n            'vars' are optional; additional local variables\n        \"\"\"\n        f_locals = self.f_locals.copy()\n        f_locals.update(vars)\n        exec(code, self.f_globals, f_locals)\n\n    def repr(self, object: object) -> str:\n        \"\"\" return a 'safe' (non-recursive, one-line) string repr for 'object'\n        \"\"\"\n        return saferepr(object)\n\n    def is_true(self, object):\n        return object\n\n    def getargs(self, var: bool = False):\n        \"\"\" return a list of tuples (name, value) for all arguments\n\n            if 'var' is set True also include the variable and keyword\n            arguments when present\n        \"\"\"\n        retval = []\n        for arg in self.code.getargs(var):\n            try:\n                retval.append((arg, self.f_locals[arg]))\n            except KeyError:\n                pass  # this can occur when using Psyco\n        return retval"}, {"id": "_pytest._code.Frame.__init__", "kind": "function", "range": [124, 4, 129, 38, 3733, 3963], "file_path": "src/_pytest/_code/code.py", "content": "def __init__(self, frame: FrameType) -> None:\n        self.lineno = frame.f_lineno - 1\n        self.f_globals = frame.f_globals\n        self.f_locals = frame.f_locals\n        self.raw = frame\n        self.code = Code(frame.f_code)"}, {"id": "_pytest._code.Frame.statement", "kind": "function", "range": [131, 4, 138, 61, 3969, 4235], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def statement(self) -> \"Source\":\n        \"\"\" statement this frame is at \"\"\"\n        import _pytest._code\n\n        if self.code.fullsource is None:\n            return _pytest._code.Source(\"\")\n        return self.code.fullsource.getstatement(self.lineno)"}, {"id": "_pytest._code.Frame.eval", "kind": "function", "range": [140, 4, 149, 51, 4241, 4555], "file_path": "src/_pytest/_code/code.py", "content": "def eval(self, code, **vars):\n        \"\"\" evaluate 'code' in the frame\n\n            'vars' are optional additional local variables\n\n            returns the result of the evaluation\n        \"\"\"\n        f_locals = self.f_locals.copy()\n        f_locals.update(vars)\n        return eval(code, self.f_globals, f_locals)"}, {"id": "_pytest._code.Frame.exec_", "kind": "function", "range": [151, 4, 158, 44, 4561, 4824], "file_path": "src/_pytest/_code/code.py", "content": "def exec_(self, code, **vars) -> None:\n        \"\"\" exec 'code' in the frame\n\n            'vars' are optional; additional local variables\n        \"\"\"\n        f_locals = self.f_locals.copy()\n        f_locals.update(vars)\n        exec(code, self.f_globals, f_locals)"}, {"id": "_pytest._code.Frame.repr", "kind": "function", "range": [160, 4, 163, 31, 4830, 4991], "file_path": "src/_pytest/_code/code.py", "content": "def repr(self, object: object) -> str:\n        \"\"\" return a 'safe' (non-recursive, one-line) string repr for 'object'\n        \"\"\"\n        return saferepr(object)"}, {"id": "_pytest._code.Frame.is_true", "kind": "function", "range": [165, 4, 166, 21, 4997, 5045], "file_path": "src/_pytest/_code/code.py", "content": "def is_true(self, object):\n        return object"}, {"id": "_pytest._code.Frame.getargs", "kind": "function", "range": [168, 4, 180, 21, 5051, 5519], "file_path": "src/_pytest/_code/code.py", "content": "def getargs(self, var: bool = False):\n        \"\"\" return a list of tuples (name, value) for all arguments\n\n            if 'var' is set True also include the variable and keyword\n            arguments when present\n        \"\"\"\n        retval = []\n        for arg in self.code.getargs(var):\n            try:\n                retval.append((arg, self.f_locals[arg]))\n            except KeyError:\n                pass  # this can occur when using Psyco\n        return retval"}, {"id": "_pytest._code.TracebackEntry", "kind": "class", "range": [183, 0, 291, 42, 5522, 8966], "file_path": "src/_pytest/_code/code.py", "content": "class TracebackEntry:\n    \"\"\" a single entry in a traceback \"\"\"\n\n    _repr_style = None  # type: Optional[Literal[\"short\", \"long\"]]\n    exprinfo = None\n\n    def __init__(self, rawentry: TracebackType, excinfo=None) -> None:\n        self._excinfo = excinfo\n        self._rawentry = rawentry\n        self.lineno = rawentry.tb_lineno - 1\n\n    def set_repr_style(self, mode: \"Literal['short', 'long']\") -> None:\n        assert mode in (\"short\", \"long\")\n        self._repr_style = mode\n\n    @property\n    def frame(self) -> Frame:\n        return Frame(self._rawentry.tb_frame)\n\n    @property\n    def relline(self) -> int:\n        return self.lineno - self.frame.code.firstlineno\n\n    def __repr__(self) -> str:\n        return \"<TracebackEntry %s:%d>\" % (self.frame.code.path, self.lineno + 1)\n\n    @property\n    def statement(self) -> \"Source\":\n        \"\"\" _pytest._code.Source object for the current statement \"\"\"\n        source = self.frame.code.fullsource\n        assert source is not None\n        return source.getstatement(self.lineno)\n\n    @property\n    def path(self):\n        \"\"\" path to the source code \"\"\"\n        return self.frame.code.path\n\n    @property\n    def locals(self) -> Dict[str, Any]:\n        \"\"\" locals of underlying frame \"\"\"\n        return self.frame.f_locals\n\n    def getfirstlinesource(self) -> int:\n        return self.frame.code.firstlineno\n\n    def getsource(self, astcache=None) -> Optional[\"Source\"]:\n        \"\"\" return failing source code. \"\"\"\n        # we use the passed in astcache to not reparse asttrees\n        # within exception info printing\n        from _pytest._code.source import getstatementrange_ast\n\n        source = self.frame.code.fullsource\n        if source is None:\n            return None\n        key = astnode = None\n        if astcache is not None:\n            key = self.frame.code.path\n            if key is not None:\n                astnode = astcache.get(key, None)\n        start = self.getfirstlinesource()\n        try:\n            astnode, _, end = getstatementrange_ast(\n                self.lineno, source, astnode=astnode\n            )\n        except SyntaxError:\n            end = self.lineno + 1\n        else:\n            if key is not None:\n                astcache[key] = astnode\n        return source[start:end]\n\n    source = property(getsource)\n\n    def ishidden(self):\n        \"\"\" return True if the current frame has a var __tracebackhide__\n            resolving to True.\n\n            If __tracebackhide__ is a callable, it gets called with the\n            ExceptionInfo instance and can decide whether to hide the traceback.\n\n            mostly for internal use\n        \"\"\"\n        f = self.frame\n        tbh = f.f_locals.get(\n            \"__tracebackhide__\", f.f_globals.get(\"__tracebackhide__\", False)\n        )\n        if tbh and callable(tbh):\n            return tbh(None if self._excinfo is None else self._excinfo())\n        return tbh\n\n    def __str__(self) -> str:\n        try:\n            fn = str(self.path)\n        except py.error.Error:\n            fn = \"???\"\n        name = self.frame.code.name\n        try:\n            line = str(self.statement).lstrip()\n        except KeyboardInterrupt:\n            raise\n        except:  # noqa\n            line = \"???\"\n        return \"  File %r:%d in %s\\n  %s\\n\" % (fn, self.lineno + 1, name, line)\n\n    @property\n    def name(self) -> str:\n        \"\"\" co_name of underlying code \"\"\"\n        return self.frame.code.raw.co_name"}, {"id": "_pytest._code.TracebackEntry._repr_style", "kind": "variable", "range": [186, 4, 186, 22, 5591, 5609], "file_path": "src/_pytest/_code/code.py", "content": "_repr_style = None"}, {"id": "_pytest._code.TracebackEntry.exprinfo", "kind": "variable", "range": [187, 4, 187, 19, 5658, 5673], "file_path": "src/_pytest/_code/code.py", "content": "exprinfo = None"}, {"id": "_pytest._code.TracebackEntry.__init__", "kind": "function", "range": [189, 4, 192, 44, 5679, 5856], "file_path": "src/_pytest/_code/code.py", "content": "def __init__(self, rawentry: TracebackType, excinfo=None) -> None:\n        self._excinfo = excinfo\n        self._rawentry = rawentry\n        self.lineno = rawentry.tb_lineno - 1"}, {"id": "_pytest._code.TracebackEntry.set_repr_style", "kind": "function", "range": [194, 4, 196, 31, 5862, 6002], "file_path": "src/_pytest/_code/code.py", "content": "def set_repr_style(self, mode: \"Literal['short', 'long']\") -> None:\n        assert mode in (\"short\", \"long\")\n        self._repr_style = mode"}, {"id": "_pytest._code.TracebackEntry.frame", "kind": "function", "range": [198, 4, 200, 45, 6008, 6093], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def frame(self) -> Frame:\n        return Frame(self._rawentry.tb_frame)"}, {"id": "_pytest._code.TracebackEntry.relline", "kind": "function", "range": [202, 4, 204, 56, 6099, 6195], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def relline(self) -> int:\n        return self.lineno - self.frame.code.firstlineno"}, {"id": "_pytest._code.TracebackEntry.__repr__", "kind": "function", "range": [206, 4, 207, 81, 6201, 6309], "file_path": "src/_pytest/_code/code.py", "content": "def __repr__(self) -> str:\n        return \"<TracebackEntry %s:%d>\" % (self.frame.code.path, self.lineno + 1)"}, {"id": "_pytest._code.TracebackEntry.statement", "kind": "function", "range": [209, 4, 214, 47, 6315, 6557], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def statement(self) -> \"Source\":\n        \"\"\" _pytest._code.Source object for the current statement \"\"\"\n        source = self.frame.code.fullsource\n        assert source is not None\n        return source.getstatement(self.lineno)"}, {"id": "_pytest._code.TracebackEntry.path", "kind": "function", "range": [216, 4, 219, 35, 6563, 6668], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def path(self):\n        \"\"\" path to the source code \"\"\"\n        return self.frame.code.path"}, {"id": "_pytest._code.TracebackEntry.locals", "kind": "function", "range": [221, 4, 224, 34, 6674, 6801], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def locals(self) -> Dict[str, Any]:\n        \"\"\" locals of underlying frame \"\"\"\n        return self.frame.f_locals"}, {"id": "_pytest._code.TracebackEntry.getfirstlinesource", "kind": "function", "range": [226, 4, 227, 42, 6807, 6886], "file_path": "src/_pytest/_code/code.py", "content": "def getfirstlinesource(self) -> int:\n        return self.frame.code.firstlineno"}, {"id": "_pytest._code.TracebackEntry.getsource", "kind": "function", "range": [229, 4, 253, 32, 6892, 7796], "file_path": "src/_pytest/_code/code.py", "content": "def getsource(self, astcache=None) -> Optional[\"Source\"]:\n        \"\"\" return failing source code. \"\"\"\n        # we use the passed in astcache to not reparse asttrees\n        # within exception info printing\n        from _pytest._code.source import getstatementrange_ast\n\n        source = self.frame.code.fullsource\n        if source is None:\n            return None\n        key = astnode = None\n        if astcache is not None:\n            key = self.frame.code.path\n            if key is not None:\n                astnode = astcache.get(key, None)\n        start = self.getfirstlinesource()\n        try:\n            astnode, _, end = getstatementrange_ast(\n                self.lineno, source, astnode=astnode\n            )\n        except SyntaxError:\n            end = self.lineno + 1\n        else:\n            if key is not None:\n                astcache[key] = astnode\n        return source[start:end]"}, {"id": "_pytest._code.TracebackEntry.source", "kind": "variable", "range": [255, 4, 255, 32, 7802, 7830], "file_path": "src/_pytest/_code/code.py", "content": "source = property(getsource)"}, {"id": "_pytest._code.TracebackEntry.ishidden", "kind": "function", "range": [257, 4, 272, 18, 7836, 8430], "file_path": "src/_pytest/_code/code.py", "content": "def ishidden(self):\n        \"\"\" return True if the current frame has a var __tracebackhide__\n            resolving to True.\n\n            If __tracebackhide__ is a callable, it gets called with the\n            ExceptionInfo instance and can decide whether to hide the traceback.\n\n            mostly for internal use\n        \"\"\"\n        f = self.frame\n        tbh = f.f_locals.get(\n            \"__tracebackhide__\", f.f_globals.get(\"__tracebackhide__\", False)\n        )\n        if tbh and callable(tbh):\n            return tbh(None if self._excinfo is None else self._excinfo())\n        return tbh"}, {"id": "_pytest._code.TracebackEntry.__str__", "kind": "function", "range": [274, 4, 286, 79, 8436, 8838], "file_path": "src/_pytest/_code/code.py", "content": "def __str__(self) -> str:\n        try:\n            fn = str(self.path)\n        except py.error.Error:\n            fn = \"???\"\n        name = self.frame.code.name\n        try:\n            line = str(self.statement).lstrip()\n        except KeyboardInterrupt:\n            raise\n        except:  # noqa\n            line = \"???\"\n        return \"  File %r:%d in %s\\n  %s\\n\" % (fn, self.lineno + 1, name, line)"}, {"id": "_pytest._code.TracebackEntry.name", "kind": "function", "range": [288, 4, 291, 42, 8844, 8966], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def name(self) -> str:\n        \"\"\" co_name of underlying code \"\"\"\n        return self.frame.code.raw.co_name"}, {"id": "_pytest._code.Traceback", "kind": "class", "range": [294, 0, 416, 19, 8969, 13661], "file_path": "src/_pytest/_code/code.py", "content": "class Traceback(List[TracebackEntry]):\n    \"\"\" Traceback objects encapsulate and offer higher level\n        access to Traceback entries.\n    \"\"\"\n\n    def __init__(\n        self,\n        tb: Union[TracebackType, Iterable[TracebackEntry]],\n        excinfo: Optional[\"ReferenceType[ExceptionInfo]\"] = None,\n    ) -> None:\n        \"\"\" initialize from given python traceback object and ExceptionInfo \"\"\"\n        self._excinfo = excinfo\n        if isinstance(tb, TracebackType):\n\n            def f(cur: TracebackType) -> Iterable[TracebackEntry]:\n                cur_ = cur  # type: Optional[TracebackType]\n                while cur_ is not None:\n                    yield TracebackEntry(cur_, excinfo=excinfo)\n                    cur_ = cur_.tb_next\n\n            super().__init__(f(tb))\n        else:\n            super().__init__(tb)\n\n    def cut(\n        self,\n        path=None,\n        lineno: Optional[int] = None,\n        firstlineno: Optional[int] = None,\n        excludepath=None,\n    ) -> \"Traceback\":\n        \"\"\" return a Traceback instance wrapping part of this Traceback\n\n            by providing any combination of path, lineno and firstlineno, the\n            first frame to start the to-be-returned traceback is determined\n\n            this allows cutting the first part of a Traceback instance e.g.\n            for formatting reasons (removing some uninteresting bits that deal\n            with handling of the exception/traceback)\n        \"\"\"\n        for x in self:\n            code = x.frame.code\n            codepath = code.path\n            if (\n                (path is None or codepath == path)\n                and (\n                    excludepath is None\n                    or not isinstance(codepath, py.path.local)\n                    or not codepath.relto(excludepath)\n                )\n                and (lineno is None or x.lineno == lineno)\n                and (firstlineno is None or x.frame.code.firstlineno == firstlineno)\n            ):\n                return Traceback(x._rawentry, self._excinfo)\n        return self\n\n    @overload\n    def __getitem__(self, key: int) -> TracebackEntry:\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __getitem__(self, key: slice) -> \"Traceback\":  # noqa: F811\n        raise NotImplementedError()\n\n    def __getitem__(  # noqa: F811\n        self, key: Union[int, slice]\n    ) -> Union[TracebackEntry, \"Traceback\"]:\n        if isinstance(key, slice):\n            return self.__class__(super().__getitem__(key))\n        else:\n            return super().__getitem__(key)\n\n    def filter(\n        self, fn: Callable[[TracebackEntry], bool] = lambda x: not x.ishidden()\n    ) -> \"Traceback\":\n        \"\"\" return a Traceback instance with certain items removed\n\n            fn is a function that gets a single argument, a TracebackEntry\n            instance, and should return True when the item should be added\n            to the Traceback, False when not\n\n            by default this removes all the TracebackEntries which are hidden\n            (see ishidden() above)\n        \"\"\"\n        return Traceback(filter(fn, self), self._excinfo)\n\n    def getcrashentry(self) -> TracebackEntry:\n        \"\"\" return last non-hidden traceback entry that lead\n        to the exception of a traceback.\n        \"\"\"\n        for i in range(-1, -len(self) - 1, -1):\n            entry = self[i]\n            if not entry.ishidden():\n                return entry\n        return self[-1]\n\n    def recursionindex(self) -> Optional[int]:\n        \"\"\" return the index of the frame/TracebackEntry where recursion\n            originates if appropriate, None if no recursion occurred\n        \"\"\"\n        cache = {}  # type: Dict[Tuple[Any, int, int], List[Dict[str, Any]]]\n        for i, entry in enumerate(self):\n            # id for the code.raw is needed to work around\n            # the strange metaprogramming in the decorator lib from pypi\n            # which generates code objects that have hash/value equality\n            # XXX needs a test\n            key = entry.frame.code.path, id(entry.frame.code.raw), entry.lineno\n            # print \"checking for recursion at\", key\n            values = cache.setdefault(key, [])\n            if values:\n                f = entry.frame\n                loc = f.f_locals\n                for otherloc in values:\n                    if f.is_true(\n                        f.eval(\n                            co_equal,\n                            __recursioncache_locals_1=loc,\n                            __recursioncache_locals_2=otherloc,\n                        )\n                    ):\n                        return i\n            values.append(entry.frame.f_locals)\n        return None"}, {"id": "_pytest._code.Traceback.__init__", "kind": "function", "range": [299, 4, 316, 32, 9119, 9797], "file_path": "src/_pytest/_code/code.py", "content": "def __init__(\n        self,\n        tb: Union[TracebackType, Iterable[TracebackEntry]],\n        excinfo: Optional[\"ReferenceType[ExceptionInfo]\"] = None,\n    ) -> None:\n        \"\"\" initialize from given python traceback object and ExceptionInfo \"\"\"\n        self._excinfo = excinfo\n        if isinstance(tb, TracebackType):\n\n            def f(cur: TracebackType) -> Iterable[TracebackEntry]:\n                cur_ = cur  # type: Optional[TracebackType]\n                while cur_ is not None:\n                    yield TracebackEntry(cur_, excinfo=excinfo)\n                    cur_ = cur_.tb_next\n\n            super().__init__(f(tb))\n        else:\n            super().__init__(tb)"}, {"id": "_pytest._code.Traceback.cut", "kind": "function", "range": [318, 4, 348, 19, 9803, 11016], "file_path": "src/_pytest/_code/code.py", "content": "def cut(\n        self,\n        path=None,\n        lineno: Optional[int] = None,\n        firstlineno: Optional[int] = None,\n        excludepath=None,\n    ) -> \"Traceback\":\n        \"\"\" return a Traceback instance wrapping part of this Traceback\n\n            by providing any combination of path, lineno and firstlineno, the\n            first frame to start the to-be-returned traceback is determined\n\n            this allows cutting the first part of a Traceback instance e.g.\n            for formatting reasons (removing some uninteresting bits that deal\n            with handling of the exception/traceback)\n        \"\"\"\n        for x in self:\n            code = x.frame.code\n            codepath = code.path\n            if (\n                (path is None or codepath == path)\n                and (\n                    excludepath is None\n                    or not isinstance(codepath, py.path.local)\n                    or not codepath.relto(excludepath)\n                )\n                and (lineno is None or x.lineno == lineno)\n                and (firstlineno is None or x.frame.code.firstlineno == firstlineno)\n            ):\n                return Traceback(x._rawentry, self._excinfo)\n        return self"}, {"id": "_pytest._code.Traceback.__getitem__", "kind": "function", "range": [350, 4, 352, 35, 11022, 11122], "file_path": "src/_pytest/_code/code.py", "content": "@overload\n    def __getitem__(self, key: int) -> TracebackEntry:\n        raise NotImplementedError()"}, {"id": "_pytest._code.Traceback.__getitem__", "kind": "function", "range": [354, 4, 356, 35, 11128, 11255], "file_path": "src/_pytest/_code/code.py", "content": "@overload  # noqa: F811\n    def __getitem__(self, key: slice) -> \"Traceback\":  # noqa: F811\n        raise NotImplementedError()"}, {"id": "_pytest._code.Traceback.__getitem__", "kind": "function", "range": [358, 4, 364, 43, 11261, 11526], "file_path": "src/_pytest/_code/code.py", "content": "def __getitem__(  # noqa: F811\n        self, key: Union[int, slice]\n    ) -> Union[TracebackEntry, \"Traceback\"]:\n        if isinstance(key, slice):\n            return self.__class__(super().__getitem__(key))\n        else:\n            return super().__getitem__(key)"}, {"id": "_pytest._code.Traceback.filter", "kind": "function", "range": [366, 4, 378, 57, 11532, 12092], "file_path": "src/_pytest/_code/code.py", "content": "def filter(\n        self, fn: Callable[[TracebackEntry], bool] = lambda x: not x.ishidden()\n    ) -> \"Traceback\":\n        \"\"\" return a Traceback instance with certain items removed\n\n            fn is a function that gets a single argument, a TracebackEntry\n            instance, and should return True when the item should be added\n            to the Traceback, False when not\n\n            by default this removes all the TracebackEntries which are hidden\n            (see ishidden() above)\n        \"\"\"\n        return Traceback(filter(fn, self), self._excinfo)"}, {"id": "_pytest._code.Traceback.getcrashentry", "kind": "function", "range": [380, 4, 388, 23, 12098, 12420], "file_path": "src/_pytest/_code/code.py", "content": "def getcrashentry(self) -> TracebackEntry:\n        \"\"\" return last non-hidden traceback entry that lead\n        to the exception of a traceback.\n        \"\"\"\n        for i in range(-1, -len(self) - 1, -1):\n            entry = self[i]\n            if not entry.ishidden():\n                return entry\n        return self[-1]"}, {"id": "_pytest._code.Traceback.recursionindex", "kind": "function", "range": [390, 4, 416, 19, 12426, 13661], "file_path": "src/_pytest/_code/code.py", "content": "def recursionindex(self) -> Optional[int]:\n        \"\"\" return the index of the frame/TracebackEntry where recursion\n            originates if appropriate, None if no recursion occurred\n        \"\"\"\n        cache = {}  # type: Dict[Tuple[Any, int, int], List[Dict[str, Any]]]\n        for i, entry in enumerate(self):\n            # id for the code.raw is needed to work around\n            # the strange metaprogramming in the decorator lib from pypi\n            # which generates code objects that have hash/value equality\n            # XXX needs a test\n            key = entry.frame.code.path, id(entry.frame.code.raw), entry.lineno\n            # print \"checking for recursion at\", key\n            values = cache.setdefault(key, [])\n            if values:\n                f = entry.frame\n                loc = f.f_locals\n                for otherloc in values:\n                    if f.is_true(\n                        f.eval(\n                            co_equal,\n                            __recursioncache_locals_1=loc,\n                            __recursioncache_locals_2=otherloc,\n                        )\n                    ):\n                        return i\n            values.append(entry.frame.f_locals)\n        return None"}, {"id": "_pytest._code.co_equal", "kind": "variable", "range": [419, 0, 421, 1, 13664, 13759], "file_path": "src/_pytest/_code/code.py", "content": "co_equal = compile(\n    \"__recursioncache_locals_1 == __recursioncache_locals_2\", \"?\", \"eval\"\n)"}, {"id": "_pytest._code._E", "kind": "variable", "range": [424, 0, 424, 39, 13762, 13801], "file_path": "src/_pytest/_code/code.py", "content": "_E = TypeVar(\"_E\", bound=BaseException)"}, {"id": "_pytest._code.ExceptionInfo", "kind": "class", "range": [427, 0, 648, 19, 13804, 21496], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(repr=False)\nclass ExceptionInfo(Generic[_E]):\n    \"\"\" wraps sys.exc_info() objects and offers\n        help for navigating the traceback.\n    \"\"\"\n\n    _assert_start_repr = \"AssertionError('assert \"\n\n    _excinfo = attr.ib(type=Optional[Tuple[\"Type[_E]\", \"_E\", TracebackType]])\n    _striptext = attr.ib(type=str, default=\"\")\n    _traceback = attr.ib(type=Optional[Traceback], default=None)\n\n    @classmethod\n    def from_exc_info(\n        cls,\n        exc_info: Tuple[\"Type[_E]\", \"_E\", TracebackType],\n        exprinfo: Optional[str] = None,\n    ) -> \"ExceptionInfo[_E]\":\n        \"\"\"returns an ExceptionInfo for an existing exc_info tuple.\n\n        .. warning::\n\n            Experimental API\n\n\n        :param exprinfo: a text string helping to determine if we should\n                         strip ``AssertionError`` from the output, defaults\n                         to the exception message/``__str__()``\n        \"\"\"\n        _striptext = \"\"\n        if exprinfo is None and isinstance(exc_info[1], AssertionError):\n            exprinfo = getattr(exc_info[1], \"msg\", None)\n            if exprinfo is None:\n                exprinfo = saferepr(exc_info[1])\n            if exprinfo and exprinfo.startswith(cls._assert_start_repr):\n                _striptext = \"AssertionError: \"\n\n        return cls(exc_info, _striptext)\n\n    @classmethod\n    def from_current(\n        cls, exprinfo: Optional[str] = None\n    ) -> \"ExceptionInfo[BaseException]\":\n        \"\"\"returns an ExceptionInfo matching the current traceback\n\n        .. warning::\n\n            Experimental API\n\n\n        :param exprinfo: a text string helping to determine if we should\n                         strip ``AssertionError`` from the output, defaults\n                         to the exception message/``__str__()``\n        \"\"\"\n        tup = sys.exc_info()\n        assert tup[0] is not None, \"no current exception\"\n        assert tup[1] is not None, \"no current exception\"\n        assert tup[2] is not None, \"no current exception\"\n        exc_info = (tup[0], tup[1], tup[2])\n        return ExceptionInfo.from_exc_info(exc_info, exprinfo)\n\n    @classmethod\n    def for_later(cls) -> \"ExceptionInfo[_E]\":\n        \"\"\"return an unfilled ExceptionInfo\n        \"\"\"\n        return cls(None)\n\n    def fill_unfilled(self, exc_info: Tuple[\"Type[_E]\", _E, TracebackType]) -> None:\n        \"\"\"fill an unfilled ExceptionInfo created with for_later()\"\"\"\n        assert self._excinfo is None, \"ExceptionInfo was already filled\"\n        self._excinfo = exc_info\n\n    @property\n    def type(self) -> \"Type[_E]\":\n        \"\"\"the exception class\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".type can only be used after the context manager exits\"\n        return self._excinfo[0]\n\n    @property\n    def value(self) -> _E:\n        \"\"\"the exception value\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".value can only be used after the context manager exits\"\n        return self._excinfo[1]\n\n    @property\n    def tb(self) -> TracebackType:\n        \"\"\"the exception raw traceback\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".tb can only be used after the context manager exits\"\n        return self._excinfo[2]\n\n    @property\n    def typename(self) -> str:\n        \"\"\"the type name of the exception\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".typename can only be used after the context manager exits\"\n        return self.type.__name__\n\n    @property\n    def traceback(self) -> Traceback:\n        \"\"\"the traceback\"\"\"\n        if self._traceback is None:\n            self._traceback = Traceback(self.tb, excinfo=ref(self))\n        return self._traceback\n\n    @traceback.setter\n    def traceback(self, value: Traceback) -> None:\n        self._traceback = value\n\n    def __repr__(self) -> str:\n        if self._excinfo is None:\n            return \"<ExceptionInfo for raises contextmanager>\"\n        return \"<{} {} tblen={}>\".format(\n            self.__class__.__name__, saferepr(self._excinfo[1]), len(self.traceback)\n        )\n\n    def exconly(self, tryshort: bool = False) -> str:\n        \"\"\" return the exception as a string\n\n            when 'tryshort' resolves to True, and the exception is a\n            _pytest._code._AssertionError, only the actual exception part of\n            the exception representation is returned (so 'AssertionError: ' is\n            removed from the beginning)\n        \"\"\"\n        lines = format_exception_only(self.type, self.value)\n        text = \"\".join(lines)\n        text = text.rstrip()\n        if tryshort:\n            if text.startswith(self._striptext):\n                text = text[len(self._striptext) :]\n        return text\n\n    def errisinstance(\n        self, exc: Union[\"Type[BaseException]\", Tuple[\"Type[BaseException]\", ...]]\n    ) -> bool:\n        \"\"\" return True if the exception is an instance of exc \"\"\"\n        return isinstance(self.value, exc)\n\n    def _getreprcrash(self) -> \"ReprFileLocation\":\n        exconly = self.exconly(tryshort=True)\n        entry = self.traceback.getcrashentry()\n        path, lineno = entry.frame.code.raw.co_filename, entry.lineno\n        return ReprFileLocation(path, lineno + 1, exconly)\n\n    def getrepr(\n        self,\n        showlocals: bool = False,\n        style: \"_TracebackStyle\" = \"long\",\n        abspath: bool = False,\n        tbfilter: bool = True,\n        funcargs: bool = False,\n        truncate_locals: bool = True,\n        chain: bool = True,\n    ) -> Union[\"ReprExceptionInfo\", \"ExceptionChainRepr\"]:\n        \"\"\"\n        Return str()able representation of this exception info.\n\n        :param bool showlocals:\n            Show locals per traceback entry.\n            Ignored if ``style==\"native\"``.\n\n        :param str style: long|short|no|native traceback style\n\n        :param bool abspath:\n            If paths should be changed to absolute or left unchanged.\n\n        :param bool tbfilter:\n            Hide entries that contain a local variable ``__tracebackhide__==True``.\n            Ignored if ``style==\"native\"``.\n\n        :param bool funcargs:\n            Show fixtures (\"funcargs\" for legacy purposes) per traceback entry.\n\n        :param bool truncate_locals:\n            With ``showlocals==True``, make sure locals can be safely represented as strings.\n\n        :param bool chain: if chained exceptions in Python 3 should be shown.\n\n        .. versionchanged:: 3.9\n\n            Added the ``chain`` parameter.\n        \"\"\"\n        if style == \"native\":\n            return ReprExceptionInfo(\n                ReprTracebackNative(\n                    traceback.format_exception(\n                        self.type, self.value, self.traceback[0]._rawentry\n                    )\n                ),\n                self._getreprcrash(),\n            )\n\n        fmt = FormattedExcinfo(\n            showlocals=showlocals,\n            style=style,\n            abspath=abspath,\n            tbfilter=tbfilter,\n            funcargs=funcargs,\n            truncate_locals=truncate_locals,\n            chain=chain,\n        )\n        return fmt.repr_excinfo(self)\n\n    def match(self, regexp: \"Union[str, Pattern]\") -> \"Literal[True]\":\n        \"\"\"\n        Check whether the regular expression `regexp` matches the string\n        representation of the exception using :func:`python:re.search`.\n        If it matches `True` is returned.\n        If it doesn't match an `AssertionError` is raised.\n        \"\"\"\n        __tracebackhide__ = True\n        assert re.search(\n            regexp, str(self.value)\n        ), \"Pattern {!r} does not match {!r}\".format(regexp, str(self.value))\n        # Return True to allow for \"assert excinfo.match()\".\n        return True"}, {"id": "_pytest._code.ExceptionInfo._assert_start_repr", "kind": "variable", "range": [433, 4, 433, 50, 13962, 14008], "file_path": "src/_pytest/_code/code.py", "content": "_assert_start_repr = \"AssertionError('assert \""}, {"id": "_pytest._code.ExceptionInfo._excinfo", "kind": "variable", "range": [435, 4, 435, 77, 14014, 14087], "file_path": "src/_pytest/_code/code.py", "content": "_excinfo = attr.ib(type=Optional[Tuple[\"Type[_E]\", \"_E\", TracebackType]])"}, {"id": "_pytest._code.ExceptionInfo._striptext", "kind": "variable", "range": [436, 4, 436, 46, 14092, 14134], "file_path": "src/_pytest/_code/code.py", "content": "_striptext = attr.ib(type=str, default=\"\")"}, {"id": "_pytest._code.ExceptionInfo._traceback", "kind": "variable", "range": [437, 4, 437, 64, 14139, 14199], "file_path": "src/_pytest/_code/code.py", "content": "_traceback = attr.ib(type=Optional[Traceback], default=None)"}, {"id": "_pytest._code.ExceptionInfo.from_exc_info", "kind": "function", "range": [439, 4, 464, 40, 14205, 15127], "file_path": "src/_pytest/_code/code.py", "content": "@classmethod\n    def from_exc_info(\n        cls,\n        exc_info: Tuple[\"Type[_E]\", \"_E\", TracebackType],\n        exprinfo: Optional[str] = None,\n    ) -> \"ExceptionInfo[_E]\":\n        \"\"\"returns an ExceptionInfo for an existing exc_info tuple.\n\n        .. warning::\n\n            Experimental API\n\n\n        :param exprinfo: a text string helping to determine if we should\n                         strip ``AssertionError`` from the output, defaults\n                         to the exception message/``__str__()``\n        \"\"\"\n        _striptext = \"\"\n        if exprinfo is None and isinstance(exc_info[1], AssertionError):\n            exprinfo = getattr(exc_info[1], \"msg\", None)\n            if exprinfo is None:\n                exprinfo = saferepr(exc_info[1])\n            if exprinfo and exprinfo.startswith(cls._assert_start_repr):\n                _striptext = \"AssertionError: \"\n\n        return cls(exc_info, _striptext)"}, {"id": "_pytest._code.ExceptionInfo.from_current", "kind": "function", "range": [466, 4, 486, 62, 15133, 15908], "file_path": "src/_pytest/_code/code.py", "content": "@classmethod\n    def from_current(\n        cls, exprinfo: Optional[str] = None\n    ) -> \"ExceptionInfo[BaseException]\":\n        \"\"\"returns an ExceptionInfo matching the current traceback\n\n        .. warning::\n\n            Experimental API\n\n\n        :param exprinfo: a text string helping to determine if we should\n                         strip ``AssertionError`` from the output, defaults\n                         to the exception message/``__str__()``\n        \"\"\"\n        tup = sys.exc_info()\n        assert tup[0] is not None, \"no current exception\"\n        assert tup[1] is not None, \"no current exception\"\n        assert tup[2] is not None, \"no current exception\"\n        exc_info = (tup[0], tup[1], tup[2])\n        return ExceptionInfo.from_exc_info(exc_info, exprinfo)"}, {"id": "_pytest._code.ExceptionInfo.for_later", "kind": "function", "range": [488, 4, 492, 24, 15914, 16054], "file_path": "src/_pytest/_code/code.py", "content": "@classmethod\n    def for_later(cls) -> \"ExceptionInfo[_E]\":\n        \"\"\"return an unfilled ExceptionInfo\n        \"\"\"\n        return cls(None)"}, {"id": "_pytest._code.ExceptionInfo.fill_unfilled", "kind": "function", "range": [494, 4, 497, 32, 16060, 16316], "file_path": "src/_pytest/_code/code.py", "content": "def fill_unfilled(self, exc_info: Tuple[\"Type[_E]\", _E, TracebackType]) -> None:\n        \"\"\"fill an unfilled ExceptionInfo created with for_later()\"\"\"\n        assert self._excinfo is None, \"ExceptionInfo was already filled\"\n        self._excinfo = exc_info"}, {"id": "_pytest._code.ExceptionInfo.type", "kind": "function", "range": [499, 4, 505, 31, 16322, 16554], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def type(self) -> \"Type[_E]\":\n        \"\"\"the exception class\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".type can only be used after the context manager exits\"\n        return self._excinfo[0]"}, {"id": "_pytest._code.ExceptionInfo.value", "kind": "function", "range": [507, 4, 513, 31, 16560, 16786], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def value(self) -> _E:\n        \"\"\"the exception value\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".value can only be used after the context manager exits\"\n        return self._excinfo[1]"}, {"id": "_pytest._code.ExceptionInfo.tb", "kind": "function", "range": [515, 4, 521, 31, 16792, 17031], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def tb(self) -> TracebackType:\n        \"\"\"the exception raw traceback\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".tb can only be used after the context manager exits\"\n        return self._excinfo[2]"}, {"id": "_pytest._code.ExceptionInfo.typename", "kind": "function", "range": [523, 4, 529, 33, 17037, 17283], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def typename(self) -> str:\n        \"\"\"the type name of the exception\"\"\"\n        assert (\n            self._excinfo is not None\n        ), \".typename can only be used after the context manager exits\"\n        return self.type.__name__"}, {"id": "_pytest._code.ExceptionInfo.traceback", "kind": "function", "range": [531, 4, 536, 30, 17289, 17499], "file_path": "src/_pytest/_code/code.py", "content": "@property\n    def traceback(self) -> Traceback:\n        \"\"\"the traceback\"\"\"\n        if self._traceback is None:\n            self._traceback = Traceback(self.tb, excinfo=ref(self))\n        return self._traceback"}, {"id": "_pytest._code.ExceptionInfo.traceback", "kind": "function", "range": [538, 4, 540, 31, 17505, 17605], "file_path": "src/_pytest/_code/code.py", "content": "@traceback.setter\n    def traceback(self, value: Traceback) -> None:\n        self._traceback = value"}, {"id": "_pytest._code.ExceptionInfo.__repr__", "kind": "function", "range": [542, 4, 547, 9, 17611, 17871], "file_path": "src/_pytest/_code/code.py", "content": "def __repr__(self) -> str:\n        if self._excinfo is None:\n            return \"<ExceptionInfo for raises contextmanager>\"\n        return \"<{} {} tblen={}>\".format(\n            self.__class__.__name__, saferepr(self._excinfo[1]), len(self.traceback)\n        )"}, {"id": "_pytest._code.ExceptionInfo.exconly", "kind": "function", "range": [549, 4, 563, 19, 17877, 18511], "file_path": "src/_pytest/_code/code.py", "content": "def exconly(self, tryshort: bool = False) -> str:\n        \"\"\" return the exception as a string\n\n            when 'tryshort' resolves to True, and the exception is a\n            _pytest._code._AssertionError, only the actual exception part of\n            the exception representation is returned (so 'AssertionError: ' is\n            removed from the beginning)\n        \"\"\"\n        lines = format_exception_only(self.type, self.value)\n        text = \"\".join(lines)\n        text = text.rstrip()\n        if tryshort:\n            if text.startswith(self._striptext):\n                text = text[len(self._striptext) :]\n        return text"}, {"id": "_pytest._code.ExceptionInfo.errisinstance", "kind": "function", "range": [565, 4, 569, 42, 18517, 18743], "file_path": "src/_pytest/_code/code.py", "content": "def errisinstance(\n        self, exc: Union[\"Type[BaseException]\", Tuple[\"Type[BaseException]\", ...]]\n    ) -> bool:\n        \"\"\" return True if the exception is an instance of exc \"\"\"\n        return isinstance(self.value, exc)"}, {"id": "_pytest._code.ExceptionInfo._getreprcrash", "kind": "function", "range": [571, 4, 575, 58, 18749, 19017], "file_path": "src/_pytest/_code/code.py", "content": "def _getreprcrash(self) -> \"ReprFileLocation\":\n        exconly = self.exconly(tryshort=True)\n        entry = self.traceback.getcrashentry()\n        path, lineno = entry.frame.code.raw.co_filename, entry.lineno\n        return ReprFileLocation(path, lineno + 1, exconly)"}, {"id": "_pytest._code.ExceptionInfo.getrepr", "kind": "function", "range": [577, 4, 634, 37, 19023, 20900], "file_path": "src/_pytest/_code/code.py", "content": "def getrepr(\n        self,\n        showlocals: bool = False,\n        style: \"_TracebackStyle\" = \"long\",\n        abspath: bool = False,\n        tbfilter: bool = True,\n        funcargs: bool = False,\n        truncate_locals: bool = True,\n        chain: bool = True,\n    ) -> Union[\"ReprExceptionInfo\", \"ExceptionChainRepr\"]:\n        \"\"\"\n        Return str()able representation of this exception info.\n\n        :param bool showlocals:\n            Show locals per traceback entry.\n            Ignored if ``style==\"native\"``.\n\n        :param str style: long|short|no|native traceback style\n\n        :param bool abspath:\n            If paths should be changed to absolute or left unchanged.\n\n        :param bool tbfilter:\n            Hide entries that contain a local variable ``__tracebackhide__==True``.\n            Ignored if ``style==\"native\"``.\n\n        :param bool funcargs:\n            Show fixtures (\"funcargs\" for legacy purposes) per traceback entry.\n\n        :param bool truncate_locals:\n            With ``showlocals==True``, make sure locals can be safely represented as strings.\n\n        :param bool chain: if chained exceptions in Python 3 should be shown.\n\n        .. versionchanged:: 3.9\n\n            Added the ``chain`` parameter.\n        \"\"\"\n        if style == \"native\":\n            return ReprExceptionInfo(\n                ReprTracebackNative(\n                    traceback.format_exception(\n                        self.type, self.value, self.traceback[0]._rawentry\n                    )\n                ),\n                self._getreprcrash(),\n            )\n\n        fmt = FormattedExcinfo(\n            showlocals=showlocals,\n            style=style,\n            abspath=abspath,\n            tbfilter=tbfilter,\n            funcargs=funcargs,\n            truncate_locals=truncate_locals,\n            chain=chain,\n        )\n        return fmt.repr_excinfo(self)"}, {"id": "_pytest._code.ExceptionInfo.match", "kind": "function", "range": [636, 4, 648, 19, 20906, 21496], "file_path": "src/_pytest/_code/code.py", "content": "def match(self, regexp: \"Union[str, Pattern]\") -> \"Literal[True]\":\n        \"\"\"\n        Check whether the regular expression `regexp` matches the string\n        representation of the exception using :func:`python:re.search`.\n        If it matches `True` is returned.\n        If it doesn't match an `AssertionError` is raised.\n        \"\"\"\n        __tracebackhide__ = True\n        assert re.search(\n            regexp, str(self.value)\n        ), \"Pattern {!r} does not match {!r}\".format(regexp, str(self.value))\n        # Return True to allow for \"assert excinfo.match()\".\n        return True"}, {"id": "_pytest._code.FormattedExcinfo", "kind": "class", "range": [651, 0, 911, 45, 21499, 32060], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s\nclass FormattedExcinfo:\n    \"\"\" presenting information about failing Functions and Generators. \"\"\"\n\n    # for traceback entries\n    flow_marker = \">\"\n    fail_marker = \"E\"\n\n    showlocals = attr.ib(type=bool, default=False)\n    style = attr.ib(type=\"_TracebackStyle\", default=\"long\")\n    abspath = attr.ib(type=bool, default=True)\n    tbfilter = attr.ib(type=bool, default=True)\n    funcargs = attr.ib(type=bool, default=False)\n    truncate_locals = attr.ib(type=bool, default=True)\n    chain = attr.ib(type=bool, default=True)\n    astcache = attr.ib(default=attr.Factory(dict), init=False, repr=False)\n\n    def _getindent(self, source: \"Source\") -> int:\n        # figure out indent for given source\n        try:\n            s = str(source.getstatement(len(source) - 1))\n        except KeyboardInterrupt:\n            raise\n        except:  # noqa\n            try:\n                s = str(source[-1])\n            except KeyboardInterrupt:\n                raise\n            except:  # noqa\n                return 0\n        return 4 + (len(s) - len(s.lstrip()))\n\n    def _getentrysource(self, entry: TracebackEntry) -> Optional[\"Source\"]:\n        source = entry.getsource(self.astcache)\n        if source is not None:\n            source = source.deindent()\n        return source\n\n    def repr_args(self, entry: TracebackEntry) -> Optional[\"ReprFuncArgs\"]:\n        if self.funcargs:\n            args = []\n            for argname, argvalue in entry.frame.getargs(var=True):\n                args.append((argname, saferepr(argvalue)))\n            return ReprFuncArgs(args)\n        return None\n\n    def get_source(\n        self,\n        source: \"Source\",\n        line_index: int = -1,\n        excinfo: Optional[ExceptionInfo] = None,\n        short: bool = False,\n    ) -> List[str]:\n        \"\"\" return formatted and marked up source lines. \"\"\"\n        import _pytest._code\n\n        lines = []\n        if source is None or line_index >= len(source.lines):\n            source = _pytest._code.Source(\"???\")\n            line_index = 0\n        if line_index < 0:\n            line_index += len(source)\n        space_prefix = \"    \"\n        if short:\n            lines.append(space_prefix + source.lines[line_index].strip())\n        else:\n            for line in source.lines[:line_index]:\n                lines.append(space_prefix + line)\n            lines.append(self.flow_marker + \"   \" + source.lines[line_index])\n            for line in source.lines[line_index + 1 :]:\n                lines.append(space_prefix + line)\n        if excinfo is not None:\n            indent = 4 if short else self._getindent(source)\n            lines.extend(self.get_exconly(excinfo, indent=indent, markall=True))\n        return lines\n\n    def get_exconly(\n        self, excinfo: ExceptionInfo, indent: int = 4, markall: bool = False\n    ) -> List[str]:\n        lines = []\n        indentstr = \" \" * indent\n        # get the real exception information out\n        exlines = excinfo.exconly(tryshort=True).split(\"\\n\")\n        failindent = self.fail_marker + indentstr[1:]\n        for line in exlines:\n            lines.append(failindent + line)\n            if not markall:\n                failindent = indentstr\n        return lines\n\n    def repr_locals(self, locals: Dict[str, object]) -> Optional[\"ReprLocals\"]:\n        if self.showlocals:\n            lines = []\n            keys = [loc for loc in locals if loc[0] != \"@\"]\n            keys.sort()\n            for name in keys:\n                value = locals[name]\n                if name == \"__builtins__\":\n                    lines.append(\"__builtins__ = <builtins>\")\n                else:\n                    # This formatting could all be handled by the\n                    # _repr() function, which is only reprlib.Repr in\n                    # disguise, so is very configurable.\n                    if self.truncate_locals:\n                        str_repr = saferepr(value)\n                    else:\n                        str_repr = safeformat(value)\n                    # if len(str_repr) < 70 or not isinstance(value,\n                    #                            (list, tuple, dict)):\n                    lines.append(\"{:<10} = {}\".format(name, str_repr))\n                    # else:\n                    #    self._line(\"%-10s =\\\\\" % (name,))\n                    #    # XXX\n                    #    pprint.pprint(value, stream=self.excinfowriter)\n            return ReprLocals(lines)\n        return None\n\n    def repr_traceback_entry(\n        self, entry: TracebackEntry, excinfo: Optional[ExceptionInfo] = None\n    ) -> \"ReprEntry\":\n        import _pytest._code\n\n        source = self._getentrysource(entry)\n        if source is None:\n            source = _pytest._code.Source(\"???\")\n            line_index = 0\n        else:\n            line_index = entry.lineno - entry.getfirstlinesource()\n\n        lines = []  # type: List[str]\n        style = entry._repr_style if entry._repr_style is not None else self.style\n        if style in (\"short\", \"long\"):\n            short = style == \"short\"\n            reprargs = self.repr_args(entry) if not short else None\n            s = self.get_source(source, line_index, excinfo, short=short)\n            lines.extend(s)\n            if short:\n                message = \"in %s\" % (entry.name)\n            else:\n                message = excinfo and excinfo.typename or \"\"\n            path = self._makepath(entry.path)\n            reprfileloc = ReprFileLocation(path, entry.lineno + 1, message)\n            localsrepr = self.repr_locals(entry.locals)\n            return ReprEntry(lines, reprargs, localsrepr, reprfileloc, style)\n        if excinfo:\n            lines.extend(self.get_exconly(excinfo, indent=4))\n        return ReprEntry(lines, None, None, None, style)\n\n    def _makepath(self, path):\n        if not self.abspath:\n            try:\n                np = py.path.local().bestrelpath(path)\n            except OSError:\n                return path\n            if len(np) < len(str(path)):\n                path = np\n        return path\n\n    def repr_traceback(self, excinfo: ExceptionInfo) -> \"ReprTraceback\":\n        traceback = excinfo.traceback\n        if self.tbfilter:\n            traceback = traceback.filter()\n\n        if excinfo.errisinstance(RecursionError):\n            traceback, extraline = self._truncate_recursive_traceback(traceback)\n        else:\n            extraline = None\n\n        last = traceback[-1]\n        entries = []\n        for index, entry in enumerate(traceback):\n            einfo = (last == entry) and excinfo or None\n            reprentry = self.repr_traceback_entry(entry, einfo)\n            entries.append(reprentry)\n        return ReprTraceback(entries, extraline, style=self.style)\n\n    def _truncate_recursive_traceback(\n        self, traceback: Traceback\n    ) -> Tuple[Traceback, Optional[str]]:\n        \"\"\"\n        Truncate the given recursive traceback trying to find the starting point\n        of the recursion.\n\n        The detection is done by going through each traceback entry and finding the\n        point in which the locals of the frame are equal to the locals of a previous frame (see ``recursionindex()``.\n\n        Handle the situation where the recursion process might raise an exception (for example\n        comparing numpy arrays using equality raises a TypeError), in which case we do our best to\n        warn the user of the error and show a limited traceback.\n        \"\"\"\n        try:\n            recursionindex = traceback.recursionindex()\n        except Exception as e:\n            max_frames = 10\n            extraline = (\n                \"!!! Recursion error detected, but an error occurred locating the origin of recursion.\\n\"\n                \"  The following exception happened when comparing locals in the stack frame:\\n\"\n                \"    {exc_type}: {exc_msg}\\n\"\n                \"  Displaying first and last {max_frames} stack frames out of {total}.\"\n            ).format(\n                exc_type=type(e).__name__,\n                exc_msg=str(e),\n                max_frames=max_frames,\n                total=len(traceback),\n            )  # type: Optional[str]\n            # Type ignored because adding two instaces of a List subtype\n            # currently incorrectly has type List instead of the subtype.\n            traceback = traceback[:max_frames] + traceback[-max_frames:]  # type: ignore\n        else:\n            if recursionindex is not None:\n                extraline = \"!!! Recursion detected (same locals & position)\"\n                traceback = traceback[: recursionindex + 1]\n            else:\n                extraline = None\n\n        return traceback, extraline\n\n    def repr_excinfo(self, excinfo: ExceptionInfo) -> \"ExceptionChainRepr\":\n        repr_chain = (\n            []\n        )  # type: List[Tuple[ReprTraceback, Optional[ReprFileLocation], Optional[str]]]\n        e = excinfo.value\n        excinfo_ = excinfo  # type: Optional[ExceptionInfo]\n        descr = None\n        seen = set()  # type: Set[int]\n        while e is not None and id(e) not in seen:\n            seen.add(id(e))\n            if excinfo_:\n                reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()  # type: Optional[ReprFileLocation]\n            else:\n                # fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work\n                reprtraceback = ReprTracebackNative(\n                    traceback.format_exception(type(e), e, None)\n                )\n                reprcrash = None\n\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = (\n                    ExceptionInfo((type(e), e, e.__traceback__))\n                    if e.__traceback__\n                    else None\n                )\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = (\n                    ExceptionInfo((type(e), e, e.__traceback__))\n                    if e.__traceback__\n                    else None\n                )\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)"}, {"id": "_pytest._code.FormattedExcinfo.flow_marker", "kind": "variable", "range": [656, 4, 656, 21, 21639, 21656], "file_path": "src/_pytest/_code/code.py", "content": "flow_marker = \">\""}, {"id": "_pytest._code.FormattedExcinfo.fail_marker", "kind": "variable", "range": [657, 4, 657, 21, 21661, 21678], "file_path": "src/_pytest/_code/code.py", "content": "fail_marker = \"E\""}, {"id": "_pytest._code.FormattedExcinfo.showlocals", "kind": "variable", "range": [659, 4, 659, 50, 21684, 21730], "file_path": "src/_pytest/_code/code.py", "content": "showlocals = attr.ib(type=bool, default=False)"}, {"id": "_pytest._code.FormattedExcinfo.style", "kind": "variable", "range": [660, 4, 660, 59, 21735, 21790], "file_path": "src/_pytest/_code/code.py", "content": "style = attr.ib(type=\"_TracebackStyle\", default=\"long\")"}, {"id": "_pytest._code.FormattedExcinfo.abspath", "kind": "variable", "range": [661, 4, 661, 46, 21795, 21837], "file_path": "src/_pytest/_code/code.py", "content": "abspath = attr.ib(type=bool, default=True)"}, {"id": "_pytest._code.FormattedExcinfo.tbfilter", "kind": "variable", "range": [662, 4, 662, 47, 21842, 21885], "file_path": "src/_pytest/_code/code.py", "content": "tbfilter = attr.ib(type=bool, default=True)"}, {"id": "_pytest._code.FormattedExcinfo.funcargs", "kind": "variable", "range": [663, 4, 663, 48, 21890, 21934], "file_path": "src/_pytest/_code/code.py", "content": "funcargs = attr.ib(type=bool, default=False)"}, {"id": "_pytest._code.FormattedExcinfo.truncate_locals", "kind": "variable", "range": [664, 4, 664, 54, 21939, 21989], "file_path": "src/_pytest/_code/code.py", "content": "truncate_locals = attr.ib(type=bool, default=True)"}, {"id": "_pytest._code.FormattedExcinfo.chain", "kind": "variable", "range": [665, 4, 665, 44, 21994, 22034], "file_path": "src/_pytest/_code/code.py", "content": "chain = attr.ib(type=bool, default=True)"}, {"id": "_pytest._code.FormattedExcinfo.astcache", "kind": "variable", "range": [666, 4, 666, 74, 22039, 22109], "file_path": "src/_pytest/_code/code.py", "content": "astcache = attr.ib(default=attr.Factory(dict), init=False, repr=False)"}, {"id": "_pytest._code.FormattedExcinfo._getindent", "kind": "function", "range": [668, 4, 681, 45, 22115, 22565], "file_path": "src/_pytest/_code/code.py", "content": "def _getindent(self, source: \"Source\") -> int:\n        # figure out indent for given source\n        try:\n            s = str(source.getstatement(len(source) - 1))\n        except KeyboardInterrupt:\n            raise\n        except:  # noqa\n            try:\n                s = str(source[-1])\n            except KeyboardInterrupt:\n                raise\n            except:  # noqa\n                return 0\n        return 4 + (len(s) - len(s.lstrip()))"}, {"id": "_pytest._code.FormattedExcinfo._getentrysource", "kind": "function", "range": [683, 4, 687, 21, 22571, 22782], "file_path": "src/_pytest/_code/code.py", "content": "def _getentrysource(self, entry: TracebackEntry) -> Optional[\"Source\"]:\n        source = entry.getsource(self.astcache)\n        if source is not None:\n            source = source.deindent()\n        return source"}, {"id": "_pytest._code.FormattedExcinfo.repr_args", "kind": "function", "range": [689, 4, 695, 19, 22788, 23092], "file_path": "src/_pytest/_code/code.py", "content": "def repr_args(self, entry: TracebackEntry) -> Optional[\"ReprFuncArgs\"]:\n        if self.funcargs:\n            args = []\n            for argname, argvalue in entry.frame.getargs(var=True):\n                args.append((argname, saferepr(argvalue)))\n            return ReprFuncArgs(args)\n        return None"}, {"id": "_pytest._code.FormattedExcinfo.get_source", "kind": "function", "range": [697, 4, 725, 20, 23098, 24210], "file_path": "src/_pytest/_code/code.py", "content": "def get_source(\n        self,\n        source: \"Source\",\n        line_index: int = -1,\n        excinfo: Optional[ExceptionInfo] = None,\n        short: bool = False,\n    ) -> List[str]:\n        \"\"\" return formatted and marked up source lines. \"\"\"\n        import _pytest._code\n\n        lines = []\n        if source is None or line_index >= len(source.lines):\n            source = _pytest._code.Source(\"???\")\n            line_index = 0\n        if line_index < 0:\n            line_index += len(source)\n        space_prefix = \"    \"\n        if short:\n            lines.append(space_prefix + source.lines[line_index].strip())\n        else:\n            for line in source.lines[:line_index]:\n                lines.append(space_prefix + line)\n            lines.append(self.flow_marker + \"   \" + source.lines[line_index])\n            for line in source.lines[line_index + 1 :]:\n                lines.append(space_prefix + line)\n        if excinfo is not None:\n            indent = 4 if short else self._getindent(source)\n            lines.extend(self.get_exconly(excinfo, indent=indent, markall=True))\n        return lines"}, {"id": "_pytest._code.FormattedExcinfo.get_exconly", "kind": "function", "range": [727, 4, 739, 20, 24216, 24706], "file_path": "src/_pytest/_code/code.py", "content": "def get_exconly(\n        self, excinfo: ExceptionInfo, indent: int = 4, markall: bool = False\n    ) -> List[str]:\n        lines = []\n        indentstr = \" \" * indent\n        # get the real exception information out\n        exlines = excinfo.exconly(tryshort=True).split(\"\\n\")\n        failindent = self.fail_marker + indentstr[1:]\n        for line in exlines:\n            lines.append(failindent + line)\n            if not markall:\n                failindent = indentstr\n        return lines"}, {"id": "_pytest._code.FormattedExcinfo.repr_locals", "kind": "function", "range": [741, 4, 766, 19, 24712, 25943], "file_path": "src/_pytest/_code/code.py", "content": "def repr_locals(self, locals: Dict[str, object]) -> Optional[\"ReprLocals\"]:\n        if self.showlocals:\n            lines = []\n            keys = [loc for loc in locals if loc[0] != \"@\"]\n            keys.sort()\n            for name in keys:\n                value = locals[name]\n                if name == \"__builtins__\":\n                    lines.append(\"__builtins__ = <builtins>\")\n                else:\n                    # This formatting could all be handled by the\n                    # _repr() function, which is only reprlib.Repr in\n                    # disguise, so is very configurable.\n                    if self.truncate_locals:\n                        str_repr = saferepr(value)\n                    else:\n                        str_repr = safeformat(value)\n                    # if len(str_repr) < 70 or not isinstance(value,\n                    #                            (list, tuple, dict)):\n                    lines.append(\"{:<10} = {}\".format(name, str_repr))\n                    # else:\n                    #    self._line(\"%-10s =\\\\\" % (name,))\n                    #    # XXX\n                    #    pprint.pprint(value, stream=self.excinfowriter)\n            return ReprLocals(lines)\n        return None"}, {"id": "_pytest._code.FormattedExcinfo.repr_traceback_entry", "kind": "function", "range": [768, 4, 797, 56, 25949, 27245], "file_path": "src/_pytest/_code/code.py", "content": "def repr_traceback_entry(\n        self, entry: TracebackEntry, excinfo: Optional[ExceptionInfo] = None\n    ) -> \"ReprEntry\":\n        import _pytest._code\n\n        source = self._getentrysource(entry)\n        if source is None:\n            source = _pytest._code.Source(\"???\")\n            line_index = 0\n        else:\n            line_index = entry.lineno - entry.getfirstlinesource()\n\n        lines = []  # type: List[str]\n        style = entry._repr_style if entry._repr_style is not None else self.style\n        if style in (\"short\", \"long\"):\n            short = style == \"short\"\n            reprargs = self.repr_args(entry) if not short else None\n            s = self.get_source(source, line_index, excinfo, short=short)\n            lines.extend(s)\n            if short:\n                message = \"in %s\" % (entry.name)\n            else:\n                message = excinfo and excinfo.typename or \"\"\n            path = self._makepath(entry.path)\n            reprfileloc = ReprFileLocation(path, entry.lineno + 1, message)\n            localsrepr = self.repr_locals(entry.locals)\n            return ReprEntry(lines, reprargs, localsrepr, reprfileloc, style)\n        if excinfo:\n            lines.extend(self.get_exconly(excinfo, indent=4))\n        return ReprEntry(lines, None, None, None, style)"}, {"id": "_pytest._code.FormattedExcinfo._makepath", "kind": "function", "range": [799, 4, 807, 19, 27251, 27521], "file_path": "src/_pytest/_code/code.py", "content": "def _makepath(self, path):\n        if not self.abspath:\n            try:\n                np = py.path.local().bestrelpath(path)\n            except OSError:\n                return path\n            if len(np) < len(str(path)):\n                path = np\n        return path"}, {"id": "_pytest._code.FormattedExcinfo.repr_traceback", "kind": "function", "range": [809, 4, 825, 66, 27527, 28203], "file_path": "src/_pytest/_code/code.py", "content": "def repr_traceback(self, excinfo: ExceptionInfo) -> \"ReprTraceback\":\n        traceback = excinfo.traceback\n        if self.tbfilter:\n            traceback = traceback.filter()\n\n        if excinfo.errisinstance(RecursionError):\n            traceback, extraline = self._truncate_recursive_traceback(traceback)\n        else:\n            extraline = None\n\n        last = traceback[-1]\n        entries = []\n        for index, entry in enumerate(traceback):\n            einfo = (last == entry) and excinfo or None\n            reprentry = self.repr_traceback_entry(entry, einfo)\n            entries.append(reprentry)\n        return ReprTraceback(entries, extraline, style=self.style)"}, {"id": "_pytest._code.FormattedExcinfo._truncate_recursive_traceback", "kind": "function", "range": [827, 4, 866, 35, 28209, 30135], "file_path": "src/_pytest/_code/code.py", "content": "def _truncate_recursive_traceback(\n        self, traceback: Traceback\n    ) -> Tuple[Traceback, Optional[str]]:\n        \"\"\"\n        Truncate the given recursive traceback trying to find the starting point\n        of the recursion.\n\n        The detection is done by going through each traceback entry and finding the\n        point in which the locals of the frame are equal to the locals of a previous frame (see ``recursionindex()``.\n\n        Handle the situation where the recursion process might raise an exception (for example\n        comparing numpy arrays using equality raises a TypeError), in which case we do our best to\n        warn the user of the error and show a limited traceback.\n        \"\"\"\n        try:\n            recursionindex = traceback.recursionindex()\n        except Exception as e:\n            max_frames = 10\n            extraline = (\n                \"!!! Recursion error detected, but an error occurred locating the origin of recursion.\\n\"\n                \"  The following exception happened when comparing locals in the stack frame:\\n\"\n                \"    {exc_type}: {exc_msg}\\n\"\n                \"  Displaying first and last {max_frames} stack frames out of {total}.\"\n            ).format(\n                exc_type=type(e).__name__,\n                exc_msg=str(e),\n                max_frames=max_frames,\n                total=len(traceback),\n            )  # type: Optional[str]\n            # Type ignored because adding two instaces of a List subtype\n            # currently incorrectly has type List instead of the subtype.\n            traceback = traceback[:max_frames] + traceback[-max_frames:]  # type: ignore\n        else:\n            if recursionindex is not None:\n                extraline = \"!!! Recursion detected (same locals & position)\"\n                traceback = traceback[: recursionindex + 1]\n            else:\n                extraline = None\n\n        return traceback, extraline"}, {"id": "_pytest._code.FormattedExcinfo.repr_excinfo", "kind": "function", "range": [868, 4, 911, 45, 30141, 32060], "file_path": "src/_pytest/_code/code.py", "content": "def repr_excinfo(self, excinfo: ExceptionInfo) -> \"ExceptionChainRepr\":\n        repr_chain = (\n            []\n        )  # type: List[Tuple[ReprTraceback, Optional[ReprFileLocation], Optional[str]]]\n        e = excinfo.value\n        excinfo_ = excinfo  # type: Optional[ExceptionInfo]\n        descr = None\n        seen = set()  # type: Set[int]\n        while e is not None and id(e) not in seen:\n            seen.add(id(e))\n            if excinfo_:\n                reprtraceback = self.repr_traceback(excinfo_)\n                reprcrash = excinfo_._getreprcrash()  # type: Optional[ReprFileLocation]\n            else:\n                # fallback to native repr if the exception doesn't have a traceback:\n                # ExceptionInfo objects require a full traceback to work\n                reprtraceback = ReprTracebackNative(\n                    traceback.format_exception(type(e), e, None)\n                )\n                reprcrash = None\n\n            repr_chain += [(reprtraceback, reprcrash, descr)]\n            if e.__cause__ is not None and self.chain:\n                e = e.__cause__\n                excinfo_ = (\n                    ExceptionInfo((type(e), e, e.__traceback__))\n                    if e.__traceback__\n                    else None\n                )\n                descr = \"The above exception was the direct cause of the following exception:\"\n            elif (\n                e.__context__ is not None and not e.__suppress_context__ and self.chain\n            ):\n                e = e.__context__\n                excinfo_ = (\n                    ExceptionInfo((type(e), e, e.__traceback__))\n                    if e.__traceback__\n                    else None\n                )\n                descr = \"During handling of the above exception, another exception occurred:\"\n            else:\n                e = None\n        repr_chain.reverse()\n        return ExceptionChainRepr(repr_chain)"}, {"id": "_pytest._code.TerminalRepr", "kind": "class", "range": [914, 0, 928, 35, 32063, 32584], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass TerminalRepr:\n    def __str__(self) -> str:\n        # FYI this is called from pytest-xdist's serialization of exception\n        # information.\n        io = StringIO()\n        tw = TerminalWriter(file=io)\n        self.toterminal(tw)\n        return io.getvalue().strip()\n\n    def __repr__(self) -> str:\n        return \"<{} instance at {:0x}>\".format(self.__class__, id(self))\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        raise NotImplementedError()"}, {"id": "_pytest._code.TerminalRepr.__str__", "kind": "function", "range": [916, 4, 922, 36, 32138, 32388], "file_path": "src/_pytest/_code/code.py", "content": "def __str__(self) -> str:\n        # FYI this is called from pytest-xdist's serialization of exception\n        # information.\n        io = StringIO()\n        tw = TerminalWriter(file=io)\n        self.toterminal(tw)\n        return io.getvalue().strip()"}, {"id": "_pytest._code.TerminalRepr.__repr__", "kind": "function", "range": [924, 4, 925, 72, 32394, 32493], "file_path": "src/_pytest/_code/code.py", "content": "def __repr__(self) -> str:\n        return \"<{} instance at {:0x}>\".format(self.__class__, id(self))"}, {"id": "_pytest._code.TerminalRepr.toterminal", "kind": "function", "range": [927, 4, 928, 35, 32499, 32584], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        raise NotImplementedError()"}, {"id": "_pytest._code.ExceptionRepr", "kind": "class", "range": [931, 0, 942, 28, 32587, 33060], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ExceptionRepr(TerminalRepr):\n    def __attrs_post_init__(self):\n        self.sections = []  # type: List[Tuple[str, str, str]]\n\n    def addsection(self, name: str, content: str, sep: str = \"-\") -> None:\n        self.sections.append((name, content, sep))\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        for name, content, sep in self.sections:\n            tw.sep(sep, name)\n            tw.line(content)"}, {"id": "_pytest._code.ExceptionRepr.__attrs_post_init__", "kind": "function", "range": [933, 4, 934, 62, 32677, 32770], "file_path": "src/_pytest/_code/code.py", "content": "def __attrs_post_init__(self):\n        self.sections = []  # type: List[Tuple[str, str, str]]"}, {"id": "_pytest._code.ExceptionRepr.addsection", "kind": "function", "range": [936, 4, 937, 50, 32776, 32897], "file_path": "src/_pytest/_code/code.py", "content": "def addsection(self, name: str, content: str, sep: str = \"-\") -> None:\n        self.sections.append((name, content, sep))"}, {"id": "_pytest._code.ExceptionRepr.toterminal", "kind": "function", "range": [939, 4, 942, 28, 32903, 33060], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        for name, content, sep in self.sections:\n            tw.sep(sep, name)\n            tw.line(content)"}, {"id": "_pytest._code.ExceptionChainRepr", "kind": "class", "range": [945, 0, 966, 30, 33063, 33834], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ExceptionChainRepr(ExceptionRepr):\n    chain = attr.ib(\n        type=Sequence[\n            Tuple[\"ReprTraceback\", Optional[\"ReprFileLocation\"], Optional[str]]\n        ]\n    )\n\n    def __attrs_post_init__(self):\n        super().__attrs_post_init__()\n        # reprcrash and reprtraceback of the outermost (the newest) exception\n        # in the chain\n        self.reprtraceback = self.chain[-1][0]\n        self.reprcrash = self.chain[-1][1]\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        for element in self.chain:\n            element[0].toterminal(tw)\n            if element[2] is not None:\n                tw.line(\"\")\n                tw.line(element[2], yellow=True)\n        super().toterminal(tw)"}, {"id": "_pytest._code.ExceptionChainRepr.chain", "kind": "variable", "range": [947, 4, 951, 5, 33159, 33294], "file_path": "src/_pytest/_code/code.py", "content": "chain = attr.ib(\n        type=Sequence[\n            Tuple[\"ReprTraceback\", Optional[\"ReprFileLocation\"], Optional[str]]\n        ]\n    )"}, {"id": "_pytest._code.ExceptionChainRepr.__attrs_post_init__", "kind": "function", "range": [953, 4, 958, 42, 33300, 33559], "file_path": "src/_pytest/_code/code.py", "content": "def __attrs_post_init__(self):\n        super().__attrs_post_init__()\n        # reprcrash and reprtraceback of the outermost (the newest) exception\n        # in the chain\n        self.reprtraceback = self.chain[-1][0]\n        self.reprcrash = self.chain[-1][1]"}, {"id": "_pytest._code.ExceptionChainRepr.toterminal", "kind": "function", "range": [960, 4, 966, 30, 33565, 33834], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        for element in self.chain:\n            element[0].toterminal(tw)\n            if element[2] is not None:\n                tw.line(\"\")\n                tw.line(element[2], yellow=True)\n        super().toterminal(tw)"}, {"id": "_pytest._code.ReprExceptionInfo", "kind": "class", "range": [969, 0, 976, 30, 33837, 34154], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprExceptionInfo(ExceptionRepr):\n    reprtraceback = attr.ib(type=\"ReprTraceback\")\n    reprcrash = attr.ib(type=\"ReprFileLocation\")\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        self.reprtraceback.toterminal(tw)\n        super().toterminal(tw)"}, {"id": "_pytest._code.ReprExceptionInfo.reprtraceback", "kind": "variable", "range": [971, 4, 971, 49, 33932, 33977], "file_path": "src/_pytest/_code/code.py", "content": "reprtraceback = attr.ib(type=\"ReprTraceback\")"}, {"id": "_pytest._code.ReprExceptionInfo.reprcrash", "kind": "variable", "range": [972, 4, 972, 48, 33982, 34026], "file_path": "src/_pytest/_code/code.py", "content": "reprcrash = attr.ib(type=\"ReprFileLocation\")"}, {"id": "_pytest._code.ReprExceptionInfo.toterminal", "kind": "function", "range": [974, 4, 976, 30, 34032, 34154], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        self.reprtraceback.toterminal(tw)\n        super().toterminal(tw)"}, {"id": "_pytest._code.ReprTraceback", "kind": "class", "range": [979, 0, 1003, 35, 34157, 35072], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprTraceback(TerminalRepr):\n    reprentries = attr.ib(type=Sequence[Union[\"ReprEntry\", \"ReprEntryNative\"]])\n    extraline = attr.ib(type=Optional[str])\n    style = attr.ib(type=\"_TracebackStyle\")\n\n    entrysep = \"_ \"\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        # the entries might have different styles\n        for i, entry in enumerate(self.reprentries):\n            if entry.style == \"long\":\n                tw.line(\"\")\n            entry.toterminal(tw)\n            if i < len(self.reprentries) - 1:\n                next_entry = self.reprentries[i + 1]\n                if (\n                    entry.style == \"long\"\n                    or entry.style == \"short\"\n                    and next_entry.style == \"long\"\n                ):\n                    tw.sep(self.entrysep)\n\n        if self.extraline:\n            tw.line(self.extraline)"}, {"id": "_pytest._code.ReprTraceback.reprentries", "kind": "variable", "range": [981, 4, 981, 79, 34247, 34322], "file_path": "src/_pytest/_code/code.py", "content": "reprentries = attr.ib(type=Sequence[Union[\"ReprEntry\", \"ReprEntryNative\"]])"}, {"id": "_pytest._code.ReprTraceback.extraline", "kind": "variable", "range": [982, 4, 982, 43, 34327, 34366], "file_path": "src/_pytest/_code/code.py", "content": "extraline = attr.ib(type=Optional[str])"}, {"id": "_pytest._code.ReprTraceback.style", "kind": "variable", "range": [983, 4, 983, 43, 34371, 34410], "file_path": "src/_pytest/_code/code.py", "content": "style = attr.ib(type=\"_TracebackStyle\")"}, {"id": "_pytest._code.ReprTraceback.entrysep", "kind": "variable", "range": [985, 4, 985, 19, 34416, 34431], "file_path": "src/_pytest/_code/code.py", "content": "entrysep = \"_ \""}, {"id": "_pytest._code.ReprTraceback.toterminal", "kind": "function", "range": [987, 4, 1003, 35, 34437, 35072], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        # the entries might have different styles\n        for i, entry in enumerate(self.reprentries):\n            if entry.style == \"long\":\n                tw.line(\"\")\n            entry.toterminal(tw)\n            if i < len(self.reprentries) - 1:\n                next_entry = self.reprentries[i + 1]\n                if (\n                    entry.style == \"long\"\n                    or entry.style == \"short\"\n                    and next_entry.style == \"long\"\n                ):\n                    tw.sep(self.entrysep)\n\n        if self.extraline:\n            tw.line(self.extraline)"}, {"id": "_pytest._code.ReprTracebackNative", "kind": "class", "range": [1006, 0, 1010, 29, 35075, 35286], "file_path": "src/_pytest/_code/code.py", "content": "class ReprTracebackNative(ReprTraceback):\n    def __init__(self, tblines: Sequence[str]) -> None:\n        self.style = \"native\"\n        self.reprentries = [ReprEntryNative(tblines)]\n        self.extraline = None"}, {"id": "_pytest._code.ReprTracebackNative.__init__", "kind": "function", "range": [1007, 4, 1010, 29, 35121, 35286], "file_path": "src/_pytest/_code/code.py", "content": "def __init__(self, tblines: Sequence[str]) -> None:\n        self.style = \"native\"\n        self.reprentries = [ReprEntryNative(tblines)]\n        self.extraline = None"}, {"id": "_pytest._code.ReprEntryNative", "kind": "class", "range": [1013, 0, 1019, 37, 35289, 35555], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprEntryNative(TerminalRepr):\n    lines = attr.ib(type=Sequence[str])\n    style = \"native\"  # type: _TracebackStyle\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        tw.write(\"\".join(self.lines))"}, {"id": "_pytest._code.ReprEntryNative.lines", "kind": "variable", "range": [1015, 4, 1015, 39, 35381, 35416], "file_path": "src/_pytest/_code/code.py", "content": "lines = attr.ib(type=Sequence[str])"}, {"id": "_pytest._code.ReprEntryNative.style", "kind": "variable", "range": [1016, 4, 1016, 20, 35421, 35437], "file_path": "src/_pytest/_code/code.py", "content": "style = \"native\""}, {"id": "_pytest._code.ReprEntryNative.toterminal", "kind": "function", "range": [1018, 4, 1019, 37, 35468, 35555], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        tw.write(\"\".join(self.lines))"}, {"id": "_pytest._code.ReprEntry", "kind": "class", "range": [1022, 0, 1100, 9, 35558, 38429], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprEntry(TerminalRepr):\n    lines = attr.ib(type=Sequence[str])\n    reprfuncargs = attr.ib(type=Optional[\"ReprFuncArgs\"])\n    reprlocals = attr.ib(type=Optional[\"ReprLocals\"])\n    reprfileloc = attr.ib(type=Optional[\"ReprFileLocation\"])\n    style = attr.ib(type=\"_TracebackStyle\")\n\n    def _write_entry_lines(self, tw: TerminalWriter) -> None:\n        \"\"\"Writes the source code portions of a list of traceback entries with syntax highlighting.\n\n        Usually entries are lines like these:\n\n            \"     x = 1\"\n            \">    assert x == 2\"\n            \"E    assert 1 == 2\"\n\n        This function takes care of rendering the \"source\" portions of it (the lines without\n        the \"E\" prefix) using syntax highlighting, taking care to not highlighting the \">\"\n        character, as doing so might break line continuations.\n        \"\"\"\n\n        if not self.lines:\n            return\n\n        # separate indents and source lines that are not failures: we want to\n        # highlight the code but not the indentation, which may contain markers\n        # such as \">   assert 0\"\n        fail_marker = \"{}   \".format(FormattedExcinfo.fail_marker)\n        indent_size = len(fail_marker)\n        indents = []\n        source_lines = []\n        failure_lines = []\n        seeing_failures = False\n        for line in self.lines:\n            is_source_line = not line.startswith(fail_marker)\n            if is_source_line:\n                assert not seeing_failures, (\n                    \"Unexpected failure lines between source lines:\\n\"\n                    + \"\\n\".join(self.lines)\n                )\n                indents.append(line[:indent_size])\n                source_lines.append(line[indent_size:])\n            else:\n                seeing_failures = True\n                failure_lines.append(line)\n\n        tw._write_source(source_lines, indents)\n\n        # failure lines are always completely red and bold\n        for line in failure_lines:\n            tw.line(line, bold=True, red=True)\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        if self.style == \"short\":\n            assert self.reprfileloc is not None\n            self.reprfileloc.toterminal(tw)\n            self._write_entry_lines(tw)\n            if self.reprlocals:\n                self.reprlocals.toterminal(tw, indent=\" \" * 8)\n            return\n\n        if self.reprfuncargs:\n            self.reprfuncargs.toterminal(tw)\n\n        self._write_entry_lines(tw)\n\n        if self.reprlocals:\n            tw.line(\"\")\n            self.reprlocals.toterminal(tw)\n        if self.reprfileloc:\n            if self.lines:\n                tw.line(\"\")\n            self.reprfileloc.toterminal(tw)\n\n    def __str__(self) -> str:\n        return \"{}\\n{}\\n{}\".format(\n            \"\\n\".join(self.lines), self.reprlocals, self.reprfileloc\n        )"}, {"id": "_pytest._code.ReprEntry.lines", "kind": "variable", "range": [1024, 4, 1024, 39, 35644, 35679], "file_path": "src/_pytest/_code/code.py", "content": "lines = attr.ib(type=Sequence[str])"}, {"id": "_pytest._code.ReprEntry.reprfuncargs", "kind": "variable", "range": [1025, 4, 1025, 57, 35684, 35737], "file_path": "src/_pytest/_code/code.py", "content": "reprfuncargs = attr.ib(type=Optional[\"ReprFuncArgs\"])"}, {"id": "_pytest._code.ReprEntry.reprlocals", "kind": "variable", "range": [1026, 4, 1026, 53, 35742, 35791], "file_path": "src/_pytest/_code/code.py", "content": "reprlocals = attr.ib(type=Optional[\"ReprLocals\"])"}, {"id": "_pytest._code.ReprEntry.reprfileloc", "kind": "variable", "range": [1027, 4, 1027, 60, 35796, 35852], "file_path": "src/_pytest/_code/code.py", "content": "reprfileloc = attr.ib(type=Optional[\"ReprFileLocation\"])"}, {"id": "_pytest._code.ReprEntry.style", "kind": "variable", "range": [1028, 4, 1028, 43, 35857, 35896], "file_path": "src/_pytest/_code/code.py", "content": "style = attr.ib(type=\"_TracebackStyle\")"}, {"id": "_pytest._code.ReprEntry._write_entry_lines", "kind": "function", "range": [1030, 4, 1073, 46, 35902, 37611], "file_path": "src/_pytest/_code/code.py", "content": "def _write_entry_lines(self, tw: TerminalWriter) -> None:\n        \"\"\"Writes the source code portions of a list of traceback entries with syntax highlighting.\n\n        Usually entries are lines like these:\n\n            \"     x = 1\"\n            \">    assert x == 2\"\n            \"E    assert 1 == 2\"\n\n        This function takes care of rendering the \"source\" portions of it (the lines without\n        the \"E\" prefix) using syntax highlighting, taking care to not highlighting the \">\"\n        character, as doing so might break line continuations.\n        \"\"\"\n\n        if not self.lines:\n            return\n\n        # separate indents and source lines that are not failures: we want to\n        # highlight the code but not the indentation, which may contain markers\n        # such as \">   assert 0\"\n        fail_marker = \"{}   \".format(FormattedExcinfo.fail_marker)\n        indent_size = len(fail_marker)\n        indents = []\n        source_lines = []\n        failure_lines = []\n        seeing_failures = False\n        for line in self.lines:\n            is_source_line = not line.startswith(fail_marker)\n            if is_source_line:\n                assert not seeing_failures, (\n                    \"Unexpected failure lines between source lines:\\n\"\n                    + \"\\n\".join(self.lines)\n                )\n                indents.append(line[:indent_size])\n                source_lines.append(line[indent_size:])\n            else:\n                seeing_failures = True\n                failure_lines.append(line)\n\n        tw._write_source(source_lines, indents)\n\n        # failure lines are always completely red and bold\n        for line in failure_lines:\n            tw.line(line, bold=True, red=True)"}, {"id": "_pytest._code.ReprEntry.toterminal", "kind": "function", "range": [1075, 4, 1095, 43, 37617, 38283], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        if self.style == \"short\":\n            assert self.reprfileloc is not None\n            self.reprfileloc.toterminal(tw)\n            self._write_entry_lines(tw)\n            if self.reprlocals:\n                self.reprlocals.toterminal(tw, indent=\" \" * 8)\n            return\n\n        if self.reprfuncargs:\n            self.reprfuncargs.toterminal(tw)\n\n        self._write_entry_lines(tw)\n\n        if self.reprlocals:\n            tw.line(\"\")\n            self.reprlocals.toterminal(tw)\n        if self.reprfileloc:\n            if self.lines:\n                tw.line(\"\")\n            self.reprfileloc.toterminal(tw)"}, {"id": "_pytest._code.ReprEntry.__str__", "kind": "function", "range": [1097, 4, 1100, 9, 38289, 38429], "file_path": "src/_pytest/_code/code.py", "content": "def __str__(self) -> str:\n        return \"{}\\n{}\\n{}\".format(\n            \"\\n\".join(self.lines), self.reprlocals, self.reprfileloc\n        )"}, {"id": "_pytest._code.ReprFileLocation", "kind": "class", "range": [1103, 0, 1117, 51, 38432, 38998], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprFileLocation(TerminalRepr):\n    path = attr.ib(type=str, converter=str)\n    lineno = attr.ib(type=int)\n    message = attr.ib(type=str)\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        # filename and lineno output for each entry,\n        # using an output format that most editors understand\n        msg = self.message\n        i = msg.find(\"\\n\")\n        if i != -1:\n            msg = msg[:i]\n        tw.write(self.path, bold=True, red=True)\n        tw.line(\":{}: {}\".format(self.lineno, msg))"}, {"id": "_pytest._code.ReprFileLocation.path", "kind": "variable", "range": [1105, 4, 1105, 43, 38525, 38564], "file_path": "src/_pytest/_code/code.py", "content": "path = attr.ib(type=str, converter=str)"}, {"id": "_pytest._code.ReprFileLocation.lineno", "kind": "variable", "range": [1106, 4, 1106, 30, 38569, 38595], "file_path": "src/_pytest/_code/code.py", "content": "lineno = attr.ib(type=int)"}, {"id": "_pytest._code.ReprFileLocation.message", "kind": "variable", "range": [1107, 4, 1107, 31, 38600, 38627], "file_path": "src/_pytest/_code/code.py", "content": "message = attr.ib(type=str)"}, {"id": "_pytest._code.ReprFileLocation.toterminal", "kind": "function", "range": [1109, 4, 1117, 51, 38633, 38998], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        # filename and lineno output for each entry,\n        # using an output format that most editors understand\n        msg = self.message\n        i = msg.find(\"\\n\")\n        if i != -1:\n            msg = msg[:i]\n        tw.write(self.path, bold=True, red=True)\n        tw.line(\":{}: {}\".format(self.lineno, msg))"}, {"id": "_pytest._code.ReprLocals", "kind": "class", "range": [1120, 0, 1126, 34, 39001, 39256], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprLocals(TerminalRepr):\n    lines = attr.ib(type=Sequence[str])\n\n    def toterminal(self, tw: TerminalWriter, indent=\"\") -> None:\n        for line in self.lines:\n            tw.line(indent + line)"}, {"id": "_pytest._code.ReprLocals.lines", "kind": "variable", "range": [1122, 4, 1122, 39, 39088, 39123], "file_path": "src/_pytest/_code/code.py", "content": "lines = attr.ib(type=Sequence[str])"}, {"id": "_pytest._code.ReprLocals.toterminal", "kind": "function", "range": [1124, 4, 1126, 34, 39129, 39256], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter, indent=\"\") -> None:\n        for line in self.lines:\n            tw.line(indent + line)"}, {"id": "_pytest._code.ReprFuncArgs", "kind": "class", "range": [1129, 0, 1149, 23, 39259, 40023], "file_path": "src/_pytest/_code/code.py", "content": "@attr.s(**{ATTRS_EQ_FIELD: False})  # type: ignore\nclass ReprFuncArgs(TerminalRepr):\n    args = attr.ib(type=Sequence[Tuple[str, object]])\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        if self.args:\n            linesofar = \"\"\n            for name, value in self.args:\n                ns = \"{} = {}\".format(name, value)\n                if len(ns) + len(linesofar) + 2 > tw.fullwidth:\n                    if linesofar:\n                        tw.line(linesofar)\n                    linesofar = ns\n                else:\n                    if linesofar:\n                        linesofar += \", \" + ns\n                    else:\n                        linesofar = ns\n            if linesofar:\n                tw.line(linesofar)\n            tw.line(\"\")"}, {"id": "_pytest._code.ReprFuncArgs.args", "kind": "variable", "range": [1131, 4, 1131, 53, 39348, 39397], "file_path": "src/_pytest/_code/code.py", "content": "args = attr.ib(type=Sequence[Tuple[str, object]])"}, {"id": "_pytest._code.ReprFuncArgs.toterminal", "kind": "function", "range": [1133, 4, 1149, 23, 39403, 40023], "file_path": "src/_pytest/_code/code.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        if self.args:\n            linesofar = \"\"\n            for name, value in self.args:\n                ns = \"{} = {}\".format(name, value)\n                if len(ns) + len(linesofar) + 2 > tw.fullwidth:\n                    if linesofar:\n                        tw.line(linesofar)\n                    linesofar = ns\n                else:\n                    if linesofar:\n                        linesofar += \", \" + ns\n                    else:\n                        linesofar = ns\n            if linesofar:\n                tw.line(linesofar)\n            tw.line(\"\")"}, {"id": "_pytest._code.getrawcode", "kind": "function", "range": [1152, 0, 1164, 18, 40026, 40555], "file_path": "src/_pytest/_code/code.py", "content": "def getrawcode(obj, trycall: bool = True):\n    \"\"\" return code object for given function. \"\"\"\n    try:\n        return obj.__code__\n    except AttributeError:\n        obj = getattr(obj, \"f_code\", obj)\n        obj = getattr(obj, \"__code__\", obj)\n        if trycall and not hasattr(obj, \"co_firstlineno\"):\n            if hasattr(obj, \"__call__\") and not inspect.isclass(obj):\n                x = getrawcode(obj.__call__, trycall=False)\n                if hasattr(x, \"co_firstlineno\"):\n                    return x\n        return obj"}, {"id": "_pytest._code._PLUGGY_DIR", "kind": "variable", "range": [1172, 0, 1172, 57, 40781, 40838], "file_path": "src/_pytest/_code/code.py", "content": "_PLUGGY_DIR = py.path.local(pluggy.__file__.rstrip(\"oc\"))"}, {"id": "_pytest._code._PYTEST_DIR", "kind": "variable", "range": [1176, 0, 1176, 55, 40994, 41049], "file_path": "src/_pytest/_code/code.py", "content": "_PYTEST_DIR = py.path.local(_pytest.__file__).dirpath()"}, {"id": "_pytest._code._PY_DIR", "kind": "variable", "range": [1177, 0, 1177, 46, 41050, 41096], "file_path": "src/_pytest/_code/code.py", "content": "_PY_DIR = py.path.local(py.__file__).dirpath()"}, {"id": "_pytest._code.filter_traceback", "kind": "function", "range": [1180, 0, 1197, 5, 41099, 41964], "file_path": "src/_pytest/_code/code.py", "content": "def filter_traceback(entry: TracebackEntry) -> bool:\n    \"\"\"Return True if a TracebackEntry instance should be removed from tracebacks:\n    * dynamically generated code (no code to show up for it);\n    * internal traceback from pytest or its internal libraries, py and pluggy.\n    \"\"\"\n    # entry.path might sometimes return a str object when the entry\n    # points to dynamically generated code\n    # see https://bitbucket.org/pytest-dev/py/issues/71\n    raw_filename = entry.frame.code.raw.co_filename\n    is_generated = \"<\" in raw_filename and \">\" in raw_filename\n    if is_generated:\n        return False\n    # entry.path might point to a non-existing file, in which case it will\n    # also return a str object. see #1133\n    p = py.path.local(entry.path)\n    return (\n        not p.relto(_PLUGGY_DIR) and not p.relto(_PYTEST_DIR) and not p.relto(_PY_DIR)\n    )"}, {"id": "_pytest._code.Source", "kind": "class", "range": [28, 0, 228, 21, 563, 7627], "file_path": "src/_pytest/_code/source.py", "content": "class Source:\n    \"\"\" an immutable object holding a source code fragment,\n        possibly deindenting it.\n    \"\"\"\n\n    _compilecounter = 0\n\n    def __init__(self, *parts, **kwargs) -> None:\n        self.lines = lines = []  # type: List[str]\n        de = kwargs.get(\"deindent\", True)\n        for part in parts:\n            if not part:\n                partlines = []  # type: List[str]\n            elif isinstance(part, Source):\n                partlines = part.lines\n            elif isinstance(part, (tuple, list)):\n                partlines = [x.rstrip(\"\\n\") for x in part]\n            elif isinstance(part, str):\n                partlines = part.split(\"\\n\")\n            else:\n                partlines = getsource(part, deindent=de).lines\n            if de:\n                partlines = deindent(partlines)\n            lines.extend(partlines)\n\n    def __eq__(self, other):\n        try:\n            return self.lines == other.lines\n        except AttributeError:\n            if isinstance(other, str):\n                return str(self) == other\n            return False\n\n    # Ignore type because of https://github.com/python/mypy/issues/4266.\n    __hash__ = None  # type: ignore\n\n    @overload\n    def __getitem__(self, key: int) -> str:\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def __getitem__(self, key: slice) -> \"Source\":  # noqa: F811\n        raise NotImplementedError()\n\n    def __getitem__(self, key: Union[int, slice]) -> Union[str, \"Source\"]:  # noqa: F811\n        if isinstance(key, int):\n            return self.lines[key]\n        else:\n            if key.step not in (None, 1):\n                raise IndexError(\"cannot slice a Source with a step\")\n            newsource = Source()\n            newsource.lines = self.lines[key.start : key.stop]\n            return newsource\n\n    def __iter__(self) -> Iterator[str]:\n        return iter(self.lines)\n\n    def __len__(self) -> int:\n        return len(self.lines)\n\n    def strip(self) -> \"Source\":\n        \"\"\" return new source object with trailing\n            and leading blank lines removed.\n        \"\"\"\n        start, end = 0, len(self)\n        while start < end and not self.lines[start].strip():\n            start += 1\n        while end > start and not self.lines[end - 1].strip():\n            end -= 1\n        source = Source()\n        source.lines[:] = self.lines[start:end]\n        return source\n\n    def putaround(\n        self, before: str = \"\", after: str = \"\", indent: str = \" \" * 4\n    ) -> \"Source\":\n        \"\"\" return a copy of the source object with\n            'before' and 'after' wrapped around it.\n        \"\"\"\n        beforesource = Source(before)\n        aftersource = Source(after)\n        newsource = Source()\n        lines = [(indent + line) for line in self.lines]\n        newsource.lines = beforesource.lines + lines + aftersource.lines\n        return newsource\n\n    def indent(self, indent: str = \" \" * 4) -> \"Source\":\n        \"\"\" return a copy of the source object with\n            all lines indented by the given indent-string.\n        \"\"\"\n        newsource = Source()\n        newsource.lines = [(indent + line) for line in self.lines]\n        return newsource\n\n    def getstatement(self, lineno: int) -> \"Source\":\n        \"\"\" return Source statement which contains the\n            given linenumber (counted from 0).\n        \"\"\"\n        start, end = self.getstatementrange(lineno)\n        return self[start:end]\n\n    def getstatementrange(self, lineno: int) -> Tuple[int, int]:\n        \"\"\" return (start, end) tuple which spans the minimal\n            statement region which containing the given lineno.\n        \"\"\"\n        if not (0 <= lineno < len(self)):\n            raise IndexError(\"lineno out of range\")\n        ast, start, end = getstatementrange_ast(lineno, self)\n        return start, end\n\n    def deindent(self) -> \"Source\":\n        \"\"\"return a new source object deindented.\"\"\"\n        newsource = Source()\n        newsource.lines[:] = deindent(self.lines)\n        return newsource\n\n    def isparseable(self, deindent: bool = True) -> bool:\n        \"\"\" return True if source is parseable, heuristically\n            deindenting it by default.\n        \"\"\"\n        if deindent:\n            source = str(self.deindent())\n        else:\n            source = str(self)\n        try:\n            ast.parse(source)\n        except (SyntaxError, ValueError, TypeError):\n            return False\n        else:\n            return True\n\n    def __str__(self) -> str:\n        return \"\\n\".join(self.lines)\n\n    @overload\n    def compile(\n        self,\n        filename: Optional[str] = ...,\n        mode: str = ...,\n        flag: \"Literal[0]\" = ...,\n        dont_inherit: int = ...,\n        _genframe: Optional[FrameType] = ...,\n    ) -> CodeType:\n        raise NotImplementedError()\n\n    @overload  # noqa: F811\n    def compile(  # noqa: F811\n        self,\n        filename: Optional[str] = ...,\n        mode: str = ...,\n        flag: int = ...,\n        dont_inherit: int = ...,\n        _genframe: Optional[FrameType] = ...,\n    ) -> Union[CodeType, ast.AST]:\n        raise NotImplementedError()\n\n    def compile(  # noqa: F811\n        self,\n        filename: Optional[str] = None,\n        mode: str = \"exec\",\n        flag: int = 0,\n        dont_inherit: int = 0,\n        _genframe: Optional[FrameType] = None,\n    ) -> Union[CodeType, ast.AST]:\n        \"\"\" return compiled code object. if filename is None\n            invent an artificial filename which displays\n            the source/line position of the caller frame.\n        \"\"\"\n        if not filename or py.path.local(filename).check(file=0):\n            if _genframe is None:\n                _genframe = sys._getframe(1)  # the caller\n            fn, lineno = _genframe.f_code.co_filename, _genframe.f_lineno\n            base = \"<%d-codegen \" % self._compilecounter\n            self.__class__._compilecounter += 1\n            if not filename:\n                filename = base + \"%s:%d>\" % (fn, lineno)\n            else:\n                filename = base + \"%r %s:%d>\" % (filename, fn, lineno)\n        source = \"\\n\".join(self.lines) + \"\\n\"\n        try:\n            co = compile(source, filename, mode, flag)\n        except SyntaxError as ex:\n            # re-represent syntax errors from parsing python strings\n            msglines = self.lines[: ex.lineno]\n            if ex.offset:\n                msglines.append(\" \" * ex.offset + \"^\")\n            msglines.append(\"(code was compiled probably from here: %s)\" % filename)\n            newex = SyntaxError(\"\\n\".join(msglines))\n            newex.offset = ex.offset\n            newex.lineno = ex.lineno\n            newex.text = ex.text\n            raise newex\n        else:\n            if flag & ast.PyCF_ONLY_AST:\n                assert isinstance(co, ast.AST)\n                return co\n            assert isinstance(co, CodeType)\n            lines = [(x + \"\\n\") for x in self.lines]\n            # Type ignored because linecache.cache is private.\n            linecache.cache[filename] = (1, None, lines, filename)  # type: ignore\n            return co"}, {"id": "_pytest._code.Source._compilecounter", "kind": "variable", "range": [33, 4, 33, 23, 683, 702], "file_path": "src/_pytest/_code/source.py", "content": "_compilecounter = 0"}, {"id": "_pytest._code.Source.__init__", "kind": "function", "range": [35, 4, 51, 35, 708, 1408], "file_path": "src/_pytest/_code/source.py", "content": "def __init__(self, *parts, **kwargs) -> None:\n        self.lines = lines = []  # type: List[str]\n        de = kwargs.get(\"deindent\", True)\n        for part in parts:\n            if not part:\n                partlines = []  # type: List[str]\n            elif isinstance(part, Source):\n                partlines = part.lines\n            elif isinstance(part, (tuple, list)):\n                partlines = [x.rstrip(\"\\n\") for x in part]\n            elif isinstance(part, str):\n                partlines = part.split(\"\\n\")\n            else:\n                partlines = getsource(part, deindent=de).lines\n            if de:\n                partlines = deindent(partlines)\n            lines.extend(partlines)"}, {"id": "_pytest._code.Source.__eq__", "kind": "function", "range": [53, 4, 59, 24, 1414, 1633], "file_path": "src/_pytest/_code/source.py", "content": "def __eq__(self, other):\n        try:\n            return self.lines == other.lines\n        except AttributeError:\n            if isinstance(other, str):\n                return str(self) == other\n            return False"}, {"id": "_pytest._code.Source.__hash__", "kind": "variable", "range": [62, 4, 62, 19, 1712, 1727], "file_path": "src/_pytest/_code/source.py", "content": "__hash__ = None"}, {"id": "_pytest._code.Source.__getitem__", "kind": "function", "range": [64, 4, 66, 35, 1749, 1838], "file_path": "src/_pytest/_code/source.py", "content": "@overload\n    def __getitem__(self, key: int) -> str:\n        raise NotImplementedError()"}, {"id": "_pytest._code.Source.__getitem__", "kind": "function", "range": [68, 4, 70, 35, 1844, 1968], "file_path": "src/_pytest/_code/source.py", "content": "@overload  # noqa: F811\n    def __getitem__(self, key: slice) -> \"Source\":  # noqa: F811\n        raise NotImplementedError()"}, {"id": "_pytest._code.Source.__getitem__", "kind": "function", "range": [72, 4, 80, 28, 1974, 2377], "file_path": "src/_pytest/_code/source.py", "content": "def __getitem__(self, key: Union[int, slice]) -> Union[str, \"Source\"]:  # noqa: F811\n        if isinstance(key, int):\n            return self.lines[key]\n        else:\n            if key.step not in (None, 1):\n                raise IndexError(\"cannot slice a Source with a step\")\n            newsource = Source()\n            newsource.lines = self.lines[key.start : key.stop]\n            return newsource"}, {"id": "_pytest._code.Source.__iter__", "kind": "function", "range": [82, 4, 83, 31, 2383, 2451], "file_path": "src/_pytest/_code/source.py", "content": "def __iter__(self) -> Iterator[str]:\n        return iter(self.lines)"}, {"id": "_pytest._code.Source.__len__", "kind": "function", "range": [85, 4, 86, 30, 2457, 2513], "file_path": "src/_pytest/_code/source.py", "content": "def __len__(self) -> int:\n        return len(self.lines)"}, {"id": "_pytest._code.Source.strip", "kind": "function", "range": [88, 4, 99, 21, 2519, 2953], "file_path": "src/_pytest/_code/source.py", "content": "def strip(self) -> \"Source\":\n        \"\"\" return new source object with trailing\n            and leading blank lines removed.\n        \"\"\"\n        start, end = 0, len(self)\n        while start < end and not self.lines[start].strip():\n            start += 1\n        while end > start and not self.lines[end - 1].strip():\n            end -= 1\n        source = Source()\n        source.lines[:] = self.lines[start:end]\n        return source"}, {"id": "_pytest._code.Source.putaround", "kind": "function", "range": [101, 4, 112, 24, 2959, 3437], "file_path": "src/_pytest/_code/source.py", "content": "def putaround(\n        self, before: str = \"\", after: str = \"\", indent: str = \" \" * 4\n    ) -> \"Source\":\n        \"\"\" return a copy of the source object with\n            'before' and 'after' wrapped around it.\n        \"\"\"\n        beforesource = Source(before)\n        aftersource = Source(after)\n        newsource = Source()\n        lines = [(indent + line) for line in self.lines]\n        newsource.lines = beforesource.lines + lines + aftersource.lines\n        return newsource"}, {"id": "_pytest._code.Source.indent", "kind": "function", "range": [114, 4, 120, 24, 3443, 3739], "file_path": "src/_pytest/_code/source.py", "content": "def indent(self, indent: str = \" \" * 4) -> \"Source\":\n        \"\"\" return a copy of the source object with\n            all lines indented by the given indent-string.\n        \"\"\"\n        newsource = Source()\n        newsource.lines = [(indent + line) for line in self.lines]\n        return newsource"}, {"id": "_pytest._code.Source.getstatement", "kind": "function", "range": [122, 4, 127, 30, 3745, 3990], "file_path": "src/_pytest/_code/source.py", "content": "def getstatement(self, lineno: int) -> \"Source\":\n        \"\"\" return Source statement which contains the\n            given linenumber (counted from 0).\n        \"\"\"\n        start, end = self.getstatementrange(lineno)\n        return self[start:end]"}, {"id": "_pytest._code.Source.getstatementrange", "kind": "function", "range": [129, 4, 136, 25, 3996, 4376], "file_path": "src/_pytest/_code/source.py", "content": "def getstatementrange(self, lineno: int) -> Tuple[int, int]:\n        \"\"\" return (start, end) tuple which spans the minimal\n            statement region which containing the given lineno.\n        \"\"\"\n        if not (0 <= lineno < len(self)):\n            raise IndexError(\"lineno out of range\")\n        ast, start, end = getstatementrange_ast(lineno, self)\n        return start, end"}, {"id": "_pytest._code.Source.deindent", "kind": "function", "range": [138, 4, 142, 24, 4382, 4570], "file_path": "src/_pytest/_code/source.py", "content": "def deindent(self) -> \"Source\":\n        \"\"\"return a new source object deindented.\"\"\"\n        newsource = Source()\n        newsource.lines[:] = deindent(self.lines)\n        return newsource"}, {"id": "_pytest._code.Source.isparseable", "kind": "function", "range": [144, 4, 157, 23, 4576, 5009], "file_path": "src/_pytest/_code/source.py", "content": "def isparseable(self, deindent: bool = True) -> bool:\n        \"\"\" return True if source is parseable, heuristically\n            deindenting it by default.\n        \"\"\"\n        if deindent:\n            source = str(self.deindent())\n        else:\n            source = str(self)\n        try:\n            ast.parse(source)\n        except (SyntaxError, ValueError, TypeError):\n            return False\n        else:\n            return True"}, {"id": "_pytest._code.Source.__str__", "kind": "function", "range": [159, 4, 160, 36, 5015, 5077], "file_path": "src/_pytest/_code/source.py", "content": "def __str__(self) -> str:\n        return \"\\n\".join(self.lines)"}, {"id": "_pytest._code.Source.compile", "kind": "function", "range": [162, 4, 171, 35, 5083, 5355], "file_path": "src/_pytest/_code/source.py", "content": "@overload\n    def compile(\n        self,\n        filename: Optional[str] = ...,\n        mode: str = ...,\n        flag: \"Literal[0]\" = ...,\n        dont_inherit: int = ...,\n        _genframe: Optional[FrameType] = ...,\n    ) -> CodeType:\n        raise NotImplementedError()"}, {"id": "_pytest._code.Source.compile", "kind": "function", "range": [173, 4, 182, 35, 5361, 5668], "file_path": "src/_pytest/_code/source.py", "content": "@overload  # noqa: F811\n    def compile(  # noqa: F811\n        self,\n        filename: Optional[str] = ...,\n        mode: str = ...,\n        flag: int = ...,\n        dont_inherit: int = ...,\n        _genframe: Optional[FrameType] = ...,\n    ) -> Union[CodeType, ast.AST]:\n        raise NotImplementedError()"}, {"id": "_pytest._code.Source.compile", "kind": "function", "range": [184, 4, 228, 21, 5674, 7627], "file_path": "src/_pytest/_code/source.py", "content": "def compile(  # noqa: F811\n        self,\n        filename: Optional[str] = None,\n        mode: str = \"exec\",\n        flag: int = 0,\n        dont_inherit: int = 0,\n        _genframe: Optional[FrameType] = None,\n    ) -> Union[CodeType, ast.AST]:\n        \"\"\" return compiled code object. if filename is None\n            invent an artificial filename which displays\n            the source/line position of the caller frame.\n        \"\"\"\n        if not filename or py.path.local(filename).check(file=0):\n            if _genframe is None:\n                _genframe = sys._getframe(1)  # the caller\n            fn, lineno = _genframe.f_code.co_filename, _genframe.f_lineno\n            base = \"<%d-codegen \" % self._compilecounter\n            self.__class__._compilecounter += 1\n            if not filename:\n                filename = base + \"%s:%d>\" % (fn, lineno)\n            else:\n                filename = base + \"%r %s:%d>\" % (filename, fn, lineno)\n        source = \"\\n\".join(self.lines) + \"\\n\"\n        try:\n            co = compile(source, filename, mode, flag)\n        except SyntaxError as ex:\n            # re-represent syntax errors from parsing python strings\n            msglines = self.lines[: ex.lineno]\n            if ex.offset:\n                msglines.append(\" \" * ex.offset + \"^\")\n            msglines.append(\"(code was compiled probably from here: %s)\" % filename)\n            newex = SyntaxError(\"\\n\".join(msglines))\n            newex.offset = ex.offset\n            newex.lineno = ex.lineno\n            newex.text = ex.text\n            raise newex\n        else:\n            if flag & ast.PyCF_ONLY_AST:\n                assert isinstance(co, ast.AST)\n                return co\n            assert isinstance(co, CodeType)\n            lines = [(x + \"\\n\") for x in self.lines]\n            # Type ignored because linecache.cache is private.\n            linecache.cache[filename] = (1, None, lines, filename)  # type: ignore\n            return co"}, {"id": "_pytest._code.compile_", "kind": "function", "range": [236, 0, 244, 31, 7668, 7903], "file_path": "src/_pytest/_code/source.py", "content": "@overload\ndef compile_(\n    source: Union[str, bytes, ast.mod, ast.AST],\n    filename: Optional[str] = ...,\n    mode: str = ...,\n    flags: \"Literal[0]\" = ...,\n    dont_inherit: int = ...,\n) -> CodeType:\n    raise NotImplementedError()"}, {"id": "_pytest._code.compile_", "kind": "function", "range": [247, 0, 255, 31, 7906, 8176], "file_path": "src/_pytest/_code/source.py", "content": "@overload  # noqa: F811\ndef compile_(  # noqa: F811\n    source: Union[str, bytes, ast.mod, ast.AST],\n    filename: Optional[str] = ...,\n    mode: str = ...,\n    flags: int = ...,\n    dont_inherit: int = ...,\n) -> Union[CodeType, ast.AST]:\n    raise NotImplementedError()"}, {"id": "_pytest._code.compile_", "kind": "function", "range": [258, 0, 278, 64, 8179, 9011], "file_path": "src/_pytest/_code/source.py", "content": "def compile_(  # noqa: F811\n    source: Union[str, bytes, ast.mod, ast.AST],\n    filename: Optional[str] = None,\n    mode: str = \"exec\",\n    flags: int = 0,\n    dont_inherit: int = 0,\n) -> Union[CodeType, ast.AST]:\n    \"\"\" compile the given source to a raw code object,\n        and maintain an internal cache which allows later\n        retrieval of the source code for the code object\n        and any recursively created code objects.\n    \"\"\"\n    if isinstance(source, ast.AST):\n        # XXX should Source support having AST?\n        assert filename is not None\n        co = compile(source, filename, mode, flags, dont_inherit)\n        assert isinstance(co, (CodeType, ast.AST))\n        return co\n    _genframe = sys._getframe(1)  # the caller\n    s = Source(source)\n    return s.compile(filename, mode, flags, _genframe=_genframe)"}, {"id": "_pytest._code.getfslineno", "kind": "function", "range": [281, 0, 313, 42, 9014, 10047], "file_path": "src/_pytest/_code/source.py", "content": "def getfslineno(obj: Any) -> Tuple[Union[str, py.path.local], int]:\n    \"\"\" Return source location (path, lineno) for the given object.\n    If the source cannot be determined return (\"\", -1).\n\n    The line number is 0-based.\n    \"\"\"\n    from .code import Code\n\n    # xxx let decorators etc specify a sane ordering\n    # NOTE: this used to be done in _pytest.compat.getfslineno, initially added\n    #       in 6ec13a2b9.  It (\"place_as\") appears to be something very custom.\n    obj = get_real_func(obj)\n    if hasattr(obj, \"place_as\"):\n        obj = obj.place_as\n\n    try:\n        code = Code(obj)\n    except TypeError:\n        try:\n            fn = inspect.getsourcefile(obj) or inspect.getfile(obj)\n        except TypeError:\n            return \"\", -1\n\n        fspath = fn and py.path.local(fn) or \"\"\n        lineno = -1\n        if fspath:\n            try:\n                _, lineno = findsource(obj)\n            except OSError:\n                pass\n        return fspath, lineno\n    else:\n        return code.path, code.firstlineno"}, {"id": "_pytest._code.findsource", "kind": "function", "range": [321, 0, 328, 25, 10075, 10343], "file_path": "src/_pytest/_code/source.py", "content": "def findsource(obj) -> Tuple[Optional[Source], int]:\n    try:\n        sourcelines, lineno = inspect.findsource(obj)\n    except Exception:\n        return None, -1\n    source = Source()\n    source.lines = [line.rstrip() for line in sourcelines]\n    return source, lineno"}, {"id": "_pytest._code.getsource", "kind": "function", "range": [331, 0, 340, 35, 10346, 10674], "file_path": "src/_pytest/_code/source.py", "content": "def getsource(obj, **kwargs) -> Source:\n    from .code import getrawcode\n\n    obj = getrawcode(obj)\n    try:\n        strsrc = inspect.getsource(obj)\n    except IndentationError:\n        strsrc = '\"Buggy python version consider upgrading, cannot get source\"'\n    assert isinstance(strsrc, str)\n    return Source(strsrc, **kwargs)"}, {"id": "_pytest._code.deindent", "kind": "function", "range": [343, 0, 344, 57, 10677, 10783], "file_path": "src/_pytest/_code/source.py", "content": "def deindent(lines: Sequence[str]) -> List[str]:\n    return textwrap.dedent(\"\\n\".join(lines)).splitlines()"}, {"id": "_pytest._code.get_statement_startend2", "kind": "function", "range": [347, 0, 368, 21, 10786, 11670], "file_path": "src/_pytest/_code/source.py", "content": "def get_statement_startend2(lineno: int, node: ast.AST) -> Tuple[int, Optional[int]]:\n    import ast\n\n    # flatten all statements and except handlers into one lineno-list\n    # AST's line numbers start indexing at 1\n    values = []  # type: List[int]\n    for x in ast.walk(node):\n        if isinstance(x, (ast.stmt, ast.ExceptHandler)):\n            values.append(x.lineno - 1)\n            for name in (\"finalbody\", \"orelse\"):\n                val = getattr(x, name, None)  # type: Optional[List[ast.stmt]]\n                if val:\n                    # treat the finally/orelse part as its own statement\n                    values.append(val[0].lineno - 1 - 1)\n    values.sort()\n    insert_index = bisect_right(values, lineno)\n    start = values[insert_index - 1]\n    if insert_index >= len(values):\n        end = None\n    else:\n        end = values[insert_index]\n    return start, end"}, {"id": "_pytest._code.getstatementrange_ast", "kind": "function", "range": [371, 0, 415, 30, 11673, 13361], "file_path": "src/_pytest/_code/source.py", "content": "def getstatementrange_ast(\n    lineno: int,\n    source: Source,\n    assertion: bool = False,\n    astnode: Optional[ast.AST] = None,\n) -> Tuple[ast.AST, int, int]:\n    if astnode is None:\n        content = str(source)\n        # See #4260:\n        # don't produce duplicate warnings when compiling source to find ast\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            astnode = ast.parse(content, \"source\", \"exec\")\n\n    start, end = get_statement_startend2(lineno, astnode)\n    # we need to correct the end:\n    # - ast-parsing strips comments\n    # - there might be empty lines\n    # - we might have lesser indented code blocks at the end\n    if end is None:\n        end = len(source.lines)\n\n    if end > start + 1:\n        # make sure we don't span differently indented code blocks\n        # by using the BlockFinder helper used which inspect.getsource() uses itself\n        block_finder = inspect.BlockFinder()\n        # if we start with an indented line, put blockfinder to \"started\" mode\n        block_finder.started = source.lines[start][0].isspace()\n        it = ((x + \"\\n\") for x in source.lines[start:end])\n        try:\n            for tok in tokenize.generate_tokens(lambda: next(it)):\n                block_finder.tokeneater(*tok)\n        except (inspect.EndOfBlock, IndentationError):\n            end = block_finder.last + start\n        except Exception:\n            pass\n\n    # the end might still point to a comment or empty line, correct it\n    while end:\n        line = source.lines[end - 1].lstrip()\n        if line.startswith(\"#\") or not line:\n            end -= 1\n        else:\n            break\n    return astnode, start, end"}, {"id": "_pytest.debugging._validate_usepdb_cls", "kind": "function", "range": [10, 0, 18, 31, 222, 536], "file_path": "src/_pytest/debugging.py", "content": "def _validate_usepdb_cls(value):\n    \"\"\"Validate syntax of --pdbcls option.\"\"\"\n    try:\n        modname, classname = value.split(\":\")\n    except ValueError:\n        raise argparse.ArgumentTypeError(\n            \"{!r} is not in the format 'modname:classname'\".format(value)\n        )\n    return (modname, classname)"}, {"id": "_pytest.debugging.pytest_addoption", "kind": "function", "range": [21, 0, 42, 5, 539, 1237], "file_path": "src/_pytest/debugging.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"--pdb\",\n        dest=\"usepdb\",\n        action=\"store_true\",\n        help=\"start the interactive Python debugger on errors or KeyboardInterrupt.\",\n    )\n    group._addoption(\n        \"--pdbcls\",\n        dest=\"usepdb_cls\",\n        metavar=\"modulename:classname\",\n        type=_validate_usepdb_cls,\n        help=\"start a custom interactive Python debugger on errors. \"\n        \"For example: --pdbcls=IPython.terminal.debugger:TerminalPdb\",\n    )\n    group._addoption(\n        \"--trace\",\n        dest=\"trace\",\n        action=\"store_true\",\n        help=\"Immediately break when running each test.\",\n    )"}, {"id": "_pytest.debugging.pytest_configure", "kind": "function", "range": [45, 0, 69, 31, 1240, 2049], "file_path": "src/_pytest/debugging.py", "content": "def pytest_configure(config):\n    import pdb\n\n    if config.getvalue(\"trace\"):\n        config.pluginmanager.register(PdbTrace(), \"pdbtrace\")\n    if config.getvalue(\"usepdb\"):\n        config.pluginmanager.register(PdbInvoke(), \"pdbinvoke\")\n\n    pytestPDB._saved.append(\n        (pdb.set_trace, pytestPDB._pluginmanager, pytestPDB._config)\n    )\n    pdb.set_trace = pytestPDB.set_trace\n    pytestPDB._pluginmanager = config.pluginmanager\n    pytestPDB._config = config\n\n    # NOTE: not using pytest_unconfigure, since it might get called although\n    #       pytest_configure was not (if another plugin raises UsageError).\n    def fin():\n        (\n            pdb.set_trace,\n            pytestPDB._pluginmanager,\n            pytestPDB._config,\n        ) = pytestPDB._saved.pop()\n\n    config._cleanup.append(fin)"}, {"id": "_pytest.debugging.pytestPDB", "kind": "class", "range": [72, 0, 253, 29, 2052, 8407], "file_path": "src/_pytest/debugging.py", "content": "class pytestPDB:\n    \"\"\" Pseudo PDB that defers to the real pdb. \"\"\"\n\n    _pluginmanager = None\n    _config = None\n    _saved = []  # type: list\n    _recursive_debug = 0\n    _wrapped_pdb_cls = None\n\n    @classmethod\n    def _is_capturing(cls, capman):\n        if capman:\n            return capman.is_capturing()\n        return False\n\n    @classmethod\n    def _import_pdb_cls(cls, capman):\n        if not cls._config:\n            import pdb\n\n            # Happens when using pytest.set_trace outside of a test.\n            return pdb.Pdb\n\n        usepdb_cls = cls._config.getvalue(\"usepdb_cls\")\n\n        if cls._wrapped_pdb_cls and cls._wrapped_pdb_cls[0] == usepdb_cls:\n            return cls._wrapped_pdb_cls[1]\n\n        if usepdb_cls:\n            modname, classname = usepdb_cls\n\n            try:\n                __import__(modname)\n                mod = sys.modules[modname]\n\n                # Handle --pdbcls=pdb:pdb.Pdb (useful e.g. with pdbpp).\n                parts = classname.split(\".\")\n                pdb_cls = getattr(mod, parts[0])\n                for part in parts[1:]:\n                    pdb_cls = getattr(pdb_cls, part)\n            except Exception as exc:\n                value = \":\".join((modname, classname))\n                raise UsageError(\n                    \"--pdbcls: could not import {!r}: {}\".format(value, exc)\n                )\n        else:\n            import pdb\n\n            pdb_cls = pdb.Pdb\n\n        wrapped_cls = cls._get_pdb_wrapper_class(pdb_cls, capman)\n        cls._wrapped_pdb_cls = (usepdb_cls, wrapped_cls)\n        return wrapped_cls\n\n    @classmethod\n    def _get_pdb_wrapper_class(cls, pdb_cls, capman):\n        import _pytest.config\n\n        class PytestPdbWrapper(pdb_cls):\n            _pytest_capman = capman\n            _continued = False\n\n            def do_debug(self, arg):\n                cls._recursive_debug += 1\n                ret = super().do_debug(arg)\n                cls._recursive_debug -= 1\n                return ret\n\n            def do_continue(self, arg):\n                ret = super().do_continue(arg)\n                if cls._recursive_debug == 0:\n                    tw = _pytest.config.create_terminal_writer(cls._config)\n                    tw.line()\n\n                    capman = self._pytest_capman\n                    capturing = pytestPDB._is_capturing(capman)\n                    if capturing:\n                        if capturing == \"global\":\n                            tw.sep(\">\", \"PDB continue (IO-capturing resumed)\")\n                        else:\n                            tw.sep(\n                                \">\",\n                                \"PDB continue (IO-capturing resumed for %s)\"\n                                % capturing,\n                            )\n                        capman.resume()\n                    else:\n                        tw.sep(\">\", \"PDB continue\")\n                cls._pluginmanager.hook.pytest_leave_pdb(config=cls._config, pdb=self)\n                self._continued = True\n                return ret\n\n            do_c = do_cont = do_continue\n\n            def do_quit(self, arg):\n                \"\"\"Raise Exit outcome when quit command is used in pdb.\n\n                This is a bit of a hack - it would be better if BdbQuit\n                could be handled, but this would require to wrap the\n                whole pytest run, and adjust the report etc.\n                \"\"\"\n                ret = super().do_quit(arg)\n\n                if cls._recursive_debug == 0:\n                    outcomes.exit(\"Quitting debugger\")\n\n                return ret\n\n            do_q = do_quit\n            do_exit = do_quit\n\n            def setup(self, f, tb):\n                \"\"\"Suspend on setup().\n\n                Needed after do_continue resumed, and entering another\n                breakpoint again.\n                \"\"\"\n                ret = super().setup(f, tb)\n                if not ret and self._continued:\n                    # pdb.setup() returns True if the command wants to exit\n                    # from the interaction: do not suspend capturing then.\n                    if self._pytest_capman:\n                        self._pytest_capman.suspend_global_capture(in_=True)\n                return ret\n\n            def get_stack(self, f, t):\n                stack, i = super().get_stack(f, t)\n                if f is None:\n                    # Find last non-hidden frame.\n                    i = max(0, len(stack) - 1)\n                    while i and stack[i][0].f_locals.get(\"__tracebackhide__\", False):\n                        i -= 1\n                return stack, i\n\n        return PytestPdbWrapper\n\n    @classmethod\n    def _init_pdb(cls, method, *args, **kwargs):\n        \"\"\" Initialize PDB debugging, dropping any IO capturing. \"\"\"\n        import _pytest.config\n\n        if cls._pluginmanager is not None:\n            capman = cls._pluginmanager.getplugin(\"capturemanager\")\n        else:\n            capman = None\n        if capman:\n            capman.suspend(in_=True)\n\n        if cls._config:\n            tw = _pytest.config.create_terminal_writer(cls._config)\n            tw.line()\n\n            if cls._recursive_debug == 0:\n                # Handle header similar to pdb.set_trace in py37+.\n                header = kwargs.pop(\"header\", None)\n                if header is not None:\n                    tw.sep(\">\", header)\n                else:\n                    capturing = cls._is_capturing(capman)\n                    if capturing == \"global\":\n                        tw.sep(\">\", \"PDB {} (IO-capturing turned off)\".format(method))\n                    elif capturing:\n                        tw.sep(\n                            \">\",\n                            \"PDB %s (IO-capturing turned off for %s)\"\n                            % (method, capturing),\n                        )\n                    else:\n                        tw.sep(\">\", \"PDB {}\".format(method))\n\n        _pdb = cls._import_pdb_cls(capman)(**kwargs)\n\n        if cls._pluginmanager:\n            cls._pluginmanager.hook.pytest_enter_pdb(config=cls._config, pdb=_pdb)\n        return _pdb\n\n    @classmethod\n    def set_trace(cls, *args, **kwargs):\n        \"\"\"Invoke debugging via ``Pdb.set_trace``, dropping any IO capturing.\"\"\"\n        frame = sys._getframe().f_back\n        _pdb = cls._init_pdb(\"set_trace\", *args, **kwargs)\n        _pdb.set_trace(frame)"}, {"id": "_pytest.debugging.pytestPDB._pluginmanager", "kind": "variable", "range": [75, 4, 75, 25, 2126, 2147], "file_path": "src/_pytest/debugging.py", "content": "_pluginmanager = None"}, {"id": "_pytest.debugging.pytestPDB._config", "kind": "variable", "range": [76, 4, 76, 18, 2152, 2166], "file_path": "src/_pytest/debugging.py", "content": "_config = None"}, {"id": "_pytest.debugging.pytestPDB._saved", "kind": "variable", "range": [77, 4, 77, 15, 2171, 2182], "file_path": "src/_pytest/debugging.py", "content": "_saved = []"}, {"id": "_pytest.debugging.pytestPDB._recursive_debug", "kind": "variable", "range": [78, 4, 78, 24, 2201, 2221], "file_path": "src/_pytest/debugging.py", "content": "_recursive_debug = 0"}, {"id": "_pytest.debugging.pytestPDB._wrapped_pdb_cls", "kind": "variable", "range": [79, 4, 79, 27, 2226, 2249], "file_path": "src/_pytest/debugging.py", "content": "_wrapped_pdb_cls = None"}, {"id": "_pytest.debugging.pytestPDB._is_capturing", "kind": "function", "range": [81, 4, 85, 20, 2255, 2384], "file_path": "src/_pytest/debugging.py", "content": "@classmethod\n    def _is_capturing(cls, capman):\n        if capman:\n            return capman.is_capturing()\n        return False"}, {"id": "_pytest.debugging.pytestPDB._import_pdb_cls", "kind": "function", "range": [87, 4, 124, 26, 2390, 3628], "file_path": "src/_pytest/debugging.py", "content": "@classmethod\n    def _import_pdb_cls(cls, capman):\n        if not cls._config:\n            import pdb\n\n            # Happens when using pytest.set_trace outside of a test.\n            return pdb.Pdb\n\n        usepdb_cls = cls._config.getvalue(\"usepdb_cls\")\n\n        if cls._wrapped_pdb_cls and cls._wrapped_pdb_cls[0] == usepdb_cls:\n            return cls._wrapped_pdb_cls[1]\n\n        if usepdb_cls:\n            modname, classname = usepdb_cls\n\n            try:\n                __import__(modname)\n                mod = sys.modules[modname]\n\n                # Handle --pdbcls=pdb:pdb.Pdb (useful e.g. with pdbpp).\n                parts = classname.split(\".\")\n                pdb_cls = getattr(mod, parts[0])\n                for part in parts[1:]:\n                    pdb_cls = getattr(pdb_cls, part)\n            except Exception as exc:\n                value = \":\".join((modname, classname))\n                raise UsageError(\n                    \"--pdbcls: could not import {!r}: {}\".format(value, exc)\n                )\n        else:\n            import pdb\n\n            pdb_cls = pdb.Pdb\n\n        wrapped_cls = cls._get_pdb_wrapper_class(pdb_cls, capman)\n        cls._wrapped_pdb_cls = (usepdb_cls, wrapped_cls)\n        return wrapped_cls"}, {"id": "_pytest.debugging.pytestPDB._get_pdb_wrapper_class", "kind": "function", "range": [126, 4, 206, 31, 3634, 6672], "file_path": "src/_pytest/debugging.py", "content": "@classmethod\n    def _get_pdb_wrapper_class(cls, pdb_cls, capman):\n        import _pytest.config\n\n        class PytestPdbWrapper(pdb_cls):\n            _pytest_capman = capman\n            _continued = False\n\n            def do_debug(self, arg):\n                cls._recursive_debug += 1\n                ret = super().do_debug(arg)\n                cls._recursive_debug -= 1\n                return ret\n\n            def do_continue(self, arg):\n                ret = super().do_continue(arg)\n                if cls._recursive_debug == 0:\n                    tw = _pytest.config.create_terminal_writer(cls._config)\n                    tw.line()\n\n                    capman = self._pytest_capman\n                    capturing = pytestPDB._is_capturing(capman)\n                    if capturing:\n                        if capturing == \"global\":\n                            tw.sep(\">\", \"PDB continue (IO-capturing resumed)\")\n                        else:\n                            tw.sep(\n                                \">\",\n                                \"PDB continue (IO-capturing resumed for %s)\"\n                                % capturing,\n                            )\n                        capman.resume()\n                    else:\n                        tw.sep(\">\", \"PDB continue\")\n                cls._pluginmanager.hook.pytest_leave_pdb(config=cls._config, pdb=self)\n                self._continued = True\n                return ret\n\n            do_c = do_cont = do_continue\n\n            def do_quit(self, arg):\n                \"\"\"Raise Exit outcome when quit command is used in pdb.\n\n                This is a bit of a hack - it would be better if BdbQuit\n                could be handled, but this would require to wrap the\n                whole pytest run, and adjust the report etc.\n                \"\"\"\n                ret = super().do_quit(arg)\n\n                if cls._recursive_debug == 0:\n                    outcomes.exit(\"Quitting debugger\")\n\n                return ret\n\n            do_q = do_quit\n            do_exit = do_quit\n\n            def setup(self, f, tb):\n                \"\"\"Suspend on setup().\n\n                Needed after do_continue resumed, and entering another\n                breakpoint again.\n                \"\"\"\n                ret = super().setup(f, tb)\n                if not ret and self._continued:\n                    # pdb.setup() returns True if the command wants to exit\n                    # from the interaction: do not suspend capturing then.\n                    if self._pytest_capman:\n                        self._pytest_capman.suspend_global_capture(in_=True)\n                return ret\n\n            def get_stack(self, f, t):\n                stack, i = super().get_stack(f, t)\n                if f is None:\n                    # Find last non-hidden frame.\n                    i = max(0, len(stack) - 1)\n                    while i and stack[i][0].f_locals.get(\"__tracebackhide__\", False):\n                        i -= 1\n                return stack, i\n\n        return PytestPdbWrapper"}, {"id": "_pytest.debugging.pytestPDB._init_pdb", "kind": "function", "range": [208, 4, 246, 19, 6678, 8139], "file_path": "src/_pytest/debugging.py", "content": "@classmethod\n    def _init_pdb(cls, method, *args, **kwargs):\n        \"\"\" Initialize PDB debugging, dropping any IO capturing. \"\"\"\n        import _pytest.config\n\n        if cls._pluginmanager is not None:\n            capman = cls._pluginmanager.getplugin(\"capturemanager\")\n        else:\n            capman = None\n        if capman:\n            capman.suspend(in_=True)\n\n        if cls._config:\n            tw = _pytest.config.create_terminal_writer(cls._config)\n            tw.line()\n\n            if cls._recursive_debug == 0:\n                # Handle header similar to pdb.set_trace in py37+.\n                header = kwargs.pop(\"header\", None)\n                if header is not None:\n                    tw.sep(\">\", header)\n                else:\n                    capturing = cls._is_capturing(capman)\n                    if capturing == \"global\":\n                        tw.sep(\">\", \"PDB {} (IO-capturing turned off)\".format(method))\n                    elif capturing:\n                        tw.sep(\n                            \">\",\n                            \"PDB %s (IO-capturing turned off for %s)\"\n                            % (method, capturing),\n                        )\n                    else:\n                        tw.sep(\">\", \"PDB {}\".format(method))\n\n        _pdb = cls._import_pdb_cls(capman)(**kwargs)\n\n        if cls._pluginmanager:\n            cls._pluginmanager.hook.pytest_enter_pdb(config=cls._config, pdb=_pdb)\n        return _pdb"}, {"id": "_pytest.debugging.pytestPDB.set_trace", "kind": "function", "range": [248, 4, 253, 29, 8145, 8407], "file_path": "src/_pytest/debugging.py", "content": "@classmethod\n    def set_trace(cls, *args, **kwargs):\n        \"\"\"Invoke debugging via ``Pdb.set_trace``, dropping any IO capturing.\"\"\"\n        frame = sys._getframe().f_back\n        _pdb = cls._init_pdb(\"set_trace\", *args, **kwargs)\n        _pdb.set_trace(frame)"}, {"id": "_pytest.debugging.PdbInvoke", "kind": "class", "range": [256, 0, 268, 23, 8410, 8919], "file_path": "src/_pytest/debugging.py", "content": "class PdbInvoke:\n    def pytest_exception_interact(self, node, call, report):\n        capman = node.config.pluginmanager.getplugin(\"capturemanager\")\n        if capman:\n            capman.suspend_global_capture(in_=True)\n            out, err = capman.read_global_capture()\n            sys.stdout.write(out)\n            sys.stdout.write(err)\n        _enter_pdb(node, call.excinfo, report)\n\n    def pytest_internalerror(self, excrepr, excinfo):\n        tb = _postmortem_traceback(excinfo)\n        post_mortem(tb)"}, {"id": "_pytest.debugging.PdbInvoke.pytest_exception_interact", "kind": "function", "range": [257, 4, 264, 46, 8431, 8796], "file_path": "src/_pytest/debugging.py", "content": "def pytest_exception_interact(self, node, call, report):\n        capman = node.config.pluginmanager.getplugin(\"capturemanager\")\n        if capman:\n            capman.suspend_global_capture(in_=True)\n            out, err = capman.read_global_capture()\n            sys.stdout.write(out)\n            sys.stdout.write(err)\n        _enter_pdb(node, call.excinfo, report)"}, {"id": "_pytest.debugging.PdbInvoke.pytest_internalerror", "kind": "function", "range": [266, 4, 268, 23, 8802, 8919], "file_path": "src/_pytest/debugging.py", "content": "def pytest_internalerror(self, excrepr, excinfo):\n        tb = _postmortem_traceback(excinfo)\n        post_mortem(tb)"}, {"id": "_pytest.debugging.PdbTrace", "kind": "class", "range": [271, 0, 275, 13, 8922, 9082], "file_path": "src/_pytest/debugging.py", "content": "class PdbTrace:\n    @hookimpl(hookwrapper=True)\n    def pytest_pyfunc_call(self, pyfuncitem):\n        wrap_pytest_function_for_tracing(pyfuncitem)\n        yield"}, {"id": "_pytest.debugging.PdbTrace.pytest_pyfunc_call", "kind": "function", "range": [272, 4, 275, 13, 8942, 9082], "file_path": "src/_pytest/debugging.py", "content": "@hookimpl(hookwrapper=True)\n    def pytest_pyfunc_call(self, pyfuncitem):\n        wrap_pytest_function_for_tracing(pyfuncitem)\n        yield"}, {"id": "_pytest.debugging.wrap_pytest_function_for_tracing", "kind": "function", "range": [278, 0, 294, 28, 9085, 9881], "file_path": "src/_pytest/debugging.py", "content": "def wrap_pytest_function_for_tracing(pyfuncitem):\n    \"\"\"Changes the python function object of the given Function item by a wrapper which actually\n    enters pdb before calling the python function itself, effectively leaving the user\n    in the pdb prompt in the first statement of the function.\n    \"\"\"\n    _pdb = pytestPDB._init_pdb(\"runcall\")\n    testfunction = pyfuncitem.obj\n\n    # we can't just return `partial(pdb.runcall, testfunction)` because (on\n    # python < 3.7.4) runcall's first param is `func`, which means we'd get\n    # an exception if one of the kwargs to testfunction was called `func`\n    @functools.wraps(testfunction)\n    def wrapper(*args, **kwargs):\n        func = functools.partial(testfunction, *args, **kwargs)\n        _pdb.runcall(func)\n\n    pyfuncitem.obj = wrapper"}, {"id": "_pytest.debugging.maybe_wrap_pytest_function_for_tracing", "kind": "function", "range": [297, 0, 301, 52, 9884, 10143], "file_path": "src/_pytest/debugging.py", "content": "def maybe_wrap_pytest_function_for_tracing(pyfuncitem):\n    \"\"\"Wrap the given pytestfunct item for tracing support if --trace was given in\n    the command line\"\"\"\n    if pyfuncitem.config.getvalue(\"trace\"):\n        wrap_pytest_function_for_tracing(pyfuncitem)"}, {"id": "_pytest.debugging._enter_pdb", "kind": "function", "range": [304, 0, 330, 14, 10146, 11019], "file_path": "src/_pytest/debugging.py", "content": "def _enter_pdb(node, excinfo, rep):\n    # XXX we re-use the TerminalReporter's terminalwriter\n    # because this seems to avoid some encoding related troubles\n    # for not completely clear reasons.\n    tw = node.config.pluginmanager.getplugin(\"terminalreporter\")._tw\n    tw.line()\n\n    showcapture = node.config.option.showcapture\n\n    for sectionname, content in (\n        (\"stdout\", rep.capstdout),\n        (\"stderr\", rep.capstderr),\n        (\"log\", rep.caplog),\n    ):\n        if showcapture in (sectionname, \"all\") and content:\n            tw.sep(\">\", \"captured \" + sectionname)\n            if content[-1:] == \"\\n\":\n                content = content[:-1]\n            tw.line(content)\n\n    tw.sep(\">\", \"traceback\")\n    rep.toterminal(tw)\n    tw.sep(\">\", \"entering PDB\")\n    tb = _postmortem_traceback(excinfo)\n    rep._pdbshown = True\n    post_mortem(tb)\n    return rep"}, {"id": "_pytest.debugging._postmortem_traceback", "kind": "function", "range": [333, 0, 341, 34, 11022, 11362], "file_path": "src/_pytest/debugging.py", "content": "def _postmortem_traceback(excinfo):\n    from doctest import UnexpectedException\n\n    if isinstance(excinfo.value, UnexpectedException):\n        # A doctest.UnexpectedException is not useful for post_mortem.\n        # Use the underlying exception instead:\n        return excinfo.value.exc_info[2]\n    else:\n        return excinfo._excinfo[2]"}, {"id": "_pytest.debugging.post_mortem", "kind": "function", "range": [344, 0, 349, 42, 11365, 11530], "file_path": "src/_pytest/debugging.py", "content": "def post_mortem(t):\n    p = pytestPDB._init_pdb(\"post_mortem\")\n    p.reset()\n    p.interaction(None, t)\n    if p.quitting:\n        outcomes.exit(\"Quitting debugger\")"}, {"id": "_pytest.assertion.DEFAULT_MAX_LINES", "kind": "variable", "range": [8, 0, 8, 21, 196, 217], "file_path": "src/_pytest/assertion/truncate.py", "content": "DEFAULT_MAX_LINES = 8"}, {"id": "_pytest.assertion.DEFAULT_MAX_CHARS", "kind": "variable", "range": [9, 0, 9, 26, 218, 244], "file_path": "src/_pytest/assertion/truncate.py", "content": "DEFAULT_MAX_CHARS = 8 * 80"}, {"id": "_pytest.assertion.USAGE_MSG", "kind": "variable", "range": [10, 0, 10, 31, 245, 276], "file_path": "src/_pytest/assertion/truncate.py", "content": "USAGE_MSG = \"use '-vv' to show\""}, {"id": "_pytest.assertion.truncate_if_required", "kind": "function", "range": [13, 0, 19, 22, 279, 541], "file_path": "src/_pytest/assertion/truncate.py", "content": "def truncate_if_required(explanation, item, max_length=None):\n    \"\"\"\n    Truncate this assertion explanation if the given test item is eligible.\n    \"\"\"\n    if _should_truncate_item(item):\n        return _truncate_explanation(explanation)\n    return explanation"}, {"id": "_pytest.assertion._should_truncate_item", "kind": "function", "range": [22, 0, 27, 47, 544, 743], "file_path": "src/_pytest/assertion/truncate.py", "content": "def _should_truncate_item(item):\n    \"\"\"\n    Whether or not this test item is eligible for truncation.\n    \"\"\"\n    verbose = item.config.option.verbose\n    return verbose < 2 and not _running_on_ci()"}, {"id": "_pytest.assertion._running_on_ci", "kind": "function", "range": [30, 0, 33, 53, 746, 918], "file_path": "src/_pytest/assertion/truncate.py", "content": "def _running_on_ci():\n    \"\"\"Check if we're currently running on a CI system.\"\"\"\n    env_vars = [\"CI\", \"BUILD_NUMBER\"]\n    return any(var in os.environ for var in env_vars)"}, {"id": "_pytest.assertion._truncate_explanation", "kind": "function", "range": [36, 0, 72, 32, 921, 2404], "file_path": "src/_pytest/assertion/truncate.py", "content": "def _truncate_explanation(input_lines, max_lines=None, max_chars=None):\n    \"\"\"\n    Truncate given list of strings that makes up the assertion explanation.\n\n    Truncates to either 8 lines, or 640 characters - whichever the input reaches\n    first. The remaining lines will be replaced by a usage message.\n    \"\"\"\n\n    if max_lines is None:\n        max_lines = DEFAULT_MAX_LINES\n    if max_chars is None:\n        max_chars = DEFAULT_MAX_CHARS\n\n    # Check if truncation required\n    input_char_count = len(\"\".join(input_lines))\n    if len(input_lines) <= max_lines and input_char_count <= max_chars:\n        return input_lines\n\n    # Truncate first to max_lines, and then truncate to max_chars if max_chars\n    # is exceeded.\n    truncated_explanation = input_lines[:max_lines]\n    truncated_explanation = _truncate_by_char_count(truncated_explanation, max_chars)\n\n    # Add ellipsis to final line\n    truncated_explanation[-1] = truncated_explanation[-1] + \"...\"\n\n    # Append useful message to explanation\n    truncated_line_count = len(input_lines) - len(truncated_explanation)\n    truncated_line_count += 1  # Account for the part-truncated final line\n    msg = \"...Full output truncated\"\n    if truncated_line_count == 1:\n        msg += \" ({} line hidden)\".format(truncated_line_count)\n    else:\n        msg += \" ({} lines hidden)\".format(truncated_line_count)\n    msg += \", {}\".format(USAGE_MSG)\n    truncated_explanation.extend([\"\", str(msg)])\n    return truncated_explanation"}, {"id": "_pytest.assertion._truncate_by_char_count", "kind": "function", "range": [75, 0, 94, 27, 2407, 3227], "file_path": "src/_pytest/assertion/truncate.py", "content": "def _truncate_by_char_count(input_lines, max_chars):\n    # Check if truncation required\n    if len(\"\".join(input_lines)) <= max_chars:\n        return input_lines\n\n    # Find point at which input length exceeds total allowed length\n    iterated_char_count = 0\n    for iterated_index, input_line in enumerate(input_lines):\n        if iterated_char_count + len(input_line) > max_chars:\n            break\n        iterated_char_count += len(input_line)\n\n    # Create truncated explanation with modified final line\n    truncated_result = input_lines[:iterated_index]\n    final_line = input_lines[iterated_index]\n    if final_line:\n        final_line_truncate_point = max_chars - iterated_char_count\n        final_line = final_line[:final_line_truncate_point]\n    truncated_result.append(final_line)\n    return truncated_result"}, {"id": "_pytest.assertion._reprcompare", "kind": "variable", "range": [24, 0, 24, 19, 782, 801], "file_path": "src/_pytest/assertion/util.py", "content": "_reprcompare = None"}, {"id": "_pytest.assertion._assertion_pass", "kind": "variable", "range": [28, 0, 28, 22, 985, 1007], "file_path": "src/_pytest/assertion/util.py", "content": "_assertion_pass = None"}, {"id": "_pytest.assertion.format_explanation", "kind": "function", "range": [31, 0, 43, 28, 1061, 1626], "file_path": "src/_pytest/assertion/util.py", "content": "def format_explanation(explanation: str) -> str:\n    \"\"\"This formats an explanation\n\n    Normally all embedded newlines are escaped, however there are\n    three exceptions: \\n{, \\n} and \\n~.  The first two are intended\n    cover nested explanations, see function and attribute explanations\n    for examples (.visit_Call(), visit_Attribute()).  The last one is\n    for when one explanation needs to span multiple lines, e.g. when\n    displaying diffs.\n    \"\"\"\n    lines = _split_explanation(explanation)\n    result = _format_lines(lines)\n    return \"\\n\".join(result)"}, {"id": "_pytest.assertion._split_explanation", "kind": "function", "range": [46, 0, 60, 16, 1629, 2189], "file_path": "src/_pytest/assertion/util.py", "content": "def _split_explanation(explanation: str) -> List[str]:\n    \"\"\"Return a list of individual lines in the explanation\n\n    This will return a list of lines split on '\\n{', '\\n}' and '\\n~'.\n    Any other newlines will be escaped and appear in the line as the\n    literal '\\n' characters.\n    \"\"\"\n    raw_lines = (explanation or \"\").split(\"\\n\")\n    lines = [raw_lines[0]]\n    for values in raw_lines[1:]:\n        if values and values[0] in [\"{\", \"}\", \"~\", \">\"]:\n            lines.append(values)\n        else:\n            lines[-1] += \"\\\\n\" + values\n    return lines"}, {"id": "_pytest.assertion._format_lines", "kind": "function", "range": [63, 0, 95, 17, 2192, 3306], "file_path": "src/_pytest/assertion/util.py", "content": "def _format_lines(lines: Sequence[str]) -> List[str]:\n    \"\"\"Format the individual lines\n\n    This will replace the '{', '}' and '~' characters of our mini\n    formatting language with the proper 'where ...', 'and ...' and ' +\n    ...' text, taking care of indentation along the way.\n\n    Return a list of formatted lines.\n    \"\"\"\n    result = list(lines[:1])\n    stack = [0]\n    stackcnt = [0]\n    for line in lines[1:]:\n        if line.startswith(\"{\"):\n            if stackcnt[-1]:\n                s = \"and   \"\n            else:\n                s = \"where \"\n            stack.append(len(result))\n            stackcnt[-1] += 1\n            stackcnt.append(0)\n            result.append(\" +\" + \"  \" * (len(stack) - 1) + s + line[1:])\n        elif line.startswith(\"}\"):\n            stack.pop()\n            stackcnt.pop()\n            result[stack[-1]] += line[1:]\n        else:\n            assert line[0] in [\"~\", \">\"]\n            stack[-1] += 1\n            indent = len(stack) if line.startswith(\"~\") else len(stack) - 1\n            result.append(\"  \" * indent + line[1:])\n    assert len(stack) == 1\n    return result"}, {"id": "_pytest.assertion.issequence", "kind": "function", "range": [98, 0, 99, 77, 3309, 3418], "file_path": "src/_pytest/assertion/util.py", "content": "def issequence(x: Any) -> bool:\n    return isinstance(x, collections.abc.Sequence) and not isinstance(x, str)"}, {"id": "_pytest.assertion.istext", "kind": "function", "range": [102, 0, 103, 29, 3421, 3478], "file_path": "src/_pytest/assertion/util.py", "content": "def istext(x: Any) -> bool:\n    return isinstance(x, str)"}, {"id": "_pytest.assertion.isdict", "kind": "function", "range": [106, 0, 107, 30, 3481, 3539], "file_path": "src/_pytest/assertion/util.py", "content": "def isdict(x: Any) -> bool:\n    return isinstance(x, dict)"}, {"id": "_pytest.assertion.isset", "kind": "function", "range": [110, 0, 111, 42, 3542, 3611], "file_path": "src/_pytest/assertion/util.py", "content": "def isset(x: Any) -> bool:\n    return isinstance(x, (set, frozenset))"}, {"id": "_pytest.assertion.isdatacls", "kind": "function", "range": [114, 0, 115, 65, 3614, 3712], "file_path": "src/_pytest/assertion/util.py", "content": "def isdatacls(obj: Any) -> bool:\n    return getattr(obj, \"__dataclass_fields__\", None) is not None"}, {"id": "_pytest.assertion.isattrs", "kind": "function", "range": [118, 0, 119, 60, 3715, 3806], "file_path": "src/_pytest/assertion/util.py", "content": "def isattrs(obj: Any) -> bool:\n    return getattr(obj, \"__attrs_attrs__\", None) is not None"}, {"id": "_pytest.assertion.isiterable", "kind": "function", "range": [122, 0, 127, 20, 3809, 3943], "file_path": "src/_pytest/assertion/util.py", "content": "def isiterable(obj: Any) -> bool:\n    try:\n        iter(obj)\n        return not istext(obj)\n    except TypeError:\n        return False"}, {"id": "_pytest.assertion.assertrepr_compare", "kind": "function", "range": [130, 0, 186, 34, 3946, 6386], "file_path": "src/_pytest/assertion/util.py", "content": "def assertrepr_compare(config, op: str, left: Any, right: Any) -> Optional[List[str]]:\n    \"\"\"Return specialised explanations for some operators/operands\"\"\"\n    verbose = config.getoption(\"verbose\")\n    if verbose > 1:\n        left_repr = safeformat(left)\n        right_repr = safeformat(right)\n    else:\n        # XXX: \"15 chars indentation\" is wrong\n        #      (\"E       AssertionError: assert \"); should use term width.\n        maxsize = (\n            80 - 15 - len(op) - 2\n        ) // 2  # 15 chars indentation, 1 space around op\n        left_repr = saferepr(left, maxsize=maxsize)\n        right_repr = saferepr(right, maxsize=maxsize)\n\n    summary = \"{} {} {}\".format(left_repr, op, right_repr)\n\n    explanation = None\n    try:\n        if op == \"==\":\n            if istext(left) and istext(right):\n                explanation = _diff_text(left, right, verbose)\n            else:\n                if issequence(left) and issequence(right):\n                    explanation = _compare_eq_sequence(left, right, verbose)\n                elif isset(left) and isset(right):\n                    explanation = _compare_eq_set(left, right, verbose)\n                elif isdict(left) and isdict(right):\n                    explanation = _compare_eq_dict(left, right, verbose)\n                elif type(left) == type(right) and (isdatacls(left) or isattrs(left)):\n                    type_fn = (isdatacls, isattrs)\n                    explanation = _compare_eq_cls(left, right, verbose, type_fn)\n                elif verbose > 0:\n                    explanation = _compare_eq_verbose(left, right)\n                if isiterable(left) and isiterable(right):\n                    expl = _compare_eq_iterable(left, right, verbose)\n                    if explanation is not None:\n                        explanation.extend(expl)\n                    else:\n                        explanation = expl\n        elif op == \"not in\":\n            if istext(left) and istext(right):\n                explanation = _notin_text(left, right, verbose)\n    except outcomes.Exit:\n        raise\n    except Exception:\n        explanation = [\n            \"(pytest_assertion plugin: representation of details failed: {}.\".format(\n                _pytest._code.ExceptionInfo.from_current()._getreprcrash()\n            ),\n            \" Probably an object has a faulty __repr__.)\",\n        ]\n\n    if not explanation:\n        return None\n\n    return [summary] + explanation"}, {"id": "_pytest.assertion._diff_text", "kind": "function", "range": [189, 0, 234, 22, 6389, 8112], "file_path": "src/_pytest/assertion/util.py", "content": "def _diff_text(left: str, right: str, verbose: int = 0) -> List[str]:\n    \"\"\"Return the explanation for the diff between text.\n\n    Unless --verbose is used this will skip leading and trailing\n    characters which are identical to keep the diff minimal.\n    \"\"\"\n    from difflib import ndiff\n\n    explanation = []  # type: List[str]\n\n    if verbose < 1:\n        i = 0  # just in case left or right has zero length\n        for i in range(min(len(left), len(right))):\n            if left[i] != right[i]:\n                break\n        if i > 42:\n            i -= 10  # Provide some context\n            explanation = [\n                \"Skipping %s identical leading characters in diff, use -v to show\" % i\n            ]\n            left = left[i:]\n            right = right[i:]\n        if len(left) == len(right):\n            for i in range(len(left)):\n                if left[-i] != right[-i]:\n                    break\n            if i > 42:\n                i -= 10  # Provide some context\n                explanation += [\n                    \"Skipping {} identical trailing \"\n                    \"characters in diff, use -v to show\".format(i)\n                ]\n                left = left[:-i]\n                right = right[:-i]\n    keepends = True\n    if left.isspace() or right.isspace():\n        left = repr(str(left))\n        right = repr(str(right))\n        explanation += [\"Strings contain only whitespace, escaping them using repr()\"]\n    # \"right\" is the expected base against which we compare \"left\",\n    # see https://github.com/pytest-dev/pytest/issues/3333\n    explanation += [\n        line.strip(\"\\n\")\n        for line in ndiff(right.splitlines(keepends), left.splitlines(keepends))\n    ]\n    return explanation"}, {"id": "_pytest.assertion._compare_eq_verbose", "kind": "function", "range": [237, 0, 246, 22, 8115, 8471], "file_path": "src/_pytest/assertion/util.py", "content": "def _compare_eq_verbose(left: Any, right: Any) -> List[str]:\n    keepends = True\n    left_lines = repr(left).splitlines(keepends)\n    right_lines = repr(right).splitlines(keepends)\n\n    explanation = []  # type: List[str]\n    explanation += [\"+\" + line for line in left_lines]\n    explanation += [\"-\" + line for line in right_lines]\n\n    return explanation"}, {"id": "_pytest.assertion._surrounding_parens_on_own_lines", "kind": "function", "range": [249, 0, 258, 36, 8474, 8881], "file_path": "src/_pytest/assertion/util.py", "content": "def _surrounding_parens_on_own_lines(lines: List[str]) -> None:\n    \"\"\"Move opening/closing parenthesis/bracket to own lines.\"\"\"\n    opening = lines[0][:1]\n    if opening in [\"(\", \"[\", \"{\"]:\n        lines[0] = \" \" + lines[0][1:]\n        lines[:] = [opening] + lines\n    closing = lines[-1][-1:]\n    if closing in [\")\", \"]\", \"}\"]:\n        lines[-1] = lines[-1][:-1] + \",\"\n        lines[:] = lines + [closing]"}, {"id": "_pytest.assertion._compare_eq_iterable", "kind": "function", "range": [261, 0, 289, 22, 8884, 9973], "file_path": "src/_pytest/assertion/util.py", "content": "def _compare_eq_iterable(\n    left: Iterable[Any], right: Iterable[Any], verbose: int = 0\n) -> List[str]:\n    if not verbose:\n        return [\"Use -v to get the full diff\"]\n    # dynamic import to speedup pytest\n    import difflib\n\n    left_formatting = pprint.pformat(left).splitlines()\n    right_formatting = pprint.pformat(right).splitlines()\n\n    # Re-format for different output lengths.\n    lines_left = len(left_formatting)\n    lines_right = len(right_formatting)\n    if lines_left != lines_right:\n        left_formatting = _pformat_dispatch(left).splitlines()\n        right_formatting = _pformat_dispatch(right).splitlines()\n\n    if lines_left > 1 or lines_right > 1:\n        _surrounding_parens_on_own_lines(left_formatting)\n        _surrounding_parens_on_own_lines(right_formatting)\n\n    explanation = [\"Full diff:\"]\n    # \"right\" is the expected base against which we compare \"left\",\n    # see https://github.com/pytest-dev/pytest/issues/3333\n    explanation.extend(\n        line.rstrip() for line in difflib.ndiff(right_formatting, left_formatting)\n    )\n    return explanation"}, {"id": "_pytest.assertion._compare_eq_sequence", "kind": "function", "range": [292, 0, 346, 22, 9976, 11855], "file_path": "src/_pytest/assertion/util.py", "content": "def _compare_eq_sequence(\n    left: Sequence[Any], right: Sequence[Any], verbose: int = 0\n) -> List[str]:\n    comparing_bytes = isinstance(left, bytes) and isinstance(right, bytes)\n    explanation = []  # type: List[str]\n    len_left = len(left)\n    len_right = len(right)\n    for i in range(min(len_left, len_right)):\n        if left[i] != right[i]:\n            if comparing_bytes:\n                # when comparing bytes, we want to see their ascii representation\n                # instead of their numeric values (#5260)\n                # using a slice gives us the ascii representation:\n                # >>> s = b'foo'\n                # >>> s[0]\n                # 102\n                # >>> s[0:1]\n                # b'f'\n                left_value = left[i : i + 1]\n                right_value = right[i : i + 1]\n            else:\n                left_value = left[i]\n                right_value = right[i]\n\n            explanation += [\n                \"At index {} diff: {!r} != {!r}\".format(i, left_value, right_value)\n            ]\n            break\n\n    if comparing_bytes:\n        # when comparing bytes, it doesn't help to show the \"sides contain one or more\n        # items\" longer explanation, so skip it\n\n        return explanation\n\n    len_diff = len_left - len_right\n    if len_diff:\n        if len_diff > 0:\n            dir_with_more = \"Left\"\n            extra = saferepr(left[len_right])\n        else:\n            len_diff = 0 - len_diff\n            dir_with_more = \"Right\"\n            extra = saferepr(right[len_left])\n\n        if len_diff == 1:\n            explanation += [\n                \"{} contains one more item: {}\".format(dir_with_more, extra)\n            ]\n        else:\n            explanation += [\n                \"%s contains %d more items, first extra item: %s\"\n                % (dir_with_more, len_diff, extra)\n            ]\n    return explanation"}, {"id": "_pytest.assertion._compare_eq_set", "kind": "function", "range": [349, 0, 363, 22, 11858, 12380], "file_path": "src/_pytest/assertion/util.py", "content": "def _compare_eq_set(\n    left: AbstractSet[Any], right: AbstractSet[Any], verbose: int = 0\n) -> List[str]:\n    explanation = []\n    diff_left = left - right\n    diff_right = right - left\n    if diff_left:\n        explanation.append(\"Extra items in the left set:\")\n        for item in diff_left:\n            explanation.append(saferepr(item))\n    if diff_right:\n        explanation.append(\"Extra items in the right set:\")\n        for item in diff_right:\n            explanation.append(saferepr(item))\n    return explanation"}, {"id": "_pytest.assertion._compare_eq_dict", "kind": "function", "range": [366, 0, 404, 22, 12383, 13890], "file_path": "src/_pytest/assertion/util.py", "content": "def _compare_eq_dict(\n    left: Mapping[Any, Any], right: Mapping[Any, Any], verbose: int = 0\n) -> List[str]:\n    explanation = []  # type: List[str]\n    set_left = set(left)\n    set_right = set(right)\n    common = set_left.intersection(set_right)\n    same = {k: left[k] for k in common if left[k] == right[k]}\n    if same and verbose < 2:\n        explanation += [\"Omitting %s identical items, use -vv to show\" % len(same)]\n    elif same:\n        explanation += [\"Common items:\"]\n        explanation += pprint.pformat(same).splitlines()\n    diff = {k for k in common if left[k] != right[k]}\n    if diff:\n        explanation += [\"Differing items:\"]\n        for k in diff:\n            explanation += [saferepr({k: left[k]}) + \" != \" + saferepr({k: right[k]})]\n    extra_left = set_left - set_right\n    len_extra_left = len(extra_left)\n    if len_extra_left:\n        explanation.append(\n            \"Left contains %d more item%s:\"\n            % (len_extra_left, \"\" if len_extra_left == 1 else \"s\")\n        )\n        explanation.extend(\n            pprint.pformat({k: left[k] for k in extra_left}).splitlines()\n        )\n    extra_right = set_right - set_left\n    len_extra_right = len(extra_right)\n    if len_extra_right:\n        explanation.append(\n            \"Right contains %d more item%s:\"\n            % (len_extra_right, \"\" if len_extra_right == 1 else \"s\")\n        )\n        explanation.extend(\n            pprint.pformat({k: right[k] for k in extra_right}).splitlines()\n        )\n    return explanation"}, {"id": "_pytest.assertion._compare_eq_cls", "kind": "function", "range": [407, 0, 443, 22, 13893, 15121], "file_path": "src/_pytest/assertion/util.py", "content": "def _compare_eq_cls(\n    left: Any,\n    right: Any,\n    verbose: int,\n    type_fns: Tuple[Callable[[Any], bool], Callable[[Any], bool]],\n) -> List[str]:\n    isdatacls, isattrs = type_fns\n    if isdatacls(left):\n        all_fields = left.__dataclass_fields__\n        fields_to_check = [field for field, info in all_fields.items() if info.compare]\n    elif isattrs(left):\n        all_fields = left.__attrs_attrs__\n        fields_to_check = [\n            field.name for field in all_fields if getattr(field, ATTRS_EQ_FIELD)\n        ]\n\n    same = []\n    diff = []\n    for field in fields_to_check:\n        if getattr(left, field) == getattr(right, field):\n            same.append(field)\n        else:\n            diff.append(field)\n\n    explanation = []\n    if same and verbose < 2:\n        explanation.append(\"Omitting %s identical items, use -vv to show\" % len(same))\n    elif same:\n        explanation += [\"Matching attributes:\"]\n        explanation += pprint.pformat(same).splitlines()\n    if diff:\n        explanation += [\"Differing attributes:\"]\n        for field in diff:\n            explanation += [\n                (\"%s: %r != %r\") % (field, getattr(left, field), getattr(right, field))\n            ]\n    return explanation"}, {"id": "_pytest.assertion._notin_text", "kind": "function", "range": [446, 0, 462, 18, 15124, 15715], "file_path": "src/_pytest/assertion/util.py", "content": "def _notin_text(term: str, text: str, verbose: int = 0) -> List[str]:\n    index = text.find(term)\n    head = text[:index]\n    tail = text[index + len(term) :]\n    correct_text = head + tail\n    diff = _diff_text(text, correct_text, verbose)\n    newdiff = [\"%s is contained here:\" % saferepr(term, maxsize=42)]\n    for line in diff:\n        if line.startswith(\"Skipping\"):\n            continue\n        if line.startswith(\"- \"):\n            continue\n        if line.startswith(\"+ \"):\n            newdiff.append(\"  \" + line[2:])\n        else:\n            newdiff.append(line)\n    return newdiff"}, {"id": "_pytest.assertion.pytest_addoption", "kind": "function", "range": [20, 0, 41, 5, 497, 1320], "file_path": "src/_pytest/assertion/__init__.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"debugconfig\")\n    group.addoption(\n        \"--assert\",\n        action=\"store\",\n        dest=\"assertmode\",\n        choices=(\"rewrite\", \"plain\"),\n        default=\"rewrite\",\n        metavar=\"MODE\",\n        help=\"\"\"Control assertion debugging tools.  'plain'\n                            performs no assertion debugging.  'rewrite'\n                            (the default) rewrites assert statements in\n                            test modules on import to provide assert\n                            expression information.\"\"\",\n    )\n    parser.addini(\n        \"enable_assertion_pass_hook\",\n        type=\"bool\",\n        default=False,\n        help=\"Enables the pytest_assertion_pass hook.\"\n        \"Make sure to delete any previously generated pyc cache files.\",\n    )"}, {"id": "_pytest.assertion.register_assert_rewrite", "kind": "function", "range": [44, 0, 67, 35, 1323, 2358], "file_path": "src/_pytest/assertion/__init__.py", "content": "def register_assert_rewrite(*names) -> None:\n    \"\"\"Register one or more module names to be rewritten on import.\n\n    This function will make sure that this module or all modules inside\n    the package will get their assert statements rewritten.\n    Thus you should make sure to call this before the module is\n    actually imported, usually in your __init__.py if you are a plugin\n    using a package.\n\n    :raise TypeError: if the given module names are not strings.\n    \"\"\"\n    for name in names:\n        if not isinstance(name, str):\n            msg = \"expected module names as *args, got {0} instead\"\n            raise TypeError(msg.format(repr(names)))\n    for hook in sys.meta_path:\n        if isinstance(hook, rewrite.AssertionRewritingHook):\n            importhook = hook\n            break\n    else:\n        # TODO(typing): Add a protocol for mark_rewrite() and use it\n        # for importhook and for PytestPluginManager.rewrite_hook.\n        importhook = DummyRewriteHook()  # type: ignore\n    importhook.mark_rewrite(*names)"}, {"id": "_pytest.assertion.DummyRewriteHook", "kind": "class", "range": [70, 0, 74, 12, 2361, 2496], "file_path": "src/_pytest/assertion/__init__.py", "content": "class DummyRewriteHook:\n    \"\"\"A no-op import hook for when rewriting is disabled.\"\"\"\n\n    def mark_rewrite(self, *names):\n        pass"}, {"id": "_pytest.assertion.DummyRewriteHook.mark_rewrite", "kind": "function", "range": [73, 4, 74, 12, 2452, 2496], "file_path": "src/_pytest/assertion/__init__.py", "content": "def mark_rewrite(self, *names):\n        pass"}, {"id": "_pytest.assertion.AssertionState", "kind": "class", "range": [77, 0, 83, 74, 2499, 2757], "file_path": "src/_pytest/assertion/__init__.py", "content": "class AssertionState:\n    \"\"\"State for the assertion plugin.\"\"\"\n\n    def __init__(self, config, mode):\n        self.mode = mode\n        self.trace = config.trace.root.get(\"assertion\")\n        self.hook = None  # type: Optional[rewrite.AssertionRewritingHook]"}, {"id": "_pytest.assertion.AssertionState.__init__", "kind": "function", "range": [80, 4, 83, 74, 2568, 2757], "file_path": "src/_pytest/assertion/__init__.py", "content": "def __init__(self, config, mode):\n        self.mode = mode\n        self.trace = config.trace.root.get(\"assertion\")\n        self.hook = None  # type: Optional[rewrite.AssertionRewritingHook]"}, {"id": "_pytest.assertion.install_importhook", "kind": "function", "range": [86, 0, 99, 15, 2760, 3340], "file_path": "src/_pytest/assertion/__init__.py", "content": "def install_importhook(config):\n    \"\"\"Try to install the rewrite hook, raise SystemError if it fails.\"\"\"\n    config._store[assertstate_key] = AssertionState(config, \"rewrite\")\n    config._store[assertstate_key].hook = hook = rewrite.AssertionRewritingHook(config)\n    sys.meta_path.insert(0, hook)\n    config._store[assertstate_key].trace(\"installed rewrite import hook\")\n\n    def undo():\n        hook = config._store[assertstate_key].hook\n        if hook is not None and hook in sys.meta_path:\n            sys.meta_path.remove(hook)\n\n    config.add_cleanup(undo)\n    return hook"}, {"id": "_pytest.assertion.pytest_collection", "kind": "function", "range": [102, 0, 109, 49, 3343, 3741], "file_path": "src/_pytest/assertion/__init__.py", "content": "def pytest_collection(session: \"Session\") -> None:\n    # this hook is only called when test modules are collected\n    # so for example not in the master process of pytest-xdist\n    # (which does not collect test modules)\n    assertstate = session.config._store.get(assertstate_key, None)\n    if assertstate:\n        if assertstate.hook is not None:\n            assertstate.hook.set_session(session)"}, {"id": "_pytest.assertion.pytest_runtest_protocol", "kind": "function", "range": [112, 0, 165, 64, 3744, 5815], "file_path": "src/_pytest/assertion/__init__.py", "content": "@hookimpl(tryfirst=True, hookwrapper=True)\ndef pytest_runtest_protocol(item):\n    \"\"\"Setup the pytest_assertrepr_compare and pytest_assertion_pass hooks\n\n    The rewrite module will use util._reprcompare if\n    it exists to use custom reporting via the\n    pytest_assertrepr_compare hook.  This sets up this custom\n    comparison for the test.\n    \"\"\"\n\n    def callbinrepr(op, left, right):\n        # type: (str, object, object) -> Optional[str]\n        \"\"\"Call the pytest_assertrepr_compare hook and prepare the result\n\n        This uses the first result from the hook and then ensures the\n        following:\n        * Overly verbose explanations are truncated unless configured otherwise\n          (eg. if running in verbose mode).\n        * Embedded newlines are escaped to help util.format_explanation()\n          later.\n        * If the rewrite mode is used embedded %-characters are replaced\n          to protect later % formatting.\n\n        The result can be formatted by util.format_explanation() for\n        pretty printing.\n        \"\"\"\n        hook_result = item.ihook.pytest_assertrepr_compare(\n            config=item.config, op=op, left=left, right=right\n        )\n        for new_expl in hook_result:\n            if new_expl:\n                new_expl = truncate.truncate_if_required(new_expl, item)\n                new_expl = [line.replace(\"\\n\", \"\\\\n\") for line in new_expl]\n                res = \"\\n~\".join(new_expl)\n                if item.config.getvalue(\"assertmode\") == \"rewrite\":\n                    res = res.replace(\"%\", \"%%\")\n                return res\n        return None\n\n    saved_assert_hooks = util._reprcompare, util._assertion_pass\n    util._reprcompare = callbinrepr\n\n    if item.ihook.pytest_assertion_pass.get_hookimpls():\n\n        def call_assertion_pass_hook(lineno, orig, expl):\n            item.ihook.pytest_assertion_pass(\n                item=item, lineno=lineno, orig=orig, expl=expl\n            )\n\n        util._assertion_pass = call_assertion_pass_hook\n\n    yield\n\n    util._reprcompare, util._assertion_pass = saved_assert_hooks"}, {"id": "_pytest.assertion.pytest_sessionfinish", "kind": "function", "range": [168, 0, 172, 46, 5818, 6027], "file_path": "src/_pytest/assertion/__init__.py", "content": "def pytest_sessionfinish(session):\n    assertstate = session.config._store.get(assertstate_key, None)\n    if assertstate:\n        if assertstate.hook is not None:\n            assertstate.hook.set_session(None)"}, {"id": "_pytest.assertion.pytest_assertrepr_compare", "kind": "function", "range": [175, 0, 178, 80, 6030, 6218], "file_path": "src/_pytest/assertion/__init__.py", "content": "def pytest_assertrepr_compare(\n    config: Config, op: str, left: Any, right: Any\n) -> Optional[List[str]]:\n    return util.assertrepr_compare(config=config, op=op, left=left, right=right)"}, {"id": "_pytest.assertion.assertstate_key", "kind": "variable", "range": [38, 0, 38, 46, 918, 964], "file_path": "src/_pytest/assertion/rewrite.py", "content": "assertstate_key = StoreKey[\"AssertionState\"]()"}, {"id": "_pytest.assertion.PYTEST_TAG", "kind": "variable", "range": [42, 0, 42, 73, 1014, 1087], "file_path": "src/_pytest/assertion/rewrite.py", "content": "PYTEST_TAG = \"{}-pytest-{}\".format(sys.implementation.cache_tag, version)"}, {"id": "_pytest.assertion.PYC_EXT", "kind": "variable", "range": [43, 0, 43, 44, 1088, 1132], "file_path": "src/_pytest/assertion/rewrite.py", "content": "PYC_EXT = \".py\" + (__debug__ and \"c\" or \"o\")"}, {"id": "_pytest.assertion.PYC_TAIL", "kind": "variable", "range": [44, 0, 44, 37, 1133, 1170], "file_path": "src/_pytest/assertion/rewrite.py", "content": "PYC_TAIL = \".\" + PYTEST_TAG + PYC_EXT"}, {"id": "_pytest.assertion.AssertionRewritingHook", "kind": "class", "range": [47, 0, 263, 27, 1173, 9896], "file_path": "src/_pytest/assertion/rewrite.py", "content": "class AssertionRewritingHook(importlib.abc.MetaPathFinder, importlib.abc.Loader):\n    \"\"\"PEP302/PEP451 import hook which rewrites asserts.\"\"\"\n\n    def __init__(self, config):\n        self.config = config\n        try:\n            self.fnpats = config.getini(\"python_files\")\n        except ValueError:\n            self.fnpats = [\"test_*.py\", \"*_test.py\"]\n        self.session = None\n        self._rewritten_names = set()  # type: Set[str]\n        self._must_rewrite = set()  # type: Set[str]\n        # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,\n        # which might result in infinite recursion (#3506)\n        self._writing_pyc = False\n        self._basenames_to_check_rewrite = {\"conftest\"}\n        self._marked_for_rewrite_cache = {}  # type: Dict[str, bool]\n        self._session_paths_checked = False\n\n    def set_session(self, session):\n        self.session = session\n        self._session_paths_checked = False\n\n    # Indirection so we can mock calls to find_spec originated from the hook during testing\n    _find_spec = importlib.machinery.PathFinder.find_spec\n\n    def find_spec(self, name, path=None, target=None):\n        if self._writing_pyc:\n            return None\n        state = self.config._store[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(\"find_module called for: %s\" % name)\n\n        spec = self._find_spec(name, path)\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__.py`)\n            # there's nothing to rewrite there\n            # python3.5 - python3.6: `namespace`\n            # python3.7+: `None`\n            or spec.origin == \"namespace\"\n            or spec.origin is None\n            # we can only rewrite source files\n            or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)\n            # if the file doesn't exist, we can't rewrite it\n            or not os.path.exists(spec.origin)\n        ):\n            return None\n        else:\n            fn = spec.origin\n\n        if not self._should_rewrite(name, fn, state):\n            return None\n\n        return importlib.util.spec_from_file_location(\n            name,\n            fn,\n            loader=self,\n            submodule_search_locations=spec.submodule_search_locations,\n        )\n\n    def create_module(self, spec):\n        return None  # default behaviour is fine\n\n    def exec_module(self, module):\n        fn = Path(module.__spec__.origin)\n        state = self.config._store[assertstate_key]\n\n        self._rewritten_names.add(module.__name__)\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(\"read only directory: {}\".format(cache_dir))\n\n        cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(\"rewriting {!r}\".format(fn))\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(\"found cached rewritten pyc for {}\".format(fn))\n        exec(co, module.__dict__)\n\n    def _early_rewrite_bailout(self, name, state):\n        \"\"\"This is a fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this method\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(path).split(os.path.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(os.path.sep.join(parts) + \".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(\"early skip of rewriting module: {}\".format(name))\n        return True\n\n    def _should_rewrite(self, name, fn, state):\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(\"rewriting conftest file: {!r}\".format(fn))\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(fn):\n                state.trace(\n                    \"matched test file (was specified on cmdline): {!r}\".format(fn)\n                )\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten if they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(\"matched test file {!r}\".format(fn))\n                return True\n\n        return self._is_marked_for_rewrite(name, state)\n\n    def _is_marked_for_rewrite(self, name: str, state):\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(\n                        \"matched marked file {!r} (from {!r})\".format(name, marked)\n                    )\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False\n\n    def mark_rewrite(self, *names: str) -> None:\n        \"\"\"Mark import names as needing to be rewritten.\n\n        The named module or package as well as any nested modules will\n        be rewritten on import.\n        \"\"\"\n        already_imported = (\n            set(names).intersection(sys.modules).difference(self._rewritten_names)\n        )\n        for name in already_imported:\n            mod = sys.modules[name]\n            if not AssertionRewriter.is_rewrite_disabled(\n                mod.__doc__ or \"\"\n            ) and not isinstance(mod.__loader__, type(self)):\n                self._warn_already_imported(name)\n        self._must_rewrite.update(names)\n        self._marked_for_rewrite_cache.clear()\n\n    def _warn_already_imported(self, name):\n        from _pytest.warning_types import PytestAssertRewriteWarning\n        from _pytest.warnings import _issue_warning_captured\n\n        _issue_warning_captured(\n            PytestAssertRewriteWarning(\n                \"Module already imported so cannot be rewritten: %s\" % name\n            ),\n            self.config.hook,\n            stacklevel=5,\n        )\n\n    def get_data(self, pathname):\n        \"\"\"Optional PEP302 get_data API.\"\"\"\n        with open(pathname, \"rb\") as f:\n            return f.read()"}, {"id": "_pytest.assertion.AssertionRewritingHook.__init__", "kind": "function", "range": [50, 4, 64, 43, 1320, 2032], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def __init__(self, config):\n        self.config = config\n        try:\n            self.fnpats = config.getini(\"python_files\")\n        except ValueError:\n            self.fnpats = [\"test_*.py\", \"*_test.py\"]\n        self.session = None\n        self._rewritten_names = set()  # type: Set[str]\n        self._must_rewrite = set()  # type: Set[str]\n        # flag to guard against trying to rewrite a pyc file while we are already writing another pyc file,\n        # which might result in infinite recursion (#3506)\n        self._writing_pyc = False\n        self._basenames_to_check_rewrite = {\"conftest\"}\n        self._marked_for_rewrite_cache = {}  # type: Dict[str, bool]\n        self._session_paths_checked = False"}, {"id": "_pytest.assertion.AssertionRewritingHook.set_session", "kind": "function", "range": [66, 4, 68, 43, 2038, 2144], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def set_session(self, session):\n        self.session = session\n        self._session_paths_checked = False"}, {"id": "_pytest.assertion.AssertionRewritingHook._find_spec", "kind": "variable", "range": [71, 4, 71, 57, 2242, 2295], "file_path": "src/_pytest/assertion/rewrite.py", "content": "_find_spec = importlib.machinery.PathFinder.find_spec"}, {"id": "_pytest.assertion.AssertionRewritingHook.find_spec", "kind": "function", "range": [73, 4, 108, 9, 2301, 3602], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def find_spec(self, name, path=None, target=None):\n        if self._writing_pyc:\n            return None\n        state = self.config._store[assertstate_key]\n        if self._early_rewrite_bailout(name, state):\n            return None\n        state.trace(\"find_module called for: %s\" % name)\n\n        spec = self._find_spec(name, path)\n        if (\n            # the import machinery could not find a file to import\n            spec is None\n            # this is a namespace package (without `__init__.py`)\n            # there's nothing to rewrite there\n            # python3.5 - python3.6: `namespace`\n            # python3.7+: `None`\n            or spec.origin == \"namespace\"\n            or spec.origin is None\n            # we can only rewrite source files\n            or not isinstance(spec.loader, importlib.machinery.SourceFileLoader)\n            # if the file doesn't exist, we can't rewrite it\n            or not os.path.exists(spec.origin)\n        ):\n            return None\n        else:\n            fn = spec.origin\n\n        if not self._should_rewrite(name, fn, state):\n            return None\n\n        return importlib.util.spec_from_file_location(\n            name,\n            fn,\n            loader=self,\n            submodule_search_locations=spec.submodule_search_locations,\n        )"}, {"id": "_pytest.assertion.AssertionRewritingHook.create_module", "kind": "function", "range": [110, 4, 111, 48, 3608, 3687], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def create_module(self, spec):\n        return None  # default behaviour is fine"}, {"id": "_pytest.assertion.AssertionRewritingHook.exec_module", "kind": "function", "range": [113, 4, 151, 33, 3693, 5470], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def exec_module(self, module):\n        fn = Path(module.__spec__.origin)\n        state = self.config._store[assertstate_key]\n\n        self._rewritten_names.add(module.__name__)\n\n        # The requested module looks like a test file, so rewrite it. This is\n        # the most magical part of the process: load the source, rewrite the\n        # asserts, and load the rewritten source. We also cache the rewritten\n        # module code in a special pyc. We must be aware of the possibility of\n        # concurrent pytest processes rewriting and loading pycs. To avoid\n        # tricky race conditions, we maintain the following invariant: The\n        # cached pyc is always a complete, valid pyc. Operations on it must be\n        # atomic. POSIX's atomic rename comes in handy.\n        write = not sys.dont_write_bytecode\n        cache_dir = get_cache_dir(fn)\n        if write:\n            ok = try_makedirs(cache_dir)\n            if not ok:\n                write = False\n                state.trace(\"read only directory: {}\".format(cache_dir))\n\n        cache_name = fn.name[:-3] + PYC_TAIL\n        pyc = cache_dir / cache_name\n        # Notice that even if we're in a read-only directory, I'm going\n        # to check for a cached pyc. This may not be optimal...\n        co = _read_pyc(fn, pyc, state.trace)\n        if co is None:\n            state.trace(\"rewriting {!r}\".format(fn))\n            source_stat, co = _rewrite_test(fn, self.config)\n            if write:\n                self._writing_pyc = True\n                try:\n                    _write_pyc(state, co, source_stat, pyc)\n                finally:\n                    self._writing_pyc = False\n        else:\n            state.trace(\"found cached rewritten pyc for {}\".format(fn))\n        exec(co, module.__dict__)"}, {"id": "_pytest.assertion.AssertionRewritingHook._early_rewrite_bailout", "kind": "function", "range": [153, 4, 190, 19, 5476, 7182], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _early_rewrite_bailout(self, name, state):\n        \"\"\"This is a fast way to get out of rewriting modules.\n\n        Profiling has shown that the call to PathFinder.find_spec (inside of\n        the find_spec from this class) is a major slowdown, so, this method\n        tries to filter what we're sure won't be rewritten before getting to\n        it.\n        \"\"\"\n        if self.session is not None and not self._session_paths_checked:\n            self._session_paths_checked = True\n            for path in self.session._initialpaths:\n                # Make something as c:/projects/my_project/path.py ->\n                #     ['c:', 'projects', 'my_project', 'path.py']\n                parts = str(path).split(os.path.sep)\n                # add 'path' to basenames to be checked.\n                self._basenames_to_check_rewrite.add(os.path.splitext(parts[-1])[0])\n\n        # Note: conftest already by default in _basenames_to_check_rewrite.\n        parts = name.split(\".\")\n        if parts[-1] in self._basenames_to_check_rewrite:\n            return False\n\n        # For matching the name it must be as if it was a filename.\n        path = PurePath(os.path.sep.join(parts) + \".py\")\n\n        for pat in self.fnpats:\n            # if the pattern contains subdirectories (\"tests/**.py\" for example) we can't bail out based\n            # on the name alone because we need to match against the full path\n            if os.path.dirname(pat):\n                return False\n            if fnmatch_ex(pat, path):\n                return False\n\n        if self._is_marked_for_rewrite(name, state):\n            return False\n\n        state.trace(\"early skip of rewriting module: {}\".format(name))\n        return True"}, {"id": "_pytest.assertion.AssertionRewritingHook._should_rewrite", "kind": "function", "range": [192, 4, 213, 55, 7188, 8049], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _should_rewrite(self, name, fn, state):\n        # always rewrite conftest files\n        if os.path.basename(fn) == \"conftest.py\":\n            state.trace(\"rewriting conftest file: {!r}\".format(fn))\n            return True\n\n        if self.session is not None:\n            if self.session.isinitpath(fn):\n                state.trace(\n                    \"matched test file (was specified on cmdline): {!r}\".format(fn)\n                )\n                return True\n\n        # modules not passed explicitly on the command line are only\n        # rewritten if they match the naming convention for test files\n        fn_path = PurePath(fn)\n        for pat in self.fnpats:\n            if fnmatch_ex(pat, fn_path):\n                state.trace(\"matched test file {!r}\".format(fn))\n                return True\n\n        return self._is_marked_for_rewrite(name, state)"}, {"id": "_pytest.assertion.AssertionRewritingHook._is_marked_for_rewrite", "kind": "function", "range": [215, 4, 228, 24, 8055, 8632], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _is_marked_for_rewrite(self, name: str, state):\n        try:\n            return self._marked_for_rewrite_cache[name]\n        except KeyError:\n            for marked in self._must_rewrite:\n                if name == marked or name.startswith(marked + \".\"):\n                    state.trace(\n                        \"matched marked file {!r} (from {!r})\".format(name, marked)\n                    )\n                    self._marked_for_rewrite_cache[name] = True\n                    return True\n\n            self._marked_for_rewrite_cache[name] = False\n            return False"}, {"id": "_pytest.assertion.AssertionRewritingHook.mark_rewrite", "kind": "function", "range": [230, 4, 246, 46, 8638, 9343], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def mark_rewrite(self, *names: str) -> None:\n        \"\"\"Mark import names as needing to be rewritten.\n\n        The named module or package as well as any nested modules will\n        be rewritten on import.\n        \"\"\"\n        already_imported = (\n            set(names).intersection(sys.modules).difference(self._rewritten_names)\n        )\n        for name in already_imported:\n            mod = sys.modules[name]\n            if not AssertionRewriter.is_rewrite_disabled(\n                mod.__doc__ or \"\"\n            ) and not isinstance(mod.__loader__, type(self)):\n                self._warn_already_imported(name)\n        self._must_rewrite.update(names)\n        self._marked_for_rewrite_cache.clear()"}, {"id": "_pytest.assertion.AssertionRewritingHook._warn_already_imported", "kind": "function", "range": [248, 4, 258, 9, 9349, 9749], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _warn_already_imported(self, name):\n        from _pytest.warning_types import PytestAssertRewriteWarning\n        from _pytest.warnings import _issue_warning_captured\n\n        _issue_warning_captured(\n            PytestAssertRewriteWarning(\n                \"Module already imported so cannot be rewritten: %s\" % name\n            ),\n            self.config.hook,\n            stacklevel=5,\n        )"}, {"id": "_pytest.assertion.AssertionRewritingHook.get_data", "kind": "function", "range": [260, 4, 263, 27, 9755, 9896], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def get_data(self, pathname):\n        \"\"\"Optional PEP302 get_data API.\"\"\"\n        with open(pathname, \"rb\") as f:\n            return f.read()"}, {"id": "_pytest.assertion._write_pyc_fp", "kind": "function", "range": [266, 0, 276, 31, 9899, 10477], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _write_pyc_fp(fp, source_stat, co):\n    # Technically, we don't have to have the same pyc format as\n    # (C)Python, since these \"pycs\" should never be seen by builtin\n    # import. However, there's little reason deviate.\n    fp.write(importlib.util.MAGIC_NUMBER)\n    # as of now, bytecode header expects 32-bit numbers for size and mtime (#4903)\n    mtime = int(source_stat.st_mtime) & 0xFFFFFFFF\n    size = source_stat.st_size & 0xFFFFFFFF\n    # \"<LL\" stands for 2 unsigned longs, little-ending\n    fp.write(struct.pack(\"<LL\", mtime, size))\n    fp.write(marshal.dumps(co))"}, {"id": "_pytest.assertion._rewrite_test", "kind": "function", "range": [321, 0, 330, 19, 11846, 12197], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _rewrite_test(fn, config):\n    \"\"\"read and rewrite *fn* and return the code object.\"\"\"\n    fn = fspath(fn)\n    stat = os.stat(fn)\n    with open(fn, \"rb\") as f:\n        source = f.read()\n    tree = ast.parse(source, filename=fn)\n    rewrite_asserts(tree, source, fn, config)\n    co = compile(tree, fn, \"exec\", dont_inherit=True)\n    return stat, co"}, {"id": "_pytest.assertion._read_pyc", "kind": "function", "range": [333, 0, 367, 17, 12200, 13446], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _read_pyc(source, pyc, trace=lambda x: None):\n    \"\"\"Possibly read a pytest pyc containing rewritten code.\n\n    Return rewritten code if successful or None if not.\n    \"\"\"\n    try:\n        fp = open(fspath(pyc), \"rb\")\n    except OSError:\n        return None\n    with fp:\n        try:\n            stat_result = os.stat(fspath(source))\n            mtime = int(stat_result.st_mtime)\n            size = stat_result.st_size\n            data = fp.read(12)\n        except OSError as e:\n            trace(\"_read_pyc({}): OSError {}\".format(source, e))\n            return None\n        # Check for invalid or out of date pyc file.\n        if (\n            len(data) != 12\n            or data[:4] != importlib.util.MAGIC_NUMBER\n            or struct.unpack(\"<LL\", data[4:]) != (mtime & 0xFFFFFFFF, size & 0xFFFFFFFF)\n        ):\n            trace(\"_read_pyc(%s): invalid or out of date pyc\" % source)\n            return None\n        try:\n            co = marshal.load(fp)\n        except Exception as e:\n            trace(\"_read_pyc({}): marshal.load error {}\".format(source, e))\n            return None\n        if not isinstance(co, types.CodeType):\n            trace(\"_read_pyc(%s): not a code object\" % source)\n            return None\n        return co"}, {"id": "_pytest.assertion.rewrite_asserts", "kind": "function", "range": [370, 0, 372, 59, 13449, 13621], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def rewrite_asserts(mod, source, module_path=None, config=None):\n    \"\"\"Rewrite the assert statements in mod.\"\"\"\n    AssertionRewriter(module_path, config, source).run(mod)"}, {"id": "_pytest.assertion._saferepr", "kind": "function", "range": [375, 0, 386, 45, 13624, 14124], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _saferepr(obj):\n    \"\"\"Get a safe repr of an object for assertion error messages.\n\n    The assertion formatting (util.format_explanation()) requires\n    newlines to be escaped since they are a special character for it.\n    Normally assertion.util.format_explanation() does this but for a\n    custom repr it is possible to contain one of the special escape\n    sequences, especially '\\n{' and '\\n}' are likely to be present in\n    JSON reprs.\n\n    \"\"\"\n    return saferepr(obj).replace(\"\\n\", \"\\\\n\")"}, {"id": "_pytest.assertion._format_assertmsg", "kind": "function", "range": [389, 0, 409, 14, 14127, 14894], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _format_assertmsg(obj):\n    \"\"\"Format the custom assertion message given.\n\n    For strings this simply replaces newlines with '\\n~' so that\n    util.format_explanation() will preserve them instead of escaping\n    newlines.  For other objects saferepr() is used first.\n\n    \"\"\"\n    # reprlib appears to have a bug which means that if a string\n    # contains a newline it gets escaped, however if an object has a\n    # .__repr__() which contains newlines it does not get escaped.\n    # However in either case we want to preserve the newline.\n    replaces = [(\"\\n\", \"\\n~\"), (\"%\", \"%%\")]\n    if not isinstance(obj, str):\n        obj = saferepr(obj)\n        replaces.append((\"\\\\n\", \"\\n~\"))\n\n    for r1, r2 in replaces:\n        obj = obj.replace(r1, r2)\n\n    return obj"}, {"id": "_pytest.assertion._should_repr_global_name", "kind": "function", "range": [412, 0, 419, 19, 14897, 15070], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _should_repr_global_name(obj):\n    if callable(obj):\n        return False\n\n    try:\n        return not hasattr(obj, \"__name__\")\n    except Exception:\n        return True"}, {"id": "_pytest.assertion._format_boolop", "kind": "function", "range": [422, 0, 427, 47, 15073, 15333], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _format_boolop(explanations, is_or):\n    explanation = \"(\" + (is_or and \" or \" or \" and \").join(explanations) + \")\"\n    if isinstance(explanation, str):\n        return explanation.replace(\"%\", \"%%\")\n    else:\n        return explanation.replace(b\"%\", b\"%%\")"}, {"id": "_pytest.assertion._call_reprcompare", "kind": "function", "range": [430, 0, 443, 15, 15336, 15852], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _call_reprcompare(ops, results, expls, each_obj):\n    # type: (Tuple[str, ...], Tuple[bool, ...], Tuple[str, ...], Tuple[object, ...]) -> str\n    for i, res, expl in zip(range(len(ops)), results, expls):\n        try:\n            done = not res\n        except Exception:\n            done = True\n        if done:\n            break\n    if util._reprcompare is not None:\n        custom = util._reprcompare(ops[i], each_obj[i], each_obj[i + 1])\n        if custom is not None:\n            return custom\n    return expl"}, {"id": "_pytest.assertion._call_assertion_pass", "kind": "function", "range": [446, 0, 449, 48, 15855, 16026], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _call_assertion_pass(lineno, orig, expl):\n    # type: (int, str, str) -> None\n    if util._assertion_pass is not None:\n        util._assertion_pass(lineno, orig, expl)"}, {"id": "_pytest.assertion._check_if_assertion_pass_impl", "kind": "function", "range": [452, 0, 456, 50, 16029, 16287], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _check_if_assertion_pass_impl():\n    # type: () -> bool\n    \"\"\"Checks if any plugins implement the pytest_assertion_pass hook\n    in order not to generate explanation unecessarily (might be expensive)\"\"\"\n    return True if util._assertion_pass else False"}, {"id": "_pytest.assertion.UNARY_MAP", "kind": "variable", "range": [459, 0, 459, 84, 16290, 16374], "file_path": "src/_pytest/assertion/rewrite.py", "content": "UNARY_MAP = {ast.Not: \"not %s\", ast.Invert: \"~%s\", ast.USub: \"-%s\", ast.UAdd: \"+%s\"}"}, {"id": "_pytest.assertion.BINOP_MAP", "kind": "variable", "range": [461, 0, 485, 1, 16376, 16884], "file_path": "src/_pytest/assertion/rewrite.py", "content": "BINOP_MAP = {\n    ast.BitOr: \"|\",\n    ast.BitXor: \"^\",\n    ast.BitAnd: \"&\",\n    ast.LShift: \"<<\",\n    ast.RShift: \">>\",\n    ast.Add: \"+\",\n    ast.Sub: \"-\",\n    ast.Mult: \"*\",\n    ast.Div: \"/\",\n    ast.FloorDiv: \"//\",\n    ast.Mod: \"%%\",  # escaped for string formatting\n    ast.Eq: \"==\",\n    ast.NotEq: \"!=\",\n    ast.Lt: \"<\",\n    ast.LtE: \"<=\",\n    ast.Gt: \">\",\n    ast.GtE: \">=\",\n    ast.Pow: \"**\",\n    ast.Is: \"is\",\n    ast.IsNot: \"is not\",\n    ast.In: \"in\",\n    ast.NotIn: \"not in\",\n    ast.MatMult: \"@\",\n}"}, {"id": "_pytest.assertion.set_location", "kind": "function", "range": [488, 0, 500, 15, 16887, 17329], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def set_location(node, lineno, col_offset):\n    \"\"\"Set node location information recursively.\"\"\"\n\n    def _fix(node, lineno, col_offset):\n        if \"lineno\" in node._attributes:\n            node.lineno = lineno\n        if \"col_offset\" in node._attributes:\n            node.col_offset = col_offset\n        for child in ast.iter_child_nodes(node):\n            _fix(child, lineno, col_offset)\n\n    _fix(node, lineno, col_offset)\n    return node"}, {"id": "_pytest.assertion._get_assertion_exprs", "kind": "function", "range": [503, 0, 554, 14, 17332, 19464], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def _get_assertion_exprs(src: bytes) -> Dict[int, str]:\n    \"\"\"Returns a mapping from {lineno: \"assertion test expression\"}\"\"\"\n    ret = {}  # type: Dict[int, str]\n\n    depth = 0\n    lines = []  # type: List[str]\n    assert_lineno = None  # type: Optional[int]\n    seen_lines = set()  # type: Set[int]\n\n    def _write_and_reset() -> None:\n        nonlocal depth, lines, assert_lineno, seen_lines\n        assert assert_lineno is not None\n        ret[assert_lineno] = \"\".join(lines).rstrip().rstrip(\"\\\\\")\n        depth = 0\n        lines = []\n        assert_lineno = None\n        seen_lines = set()\n\n    tokens = tokenize.tokenize(io.BytesIO(src).readline)\n    for tp, source, (lineno, offset), _, line in tokens:\n        if tp == tokenize.NAME and source == \"assert\":\n            assert_lineno = lineno\n        elif assert_lineno is not None:\n            # keep track of depth for the assert-message `,` lookup\n            if tp == tokenize.OP and source in \"([{\":\n                depth += 1\n            elif tp == tokenize.OP and source in \")]}\":\n                depth -= 1\n\n            if not lines:\n                lines.append(line[offset:])\n                seen_lines.add(lineno)\n            # a non-nested comma separates the expression from the message\n            elif depth == 0 and tp == tokenize.OP and source == \",\":\n                # one line assert with message\n                if lineno in seen_lines and len(lines) == 1:\n                    offset_in_trimmed = offset + len(lines[-1]) - len(line)\n                    lines[-1] = lines[-1][:offset_in_trimmed]\n                # multi-line assert with message\n                elif lineno in seen_lines:\n                    lines[-1] = lines[-1][:offset]\n                # multi line assert with escapd newline before message\n                else:\n                    lines.append(line[:offset])\n                _write_and_reset()\n            elif tp in {tokenize.NEWLINE, tokenize.ENDMARKER}:\n                _write_and_reset()\n            elif lines and lineno not in seen_lines:\n                lines.append(line)\n                seen_lines.add(lineno)\n\n    return ret"}, {"id": "_pytest.assertion.AssertionRewriter", "kind": "class", "range": [557, 0, 1031, 78, 19467, 39452], "file_path": "src/_pytest/assertion/rewrite.py", "content": "class AssertionRewriter(ast.NodeVisitor):\n    \"\"\"Assertion rewriting implementation.\n\n    The main entrypoint is to call .run() with an ast.Module instance,\n    this will then find all the assert statements and rewrite them to\n    provide intermediate values and a detailed assertion error.  See\n    http://pybites.blogspot.be/2011/07/behind-scenes-of-pytests-new-assertion.html\n    for an overview of how this works.\n\n    The entry point here is .run() which will iterate over all the\n    statements in an ast.Module and for each ast.Assert statement it\n    finds call .visit() with it.  Then .visit_Assert() takes over and\n    is responsible for creating new ast statements to replace the\n    original assert statement: it rewrites the test of an assertion\n    to provide intermediate values and replace it with an if statement\n    which raises an assertion error with a detailed explanation in\n    case the expression is false and calls pytest_assertion_pass hook\n    if expression is true.\n\n    For this .visit_Assert() uses the visitor pattern to visit all the\n    AST nodes of the ast.Assert.test field, each visit call returning\n    an AST node and the corresponding explanation string.  During this\n    state is kept in several instance attributes:\n\n    :statements: All the AST statements which will replace the assert\n       statement.\n\n    :variables: This is populated by .variable() with each variable\n       used by the statements so that they can all be set to None at\n       the end of the statements.\n\n    :variable_counter: Counter to create new unique variables needed\n       by statements.  Variables are created using .variable() and\n       have the form of \"@py_assert0\".\n\n    :expl_stmts: The AST statements which will be executed to get\n       data from the assertion.  This is the code which will construct\n       the detailed assertion message that is used in the AssertionError\n       or for the pytest_assertion_pass hook.\n\n    :explanation_specifiers: A dict filled by .explanation_param()\n       with %-formatting placeholders and their corresponding\n       expressions to use in the building of an assertion message.\n       This is used by .pop_format_context() to build a message.\n\n    :stack: A stack of the explanation_specifiers dicts maintained by\n       .push_format_context() and .pop_format_context() which allows\n       to build another %-formatted string while already building one.\n\n    This state is reset on every new assert statement visited and used\n    by the other visitors.\n\n    \"\"\"\n\n    def __init__(self, module_path, config, source):\n        super().__init__()\n        self.module_path = module_path\n        self.config = config\n        if config is not None:\n            self.enable_assertion_pass_hook = config.getini(\n                \"enable_assertion_pass_hook\"\n            )\n        else:\n            self.enable_assertion_pass_hook = False\n        self.source = source\n\n    @functools.lru_cache(maxsize=1)\n    def _assert_expr_to_lineno(self):\n        return _get_assertion_exprs(self.source)\n\n    def run(self, mod: ast.Module) -> None:\n        \"\"\"Find all assert statements in *mod* and rewrite them.\"\"\"\n        if not mod.body:\n            # Nothing to do.\n            return\n        # Insert some special imports at the top of the module but after any\n        # docstrings and __future__ imports.\n        aliases = [\n            ast.alias(\"builtins\", \"@py_builtins\"),\n            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n        ]\n        doc = getattr(mod, \"docstring\", None)\n        expect_docstring = doc is None\n        if doc is not None and self.is_rewrite_disabled(doc):\n            return\n        pos = 0\n        lineno = 1\n        for item in mod.body:\n            if (\n                expect_docstring\n                and isinstance(item, ast.Expr)\n                and isinstance(item.value, ast.Str)\n            ):\n                doc = item.value.s\n                if self.is_rewrite_disabled(doc):\n                    return\n                expect_docstring = False\n            elif (\n                not isinstance(item, ast.ImportFrom)\n                or item.level > 0\n                or item.module != \"__future__\"\n            ):\n                lineno = item.lineno\n                break\n            pos += 1\n        else:\n            lineno = item.lineno\n        imports = [\n            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases\n        ]\n        mod.body[pos:pos] = imports\n        # Collect asserts.\n        nodes = [mod]  # type: List[ast.AST]\n        while nodes:\n            node = nodes.pop()\n            for name, field in ast.iter_fields(node):\n                if isinstance(field, list):\n                    new = []  # type: List\n                    for i, child in enumerate(field):\n                        if isinstance(child, ast.Assert):\n                            # Transform assert.\n                            new.extend(self.visit(child))\n                        else:\n                            new.append(child)\n                            if isinstance(child, ast.AST):\n                                nodes.append(child)\n                    setattr(node, name, new)\n                elif (\n                    isinstance(field, ast.AST)\n                    # Don't recurse into expressions as they can't contain\n                    # asserts.\n                    and not isinstance(field, ast.expr)\n                ):\n                    nodes.append(field)\n\n    @staticmethod\n    def is_rewrite_disabled(docstring):\n        return \"PYTEST_DONT_REWRITE\" in docstring\n\n    def variable(self):\n        \"\"\"Get a new variable.\"\"\"\n        # Use a character invalid in python identifiers to avoid clashing.\n        name = \"@py_assert\" + str(next(self.variable_counter))\n        self.variables.append(name)\n        return name\n\n    def assign(self, expr):\n        \"\"\"Give *expr* a name.\"\"\"\n        name = self.variable()\n        self.statements.append(ast.Assign([ast.Name(name, ast.Store())], expr))\n        return ast.Name(name, ast.Load())\n\n    def display(self, expr):\n        \"\"\"Call saferepr on the expression.\"\"\"\n        return self.helper(\"_saferepr\", expr)\n\n    def helper(self, name, *args):\n        \"\"\"Call a helper in this module.\"\"\"\n        py_name = ast.Name(\"@pytest_ar\", ast.Load())\n        attr = ast.Attribute(py_name, name, ast.Load())\n        return ast.Call(attr, list(args), [])\n\n    def builtin(self, name):\n        \"\"\"Return the builtin called *name*.\"\"\"\n        builtin_name = ast.Name(\"@py_builtins\", ast.Load())\n        return ast.Attribute(builtin_name, name, ast.Load())\n\n    def explanation_param(self, expr):\n        \"\"\"Return a new named %-formatting placeholder for expr.\n\n        This creates a %-formatting placeholder for expr in the\n        current formatting context, e.g. ``%(py0)s``.  The placeholder\n        and expr are placed in the current format context so that it\n        can be used on the next call to .pop_format_context().\n\n        \"\"\"\n        specifier = \"py\" + str(next(self.variable_counter))\n        self.explanation_specifiers[specifier] = expr\n        return \"%(\" + specifier + \")s\"\n\n    def push_format_context(self):\n        \"\"\"Create a new formatting context.\n\n        The format context is used for when an explanation wants to\n        have a variable value formatted in the assertion message.  In\n        this case the value required can be added using\n        .explanation_param().  Finally .pop_format_context() is used\n        to format a string of %-formatted values as added by\n        .explanation_param().\n\n        \"\"\"\n        self.explanation_specifiers = {}  # type: Dict[str, ast.expr]\n        self.stack.append(self.explanation_specifiers)\n\n    def pop_format_context(self, expl_expr):\n        \"\"\"Format the %-formatted string with current format context.\n\n        The expl_expr should be an ast.Str instance constructed from\n        the %-placeholders created by .explanation_param().  This will\n        add the required code to format said string to .expl_stmts and\n        return the ast.Name instance of the formatted string.\n\n        \"\"\"\n        current = self.stack.pop()\n        if self.stack:\n            self.explanation_specifiers = self.stack[-1]\n        keys = [ast.Str(key) for key in current.keys()]\n        format_dict = ast.Dict(keys, list(current.values()))\n        form = ast.BinOp(expl_expr, ast.Mod(), format_dict)\n        name = \"@py_format\" + str(next(self.variable_counter))\n        if self.enable_assertion_pass_hook:\n            self.format_variables.append(name)\n        self.expl_stmts.append(ast.Assign([ast.Name(name, ast.Store())], form))\n        return ast.Name(name, ast.Load())\n\n    def generic_visit(self, node):\n        \"\"\"Handle expressions we don't have custom code for.\"\"\"\n        assert isinstance(node, ast.expr)\n        res = self.assign(node)\n        return res, self.explanation_param(self.display(res))\n\n    def visit_Assert(self, assert_):\n        \"\"\"Return the AST statements to replace the ast.Assert instance.\n\n        This rewrites the test of an assertion to provide\n        intermediate values and replace it with an if statement which\n        raises an assertion error with a detailed explanation in case\n        the expression is false.\n\n        \"\"\"\n        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:\n            from _pytest.warning_types import PytestAssertRewriteWarning\n            import warnings\n\n            warnings.warn_explicit(\n                PytestAssertRewriteWarning(\n                    \"assertion is always true, perhaps remove parentheses?\"\n                ),\n                category=None,\n                filename=fspath(self.module_path),\n                lineno=assert_.lineno,\n            )\n\n        self.statements = []  # type: List[ast.stmt]\n        self.variables = []  # type: List[str]\n        self.variable_counter = itertools.count()\n\n        if self.enable_assertion_pass_hook:\n            self.format_variables = []  # type: List[str]\n\n        self.stack = []  # type: List[Dict[str, ast.expr]]\n        self.expl_stmts = []  # type: List[ast.stmt]\n        self.push_format_context()\n        # Rewrite assert into a bunch of statements.\n        top_condition, explanation = self.visit(assert_.test)\n\n        negation = ast.UnaryOp(ast.Not(), top_condition)\n\n        if self.enable_assertion_pass_hook:  # Experimental pytest_assertion_pass hook\n            msg = self.pop_format_context(ast.Str(explanation))\n\n            # Failed\n            if assert_.msg:\n                assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n                gluestr = \"\\n>assert \"\n            else:\n                assertmsg = ast.Str(\"\")\n                gluestr = \"assert \"\n            err_explanation = ast.BinOp(ast.Str(gluestr), ast.Add(), msg)\n            err_msg = ast.BinOp(assertmsg, ast.Add(), err_explanation)\n            err_name = ast.Name(\"AssertionError\", ast.Load())\n            fmt = self.helper(\"_format_explanation\", err_msg)\n            exc = ast.Call(err_name, [fmt], [])\n            raise_ = ast.Raise(exc, None)\n            statements_fail = []\n            statements_fail.extend(self.expl_stmts)\n            statements_fail.append(raise_)\n\n            # Passed\n            fmt_pass = self.helper(\"_format_explanation\", msg)\n            orig = self._assert_expr_to_lineno()[assert_.lineno]\n            hook_call_pass = ast.Expr(\n                self.helper(\n                    \"_call_assertion_pass\",\n                    ast.Num(assert_.lineno),\n                    ast.Str(orig),\n                    fmt_pass,\n                )\n            )\n            # If any hooks implement assert_pass hook\n            hook_impl_test = ast.If(\n                self.helper(\"_check_if_assertion_pass_impl\"),\n                self.expl_stmts + [hook_call_pass],\n                [],\n            )\n            statements_pass = [hook_impl_test]\n\n            # Test for assertion condition\n            main_test = ast.If(negation, statements_fail, statements_pass)\n            self.statements.append(main_test)\n            if self.format_variables:\n                variables = [\n                    ast.Name(name, ast.Store()) for name in self.format_variables\n                ]\n                clear_format = ast.Assign(variables, ast.NameConstant(None))\n                self.statements.append(clear_format)\n\n        else:  # Original assertion rewriting\n            # Create failure message.\n            body = self.expl_stmts\n            self.statements.append(ast.If(negation, body, []))\n            if assert_.msg:\n                assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n                explanation = \"\\n>assert \" + explanation\n            else:\n                assertmsg = ast.Str(\"\")\n                explanation = \"assert \" + explanation\n            template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))\n            msg = self.pop_format_context(template)\n            fmt = self.helper(\"_format_explanation\", msg)\n            err_name = ast.Name(\"AssertionError\", ast.Load())\n            exc = ast.Call(err_name, [fmt], [])\n            raise_ = ast.Raise(exc, None)\n\n            body.append(raise_)\n\n        # Clear temporary variables by setting them to None.\n        if self.variables:\n            variables = [ast.Name(name, ast.Store()) for name in self.variables]\n            clear = ast.Assign(variables, ast.NameConstant(None))\n            self.statements.append(clear)\n        # Fix line numbers.\n        for stmt in self.statements:\n            set_location(stmt, assert_.lineno, assert_.col_offset)\n        return self.statements\n\n    def visit_Name(self, name):\n        # Display the repr of the name if it's a local variable or\n        # _should_repr_global_name() thinks it's acceptable.\n        locs = ast.Call(self.builtin(\"locals\"), [], [])\n        inlocs = ast.Compare(ast.Str(name.id), [ast.In()], [locs])\n        dorepr = self.helper(\"_should_repr_global_name\", name)\n        test = ast.BoolOp(ast.Or(), [inlocs, dorepr])\n        expr = ast.IfExp(test, self.display(name), ast.Str(name.id))\n        return name, self.explanation_param(expr)\n\n    def visit_BoolOp(self, boolop):\n        res_var = self.variable()\n        expl_list = self.assign(ast.List([], ast.Load()))\n        app = ast.Attribute(expl_list, \"append\", ast.Load())\n        is_or = int(isinstance(boolop.op, ast.Or))\n        body = save = self.statements\n        fail_save = self.expl_stmts\n        levels = len(boolop.values) - 1\n        self.push_format_context()\n        # Process each operand, short-circuiting if needed.\n        for i, v in enumerate(boolop.values):\n            if i:\n                fail_inner = []  # type: List[ast.stmt]\n                # cond is set in a prior loop iteration below\n                self.expl_stmts.append(ast.If(cond, fail_inner, []))  # noqa\n                self.expl_stmts = fail_inner\n            self.push_format_context()\n            res, expl = self.visit(v)\n            body.append(ast.Assign([ast.Name(res_var, ast.Store())], res))\n            expl_format = self.pop_format_context(ast.Str(expl))\n            call = ast.Call(app, [expl_format], [])\n            self.expl_stmts.append(ast.Expr(call))\n            if i < levels:\n                cond = res  # type: ast.expr\n                if is_or:\n                    cond = ast.UnaryOp(ast.Not(), cond)\n                inner = []  # type: List[ast.stmt]\n                self.statements.append(ast.If(cond, inner, []))\n                self.statements = body = inner\n        self.statements = save\n        self.expl_stmts = fail_save\n        expl_template = self.helper(\"_format_boolop\", expl_list, ast.Num(is_or))\n        expl = self.pop_format_context(expl_template)\n        return ast.Name(res_var, ast.Load()), self.explanation_param(expl)\n\n    def visit_UnaryOp(self, unary):\n        pattern = UNARY_MAP[unary.op.__class__]\n        operand_res, operand_expl = self.visit(unary.operand)\n        res = self.assign(ast.UnaryOp(unary.op, operand_res))\n        return res, pattern % (operand_expl,)\n\n    def visit_BinOp(self, binop):\n        symbol = BINOP_MAP[binop.op.__class__]\n        left_expr, left_expl = self.visit(binop.left)\n        right_expr, right_expl = self.visit(binop.right)\n        explanation = \"({} {} {})\".format(left_expl, symbol, right_expl)\n        res = self.assign(ast.BinOp(left_expr, binop.op, right_expr))\n        return res, explanation\n\n    def visit_Call(self, call):\n        \"\"\"\n        visit `ast.Call` nodes\n        \"\"\"\n        new_func, func_expl = self.visit(call.func)\n        arg_expls = []\n        new_args = []\n        new_kwargs = []\n        for arg in call.args:\n            res, expl = self.visit(arg)\n            arg_expls.append(expl)\n            new_args.append(res)\n        for keyword in call.keywords:\n            res, expl = self.visit(keyword.value)\n            new_kwargs.append(ast.keyword(keyword.arg, res))\n            if keyword.arg:\n                arg_expls.append(keyword.arg + \"=\" + expl)\n            else:  # **args have `arg` keywords with an .arg of None\n                arg_expls.append(\"**\" + expl)\n\n        expl = \"{}({})\".format(func_expl, \", \".join(arg_expls))\n        new_call = ast.Call(new_func, new_args, new_kwargs)\n        res = self.assign(new_call)\n        res_expl = self.explanation_param(self.display(res))\n        outer_expl = \"{}\\n{{{} = {}\\n}}\".format(res_expl, res_expl, expl)\n        return res, outer_expl\n\n    def visit_Starred(self, starred):\n        # From Python 3.5, a Starred node can appear in a function call\n        res, expl = self.visit(starred.value)\n        new_starred = ast.Starred(res, starred.ctx)\n        return new_starred, \"*\" + expl\n\n    def visit_Attribute(self, attr):\n        if not isinstance(attr.ctx, ast.Load):\n            return self.generic_visit(attr)\n        value, value_expl = self.visit(attr.value)\n        res = self.assign(ast.Attribute(value, attr.attr, ast.Load()))\n        res_expl = self.explanation_param(self.display(res))\n        pat = \"%s\\n{%s = %s.%s\\n}\"\n        expl = pat % (res_expl, res_expl, value_expl, attr.attr)\n        return res, expl\n\n    def visit_Compare(self, comp: ast.Compare):\n        self.push_format_context()\n        left_res, left_expl = self.visit(comp.left)\n        if isinstance(comp.left, (ast.Compare, ast.BoolOp)):\n            left_expl = \"({})\".format(left_expl)\n        res_variables = [self.variable() for i in range(len(comp.ops))]\n        load_names = [ast.Name(v, ast.Load()) for v in res_variables]\n        store_names = [ast.Name(v, ast.Store()) for v in res_variables]\n        it = zip(range(len(comp.ops)), comp.ops, comp.comparators)\n        expls = []\n        syms = []\n        results = [left_res]\n        for i, op, next_operand in it:\n            next_res, next_expl = self.visit(next_operand)\n            if isinstance(next_operand, (ast.Compare, ast.BoolOp)):\n                next_expl = \"({})\".format(next_expl)\n            results.append(next_res)\n            sym = BINOP_MAP[op.__class__]\n            syms.append(ast.Str(sym))\n            expl = \"{} {} {}\".format(left_expl, sym, next_expl)\n            expls.append(ast.Str(expl))\n            res_expr = ast.Compare(left_res, [op], [next_res])\n            self.statements.append(ast.Assign([store_names[i]], res_expr))\n            left_res, left_expl = next_res, next_expl\n        # Use pytest.assertion.util._reprcompare if that's available.\n        expl_call = self.helper(\n            \"_call_reprcompare\",\n            ast.Tuple(syms, ast.Load()),\n            ast.Tuple(load_names, ast.Load()),\n            ast.Tuple(expls, ast.Load()),\n            ast.Tuple(results, ast.Load()),\n        )\n        if len(comp.ops) > 1:\n            res = ast.BoolOp(ast.And(), load_names)  # type: ast.expr\n        else:\n            res = load_names[0]\n        return res, self.explanation_param(self.pop_format_context(expl_call))"}, {"id": "_pytest.assertion.AssertionRewriter.__init__", "kind": "function", "range": [611, 4, 621, 28, 22004, 22393], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def __init__(self, module_path, config, source):\n        super().__init__()\n        self.module_path = module_path\n        self.config = config\n        if config is not None:\n            self.enable_assertion_pass_hook = config.getini(\n                \"enable_assertion_pass_hook\"\n            )\n        else:\n            self.enable_assertion_pass_hook = False\n        self.source = source"}, {"id": "_pytest.assertion.AssertionRewriter._assert_expr_to_lineno", "kind": "function", "range": [623, 4, 625, 48, 22399, 22517], "file_path": "src/_pytest/assertion/rewrite.py", "content": "@functools.lru_cache(maxsize=1)\n    def _assert_expr_to_lineno(self):\n        return _get_assertion_exprs(self.source)"}, {"id": "_pytest.assertion.AssertionRewriter.run", "kind": "function", "range": [627, 4, 690, 39, 22523, 24969], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def run(self, mod: ast.Module) -> None:\n        \"\"\"Find all assert statements in *mod* and rewrite them.\"\"\"\n        if not mod.body:\n            # Nothing to do.\n            return\n        # Insert some special imports at the top of the module but after any\n        # docstrings and __future__ imports.\n        aliases = [\n            ast.alias(\"builtins\", \"@py_builtins\"),\n            ast.alias(\"_pytest.assertion.rewrite\", \"@pytest_ar\"),\n        ]\n        doc = getattr(mod, \"docstring\", None)\n        expect_docstring = doc is None\n        if doc is not None and self.is_rewrite_disabled(doc):\n            return\n        pos = 0\n        lineno = 1\n        for item in mod.body:\n            if (\n                expect_docstring\n                and isinstance(item, ast.Expr)\n                and isinstance(item.value, ast.Str)\n            ):\n                doc = item.value.s\n                if self.is_rewrite_disabled(doc):\n                    return\n                expect_docstring = False\n            elif (\n                not isinstance(item, ast.ImportFrom)\n                or item.level > 0\n                or item.module != \"__future__\"\n            ):\n                lineno = item.lineno\n                break\n            pos += 1\n        else:\n            lineno = item.lineno\n        imports = [\n            ast.Import([alias], lineno=lineno, col_offset=0) for alias in aliases\n        ]\n        mod.body[pos:pos] = imports\n        # Collect asserts.\n        nodes = [mod]  # type: List[ast.AST]\n        while nodes:\n            node = nodes.pop()\n            for name, field in ast.iter_fields(node):\n                if isinstance(field, list):\n                    new = []  # type: List\n                    for i, child in enumerate(field):\n                        if isinstance(child, ast.Assert):\n                            # Transform assert.\n                            new.extend(self.visit(child))\n                        else:\n                            new.append(child)\n                            if isinstance(child, ast.AST):\n                                nodes.append(child)\n                    setattr(node, name, new)\n                elif (\n                    isinstance(field, ast.AST)\n                    # Don't recurse into expressions as they can't contain\n                    # asserts.\n                    and not isinstance(field, ast.expr)\n                ):\n                    nodes.append(field)"}, {"id": "_pytest.assertion.AssertionRewriter.is_rewrite_disabled", "kind": "function", "range": [692, 4, 694, 49, 24975, 25078], "file_path": "src/_pytest/assertion/rewrite.py", "content": "@staticmethod\n    def is_rewrite_disabled(docstring):\n        return \"PYTEST_DONT_REWRITE\" in docstring"}, {"id": "_pytest.assertion.AssertionRewriter.variable", "kind": "function", "range": [696, 4, 701, 19, 25084, 25331], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def variable(self):\n        \"\"\"Get a new variable.\"\"\"\n        # Use a character invalid in python identifiers to avoid clashing.\n        name = \"@py_assert\" + str(next(self.variable_counter))\n        self.variables.append(name)\n        return name"}, {"id": "_pytest.assertion.AssertionRewriter.assign", "kind": "function", "range": [703, 4, 707, 41, 25337, 25547], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def assign(self, expr):\n        \"\"\"Give *expr* a name.\"\"\"\n        name = self.variable()\n        self.statements.append(ast.Assign([ast.Name(name, ast.Store())], expr))\n        return ast.Name(name, ast.Load())"}, {"id": "_pytest.assertion.AssertionRewriter.display", "kind": "function", "range": [709, 4, 711, 45, 25553, 25670], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def display(self, expr):\n        \"\"\"Call saferepr on the expression.\"\"\"\n        return self.helper(\"_saferepr\", expr)"}, {"id": "_pytest.assertion.AssertionRewriter.helper", "kind": "function", "range": [713, 4, 717, 45, 25676, 25905], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def helper(self, name, *args):\n        \"\"\"Call a helper in this module.\"\"\"\n        py_name = ast.Name(\"@pytest_ar\", ast.Load())\n        attr = ast.Attribute(py_name, name, ast.Load())\n        return ast.Call(attr, list(args), [])"}, {"id": "_pytest.assertion.AssertionRewriter.builtin", "kind": "function", "range": [719, 4, 722, 60, 25911, 26104], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def builtin(self, name):\n        \"\"\"Return the builtin called *name*.\"\"\"\n        builtin_name = ast.Name(\"@py_builtins\", ast.Load())\n        return ast.Attribute(builtin_name, name, ast.Load())"}, {"id": "_pytest.assertion.AssertionRewriter.explanation_param", "kind": "function", "range": [724, 4, 735, 38, 26110, 26643], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def explanation_param(self, expr):\n        \"\"\"Return a new named %-formatting placeholder for expr.\n\n        This creates a %-formatting placeholder for expr in the\n        current formatting context, e.g. ``%(py0)s``.  The placeholder\n        and expr are placed in the current format context so that it\n        can be used on the next call to .pop_format_context().\n\n        \"\"\"\n        specifier = \"py\" + str(next(self.variable_counter))\n        self.explanation_specifiers[specifier] = expr\n        return \"%(\" + specifier + \")s\""}, {"id": "_pytest.assertion.AssertionRewriter.push_format_context", "kind": "function", "range": [737, 4, 749, 54, 26649, 27216], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def push_format_context(self):\n        \"\"\"Create a new formatting context.\n\n        The format context is used for when an explanation wants to\n        have a variable value formatted in the assertion message.  In\n        this case the value required can be added using\n        .explanation_param().  Finally .pop_format_context() is used\n        to format a string of %-formatted values as added by\n        .explanation_param().\n\n        \"\"\"\n        self.explanation_specifiers = {}  # type: Dict[str, ast.expr]\n        self.stack.append(self.explanation_specifiers)"}, {"id": "_pytest.assertion.AssertionRewriter.pop_format_context", "kind": "function", "range": [751, 4, 770, 41, 27222, 28187], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def pop_format_context(self, expl_expr):\n        \"\"\"Format the %-formatted string with current format context.\n\n        The expl_expr should be an ast.Str instance constructed from\n        the %-placeholders created by .explanation_param().  This will\n        add the required code to format said string to .expl_stmts and\n        return the ast.Name instance of the formatted string.\n\n        \"\"\"\n        current = self.stack.pop()\n        if self.stack:\n            self.explanation_specifiers = self.stack[-1]\n        keys = [ast.Str(key) for key in current.keys()]\n        format_dict = ast.Dict(keys, list(current.values()))\n        form = ast.BinOp(expl_expr, ast.Mod(), format_dict)\n        name = \"@py_format\" + str(next(self.variable_counter))\n        if self.enable_assertion_pass_hook:\n            self.format_variables.append(name)\n        self.expl_stmts.append(ast.Assign([ast.Name(name, ast.Store())], form))\n        return ast.Name(name, ast.Load())"}, {"id": "_pytest.assertion.AssertionRewriter.generic_visit", "kind": "function", "range": [772, 4, 776, 61, 28193, 28423], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def generic_visit(self, node):\n        \"\"\"Handle expressions we don't have custom code for.\"\"\"\n        assert isinstance(node, ast.expr)\n        res = self.assign(node)\n        return res, self.explanation_param(self.display(res))"}, {"id": "_pytest.assertion.AssertionRewriter.visit_Assert", "kind": "function", "range": [778, 4, 891, 30, 28429, 33162], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_Assert(self, assert_):\n        \"\"\"Return the AST statements to replace the ast.Assert instance.\n\n        This rewrites the test of an assertion to provide\n        intermediate values and replace it with an if statement which\n        raises an assertion error with a detailed explanation in case\n        the expression is false.\n\n        \"\"\"\n        if isinstance(assert_.test, ast.Tuple) and len(assert_.test.elts) >= 1:\n            from _pytest.warning_types import PytestAssertRewriteWarning\n            import warnings\n\n            warnings.warn_explicit(\n                PytestAssertRewriteWarning(\n                    \"assertion is always true, perhaps remove parentheses?\"\n                ),\n                category=None,\n                filename=fspath(self.module_path),\n                lineno=assert_.lineno,\n            )\n\n        self.statements = []  # type: List[ast.stmt]\n        self.variables = []  # type: List[str]\n        self.variable_counter = itertools.count()\n\n        if self.enable_assertion_pass_hook:\n            self.format_variables = []  # type: List[str]\n\n        self.stack = []  # type: List[Dict[str, ast.expr]]\n        self.expl_stmts = []  # type: List[ast.stmt]\n        self.push_format_context()\n        # Rewrite assert into a bunch of statements.\n        top_condition, explanation = self.visit(assert_.test)\n\n        negation = ast.UnaryOp(ast.Not(), top_condition)\n\n        if self.enable_assertion_pass_hook:  # Experimental pytest_assertion_pass hook\n            msg = self.pop_format_context(ast.Str(explanation))\n\n            # Failed\n            if assert_.msg:\n                assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n                gluestr = \"\\n>assert \"\n            else:\n                assertmsg = ast.Str(\"\")\n                gluestr = \"assert \"\n            err_explanation = ast.BinOp(ast.Str(gluestr), ast.Add(), msg)\n            err_msg = ast.BinOp(assertmsg, ast.Add(), err_explanation)\n            err_name = ast.Name(\"AssertionError\", ast.Load())\n            fmt = self.helper(\"_format_explanation\", err_msg)\n            exc = ast.Call(err_name, [fmt], [])\n            raise_ = ast.Raise(exc, None)\n            statements_fail = []\n            statements_fail.extend(self.expl_stmts)\n            statements_fail.append(raise_)\n\n            # Passed\n            fmt_pass = self.helper(\"_format_explanation\", msg)\n            orig = self._assert_expr_to_lineno()[assert_.lineno]\n            hook_call_pass = ast.Expr(\n                self.helper(\n                    \"_call_assertion_pass\",\n                    ast.Num(assert_.lineno),\n                    ast.Str(orig),\n                    fmt_pass,\n                )\n            )\n            # If any hooks implement assert_pass hook\n            hook_impl_test = ast.If(\n                self.helper(\"_check_if_assertion_pass_impl\"),\n                self.expl_stmts + [hook_call_pass],\n                [],\n            )\n            statements_pass = [hook_impl_test]\n\n            # Test for assertion condition\n            main_test = ast.If(negation, statements_fail, statements_pass)\n            self.statements.append(main_test)\n            if self.format_variables:\n                variables = [\n                    ast.Name(name, ast.Store()) for name in self.format_variables\n                ]\n                clear_format = ast.Assign(variables, ast.NameConstant(None))\n                self.statements.append(clear_format)\n\n        else:  # Original assertion rewriting\n            # Create failure message.\n            body = self.expl_stmts\n            self.statements.append(ast.If(negation, body, []))\n            if assert_.msg:\n                assertmsg = self.helper(\"_format_assertmsg\", assert_.msg)\n                explanation = \"\\n>assert \" + explanation\n            else:\n                assertmsg = ast.Str(\"\")\n                explanation = \"assert \" + explanation\n            template = ast.BinOp(assertmsg, ast.Add(), ast.Str(explanation))\n            msg = self.pop_format_context(template)\n            fmt = self.helper(\"_format_explanation\", msg)\n            err_name = ast.Name(\"AssertionError\", ast.Load())\n            exc = ast.Call(err_name, [fmt], [])\n            raise_ = ast.Raise(exc, None)\n\n            body.append(raise_)\n\n        # Clear temporary variables by setting them to None.\n        if self.variables:\n            variables = [ast.Name(name, ast.Store()) for name in self.variables]\n            clear = ast.Assign(variables, ast.NameConstant(None))\n            self.statements.append(clear)\n        # Fix line numbers.\n        for stmt in self.statements:\n            set_location(stmt, assert_.lineno, assert_.col_offset)\n        return self.statements"}, {"id": "_pytest.assertion.AssertionRewriter.visit_Name", "kind": "function", "range": [893, 4, 901, 49, 33168, 33682], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_Name(self, name):\n        # Display the repr of the name if it's a local variable or\n        # _should_repr_global_name() thinks it's acceptable.\n        locs = ast.Call(self.builtin(\"locals\"), [], [])\n        inlocs = ast.Compare(ast.Str(name.id), [ast.In()], [locs])\n        dorepr = self.helper(\"_should_repr_global_name\", name)\n        test = ast.BoolOp(ast.Or(), [inlocs, dorepr])\n        expr = ast.IfExp(test, self.display(name), ast.Str(name.id))\n        return name, self.explanation_param(expr)"}, {"id": "_pytest.assertion.AssertionRewriter.visit_BoolOp", "kind": "function", "range": [903, 4, 936, 74, 33688, 35349], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_BoolOp(self, boolop):\n        res_var = self.variable()\n        expl_list = self.assign(ast.List([], ast.Load()))\n        app = ast.Attribute(expl_list, \"append\", ast.Load())\n        is_or = int(isinstance(boolop.op, ast.Or))\n        body = save = self.statements\n        fail_save = self.expl_stmts\n        levels = len(boolop.values) - 1\n        self.push_format_context()\n        # Process each operand, short-circuiting if needed.\n        for i, v in enumerate(boolop.values):\n            if i:\n                fail_inner = []  # type: List[ast.stmt]\n                # cond is set in a prior loop iteration below\n                self.expl_stmts.append(ast.If(cond, fail_inner, []))  # noqa\n                self.expl_stmts = fail_inner\n            self.push_format_context()\n            res, expl = self.visit(v)\n            body.append(ast.Assign([ast.Name(res_var, ast.Store())], res))\n            expl_format = self.pop_format_context(ast.Str(expl))\n            call = ast.Call(app, [expl_format], [])\n            self.expl_stmts.append(ast.Expr(call))\n            if i < levels:\n                cond = res  # type: ast.expr\n                if is_or:\n                    cond = ast.UnaryOp(ast.Not(), cond)\n                inner = []  # type: List[ast.stmt]\n                self.statements.append(ast.If(cond, inner, []))\n                self.statements = body = inner\n        self.statements = save\n        self.expl_stmts = fail_save\n        expl_template = self.helper(\"_format_boolop\", expl_list, ast.Num(is_or))\n        expl = self.pop_format_context(expl_template)\n        return ast.Name(res_var, ast.Load()), self.explanation_param(expl)"}, {"id": "_pytest.assertion.AssertionRewriter.visit_UnaryOp", "kind": "function", "range": [938, 4, 942, 45, 35355, 35604], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_UnaryOp(self, unary):\n        pattern = UNARY_MAP[unary.op.__class__]\n        operand_res, operand_expl = self.visit(unary.operand)\n        res = self.assign(ast.UnaryOp(unary.op, operand_res))\n        return res, pattern % (operand_expl,)"}, {"id": "_pytest.assertion.AssertionRewriter.visit_BinOp", "kind": "function", "range": [944, 4, 950, 31, 35610, 35972], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_BinOp(self, binop):\n        symbol = BINOP_MAP[binop.op.__class__]\n        left_expr, left_expl = self.visit(binop.left)\n        right_expr, right_expl = self.visit(binop.right)\n        explanation = \"({} {} {})\".format(left_expl, symbol, right_expl)\n        res = self.assign(ast.BinOp(left_expr, binop.op, right_expr))\n        return res, explanation"}, {"id": "_pytest.assertion.AssertionRewriter.visit_Call", "kind": "function", "range": [952, 4, 977, 30, 35978, 36997], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_Call(self, call):\n        \"\"\"\n        visit `ast.Call` nodes\n        \"\"\"\n        new_func, func_expl = self.visit(call.func)\n        arg_expls = []\n        new_args = []\n        new_kwargs = []\n        for arg in call.args:\n            res, expl = self.visit(arg)\n            arg_expls.append(expl)\n            new_args.append(res)\n        for keyword in call.keywords:\n            res, expl = self.visit(keyword.value)\n            new_kwargs.append(ast.keyword(keyword.arg, res))\n            if keyword.arg:\n                arg_expls.append(keyword.arg + \"=\" + expl)\n            else:  # **args have `arg` keywords with an .arg of None\n                arg_expls.append(\"**\" + expl)\n\n        expl = \"{}({})\".format(func_expl, \", \".join(arg_expls))\n        new_call = ast.Call(new_func, new_args, new_kwargs)\n        res = self.assign(new_call)\n        res_expl = self.explanation_param(self.display(res))\n        outer_expl = \"{}\\n{{{} = {}\\n}}\".format(res_expl, res_expl, expl)\n        return res, outer_expl"}, {"id": "_pytest.assertion.AssertionRewriter.visit_Starred", "kind": "function", "range": [979, 4, 983, 38, 37003, 37245], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_Starred(self, starred):\n        # From Python 3.5, a Starred node can appear in a function call\n        res, expl = self.visit(starred.value)\n        new_starred = ast.Starred(res, starred.ctx)\n        return new_starred, \"*\" + expl"}, {"id": "_pytest.assertion.AssertionRewriter.visit_Attribute", "kind": "function", "range": [985, 4, 993, 24, 37251, 37682], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_Attribute(self, attr):\n        if not isinstance(attr.ctx, ast.Load):\n            return self.generic_visit(attr)\n        value, value_expl = self.visit(attr.value)\n        res = self.assign(ast.Attribute(value, attr.attr, ast.Load()))\n        res_expl = self.explanation_param(self.display(res))\n        pat = \"%s\\n{%s = %s.%s\\n}\"\n        expl = pat % (res_expl, res_expl, value_expl, attr.attr)\n        return res, expl"}, {"id": "_pytest.assertion.AssertionRewriter.visit_Compare", "kind": "function", "range": [995, 4, 1031, 78, 37688, 39452], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def visit_Compare(self, comp: ast.Compare):\n        self.push_format_context()\n        left_res, left_expl = self.visit(comp.left)\n        if isinstance(comp.left, (ast.Compare, ast.BoolOp)):\n            left_expl = \"({})\".format(left_expl)\n        res_variables = [self.variable() for i in range(len(comp.ops))]\n        load_names = [ast.Name(v, ast.Load()) for v in res_variables]\n        store_names = [ast.Name(v, ast.Store()) for v in res_variables]\n        it = zip(range(len(comp.ops)), comp.ops, comp.comparators)\n        expls = []\n        syms = []\n        results = [left_res]\n        for i, op, next_operand in it:\n            next_res, next_expl = self.visit(next_operand)\n            if isinstance(next_operand, (ast.Compare, ast.BoolOp)):\n                next_expl = \"({})\".format(next_expl)\n            results.append(next_res)\n            sym = BINOP_MAP[op.__class__]\n            syms.append(ast.Str(sym))\n            expl = \"{} {} {}\".format(left_expl, sym, next_expl)\n            expls.append(ast.Str(expl))\n            res_expr = ast.Compare(left_res, [op], [next_res])\n            self.statements.append(ast.Assign([store_names[i]], res_expr))\n            left_res, left_expl = next_res, next_expl\n        # Use pytest.assertion.util._reprcompare if that's available.\n        expl_call = self.helper(\n            \"_call_reprcompare\",\n            ast.Tuple(syms, ast.Load()),\n            ast.Tuple(load_names, ast.Load()),\n            ast.Tuple(expls, ast.Load()),\n            ast.Tuple(results, ast.Load()),\n        )\n        if len(comp.ops) > 1:\n            res = ast.BoolOp(ast.And(), load_names)  # type: ast.expr\n        else:\n            res = load_names[0]\n        return res, self.explanation_param(self.pop_format_context(expl_call))"}, {"id": "_pytest.assertion.try_makedirs", "kind": "function", "range": [1034, 0, 1051, 15, 39455, 40122], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def try_makedirs(cache_dir) -> bool:\n    \"\"\"Attempts to create the given directory and sub-directories exist, returns True if\n    successful or it already exists\"\"\"\n    try:\n        os.makedirs(fspath(cache_dir), exist_ok=True)\n    except (FileNotFoundError, NotADirectoryError, FileExistsError):\n        # One of the path components was not a directory:\n        # - we're in a zip file\n        # - it is a file\n        return False\n    except PermissionError:\n        return False\n    except OSError as e:\n        # as of now, EROFS doesn't have an equivalent OSError-subclass\n        if e.errno == errno.EROFS:\n            return False\n        raise\n    return True"}, {"id": "_pytest.assertion.get_cache_dir", "kind": "function", "range": [1054, 0, 1065, 47, 40125, 40634], "file_path": "src/_pytest/assertion/rewrite.py", "content": "def get_cache_dir(file_path: Path) -> Path:\n    \"\"\"Returns the cache directory to write .pyc files for the given .py file path\"\"\"\n    if sys.version_info >= (3, 8) and sys.pycache_prefix:\n        # given:\n        #   prefix = '/tmp/pycs'\n        #   path = '/home/user/proj/test_app.py'\n        # we want:\n        #   '/tmp/pycs/home/user/proj'\n        return Path(sys.pycache_prefix) / Path(*file_path.parts[1:-1])\n    else:\n        # classic pycache directory\n        return file_path.parent / \"__pycache__\""}, {"id": "_pytest.python_api.BASE_TYPE", "kind": "variable", "range": [32, 0, 32, 32, 810, 842], "file_path": "src/_pytest/python_api.py", "content": "BASE_TYPE = (type, STRING_TYPES)"}, {"id": "_pytest.python_api._non_numeric_type_error", "kind": "function", "range": [35, 0, 41, 5, 845, 1080], "file_path": "src/_pytest/python_api.py", "content": "def _non_numeric_type_error(value, at):\n    at_str = \" at {}\".format(at) if at else \"\"\n    return TypeError(\n        \"cannot make approximate comparisons to non-numeric values: {!r} {}\".format(\n            value, at_str\n        )\n    )"}, {"id": "_pytest.python_api.ApproxBase", "kind": "class", "range": [47, 0, 98, 12, 1116, 2841], "file_path": "src/_pytest/python_api.py", "content": "class ApproxBase:\n    \"\"\"\n    Provide shared utilities for making approximate comparisons between numbers\n    or sequences of numbers.\n    \"\"\"\n\n    # Tell numpy to use our `__eq__` operator instead of its.\n    __array_ufunc__ = None\n    __array_priority__ = 100\n\n    def __init__(self, expected, rel=None, abs=None, nan_ok=False):\n        __tracebackhide__ = True\n        self.expected = expected\n        self.abs = abs\n        self.rel = rel\n        self.nan_ok = nan_ok\n        self._check_type()\n\n    def __repr__(self):\n        raise NotImplementedError\n\n    def __eq__(self, actual):\n        return all(\n            a == self._approx_scalar(x) for a, x in self._yield_comparisons(actual)\n        )\n\n    # Ignore type because of https://github.com/python/mypy/issues/4266.\n    __hash__ = None  # type: ignore\n\n    def __ne__(self, actual):\n        return not (actual == self)\n\n    def _approx_scalar(self, x):\n        return ApproxScalar(x, rel=self.rel, abs=self.abs, nan_ok=self.nan_ok)\n\n    def _yield_comparisons(self, actual):\n        \"\"\"\n        Yield all the pairs of numbers to be compared.  This is used to\n        implement the `__eq__` method.\n        \"\"\"\n        raise NotImplementedError\n\n    def _check_type(self):\n        \"\"\"\n        Raise a TypeError if the expected value is not a valid type.\n        \"\"\"\n        # This is only a concern if the expected value is a sequence.  In every\n        # other case, the approx() function ensures that the expected value has\n        # a numeric type.  For this reason, the default is to do nothing.  The\n        # classes that deal with sequences should reimplement this method to\n        # raise if there are any non-numeric elements in the sequence.\n        pass"}, {"id": "_pytest.python_api.ApproxBase.__array_ufunc__", "kind": "variable", "range": [54, 4, 54, 26, 1326, 1348], "file_path": "src/_pytest/python_api.py", "content": "__array_ufunc__ = None"}, {"id": "_pytest.python_api.ApproxBase.__array_priority__", "kind": "variable", "range": [55, 4, 55, 28, 1353, 1377], "file_path": "src/_pytest/python_api.py", "content": "__array_priority__ = 100"}, {"id": "_pytest.python_api.ApproxBase.__init__", "kind": "function", "range": [57, 4, 63, 26, 1383, 1614], "file_path": "src/_pytest/python_api.py", "content": "def __init__(self, expected, rel=None, abs=None, nan_ok=False):\n        __tracebackhide__ = True\n        self.expected = expected\n        self.abs = abs\n        self.rel = rel\n        self.nan_ok = nan_ok\n        self._check_type()"}, {"id": "_pytest.python_api.ApproxBase.__repr__", "kind": "function", "range": [65, 4, 66, 33, 1620, 1673], "file_path": "src/_pytest/python_api.py", "content": "def __repr__(self):\n        raise NotImplementedError"}, {"id": "_pytest.python_api.ApproxBase.__eq__", "kind": "function", "range": [68, 4, 71, 9, 1679, 1818], "file_path": "src/_pytest/python_api.py", "content": "def __eq__(self, actual):\n        return all(\n            a == self._approx_scalar(x) for a, x in self._yield_comparisons(actual)\n        )"}, {"id": "_pytest.python_api.ApproxBase.__hash__", "kind": "variable", "range": [74, 4, 74, 19, 1897, 1912], "file_path": "src/_pytest/python_api.py", "content": "__hash__ = None"}, {"id": "_pytest.python_api.ApproxBase.__ne__", "kind": "function", "range": [76, 4, 77, 35, 1934, 1995], "file_path": "src/_pytest/python_api.py", "content": "def __ne__(self, actual):\n        return not (actual == self)"}, {"id": "_pytest.python_api.ApproxBase._approx_scalar", "kind": "function", "range": [79, 4, 80, 78, 2001, 2108], "file_path": "src/_pytest/python_api.py", "content": "def _approx_scalar(self, x):\n        return ApproxScalar(x, rel=self.rel, abs=self.abs, nan_ok=self.nan_ok)"}, {"id": "_pytest.python_api.ApproxBase._yield_comparisons", "kind": "function", "range": [82, 4, 87, 33, 2114, 2320], "file_path": "src/_pytest/python_api.py", "content": "def _yield_comparisons(self, actual):\n        \"\"\"\n        Yield all the pairs of numbers to be compared.  This is used to\n        implement the `__eq__` method.\n        \"\"\"\n        raise NotImplementedError"}, {"id": "_pytest.python_api.ApproxBase._check_type", "kind": "function", "range": [89, 4, 98, 12, 2326, 2841], "file_path": "src/_pytest/python_api.py", "content": "def _check_type(self):\n        \"\"\"\n        Raise a TypeError if the expected value is not a valid type.\n        \"\"\"\n        # This is only a concern if the expected value is a sequence.  In every\n        # other case, the approx() function ensures that the expected value has\n        # a numeric type.  For this reason, the default is to do nothing.  The\n        # classes that deal with sequences should reimplement this method to\n        # raise if there are any non-numeric elements in the sequence.\n        pass"}, {"id": "_pytest.python_api._recursive_list_map", "kind": "function", "range": [101, 0, 105, 19, 2844, 2992], "file_path": "src/_pytest/python_api.py", "content": "def _recursive_list_map(f, x):\n    if isinstance(x, list):\n        return list(_recursive_list_map(f, xi) for xi in x)\n    else:\n        return f(x)"}, {"id": "_pytest.python_api.ApproxNumpy", "kind": "class", "range": [108, 0, 145, 63, 2995, 4307], "file_path": "src/_pytest/python_api.py", "content": "class ApproxNumpy(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is numpy array.\n    \"\"\"\n\n    def __repr__(self):\n        list_scalars = _recursive_list_map(self._approx_scalar, self.expected.tolist())\n        return \"approx({!r})\".format(list_scalars)\n\n    def __eq__(self, actual):\n        import numpy as np\n\n        # self.expected is supposed to always be an array here\n\n        if not np.isscalar(actual):\n            try:\n                actual = np.asarray(actual)\n            except:  # noqa\n                raise TypeError(\"cannot compare '{}' to numpy.ndarray\".format(actual))\n\n        if not np.isscalar(actual) and actual.shape != self.expected.shape:\n            return False\n\n        return ApproxBase.__eq__(self, actual)\n\n    def _yield_comparisons(self, actual):\n        import numpy as np\n\n        # `actual` can either be a numpy array or a scalar, it is treated in\n        # `__eq__` before being passed to `ApproxBase.__eq__`, which is the\n        # only method that calls this one.\n\n        if np.isscalar(actual):\n            for i in np.ndindex(self.expected.shape):\n                yield actual, self.expected[i].item()\n        else:\n            for i in np.ndindex(self.expected.shape):\n                yield actual[i].item(), self.expected[i].item()"}, {"id": "_pytest.python_api.ApproxNumpy.__repr__", "kind": "function", "range": [113, 4, 115, 50, 3124, 3282], "file_path": "src/_pytest/python_api.py", "content": "def __repr__(self):\n        list_scalars = _recursive_list_map(self._approx_scalar, self.expected.tolist())\n        return \"approx({!r})\".format(list_scalars)"}, {"id": "_pytest.python_api.ApproxNumpy.__eq__", "kind": "function", "range": [117, 4, 131, 46, 3288, 3767], "file_path": "src/_pytest/python_api.py", "content": "def __eq__(self, actual):\n        import numpy as np\n\n        # self.expected is supposed to always be an array here\n\n        if not np.isscalar(actual):\n            try:\n                actual = np.asarray(actual)\n            except:  # noqa\n                raise TypeError(\"cannot compare '{}' to numpy.ndarray\".format(actual))\n\n        if not np.isscalar(actual) and actual.shape != self.expected.shape:\n            return False\n\n        return ApproxBase.__eq__(self, actual)"}, {"id": "_pytest.python_api.ApproxNumpy._yield_comparisons", "kind": "function", "range": [133, 4, 145, 63, 3773, 4307], "file_path": "src/_pytest/python_api.py", "content": "def _yield_comparisons(self, actual):\n        import numpy as np\n\n        # `actual` can either be a numpy array or a scalar, it is treated in\n        # `__eq__` before being passed to `ApproxBase.__eq__`, which is the\n        # only method that calls this one.\n\n        if np.isscalar(actual):\n            for i in np.ndindex(self.expected.shape):\n                yield actual, self.expected[i].item()\n        else:\n            for i in np.ndindex(self.expected.shape):\n                yield actual[i].item(), self.expected[i].item()"}, {"id": "_pytest.python_api.ApproxMapping", "kind": "class", "range": [148, 0, 176, 87, 4310, 5428], "file_path": "src/_pytest/python_api.py", "content": "class ApproxMapping(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a mapping with\n    numeric values (the keys can be anything).\n    \"\"\"\n\n    def __repr__(self):\n        return \"approx({!r})\".format(\n            {k: self._approx_scalar(v) for k, v in self.expected.items()}\n        )\n\n    def __eq__(self, actual):\n        if set(actual.keys()) != set(self.expected.keys()):\n            return False\n\n        return ApproxBase.__eq__(self, actual)\n\n    def _yield_comparisons(self, actual):\n        for k in self.expected.keys():\n            yield actual[k], self.expected[k]\n\n    def _check_type(self):\n        __tracebackhide__ = True\n        for key, value in self.expected.items():\n            if isinstance(value, type(self.expected)):\n                msg = \"pytest.approx() does not support nested dictionaries: key={!r} value={!r}\\n  full mapping={}\"\n                raise TypeError(msg.format(key, value, pprint.pformat(self.expected)))\n            elif not isinstance(value, Number):\n                raise _non_numeric_type_error(self.expected, at=\"key={!r}\".format(key))"}, {"id": "_pytest.python_api.ApproxMapping.__repr__", "kind": "function", "range": [154, 4, 157, 9, 4490, 4631], "file_path": "src/_pytest/python_api.py", "content": "def __repr__(self):\n        return \"approx({!r})\".format(\n            {k: self._approx_scalar(v) for k, v in self.expected.items()}\n        )"}, {"id": "_pytest.python_api.ApproxMapping.__eq__", "kind": "function", "range": [159, 4, 163, 46, 4637, 4795], "file_path": "src/_pytest/python_api.py", "content": "def __eq__(self, actual):\n        if set(actual.keys()) != set(self.expected.keys()):\n            return False\n\n        return ApproxBase.__eq__(self, actual)"}, {"id": "_pytest.python_api.ApproxMapping._yield_comparisons", "kind": "function", "range": [165, 4, 167, 45, 4801, 4923], "file_path": "src/_pytest/python_api.py", "content": "def _yield_comparisons(self, actual):\n        for k in self.expected.keys():\n            yield actual[k], self.expected[k]"}, {"id": "_pytest.python_api.ApproxMapping._check_type", "kind": "function", "range": [169, 4, 176, 87, 4929, 5428], "file_path": "src/_pytest/python_api.py", "content": "def _check_type(self):\n        __tracebackhide__ = True\n        for key, value in self.expected.items():\n            if isinstance(value, type(self.expected)):\n                msg = \"pytest.approx() does not support nested dictionaries: key={!r} value={!r}\\n  full mapping={}\"\n                raise TypeError(msg.format(key, value, pprint.pformat(self.expected)))\n            elif not isinstance(value, Number):\n                raise _non_numeric_type_error(self.expected, at=\"key={!r}\".format(key))"}, {"id": "_pytest.python_api.ApproxSequencelike", "kind": "class", "range": [179, 0, 210, 17, 5431, 6602], "file_path": "src/_pytest/python_api.py", "content": "class ApproxSequencelike(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a sequence of\n    numbers.\n    \"\"\"\n\n    def __repr__(self):\n        seq_type = type(self.expected)\n        if seq_type not in (tuple, list, set):\n            seq_type = list\n        return \"approx({!r})\".format(\n            seq_type(self._approx_scalar(x) for x in self.expected)\n        )\n\n    def __eq__(self, actual):\n        if len(actual) != len(self.expected):\n            return False\n        return ApproxBase.__eq__(self, actual)\n\n    def _yield_comparisons(self, actual):\n        return zip(actual, self.expected)\n\n    def _check_type(self):\n        __tracebackhide__ = True\n        for index, x in enumerate(self.expected):\n            if isinstance(x, type(self.expected)):\n                msg = \"pytest.approx() does not support nested data structures: {!r} at index {}\\n  full sequence: {}\"\n                raise TypeError(msg.format(x, index, pprint.pformat(self.expected)))\n            elif not isinstance(x, Number):\n                raise _non_numeric_type_error(\n                    self.expected, at=\"index {}\".format(index)\n                )"}, {"id": "_pytest.python_api.ApproxSequencelike.__repr__", "kind": "function", "range": [185, 4, 191, 9, 5581, 5830], "file_path": "src/_pytest/python_api.py", "content": "def __repr__(self):\n        seq_type = type(self.expected)\n        if seq_type not in (tuple, list, set):\n            seq_type = list\n        return \"approx({!r})\".format(\n            seq_type(self._approx_scalar(x) for x in self.expected)\n        )"}, {"id": "_pytest.python_api.ApproxSequencelike.__eq__", "kind": "function", "range": [193, 4, 196, 46, 5836, 5979], "file_path": "src/_pytest/python_api.py", "content": "def __eq__(self, actual):\n        if len(actual) != len(self.expected):\n            return False\n        return ApproxBase.__eq__(self, actual)"}, {"id": "_pytest.python_api.ApproxSequencelike._yield_comparisons", "kind": "function", "range": [198, 4, 199, 41, 5985, 6064], "file_path": "src/_pytest/python_api.py", "content": "def _yield_comparisons(self, actual):\n        return zip(actual, self.expected)"}, {"id": "_pytest.python_api.ApproxSequencelike._check_type", "kind": "function", "range": [201, 4, 210, 17, 6070, 6602], "file_path": "src/_pytest/python_api.py", "content": "def _check_type(self):\n        __tracebackhide__ = True\n        for index, x in enumerate(self.expected):\n            if isinstance(x, type(self.expected)):\n                msg = \"pytest.approx() does not support nested data structures: {!r} at index {}\\n  full sequence: {}\"\n                raise TypeError(msg.format(x, index, pprint.pformat(self.expected)))\n            elif not isinstance(x, Number):\n                raise _non_numeric_type_error(\n                    self.expected, at=\"index {}\".format(index)\n                )"}, {"id": "_pytest.python_api.ApproxScalar", "kind": "class", "range": [213, 0, 325, 58, 6605, 11385], "file_path": "src/_pytest/python_api.py", "content": "class ApproxScalar(ApproxBase):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a single number.\n    \"\"\"\n\n    # Using Real should be better than this Union, but not possible yet:\n    # https://github.com/python/typeshed/pull/3108\n    DEFAULT_ABSOLUTE_TOLERANCE = 1e-12  # type: Union[float, Decimal]\n    DEFAULT_RELATIVE_TOLERANCE = 1e-6  # type: Union[float, Decimal]\n\n    def __repr__(self):\n        \"\"\"\n        Return a string communicating both the expected value and the tolerance\n        for the comparison being made, e.g. '1.0 \u00b1 1e-6', '(3+4j) \u00b1 5e-6 \u2220 \u00b1180\u00b0'.\n        \"\"\"\n\n        # Infinities aren't compared using tolerances, so don't show a\n        # tolerance. Need to call abs to handle complex numbers, e.g. (inf + 1j)\n        if math.isinf(abs(self.expected)):\n            return str(self.expected)\n\n        # If a sensible tolerance can't be calculated, self.tolerance will\n        # raise a ValueError.  In this case, display '???'.\n        try:\n            vetted_tolerance = \"{:.1e}\".format(self.tolerance)\n            if isinstance(self.expected, complex) and not math.isinf(self.tolerance):\n                vetted_tolerance += \" \u2220 \u00b1180\u00b0\"\n        except ValueError:\n            vetted_tolerance = \"???\"\n\n        return \"{} \u00b1 {}\".format(self.expected, vetted_tolerance)\n\n    def __eq__(self, actual):\n        \"\"\"\n        Return true if the given value is equal to the expected value within\n        the pre-specified tolerance.\n        \"\"\"\n        if _is_numpy_array(actual):\n            # Call ``__eq__()`` manually to prevent infinite-recursion with\n            # numpy<1.13.  See #3748.\n            return all(self.__eq__(a) for a in actual.flat)\n\n        # Short-circuit exact equality.\n        if actual == self.expected:\n            return True\n\n        # Allow the user to control whether NaNs are considered equal to each\n        # other or not.  The abs() calls are for compatibility with complex\n        # numbers.\n        if math.isnan(abs(self.expected)):\n            return self.nan_ok and math.isnan(abs(actual))\n\n        # Infinity shouldn't be approximately equal to anything but itself, but\n        # if there's a relative tolerance, it will be infinite and infinity\n        # will seem approximately equal to everything.  The equal-to-itself\n        # case would have been short circuited above, so here we can just\n        # return false if the expected value is infinite.  The abs() call is\n        # for compatibility with complex numbers.\n        if math.isinf(abs(self.expected)):\n            return False\n\n        # Return true if the two numbers are within the tolerance.\n        return abs(self.expected - actual) <= self.tolerance\n\n    # Ignore type because of https://github.com/python/mypy/issues/4266.\n    __hash__ = None  # type: ignore\n\n    @property\n    def tolerance(self):\n        \"\"\"\n        Return the tolerance for the comparison.  This could be either an\n        absolute tolerance or a relative tolerance, depending on what the user\n        specified or which would be larger.\n        \"\"\"\n\n        def set_default(x, default):\n            return x if x is not None else default\n\n        # Figure out what the absolute tolerance should be.  ``self.abs`` is\n        # either None or a value specified by the user.\n        absolute_tolerance = set_default(self.abs, self.DEFAULT_ABSOLUTE_TOLERANCE)\n\n        if absolute_tolerance < 0:\n            raise ValueError(\n                \"absolute tolerance can't be negative: {}\".format(absolute_tolerance)\n            )\n        if math.isnan(absolute_tolerance):\n            raise ValueError(\"absolute tolerance can't be NaN.\")\n\n        # If the user specified an absolute tolerance but not a relative one,\n        # just return the absolute tolerance.\n        if self.rel is None:\n            if self.abs is not None:\n                return absolute_tolerance\n\n        # Figure out what the relative tolerance should be.  ``self.rel`` is\n        # either None or a value specified by the user.  This is done after\n        # we've made sure the user didn't ask for an absolute tolerance only,\n        # because we don't want to raise errors about the relative tolerance if\n        # we aren't even going to use it.\n        relative_tolerance = set_default(\n            self.rel, self.DEFAULT_RELATIVE_TOLERANCE\n        ) * abs(self.expected)\n\n        if relative_tolerance < 0:\n            raise ValueError(\n                \"relative tolerance can't be negative: {}\".format(absolute_tolerance)\n            )\n        if math.isnan(relative_tolerance):\n            raise ValueError(\"relative tolerance can't be NaN.\")\n\n        # Return the larger of the relative and absolute tolerances.\n        return max(relative_tolerance, absolute_tolerance)\n\n\nclass Ap"}, {"id": "_pytest.python_api.ApproxScalar.DEFAULT_ABSOLUTE_TOLERANCE", "kind": "variable", "range": [220, 4, 220, 38, 6863, 6897], "file_path": "src/_pytest/python_api.py", "content": "DEFAULT_ABSOLUTE_TOLERANCE = 1e-12"}, {"id": "_pytest.python_api.ApproxScalar.DEFAULT_RELATIVE_TOLERANCE", "kind": "variable", "range": [221, 4, 221, 37, 6933, 6966], "file_path": "src/_pytest/python_api.py", "content": "DEFAULT_RELATIVE_TOLERANCE = 1e-6"}, {"id": "_pytest.python_api.ApproxScalar.__repr__", "kind": "function", "range": [223, 4, 243, 65, 7003, 7929], "file_path": "src/_pytest/python_api.py", "content": "def __repr__(self):\n        \"\"\"\n        Return a string communicating both the expected value and the tolerance\n        for the comparison being made, e.g. '1.0 \u00b1 1e-6', '(3+4j) \u00b1 5e-6 \u2220 \u00b1180\u00b0'.\n        \"\"\"\n\n        # Infinities aren't compared using tolerances, so don't show a\n        # tolerance. Need to call abs to handle complex numbers, e.g. (inf + 1j)\n        if math.isinf(abs(self.expected)):\n            return str(self.expected)\n\n        # If a sensible tolerance can't be calculated, self.tolerance will\n        # raise a ValueError.  In this case, display '???'.\n        try:\n            vetted_tolerance = \"{:.1e}\".format(self.tolerance)\n            if isinstance(self.expected, complex) and not math.isinf(self.tolerance):\n                vetted_tolerance += \" \u2220 \u00b1180\u00b0\"\n        except ValueError:\n            vetted_tolerance = \"???\"\n\n        return \"{} \u00b1 {}\".format(self.expected, vetted_tolerance)\n\n    def _"}, {"id": "_pytest.python_api.ApproxScalar.__eq__", "kind": "function", "range": [245, 4, 275, 60, 7935, 9316], "file_path": "src/_pytest/python_api.py", "content": "self, actual):\n        \"\"\"\n        Return true if the given value is equal to the expected value within\n        the pre-specified tolerance.\n        \"\"\"\n        if _is_numpy_array(actual):\n            # Call ``__eq__()`` manually to prevent infinite-recursion with\n            # numpy<1.13.  See #3748.\n            return all(self.__eq__(a) for a in actual.flat)\n\n        # Short-circuit exact equality.\n        if actual == self.expected:\n            return True\n\n        # Allow the user to control whether NaNs are considered equal to each\n        # other or not.  The abs() calls are for compatibility with complex\n        # numbers.\n        if math.isnan(abs(self.expected)):\n            return self.nan_ok and math.isnan(abs(actual))\n\n        # Infinity shouldn't be approximately equal to anything but itself, but\n        # if there's a relative tolerance, it will be infinite and infinity\n        # will seem approximately equal to everything.  The equal-to-itself\n        # case would have been short circuited above, so here we can just\n        # return false if the expected value is infinite.  The abs() call is\n        # for compatibility with complex numbers.\n        if math.isinf(abs(self.expected)):\n            return False\n\n        # Return true if the two numbers are within the tolerance.\n        return abs(self.expected - actual) <= self.tolerance\n\n    # Ign"}, {"id": "_pytest.python_api.ApproxScalar.__hash__", "kind": "variable", "range": [278, 4, 278, 19, 9395, 9410], "file_path": "src/_pytest/python_api.py", "content": "None  # type: i"}, {"id": "_pytest.python_api.ApproxScalar.tolerance", "kind": "function", "range": [280, 4, 325, 58, 9432, 11385], "file_path": "src/_pytest/python_api.py", "content": "   def tolerance(self):\n        \"\"\"\n        Return the tolerance for the comparison.  This could be either an\n        absolute tolerance or a relative tolerance, depending on what the user\n        specified or which would be larger.\n        \"\"\"\n\n        def set_default(x, default):\n            return x if x is not None else default\n\n        # Figure out what the absolute tolerance should be.  ``self.abs`` is\n        # either None or a value specified by the user.\n        absolute_tolerance = set_default(self.abs, self.DEFAULT_ABSOLUTE_TOLERANCE)\n\n        if absolute_tolerance < 0:\n            raise ValueError(\n                \"absolute tolerance can't be negative: {}\".format(absolute_tolerance)\n            )\n        if math.isnan(absolute_tolerance):\n            raise ValueError(\"absolute tolerance can't be NaN.\")\n\n        # If the user specified an absolute tolerance but not a relative one,\n        # just return the absolute tolerance.\n        if self.rel is None:\n            if self.abs is not None:\n                return absolute_tolerance\n\n        # Figure out what the relative tolerance should be.  ``self.rel`` is\n        # either None or a value specified by the user.  This is done after\n        # we've made sure the user didn't ask for an absolute tolerance only,\n        # because we don't want to raise errors about the relative tolerance if\n        # we aren't even going to use it.\n        relative_tolerance = set_default(\n            self.rel, self.DEFAULT_RELATIVE_TOLERANCE\n        ) * abs(self.expected)\n\n        if relative_tolerance < 0:\n            raise ValueError(\n                \"relative tolerance can't be negative: {}\".format(absolute_tolerance)\n            )\n        if math.isnan(relative_tolerance):\n            raise ValueError(\"relative tolerance can't be NaN.\")\n\n        # Return the larger of the relative and absolute tolerances.\n        return max(relative_tolerance, absolute_tolerance)\n\n\nclass Ap"}, {"id": "_pytest.python_api.ApproxDecimal", "kind": "class", "range": [328, 0, 334, 48, 11388, 11613], "file_path": "src/_pytest/python_api.py", "content": "xDecimal(ApproxScalar):\n    \"\"\"\n    Perform approximate comparisons where the expected value is a decimal.\n    \"\"\"\n\n    DEFAULT_ABSOLUTE_TOLERANCE = Decimal(\"1e-12\")\n    DEFAULT_RELATIVE_TOLERANCE = Decimal(\"1e-6\")\n\n\ndef appr"}, {"id": "_pytest.python_api.ApproxDecimal.DEFAULT_ABSOLUTE_TOLERANCE", "kind": "variable", "range": [333, 4, 333, 49, 11519, 11564], "file_path": "src/_pytest/python_api.py", "content": "OLUTE_TOLERANCE = Decimal(\"1e-12\")\n    DEFAUL"}, {"id": "_pytest.python_api.ApproxDecimal.DEFAULT_RELATIVE_TOLERANCE", "kind": "variable", "range": [334, 4, 334, 48, 11569, 11613], "file_path": "src/_pytest/python_api.py", "content": "ATIVE_TOLERANCE = Decimal(\"1e-6\")\n\n\ndef appr"}, {"id": "_pytest.python_api.approx", "kind": "function", "range": [337, 0, 524, 42, 11616, 20178], "file_path": "src/_pytest/python_api.py", "content": "expected, rel=None, abs=None, nan_ok=False):\n    \"\"\"\n    Assert that two numbers (or two sets of numbers) are equal to each other\n    within some tolerance.\n\n    Due to the `intricacies of floating-point arithmetic`__, numbers that we\n    would intuitively expect to be equal are not always so::\n\n        >>> 0.1 + 0.2 == 0.3\n        False\n\n    __ https://docs.python.org/3/tutorial/floatingpoint.html\n\n    This problem is commonly encountered when writing tests, e.g. when making\n    sure that floating-point values are what you expect them to be.  One way to\n    deal with this problem is to assert that two floating-point numbers are\n    equal to within some appropriate tolerance::\n\n        >>> abs((0.1 + 0.2) - 0.3) < 1e-6\n        True\n\n    However, comparisons like this are tedious to write and difficult to\n    understand.  Furthermore, absolute comparisons like the one above are\n    usually discouraged because there's no tolerance that works well for all\n    situations.  ``1e-6`` is good for numbers around ``1``, but too small for\n    very big numbers and too big for very small ones.  It's better to express\n    the tolerance as a fraction of the expected value, but relative comparisons\n    like that are even more difficult to write correctly and concisely.\n\n    The ``approx`` class performs floating-point comparisons using a syntax\n    that's as intuitive as possible::\n\n        >>> from pytest import approx\n        >>> 0.1 + 0.2 == approx(0.3)\n        True\n\n    The same syntax also works for sequences of numbers::\n\n        >>> (0.1 + 0.2, 0.2 + 0.4) == approx((0.3, 0.6))\n        True\n\n    Dictionary *values*::\n\n        >>> {'a': 0.1 + 0.2, 'b': 0.2 + 0.4} == approx({'a': 0.3, 'b': 0.6})\n        True\n\n    ``numpy`` arrays::\n\n        >>> import numpy as np                                                          # doctest: +SKIP\n        >>> np.array([0.1, 0.2]) + np.array([0.2, 0.4]) == approx(np.array([0.3, 0.6])) # doctest: +SKIP\n        True\n\n    And for a ``numpy`` array against a scalar::\n\n        >>> import numpy as np                                         # doctest: +SKIP\n        >>> np.array([0.1, 0.2]) + np.array([0.2, 0.1]) == approx(0.3) # doctest: +SKIP\n        True\n\n    By default, ``approx`` considers numbers within a relative tolerance of\n    ``1e-6`` (i.e. one part in a million) of its expected value to be equal.\n    This treatment would lead to surprising results if the expected value was\n    ``0.0``, because nothing but ``0.0`` itself is relatively close to ``0.0``.\n    To handle this case less surprisingly, ``approx`` also considers numbers\n    within an absolute tolerance of ``1e-12`` of its expected value to be\n    equal.  Infinity and NaN are special cases.  Infinity is only considered\n    equal to itself, regardless of the relative tolerance.  NaN is not\n    considered equal to anything by default, but you can make it be equal to\n    itself by setting the ``nan_ok`` argument to True.  (This is meant to\n    facilitate comparing arrays that use NaN to mean \"no data\".)\n\n    Both the relative and absolute tolerances can be changed by passing\n    arguments to the ``approx`` constructor::\n\n        >>> 1.0001 == approx(1)\n        False\n        >>> 1.0001 == approx(1, rel=1e-3)\n        True\n        >>> 1.0001 == approx(1, abs=1e-3)\n        True\n\n    If you specify ``abs`` but not ``rel``, the comparison will not consider\n    the relative tolerance at all.  In other words, two numbers that are within\n    the default relative tolerance of ``1e-6`` will still be considered unequal\n    if they exceed the specified absolute tolerance.  If you specify both\n    ``abs`` and ``rel``, the numbers will be considered equal if either\n    tolerance is met::\n\n        >>> 1 + 1e-8 == approx(1)\n        True\n        >>> 1 + 1e-8 == approx(1, abs=1e-12)\n        False\n        >>> 1 + 1e-8 == approx(1, rel=1e-6, abs=1e-12)\n        True\n\n    If you're thinking about using ``approx``, then you might want to know how\n    it compares to other good ways of comparing floating-point numbers.  All of\n    these algorithms are based on relative and absolute tolerances and should\n    agree for the most part, but they do have meaningful differences:\n\n    - ``math.isclose(a, b, rel_tol=1e-9, abs_tol=0.0)``:  True if the relative\n      tolerance is met w.r.t. either ``a`` or ``b`` or if the absolute\n      tolerance is met.  Because the relative tolerance is calculated w.r.t.\n      both ``a`` and ``b``, this test is symmetric (i.e.  neither ``a`` nor\n      ``b`` is a \"reference value\").  You have to specify an absolute tolerance\n      if you want to compare to ``0.0`` because there is no tolerance by\n      default.  Only available in python>=3.5.  `More information...`__\n\n      __ https://docs.python.org/3/library/math.html#math.isclose\n\n    - ``numpy.isclose(a, b, rtol=1e-5, atol=1e-8)``: True if the difference\n      between ``a`` and ``b`` is less that the sum of the relative tolerance\n      w.r.t. ``b`` and the absolute tolerance.  Because the relative tolerance\n      is only calculated w.r.t. ``b``, this test is asymmetric and you can\n      think of ``b`` as the reference value.  Support for comparing sequences\n      is provided by ``numpy.allclose``.  `More information...`__\n\n      __ http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.isclose.html\n\n    - ``unittest.TestCase.assertAlmostEqual(a, b)``: True if ``a`` and ``b``\n      are within an absolute tolerance of ``1e-7``.  No relative tolerance is\n      considered and the absolute tolerance cannot be changed, so this function\n      is not appropriate for very large or very small numbers.  Also, it's only\n      available in subclasses of ``unittest.TestCase`` and it's ugly because it\n      doesn't follow PEP8.  `More information...`__\n\n      __ https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertAlmostEqual\n\n    - ``a == pytest.approx(b, rel=1e-6, abs=1e-12)``: True if the relative\n      tolerance is met w.r.t. ``b`` or if the absolute tolerance is met.\n      Because the relative tolerance is only calculated w.r.t. ``b``, this test\n      is asymmetric and you can think of ``b`` as the reference value.  In the\n      special case that you explicitly specify an absolute tolerance but not a\n      relative tolerance, only the absolute tolerance is considered.\n\n    .. warning::\n\n       .. versionchanged:: 3.2\n\n       In order to avoid inconsistent behavior, ``TypeError`` is\n       raised for ``>``, ``>=``, ``<`` and ``<=`` comparisons.\n       The example below illustrates the problem::\n\n           assert approx(0.1) > 0.1 + 1e-10  # calls approx(0.1).__gt__(0.1 + 1e-10)\n           assert 0.1 + 1e-10 > approx(0.1)  # calls approx(0.1).__lt__(0.1 + 1e-10)\n\n       In the second example one expects ``approx(0.1).__le__(0.1 + 1e-10)``\n       to be called. But instead, ``approx(0.1).__lt__(0.1 + 1e-10)`` is used to\n       comparison. This is because the call hierarchy of rich comparisons\n       follows a fixed behavior. `More information...`__\n\n       __ https://docs.python.org/3/reference/datamodel.html#object.__ge__\n    \"\"\"\n\n    # Delegate the comparison to a class that knows how to deal with the type\n    # of the expected value (e.g. int, float, list, dict, numpy.array, etc).\n    #\n    # The primary responsibility of these classes is to implement ``__eq__()``\n    # and ``__repr__()``.  The former is used to actually check if some\n    # \"actual\" value is equivalent to the given expected value within the\n    # allowed tolerance.  The latter is used to show the user the expected\n    # value and tolerance, in the case that a test failed.\n    #\n    # The actual logic for making approximate comparisons can be found in\n    # ApproxScalar, which is used to compare individual numbers.  All of the\n    # other Approx classes eventually delegate to this class.  The ApproxBase\n    # class provides some convenient methods and overloads, but isn't really\n    # essential.\n\n    __tracebackhide__ = True\n\n    if isinstance(expected, Decimal):\n        cls = ApproxDecimal\n    elif isinstance(expected, Number):\n        cls = ApproxScalar\n    elif isinstance(expected, Mapping):\n        cls = ApproxMapping\n    elif _is_numpy_array(expected):\n        cls = ApproxNumpy\n    elif (\n        isinstance(expected, Iterable)\n        and isinstance(expected, Sized)\n        and not isinstance(expected, STRING_TYPES)\n    ):\n        cls = ApproxSequencelike\n    else:\n        raise _non_numeric_type_error(expected, at=None)\n\n    return cls(expected, rel, abs, nan_ok)\n\n\ndef _is_"}, {"id": "_pytest.python_api._is_numpy_array", "kind": "function", "range": [527, 0, 537, 16, 20181, 20491], "file_path": "src/_pytest/python_api.py", "content": "py_array(obj):\n    \"\"\"\n    Return true if the given object is a numpy array.  Make a special effort to\n    avoid importing numpy unless it's really necessary.\n    \"\"\"\n    import sys\n\n    np = sys.modules.get(\"numpy\")\n    if np is not None:\n        return isinstance(obj, np.ndarray)\n    return False\n\n\n# builti"}, {"id": "_pytest.python_api._E", "kind": "variable", "range": [542, 0, 542, 39, 20526, 20565], "file_path": "src/_pytest/python_api.py", "content": "r(\"_E\", bound=BaseException)\n\n\n@overloa"}, {"id": "_pytest.python_api.raises", "kind": "function", "range": [545, 0, 551, 27, 20568, 20766], "file_path": "src/_pytest/python_api.py", "content": "ef raises(\n    expected_exception: Union[\"Type[_E]\", Tuple[\"Type[_E]\", ...]],\n    *,\n    match: \"Optional[Union[str, Pattern]]\" = ...\n) -> \"RaisesContext[_E]\":\n    ...  # pragma: no cover\n\n\n@overloa"}, {"id": "_pytest.python_api.raises", "kind": "function", "range": [554, 0, 561, 27, 20769, 21005], "file_path": "src/_pytest/python_api.py", "content": "# noqa: F811\ndef raises(  # noqa: F811\n    expected_exception: Union[\"Type[_E]\", Tuple[\"Type[_E]\", ...]],\n    func: Callable,\n    *args: Any,\n    **kwargs: Any\n) -> _pytest._code.ExceptionInfo[_E]:\n    ...  # pragma: no cover\n\n\ndef rais"}, {"id": "_pytest.python_api.raises", "kind": "function", "range": [564, 0, 709, 17, 21008, 26868], "file_path": "src/_pytest/python_api.py", "content": "  # noqa: F811\n    expected_exception: Union[\"Type[_E]\", Tuple[\"Type[_E]\", ...]],\n    *args: Any,\n    **kwargs: Any\n) -> Union[\"RaisesContext[_E]\", _pytest._code.ExceptionInfo[_E]]:\n    r\"\"\"\n    Assert that a code block/function call raises ``expected_exception``\n    or raise a failure exception otherwise.\n\n    :kwparam match: if specified, a string containing a regular expression,\n        or a regular expression object, that is tested against the string\n        representation of the exception using ``re.search``. To match a literal\n        string that may contain `special characters`__, the pattern can\n        first be escaped with ``re.escape``.\n\n        (This is only used when ``pytest.raises`` is used as a context manager,\n        and passed through to the function otherwise.\n        When using ``pytest.raises`` as a function, you can use:\n        ``pytest.raises(Exc, func, match=\"passed on\").match(\"my pattern\")``.)\n\n        __ https://docs.python.org/3/library/re.html#regular-expression-syntax\n\n    .. currentmodule:: _pytest._code\n\n    Use ``pytest.raises`` as a context manager, which will capture the exception of the given\n    type::\n\n        >>> with raises(ZeroDivisionError):\n        ...    1/0\n\n    If the code block does not raise the expected exception (``ZeroDivisionError`` in the example\n    above), or no exception at all, the check will fail instead.\n\n    You can also use the keyword argument ``match`` to assert that the\n    exception matches a text or regex::\n\n        >>> with raises(ValueError, match='must be 0 or None'):\n        ...     raise ValueError(\"value must be 0 or None\")\n\n        >>> with raises(ValueError, match=r'must be \\d+$'):\n        ...     raise ValueError(\"value must be 42\")\n\n    The context manager produces an :class:`ExceptionInfo` object which can be used to inspect the\n    details of the captured exception::\n\n        >>> with raises(ValueError) as exc_info:\n        ...     raise ValueError(\"value must be 42\")\n        >>> assert exc_info.type is ValueError\n        >>> assert exc_info.value.args[0] == \"value must be 42\"\n\n    .. note::\n\n       When using ``pytest.raises`` as a context manager, it's worthwhile to\n       note that normal context manager rules apply and that the exception\n       raised *must* be the final line in the scope of the context manager.\n       Lines of code after that, within the scope of the context manager will\n       not be executed. For example::\n\n           >>> value = 15\n           >>> with raises(ValueError) as exc_info:\n           ...     if value > 10:\n           ...         raise ValueError(\"value must be <= 10\")\n           ...     assert exc_info.type is ValueError  # this will not execute\n\n       Instead, the following approach must be taken (note the difference in\n       scope)::\n\n           >>> with raises(ValueError) as exc_info:\n           ...     if value > 10:\n           ...         raise ValueError(\"value must be <= 10\")\n           ...\n           >>> assert exc_info.type is ValueError\n\n    **Using with** ``pytest.mark.parametrize``\n\n    When using :ref:`pytest.mark.parametrize ref`\n    it is possible to parametrize tests such that\n    some runs raise an exception and others do not.\n\n    See :ref:`parametrizing_conditional_raising` for an example.\n\n    **Legacy form**\n\n    It is possible to specify a callable by passing a to-be-called lambda::\n\n        >>> raises(ZeroDivisionError, lambda: 1/0)\n        <ExceptionInfo ...>\n\n    or you can specify an arbitrary callable with arguments::\n\n        >>> def f(x): return 1/x\n        ...\n        >>> raises(ZeroDivisionError, f, 0)\n        <ExceptionInfo ...>\n        >>> raises(ZeroDivisionError, f, x=0)\n        <ExceptionInfo ...>\n\n    The form above is fully supported but discouraged for new code because the\n    context manager form is regarded as more readable and less error-prone.\n\n    .. note::\n        Similar to caught exception objects in Python, explicitly clearing\n        local references to returned ``ExceptionInfo`` objects can\n        help the Python interpreter speed up its garbage collection.\n\n        Clearing those references breaks a reference cycle\n        (``ExceptionInfo`` --> caught exception --> frame stack raising\n        the exception --> current frame stack --> local variables -->\n        ``ExceptionInfo``) which makes Python keep all objects referenced\n        from that cycle (including all local variables in the current\n        frame) alive until the next cyclic garbage collection run.\n        More detailed information can be found in the official Python\n        documentation for :ref:`the try statement <python:try>`.\n    \"\"\"\n    __tracebackhide__ = True\n    for exc in filterfalse(\n        inspect.isclass, always_iterable(expected_exception, BASE_TYPE)\n    ):\n        msg = \"exceptions must be derived from BaseException, not %s\"\n        raise TypeError(msg % type(exc))\n\n    message = \"DID NOT RAISE {}\".format(expected_exception)\n\n    if not args:\n        match = kwargs.pop(\"match\", None)\n        if kwargs:\n            msg = \"Unexpected keyword arguments passed to pytest.raises: \"\n            msg += \", \".join(sorted(kwargs))\n            msg += \"\\nUse context-manager form instead?\"\n            raise TypeError(msg)\n        return RaisesContext(expected_exception, message, match)\n    else:\n        func = args[0]\n        if not callable(func):\n            raise TypeError(\n                \"{!r} object (type: {}) must be callable\".format(func, type(func))\n            )\n        try:\n            func(*args[1:], **kwargs)\n        except expected_exception as e:\n            # We just caught the exception - there is a traceback.\n            assert e.__traceback__ is not None\n            return _pytest._code.ExceptionInfo.from_exc_info(\n                (type(e), e, e.__traceback__)\n            )\n    fail(message)\n\n\nraises.E"}, {"id": "_pytest.python_api.RaisesContext", "kind": "class", "range": [715, 0, 750, 19, 26923, 28244], "file_path": "src/_pytest/python_api.py", "content": "sContext(Generic[_E]):\n    def __init__(\n        self,\n        expected_exception: Union[\"Type[_E]\", Tuple[\"Type[_E]\", ...]],\n        message: str,\n        match_expr: Optional[Union[str, \"Pattern\"]] = None,\n    ) -> None:\n        self.expected_exception = expected_exception\n        self.message = message\n        self.match_expr = match_expr\n        self.excinfo = None  # type: Optional[_pytest._code.ExceptionInfo[_E]]\n\n    def __enter__(self) -> _pytest._code.ExceptionInfo[_E]:\n        self.excinfo = _pytest._code.ExceptionInfo.for_later()\n        return self.excinfo\n\n    def __exit__(\n        self,\n        exc_type: Optional[\"Type[BaseException]\"],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> bool:\n        __tracebackhide__ = True\n        if exc_type is None:\n            fail(self.message)\n        assert self.excinfo is not None\n        if not issubclass(exc_type, self.expected_exception):\n            return False\n        # Cast to narrow the exception type now that it's verified.\n        exc_info = cast(\n            Tuple[\"Type[_E]\", _E, TracebackType], (exc_type, exc_val, exc_tb)\n        )\n        self.excinfo.fill_unfilled(exc_info)\n        if self.match_expr is not None:\n            self.excinfo.match(self.match_expr)\n        return True\n"}, {"id": "_pytest.python_api.RaisesContext.__init__", "kind": "function", "range": [716, 4, 725, 78, 26961, 27356], "file_path": "src/_pytest/python_api.py", "content": "_(\n        self,\n        expected_exception: Union[\"Type[_E]\", Tuple[\"Type[_E]\", ...]],\n        message: str,\n        match_expr: Optional[Union[str, \"Pattern\"]] = None,\n    ) -> None:\n        self.expected_exception = expected_exception\n        self.message = message\n        self.match_expr = match_expr\n        self.excinfo = None  # type: Optional[_pytest._code.ExceptionInfo[_E]]\n\n    def _"}, {"id": "_pytest.python_api.RaisesContext.__enter__", "kind": "function", "range": [727, 4, 729, 27, 27362, 27508], "file_path": "src/_pytest/python_api.py", "content": "__(self) -> _pytest._code.ExceptionInfo[_E]:\n        self.excinfo = _pytest._code.ExceptionInfo.for_later()\n        return self.excinfo\n\n    def _"}, {"id": "_pytest.python_api.RaisesContext.__exit__", "kind": "function", "range": [731, 4, 750, 19, 27514, 28244], "file_path": "src/_pytest/python_api.py", "content": "_(\n        self,\n        exc_type: Optional[\"Type[BaseException]\"],\n        exc_val: Optional[BaseException],\n        exc_tb: Optional[TracebackType],\n    ) -> bool:\n        __tracebackhide__ = True\n        if exc_type is None:\n            fail(self.message)\n        assert self.excinfo is not None\n        if not issubclass(exc_type, self.expected_exception):\n            return False\n        # Cast to narrow the exception type now that it's verified.\n        exc_info = cast(\n            Tuple[\"Type[_E]\", _E, TracebackType], (exc_type, exc_val, exc_tb)\n        )\n        self.excinfo.fill_unfilled(exc_info)\n        if self.match_expr is not None:\n            self.excinfo.match(self.match_expr)\n        return True\n"}, {"id": "_pytest._argcomplete.FastFilesCompleter", "kind": "class", "range": [64, 0, 89, 25, 2404, 3376], "file_path": "src/_pytest/_argcomplete.py", "content": "class FastFilesCompleter:\n    \"Fast file completer class\"\n\n    def __init__(self, directories: bool = True) -> None:\n        self.directories = directories\n\n    def __call__(self, prefix: str, **kwargs: Any) -> List[str]:\n        \"\"\"only called on non option completions\"\"\"\n        if os.path.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.path.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # we are on unix, otherwise no bash\n            if not prefix or prefix[-1] == os.path.sep:\n                globbed.extend(glob(prefix + \".*\"))\n            prefix += \"*\"\n        globbed.extend(glob(prefix))\n        for x in sorted(globbed):\n            if os.path.isdir(x):\n                x += \"/\"\n            # append stripping the prefix (like bash, not like compgen)\n            completion.append(x[prefix_dir:])\n        return completion"}, {"id": "_pytest._argcomplete.FastFilesCompleter.__init__", "kind": "function", "range": [67, 4, 68, 38, 2467, 2559], "file_path": "src/_pytest/_argcomplete.py", "content": "def __init__(self, directories: bool = True) -> None:\n        self.directories = directories"}, {"id": "_pytest._argcomplete.FastFilesCompleter.__call__", "kind": "function", "range": [70, 4, 89, 25, 2565, 3376], "file_path": "src/_pytest/_argcomplete.py", "content": "def __call__(self, prefix: str, **kwargs: Any) -> List[str]:\n        \"\"\"only called on non option completions\"\"\"\n        if os.path.sep in prefix[1:]:\n            prefix_dir = len(os.path.dirname(prefix) + os.path.sep)\n        else:\n            prefix_dir = 0\n        completion = []\n        globbed = []\n        if \"*\" not in prefix and \"?\" not in prefix:\n            # we are on unix, otherwise no bash\n            if not prefix or prefix[-1] == os.path.sep:\n                globbed.extend(glob(prefix + \".*\"))\n            prefix += \"*\"\n        globbed.extend(glob(prefix))\n        for x in sorted(globbed):\n            if os.path.isdir(x):\n                x += \"/\"\n            # append stripping the prefix (like bash, not like compgen)\n            completion.append(x[prefix_dir:])\n        return completion"}, {"id": "_pytest.capture.patchsysdict", "kind": "variable", "range": [25, 0, 25, 53, 531, 584], "file_path": "src/_pytest/capture.py", "content": "patchsysdict = {0: \"stdin\", 1: \"stdout\", 2: \"stderr\"}"}, {"id": "_pytest.capture.pytest_addoption", "kind": "function", "range": [28, 0, 44, 5, 587, 1052], "file_path": "src/_pytest/capture.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group._addoption(\n        \"--capture\",\n        action=\"store\",\n        default=\"fd\",\n        metavar=\"method\",\n        choices=[\"fd\", \"sys\", \"no\", \"tee-sys\"],\n        help=\"per-test capturing method: one of fd|sys|no|tee-sys.\",\n    )\n    group._addoption(\n        \"-s\",\n        action=\"store_const\",\n        const=\"no\",\n        dest=\"capture\",\n        help=\"shortcut for --capture=no.\",\n    )"}, {"id": "_pytest.capture.pytest_load_initial_conftests", "kind": "function", "range": [47, 0, 68, 29, 1055, 1902], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(hookwrapper=True)\ndef pytest_load_initial_conftests(early_config: Config):\n    ns = early_config.known_args_namespace\n    if ns.capture == \"fd\":\n        _py36_windowsconsoleio_workaround(sys.stdout)\n    _colorama_workaround()\n    _readline_workaround()\n    pluginmanager = early_config.pluginmanager\n    capman = CaptureManager(ns.capture)\n    pluginmanager.register(capman, \"capturemanager\")\n\n    # make sure that capturemanager is properly reset at final shutdown\n    early_config.add_cleanup(capman.stop_global_capturing)\n\n    # finally trigger conftest loading but while capturing (issue93)\n    capman.start_global_capturing()\n    outcome = yield\n    capman.suspend_global_capture()\n    if outcome.excinfo is not None:\n        out, err = capman.read_global_capture()\n        sys.stdout.write(out)\n        sys.stderr.write(err)"}, {"id": "_pytest.capture._get_multicapture", "kind": "function", "range": [71, 0, 80, 69, 1905, 2423], "file_path": "src/_pytest/capture.py", "content": "def _get_multicapture(method: \"_CaptureMethod\") -> \"MultiCapture\":\n    if method == \"fd\":\n        return MultiCapture(out=True, err=True, Capture=FDCapture)\n    elif method == \"sys\":\n        return MultiCapture(out=True, err=True, Capture=SysCapture)\n    elif method == \"no\":\n        return MultiCapture(out=False, err=False, in_=False)\n    elif method == \"tee-sys\":\n        return MultiCapture(out=True, err=True, in_=False, Capture=TeeSysCapture)\n    raise ValueError(\"unknown capturing method: {!r}\".format(method))"}, {"id": "_pytest.capture.CaptureManager", "kind": "class", "range": [83, 0, 266, 36, 2426, 8966], "file_path": "src/_pytest/capture.py", "content": "class CaptureManager:\n    \"\"\"\n    Capture plugin, manages that the appropriate capture method is enabled/disabled during collection and each\n    test phase (setup, call, teardown). After each of those points, the captured output is obtained and\n    attached to the collection/runtest report.\n\n    There are two levels of capture:\n    * global: which is enabled by default and can be suppressed by the ``-s`` option. This is always enabled/disabled\n      during collection and each test phase.\n    * fixture: when a test function or one of its fixture depend on the ``capsys`` or ``capfd`` fixtures. In this\n      case special handling is needed to ensure the fixtures take precedence over the global capture.\n    \"\"\"\n\n    def __init__(self, method: \"_CaptureMethod\") -> None:\n        self._method = method\n        self._global_capturing = None\n        self._capture_fixture = None  # type: Optional[CaptureFixture]\n\n    def __repr__(self):\n        return \"<CaptureManager _method={!r} _global_capturing={!r} _capture_fixture={!r}>\".format(\n            self._method, self._global_capturing, self._capture_fixture\n        )\n\n    def is_capturing(self):\n        if self.is_globally_capturing():\n            return \"global\"\n        if self._capture_fixture:\n            return \"fixture %s\" % self._capture_fixture.request.fixturename\n        return False\n\n    # Global capturing control\n\n    def is_globally_capturing(self):\n        return self._method != \"no\"\n\n    def start_global_capturing(self):\n        assert self._global_capturing is None\n        self._global_capturing = _get_multicapture(self._method)\n        self._global_capturing.start_capturing()\n\n    def stop_global_capturing(self):\n        if self._global_capturing is not None:\n            self._global_capturing.pop_outerr_to_orig()\n            self._global_capturing.stop_capturing()\n            self._global_capturing = None\n\n    def resume_global_capture(self):\n        # During teardown of the python process, and on rare occasions, capture\n        # attributes can be `None` while trying to resume global capture.\n        if self._global_capturing is not None:\n            self._global_capturing.resume_capturing()\n\n    def suspend_global_capture(self, in_=False):\n        cap = getattr(self, \"_global_capturing\", None)\n        if cap is not None:\n            cap.suspend_capturing(in_=in_)\n\n    def suspend(self, in_=False):\n        # Need to undo local capsys-et-al if it exists before disabling global capture.\n        self.suspend_fixture()\n        self.suspend_global_capture(in_)\n\n    def resume(self):\n        self.resume_global_capture()\n        self.resume_fixture()\n\n    def read_global_capture(self):\n        return self._global_capturing.readouterr()\n\n    # Fixture Control (it's just forwarding, think about removing this later)\n\n    @contextlib.contextmanager\n    def _capturing_for_request(\n        self, request: FixtureRequest\n    ) -> Generator[\"CaptureFixture\", None, None]:\n        \"\"\"\n        Context manager that creates a ``CaptureFixture`` instance for the\n        given ``request``, ensuring there is only a single one being requested\n        at the same time.\n\n        This is used as a helper with ``capsys``, ``capfd`` etc.\n        \"\"\"\n        if self._capture_fixture:\n            other_name = next(\n                k\n                for k, v in map_fixname_class.items()\n                if v is self._capture_fixture.captureclass\n            )\n            raise request.raiseerror(\n                \"cannot use {} and {} at the same time\".format(\n                    request.fixturename, other_name\n                )\n            )\n        capture_class = map_fixname_class[request.fixturename]\n        self._capture_fixture = CaptureFixture(capture_class, request)\n        self.activate_fixture()\n        yield self._capture_fixture\n        self._capture_fixture.close()\n        self._capture_fixture = None\n\n    def activate_fixture(self):\n        \"\"\"If the current item is using ``capsys`` or ``capfd``, activate them so they take precedence over\n        the global capture.\n        \"\"\"\n        if self._capture_fixture:\n            self._capture_fixture._start()\n\n    def deactivate_fixture(self):\n        \"\"\"Deactivates the ``capsys`` or ``capfd`` fixture of this item, if any.\"\"\"\n        if self._capture_fixture:\n            self._capture_fixture.close()\n\n    def suspend_fixture(self):\n        if self._capture_fixture:\n            self._capture_fixture._suspend()\n\n    def resume_fixture(self):\n        if self._capture_fixture:\n            self._capture_fixture._resume()\n\n    # Helper context managers\n\n    @contextlib.contextmanager\n    def global_and_fixture_disabled(self):\n        \"\"\"Context manager to temporarily disable global and current fixture capturing.\"\"\"\n        self.suspend()\n        try:\n            yield\n        finally:\n            self.resume()\n\n    @contextlib.contextmanager\n    def item_capture(self, when, item):\n        self.resume_global_capture()\n        self.activate_fixture()\n        try:\n            yield\n        finally:\n            self.deactivate_fixture()\n            self.suspend_global_capture(in_=False)\n\n        out, err = self.read_global_capture()\n        item.add_report_section(when, \"stdout\", out)\n        item.add_report_section(when, \"stderr\", err)\n\n    # Hooks\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_make_collect_report(self, collector):\n        if isinstance(collector, pytest.File):\n            self.resume_global_capture()\n            outcome = yield\n            self.suspend_global_capture()\n            out, err = self.read_global_capture()\n            rep = outcome.get_result()\n            if out:\n                rep.sections.append((\"Captured stdout\", out))\n            if err:\n                rep.sections.append((\"Captured stderr\", err))\n        else:\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_setup(self, item):\n        with self.item_capture(\"setup\", item):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_call(self, item):\n        with self.item_capture(\"call\", item):\n            yield\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_teardown(self, item):\n        with self.item_capture(\"teardown\", item):\n            yield\n\n    @pytest.hookimpl(tryfirst=True)\n    def pytest_keyboard_interrupt(self, excinfo):\n        self.stop_global_capturing()\n\n    @pytest.hookimpl(tryfirst=True)\n    def pytest_internalerror(self, excinfo):\n        self.stop_global_capturing()"}, {"id": "_pytest.capture.CaptureManager.__init__", "kind": "function", "range": [96, 4, 99, 70, 3148, 3340], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, method: \"_CaptureMethod\") -> None:\n        self._method = method\n        self._global_capturing = None\n        self._capture_fixture = None  # type: Optional[CaptureFixture]"}, {"id": "_pytest.capture.CaptureManager.__repr__", "kind": "function", "range": [101, 4, 104, 9, 3346, 3547], "file_path": "src/_pytest/capture.py", "content": "def __repr__(self):\n        return \"<CaptureManager _method={!r} _global_capturing={!r} _capture_fixture={!r}>\".format(\n            self._method, self._global_capturing, self._capture_fixture\n        )"}, {"id": "_pytest.capture.CaptureManager.is_capturing", "kind": "function", "range": [106, 4, 111, 20, 3553, 3776], "file_path": "src/_pytest/capture.py", "content": "def is_capturing(self):\n        if self.is_globally_capturing():\n            return \"global\"\n        if self._capture_fixture:\n            return \"fixture %s\" % self._capture_fixture.request.fixturename\n        return False"}, {"id": "_pytest.capture.CaptureManager.is_globally_capturing", "kind": "function", "range": [115, 4, 116, 35, 3814, 3882], "file_path": "src/_pytest/capture.py", "content": "def is_globally_capturing(self):\n        return self._method != \"no\""}, {"id": "_pytest.capture.CaptureManager.start_global_capturing", "kind": "function", "range": [118, 4, 121, 48, 3888, 4081], "file_path": "src/_pytest/capture.py", "content": "def start_global_capturing(self):\n        assert self._global_capturing is None\n        self._global_capturing = _get_multicapture(self._method)\n        self._global_capturing.start_capturing()"}, {"id": "_pytest.capture.CaptureManager.stop_global_capturing", "kind": "function", "range": [123, 4, 127, 41, 4087, 4316], "file_path": "src/_pytest/capture.py", "content": "def stop_global_capturing(self):\n        if self._global_capturing is not None:\n            self._global_capturing.pop_outerr_to_orig()\n            self._global_capturing.stop_capturing()\n            self._global_capturing = None"}, {"id": "_pytest.capture.CaptureManager.resume_global_capture", "kind": "function", "range": [129, 4, 133, 53, 4322, 4609], "file_path": "src/_pytest/capture.py", "content": "def resume_global_capture(self):\n        # During teardown of the python process, and on rare occasions, capture\n        # attributes can be `None` while trying to resume global capture.\n        if self._global_capturing is not None:\n            self._global_capturing.resume_capturing()"}, {"id": "_pytest.capture.CaptureManager.suspend_global_capture", "kind": "function", "range": [135, 4, 138, 42, 4615, 4785], "file_path": "src/_pytest/capture.py", "content": "def suspend_global_capture(self, in_=False):\n        cap = getattr(self, \"_global_capturing\", None)\n        if cap is not None:\n            cap.suspend_capturing(in_=in_)"}, {"id": "_pytest.capture.CaptureManager.suspend", "kind": "function", "range": [140, 4, 143, 40, 4791, 4980], "file_path": "src/_pytest/capture.py", "content": "def suspend(self, in_=False):\n        # Need to undo local capsys-et-al if it exists before disabling global capture.\n        self.suspend_fixture()\n        self.suspend_global_capture(in_)"}, {"id": "_pytest.capture.CaptureManager.resume", "kind": "function", "range": [145, 4, 147, 29, 4986, 5070], "file_path": "src/_pytest/capture.py", "content": "def resume(self):\n        self.resume_global_capture()\n        self.resume_fixture()"}, {"id": "_pytest.capture.CaptureManager.read_global_capture", "kind": "function", "range": [149, 4, 150, 50, 5076, 5157], "file_path": "src/_pytest/capture.py", "content": "def read_global_capture(self):\n        return self._global_capturing.readouterr()"}, {"id": "_pytest.capture.CaptureManager._capturing_for_request", "kind": "function", "range": [154, 4, 181, 36, 5242, 6331], "file_path": "src/_pytest/capture.py", "content": "@contextlib.contextmanager\n    def _capturing_for_request(\n        self, request: FixtureRequest\n    ) -> Generator[\"CaptureFixture\", None, None]:\n        \"\"\"\n        Context manager that creates a ``CaptureFixture`` instance for the\n        given ``request``, ensuring there is only a single one being requested\n        at the same time.\n\n        This is used as a helper with ``capsys``, ``capfd`` etc.\n        \"\"\"\n        if self._capture_fixture:\n            other_name = next(\n                k\n                for k, v in map_fixname_class.items()\n                if v is self._capture_fixture.captureclass\n            )\n            raise request.raiseerror(\n                \"cannot use {} and {} at the same time\".format(\n                    request.fixturename, other_name\n                )\n            )\n        capture_class = map_fixname_class[request.fixturename]\n        self._capture_fixture = CaptureFixture(capture_class, request)\n        self.activate_fixture()\n        yield self._capture_fixture\n        self._capture_fixture.close()\n        self._capture_fixture = None"}, {"id": "_pytest.capture.CaptureManager.activate_fixture", "kind": "function", "range": [183, 4, 188, 42, 6337, 6589], "file_path": "src/_pytest/capture.py", "content": "def activate_fixture(self):\n        \"\"\"If the current item is using ``capsys`` or ``capfd``, activate them so they take precedence over\n        the global capture.\n        \"\"\"\n        if self._capture_fixture:\n            self._capture_fixture._start()"}, {"id": "_pytest.capture.CaptureManager.deactivate_fixture", "kind": "function", "range": [190, 4, 193, 41, 6595, 6784], "file_path": "src/_pytest/capture.py", "content": "def deactivate_fixture(self):\n        \"\"\"Deactivates the ``capsys`` or ``capfd`` fixture of this item, if any.\"\"\"\n        if self._capture_fixture:\n            self._capture_fixture.close()"}, {"id": "_pytest.capture.CaptureManager.suspend_fixture", "kind": "function", "range": [195, 4, 197, 44, 6790, 6895], "file_path": "src/_pytest/capture.py", "content": "def suspend_fixture(self):\n        if self._capture_fixture:\n            self._capture_fixture._suspend()"}, {"id": "_pytest.capture.CaptureManager.resume_fixture", "kind": "function", "range": [199, 4, 201, 43, 6901, 7004], "file_path": "src/_pytest/capture.py", "content": "def resume_fixture(self):\n        if self._capture_fixture:\n            self._capture_fixture._resume()"}, {"id": "_pytest.capture.CaptureManager.global_and_fixture_disabled", "kind": "function", "range": [205, 4, 212, 25, 7041, 7298], "file_path": "src/_pytest/capture.py", "content": "@contextlib.contextmanager\n    def global_and_fixture_disabled(self):\n        \"\"\"Context manager to temporarily disable global and current fixture capturing.\"\"\"\n        self.suspend()\n        try:\n            yield\n        finally:\n            self.resume()"}, {"id": "_pytest.capture.CaptureManager.item_capture", "kind": "function", "range": [214, 4, 226, 52, 7304, 7729], "file_path": "src/_pytest/capture.py", "content": "@contextlib.contextmanager\n    def item_capture(self, when, item):\n        self.resume_global_capture()\n        self.activate_fixture()\n        try:\n            yield\n        finally:\n            self.deactivate_fixture()\n            self.suspend_global_capture(in_=False)\n\n        out, err = self.read_global_capture()\n        item.add_report_section(when, \"stdout\", out)\n        item.add_report_section(when, \"stderr\", err)"}, {"id": "_pytest.capture.CaptureManager.pytest_make_collect_report", "kind": "function", "range": [230, 4, 243, 17, 7748, 8278], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_make_collect_report(self, collector):\n        if isinstance(collector, pytest.File):\n            self.resume_global_capture()\n            outcome = yield\n            self.suspend_global_capture()\n            out, err = self.read_global_capture()\n            rep = outcome.get_result()\n            if out:\n                rep.sections.append((\"Captured stdout\", out))\n            if err:\n                rep.sections.append((\"Captured stderr\", err))\n        else:\n            yield"}, {"id": "_pytest.capture.CaptureManager.pytest_runtest_setup", "kind": "function", "range": [245, 4, 248, 17, 8284, 8425], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_setup(self, item):\n        with self.item_capture(\"setup\", item):\n            yield"}, {"id": "_pytest.capture.CaptureManager.pytest_runtest_call", "kind": "function", "range": [250, 4, 253, 17, 8431, 8570], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_call(self, item):\n        with self.item_capture(\"call\", item):\n            yield"}, {"id": "_pytest.capture.CaptureManager.pytest_runtest_teardown", "kind": "function", "range": [255, 4, 258, 17, 8576, 8723], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_runtest_teardown(self, item):\n        with self.item_capture(\"teardown\", item):\n            yield"}, {"id": "_pytest.capture.CaptureManager.pytest_keyboard_interrupt", "kind": "function", "range": [260, 4, 262, 36, 8729, 8847], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(tryfirst=True)\n    def pytest_keyboard_interrupt(self, excinfo):\n        self.stop_global_capturing()"}, {"id": "_pytest.capture.CaptureManager.pytest_internalerror", "kind": "function", "range": [264, 4, 266, 36, 8853, 8966], "file_path": "src/_pytest/capture.py", "content": "@pytest.hookimpl(tryfirst=True)\n    def pytest_internalerror(self, excinfo):\n        self.stop_global_capturing()"}, {"id": "_pytest.capture.capsys", "kind": "function", "range": [269, 0, 279, 21, 8969, 9423], "file_path": "src/_pytest/capture.py", "content": "@pytest.fixture\ndef capsys(request):\n    \"\"\"Enable text capturing of writes to ``sys.stdout`` and ``sys.stderr``.\n\n    The captured output is made available via ``capsys.readouterr()`` method\n    calls, which return a ``(out, err)`` namedtuple.\n    ``out`` and ``err`` will be ``text`` objects.\n    \"\"\"\n    capman = request.config.pluginmanager.getplugin(\"capturemanager\")\n    with capman._capturing_for_request(request) as fixture:\n        yield fixture"}, {"id": "_pytest.capture.capsysbinary", "kind": "function", "range": [282, 0, 292, 21, 9426, 9894], "file_path": "src/_pytest/capture.py", "content": "@pytest.fixture\ndef capsysbinary(request):\n    \"\"\"Enable bytes capturing of writes to ``sys.stdout`` and ``sys.stderr``.\n\n    The captured output is made available via ``capsysbinary.readouterr()``\n    method calls, which return a ``(out, err)`` namedtuple.\n    ``out`` and ``err`` will be ``bytes`` objects.\n    \"\"\"\n    capman = request.config.pluginmanager.getplugin(\"capturemanager\")\n    with capman._capturing_for_request(request) as fixture:\n        yield fixture"}, {"id": "_pytest.capture.capfd", "kind": "function", "range": [295, 0, 305, 21, 9897, 10348], "file_path": "src/_pytest/capture.py", "content": "@pytest.fixture\ndef capfd(request):\n    \"\"\"Enable text capturing of writes to file descriptors ``1`` and ``2``.\n\n    The captured output is made available via ``capfd.readouterr()`` method\n    calls, which return a ``(out, err)`` namedtuple.\n    ``out`` and ``err`` will be ``text`` objects.\n    \"\"\"\n    capman = request.config.pluginmanager.getplugin(\"capturemanager\")\n    with capman._capturing_for_request(request) as fixture:\n        yield fixture"}, {"id": "_pytest.capture.capfdbinary", "kind": "function", "range": [308, 0, 318, 21, 10351, 10809], "file_path": "src/_pytest/capture.py", "content": "@pytest.fixture\ndef capfdbinary(request):\n    \"\"\"Enable bytes capturing of writes to file descriptors ``1`` and ``2``.\n\n    The captured output is made available via ``capfd.readouterr()`` method\n    calls, which return a ``(out, err)`` namedtuple.\n    ``out`` and ``err`` will be ``byte`` objects.\n    \"\"\"\n    capman = request.config.pluginmanager.getplugin(\"capturemanager\")\n    with capman._capturing_for_request(request) as fixture:\n        yield fixture"}, {"id": "_pytest.capture.CaptureIO", "kind": "class", "range": [321, 0, 327, 53, 10812, 11104], "file_path": "src/_pytest/capture.py", "content": "class CaptureIO(io.TextIOWrapper):\n    def __init__(self) -> None:\n        super().__init__(io.BytesIO(), encoding=\"UTF-8\", newline=\"\", write_through=True)\n\n    def getvalue(self) -> str:\n        assert isinstance(self.buffer, io.BytesIO)\n        return self.buffer.getvalue().decode(\"UTF-8\")"}, {"id": "_pytest.capture.CaptureIO.__init__", "kind": "function", "range": [322, 4, 323, 88, 10851, 10967], "file_path": "src/_pytest/capture.py", "content": "def __init__(self) -> None:\n        super().__init__(io.BytesIO(), encoding=\"UTF-8\", newline=\"\", write_through=True)"}, {"id": "_pytest.capture.CaptureIO.getvalue", "kind": "function", "range": [325, 4, 327, 53, 10973, 11104], "file_path": "src/_pytest/capture.py", "content": "def getvalue(self) -> str:\n        assert isinstance(self.buffer, io.BytesIO)\n        return self.buffer.getvalue().decode(\"UTF-8\")"}, {"id": "_pytest.capture.TeeCaptureIO", "kind": "class", "range": [330, 0, 337, 35, 11107, 11337], "file_path": "src/_pytest/capture.py", "content": "class TeeCaptureIO(CaptureIO):\n    def __init__(self, other: TextIO) -> None:\n        self._other = other\n        super().__init__()\n\n    def write(self, s: str) -> int:\n        super().write(s)\n        return self._other.write(s)"}, {"id": "_pytest.capture.TeeCaptureIO.__init__", "kind": "function", "range": [331, 4, 333, 26, 11142, 11239], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, other: TextIO) -> None:\n        self._other = other\n        super().__init__()"}, {"id": "_pytest.capture.TeeCaptureIO.write", "kind": "function", "range": [335, 4, 337, 35, 11245, 11337], "file_path": "src/_pytest/capture.py", "content": "def write(self, s: str) -> int:\n        super().write(s)\n        return self._other.write(s)"}, {"id": "_pytest.capture.CaptureFixture", "kind": "class", "range": [340, 0, 397, 17, 11340, 13526], "file_path": "src/_pytest/capture.py", "content": "class CaptureFixture:\n    \"\"\"\n    Object returned by :py:func:`capsys`, :py:func:`capsysbinary`, :py:func:`capfd` and :py:func:`capfdbinary`\n    fixtures.\n    \"\"\"\n\n    def __init__(self, captureclass, request):\n        self.captureclass = captureclass\n        self.request = request\n        self._capture = None\n        self._captured_out = self.captureclass.EMPTY_BUFFER\n        self._captured_err = self.captureclass.EMPTY_BUFFER\n\n    def _start(self):\n        if self._capture is None:\n            self._capture = MultiCapture(\n                out=True, err=True, in_=False, Capture=self.captureclass\n            )\n            self._capture.start_capturing()\n\n    def close(self):\n        if self._capture is not None:\n            out, err = self._capture.pop_outerr_to_orig()\n            self._captured_out += out\n            self._captured_err += err\n            self._capture.stop_capturing()\n            self._capture = None\n\n    def readouterr(self):\n        \"\"\"Read and return the captured output so far, resetting the internal buffer.\n\n        :return: captured content as a namedtuple with ``out`` and ``err`` string attributes\n        \"\"\"\n        captured_out, captured_err = self._captured_out, self._captured_err\n        if self._capture is not None:\n            out, err = self._capture.readouterr()\n            captured_out += out\n            captured_err += err\n        self._captured_out = self.captureclass.EMPTY_BUFFER\n        self._captured_err = self.captureclass.EMPTY_BUFFER\n        return CaptureResult(captured_out, captured_err)\n\n    def _suspend(self):\n        \"\"\"Suspends this fixture's own capturing temporarily.\"\"\"\n        if self._capture is not None:\n            self._capture.suspend_capturing()\n\n    def _resume(self):\n        \"\"\"Resumes this fixture's own capturing temporarily.\"\"\"\n        if self._capture is not None:\n            self._capture.resume_capturing()\n\n    @contextlib.contextmanager\n    def disabled(self):\n        \"\"\"Temporarily disables capture while inside the 'with' block.\"\"\"\n        capmanager = self.request.config.pluginmanager.getplugin(\"capturemanager\")\n        with capmanager.global_and_fixture_disabled():\n            yield"}, {"id": "_pytest.capture.CaptureFixture.__init__", "kind": "function", "range": [346, 4, 351, 59, 11508, 11771], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, captureclass, request):\n        self.captureclass = captureclass\n        self.request = request\n        self._capture = None\n        self._captured_out = self.captureclass.EMPTY_BUFFER\n        self._captured_err = self.captureclass.EMPTY_BUFFER"}, {"id": "_pytest.capture.CaptureFixture._start", "kind": "function", "range": [353, 4, 358, 43, 11777, 12001], "file_path": "src/_pytest/capture.py", "content": "def _start(self):\n        if self._capture is None:\n            self._capture = MultiCapture(\n                out=True, err=True, in_=False, Capture=self.captureclass\n            )\n            self._capture.start_capturing()"}, {"id": "_pytest.capture.CaptureFixture.close", "kind": "function", "range": [360, 4, 366, 32, 12007, 12271], "file_path": "src/_pytest/capture.py", "content": "def close(self):\n        if self._capture is not None:\n            out, err = self._capture.pop_outerr_to_orig()\n            self._captured_out += out\n            self._captured_err += err\n            self._capture.stop_capturing()\n            self._capture = None"}, {"id": "_pytest.capture.CaptureFixture.readouterr", "kind": "function", "range": [368, 4, 380, 56, 12277, 12895], "file_path": "src/_pytest/capture.py", "content": "def readouterr(self):\n        \"\"\"Read and return the captured output so far, resetting the internal buffer.\n\n        :return: captured content as a namedtuple with ``out`` and ``err`` string attributes\n        \"\"\"\n        captured_out, captured_err = self._captured_out, self._captured_err\n        if self._capture is not None:\n            out, err = self._capture.readouterr()\n            captured_out += out\n            captured_err += err\n        self._captured_out = self.captureclass.EMPTY_BUFFER\n        self._captured_err = self.captureclass.EMPTY_BUFFER\n        return CaptureResult(captured_out, captured_err)"}, {"id": "_pytest.capture.CaptureFixture._suspend", "kind": "function", "range": [382, 4, 385, 45, 12901, 13069], "file_path": "src/_pytest/capture.py", "content": "def _suspend(self):\n        \"\"\"Suspends this fixture's own capturing temporarily.\"\"\"\n        if self._capture is not None:\n            self._capture.suspend_capturing()"}, {"id": "_pytest.capture.CaptureFixture._resume", "kind": "function", "range": [387, 4, 390, 44, 13075, 13240], "file_path": "src/_pytest/capture.py", "content": "def _resume(self):\n        \"\"\"Resumes this fixture's own capturing temporarily.\"\"\"\n        if self._capture is not None:\n            self._capture.resume_capturing()"}, {"id": "_pytest.capture.CaptureFixture.disabled", "kind": "function", "range": [392, 4, 397, 17, 13246, 13526], "file_path": "src/_pytest/capture.py", "content": "@contextlib.contextmanager\n    def disabled(self):\n        \"\"\"Temporarily disables capture while inside the 'with' block.\"\"\"\n        capmanager = self.request.config.pluginmanager.getplugin(\"capturemanager\")\n        with capmanager.global_and_fixture_disabled():\n            yield"}, {"id": "_pytest.capture.EncodedFile", "kind": "class", "range": [400, 0, 413, 48, 13529, 13984], "file_path": "src/_pytest/capture.py", "content": "class EncodedFile(io.TextIOWrapper):\n    __slots__ = ()\n\n    @property\n    def name(self) -> str:\n        # Ensure that file.name is a string. Workaround for a Python bug\n        # fixed in >=3.7.4: https://bugs.python.org/issue36015\n        return repr(self.buffer)\n\n    @property\n    def mode(self) -> str:\n        # TextIOWrapper doesn't expose a mode, but at least some of our\n        # tests check it.\n        return self.buffer.mode.replace(\"b\", \"\")"}, {"id": "_pytest.capture.EncodedFile.__slots__", "kind": "variable", "range": [401, 4, 401, 18, 13570, 13584], "file_path": "src/_pytest/capture.py", "content": "__slots__ = ()"}, {"id": "_pytest.capture.EncodedFile.name", "kind": "function", "range": [403, 4, 407, 32, 13590, 13795], "file_path": "src/_pytest/capture.py", "content": "@property\n    def name(self) -> str:\n        # Ensure that file.name is a string. Workaround for a Python bug\n        # fixed in >=3.7.4: https://bugs.python.org/issue36015\n        return repr(self.buffer)"}, {"id": "_pytest.capture.EncodedFile.mode", "kind": "function", "range": [409, 4, 413, 48, 13801, 13984], "file_path": "src/_pytest/capture.py", "content": "@property\n    def mode(self) -> str:\n        # TextIOWrapper doesn't expose a mode, but at least some of our\n        # tests check it.\n        return self.buffer.mode.replace(\"b\", \"\")"}, {"id": "_pytest.capture.CaptureResult", "kind": "variable", "range": [416, 0, 416, 71, 13987, 14058], "file_path": "src/_pytest/capture.py", "content": "CaptureResult = collections.namedtuple(\"CaptureResult\", [\"out\", \"err\"])"}, {"id": "_pytest.capture.MultiCapture", "kind": "class", "range": [419, 0, 496, 38, 14061, 16239], "file_path": "src/_pytest/capture.py", "content": "class MultiCapture:\n    out = err = in_ = None\n    _state = None\n    _in_suspended = False\n\n    def __init__(self, out=True, err=True, in_=True, Capture=None):\n        if in_:\n            self.in_ = Capture(0)\n        if out:\n            self.out = Capture(1)\n        if err:\n            self.err = Capture(2)\n\n    def __repr__(self):\n        return \"<MultiCapture out={!r} err={!r} in_={!r} _state={!r} _in_suspended={!r}>\".format(\n            self.out, self.err, self.in_, self._state, self._in_suspended,\n        )\n\n    def start_capturing(self):\n        self._state = \"started\"\n        if self.in_:\n            self.in_.start()\n        if self.out:\n            self.out.start()\n        if self.err:\n            self.err.start()\n\n    def pop_outerr_to_orig(self):\n        \"\"\" pop current snapshot out/err capture and flush to orig streams. \"\"\"\n        out, err = self.readouterr()\n        if out:\n            self.out.writeorg(out)\n        if err:\n            self.err.writeorg(err)\n        return out, err\n\n    def suspend_capturing(self, in_=False):\n        self._state = \"suspended\"\n        if self.out:\n            self.out.suspend()\n        if self.err:\n            self.err.suspend()\n        if in_ and self.in_:\n            self.in_.suspend()\n            self._in_suspended = True\n\n    def resume_capturing(self):\n        self._state = \"resumed\"\n        if self.out:\n            self.out.resume()\n        if self.err:\n            self.err.resume()\n        if self._in_suspended:\n            self.in_.resume()\n            self._in_suspended = False\n\n    def stop_capturing(self):\n        \"\"\" stop capturing and reset capturing streams \"\"\"\n        if self._state == \"stopped\":\n            raise ValueError(\"was already stopped\")\n        self._state = \"stopped\"\n        if self.out:\n            self.out.done()\n        if self.err:\n            self.err.done()\n        if self.in_:\n            self.in_.done()\n\n    def readouterr(self) -> CaptureResult:\n        if self.out:\n            out = self.out.snap()\n        else:\n            out = \"\"\n        if self.err:\n            err = self.err.snap()\n        else:\n            err = \"\"\n        return CaptureResult(out, err)"}, {"id": "_pytest.capture.MultiCapture.out", "kind": "variable", "range": [420, 4, 420, 26, 14085, 14107], "file_path": "src/_pytest/capture.py", "content": "out = err = in_ = None"}, {"id": "_pytest.capture.MultiCapture._state", "kind": "variable", "range": [421, 4, 421, 17, 14112, 14125], "file_path": "src/_pytest/capture.py", "content": "_state = None"}, {"id": "_pytest.capture.MultiCapture._in_suspended", "kind": "variable", "range": [422, 4, 422, 25, 14130, 14151], "file_path": "src/_pytest/capture.py", "content": "_in_suspended = False"}, {"id": "_pytest.capture.MultiCapture.__init__", "kind": "function", "range": [424, 4, 430, 33, 14157, 14370], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, out=True, err=True, in_=True, Capture=None):\n        if in_:\n            self.in_ = Capture(0)\n        if out:\n            self.out = Capture(1)\n        if err:\n            self.err = Capture(2)"}, {"id": "_pytest.capture.MultiCapture.__repr__", "kind": "function", "range": [432, 4, 435, 9, 14376, 14578], "file_path": "src/_pytest/capture.py", "content": "def __repr__(self):\n        return \"<MultiCapture out={!r} err={!r} in_={!r} _state={!r} _in_suspended={!r}>\".format(\n            self.out, self.err, self.in_, self._state, self._in_suspended,\n        )"}, {"id": "_pytest.capture.MultiCapture.start_capturing", "kind": "function", "range": [437, 4, 444, 28, 14584, 14792], "file_path": "src/_pytest/capture.py", "content": "def start_capturing(self):\n        self._state = \"started\"\n        if self.in_:\n            self.in_.start()\n        if self.out:\n            self.out.start()\n        if self.err:\n            self.err.start()"}, {"id": "_pytest.capture.MultiCapture.pop_outerr_to_orig", "kind": "function", "range": [446, 4, 453, 23, 14798, 15070], "file_path": "src/_pytest/capture.py", "content": "def pop_outerr_to_orig(self):\n        \"\"\" pop current snapshot out/err capture and flush to orig streams. \"\"\"\n        out, err = self.readouterr()\n        if out:\n            self.out.writeorg(out)\n        if err:\n            self.err.writeorg(err)\n        return out, err"}, {"id": "_pytest.capture.MultiCapture.suspend_capturing", "kind": "function", "range": [455, 4, 463, 37, 15076, 15351], "file_path": "src/_pytest/capture.py", "content": "def suspend_capturing(self, in_=False):\n        self._state = \"suspended\"\n        if self.out:\n            self.out.suspend()\n        if self.err:\n            self.err.suspend()\n        if in_ and self.in_:\n            self.in_.suspend()\n            self._in_suspended = True"}, {"id": "_pytest.capture.MultiCapture.resume_capturing", "kind": "function", "range": [465, 4, 473, 38, 15357, 15618], "file_path": "src/_pytest/capture.py", "content": "def resume_capturing(self):\n        self._state = \"resumed\"\n        if self.out:\n            self.out.resume()\n        if self.err:\n            self.err.resume()\n        if self._in_suspended:\n            self.in_.resume()\n            self._in_suspended = False"}, {"id": "_pytest.capture.MultiCapture.stop_capturing", "kind": "function", "range": [475, 4, 485, 27, 15624, 15976], "file_path": "src/_pytest/capture.py", "content": "def stop_capturing(self):\n        \"\"\" stop capturing and reset capturing streams \"\"\"\n        if self._state == \"stopped\":\n            raise ValueError(\"was already stopped\")\n        self._state = \"stopped\"\n        if self.out:\n            self.out.done()\n        if self.err:\n            self.err.done()\n        if self.in_:\n            self.in_.done()"}, {"id": "_pytest.capture.MultiCapture.readouterr", "kind": "function", "range": [487, 4, 496, 38, 15982, 16239], "file_path": "src/_pytest/capture.py", "content": "def readouterr(self) -> CaptureResult:\n        if self.out:\n            out = self.out.snap()\n        else:\n            out = \"\"\n        if self.err:\n            err = self.err.snap()\n        else:\n            err = \"\"\n        return CaptureResult(out, err)"}, {"id": "_pytest.capture.NoCapture", "kind": "class", "range": [499, 0, 501, 67, 16242, 16350], "file_path": "src/_pytest/capture.py", "content": "class NoCapture:\n    EMPTY_BUFFER = None\n    __init__ = start = done = suspend = resume = lambda *args: None"}, {"id": "_pytest.capture.NoCapture.EMPTY_BUFFER", "kind": "variable", "range": [500, 4, 500, 23, 16263, 16282], "file_path": "src/_pytest/capture.py", "content": "EMPTY_BUFFER = None"}, {"id": "_pytest.capture.NoCapture.__init__", "kind": "variable", "range": [501, 4, 501, 67, 16287, 16350], "file_path": "src/_pytest/capture.py", "content": "__init__ = start = done = suspend = resume = lambda *args: None"}, {"id": "_pytest.capture.FDCaptureBinary", "kind": "class", "range": [504, 0, 590, 42, 16353, 19234], "file_path": "src/_pytest/capture.py", "content": "class FDCaptureBinary:\n    \"\"\"Capture IO to/from a given os-level filedescriptor.\n\n    snap() produces `bytes`\n    \"\"\"\n\n    EMPTY_BUFFER = b\"\"\n    _state = None\n\n    def __init__(self, targetfd, tmpfile=None):\n        self.targetfd = targetfd\n        try:\n            self.targetfd_save = os.dup(self.targetfd)\n        except OSError:\n            self.start = lambda: None\n            self.done = lambda: None\n        else:\n            self.start = self._start\n            self.done = self._done\n            if targetfd == 0:\n                assert not tmpfile, \"cannot set tmpfile with stdin\"\n                tmpfile = open(os.devnull)\n                self.syscapture = SysCapture(targetfd)\n            else:\n                if tmpfile is None:\n                    tmpfile = EncodedFile(\n                        TemporaryFile(buffering=0),\n                        encoding=\"utf-8\",\n                        errors=\"replace\",\n                        write_through=True,\n                    )\n                if targetfd in patchsysdict:\n                    self.syscapture = SysCapture(targetfd, tmpfile)\n                else:\n                    self.syscapture = NoCapture()\n            self.tmpfile = tmpfile\n            self.tmpfile_fd = tmpfile.fileno()\n\n    def __repr__(self):\n        return \"<{} {} oldfd={} _state={!r} tmpfile={}>\".format(\n            self.__class__.__name__,\n            self.targetfd,\n            getattr(self, \"targetfd_save\", \"<UNSET>\"),\n            self._state,\n            hasattr(self, \"tmpfile\") and repr(self.tmpfile) or \"<UNSET>\",\n        )\n\n    def _start(self):\n        \"\"\" Start capturing on targetfd using memorized tmpfile. \"\"\"\n        try:\n            os.fstat(self.targetfd_save)\n        except (AttributeError, OSError):\n            raise ValueError(\"saved filedescriptor not valid anymore\")\n        os.dup2(self.tmpfile_fd, self.targetfd)\n        self.syscapture.start()\n        self._state = \"started\"\n\n    def snap(self):\n        self.tmpfile.seek(0)\n        res = self.tmpfile.buffer.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def _done(self):\n        \"\"\" stop capturing, restore streams, return original capture file,\n        seeked to position zero. \"\"\"\n        targetfd_save = self.__dict__.pop(\"targetfd_save\")\n        os.dup2(targetfd_save, self.targetfd)\n        os.close(targetfd_save)\n        self.syscapture.done()\n        self.tmpfile.close()\n        self._state = \"done\"\n\n    def suspend(self):\n        self.syscapture.suspend()\n        os.dup2(self.targetfd_save, self.targetfd)\n        self._state = \"suspended\"\n\n    def resume(self):\n        self.syscapture.resume()\n        os.dup2(self.tmpfile_fd, self.targetfd)\n        self._state = \"resumed\"\n\n    def writeorg(self, data):\n        \"\"\" write to original file descriptor. \"\"\"\n        os.write(self.targetfd_save, data)"}, {"id": "_pytest.capture.FDCaptureBinary.EMPTY_BUFFER", "kind": "variable", "range": [510, 4, 510, 22, 16477, 16495], "file_path": "src/_pytest/capture.py", "content": "EMPTY_BUFFER = b\"\""}, {"id": "_pytest.capture.FDCaptureBinary._state", "kind": "variable", "range": [511, 4, 511, 17, 16500, 16513], "file_path": "src/_pytest/capture.py", "content": "_state = None"}, {"id": "_pytest.capture.FDCaptureBinary.__init__", "kind": "function", "range": [513, 4, 540, 46, 16519, 17610], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, targetfd, tmpfile=None):\n        self.targetfd = targetfd\n        try:\n            self.targetfd_save = os.dup(self.targetfd)\n        except OSError:\n            self.start = lambda: None\n            self.done = lambda: None\n        else:\n            self.start = self._start\n            self.done = self._done\n            if targetfd == 0:\n                assert not tmpfile, \"cannot set tmpfile with stdin\"\n                tmpfile = open(os.devnull)\n                self.syscapture = SysCapture(targetfd)\n            else:\n                if tmpfile is None:\n                    tmpfile = EncodedFile(\n                        TemporaryFile(buffering=0),\n                        encoding=\"utf-8\",\n                        errors=\"replace\",\n                        write_through=True,\n                    )\n                if targetfd in patchsysdict:\n                    self.syscapture = SysCapture(targetfd, tmpfile)\n                else:\n                    self.syscapture = NoCapture()\n            self.tmpfile = tmpfile\n            self.tmpfile_fd = tmpfile.fileno()"}, {"id": "_pytest.capture.FDCaptureBinary.__repr__", "kind": "function", "range": [542, 4, 549, 9, 17616, 17928], "file_path": "src/_pytest/capture.py", "content": "def __repr__(self):\n        return \"<{} {} oldfd={} _state={!r} tmpfile={}>\".format(\n            self.__class__.__name__,\n            self.targetfd,\n            getattr(self, \"targetfd_save\", \"<UNSET>\"),\n            self._state,\n            hasattr(self, \"tmpfile\") and repr(self.tmpfile) or \"<UNSET>\",\n        )"}, {"id": "_pytest.capture.FDCaptureBinary._start", "kind": "function", "range": [551, 4, 559, 31, 17934, 18299], "file_path": "src/_pytest/capture.py", "content": "def _start(self):\n        \"\"\" Start capturing on targetfd using memorized tmpfile. \"\"\"\n        try:\n            os.fstat(self.targetfd_save)\n        except (AttributeError, OSError):\n            raise ValueError(\"saved filedescriptor not valid anymore\")\n        os.dup2(self.tmpfile_fd, self.targetfd)\n        self.syscapture.start()\n        self._state = \"started\""}, {"id": "_pytest.capture.FDCaptureBinary.snap", "kind": "function", "range": [561, 4, 566, 18, 18305, 18470], "file_path": "src/_pytest/capture.py", "content": "def snap(self):\n        self.tmpfile.seek(0)\n        res = self.tmpfile.buffer.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res"}, {"id": "_pytest.capture.FDCaptureBinary._done", "kind": "function", "range": [568, 4, 576, 28, 18476, 18830], "file_path": "src/_pytest/capture.py", "content": "def _done(self):\n        \"\"\" stop capturing, restore streams, return original capture file,\n        seeked to position zero. \"\"\"\n        targetfd_save = self.__dict__.pop(\"targetfd_save\")\n        os.dup2(targetfd_save, self.targetfd)\n        os.close(targetfd_save)\n        self.syscapture.done()\n        self.tmpfile.close()\n        self._state = \"done\""}, {"id": "_pytest.capture.FDCaptureBinary.suspend", "kind": "function", "range": [578, 4, 581, 33, 18836, 18973], "file_path": "src/_pytest/capture.py", "content": "def suspend(self):\n        self.syscapture.suspend()\n        os.dup2(self.targetfd_save, self.targetfd)\n        self._state = \"suspended\""}, {"id": "_pytest.capture.FDCaptureBinary.resume", "kind": "function", "range": [583, 4, 586, 31, 18979, 19109], "file_path": "src/_pytest/capture.py", "content": "def resume(self):\n        self.syscapture.resume()\n        os.dup2(self.tmpfile_fd, self.targetfd)\n        self._state = \"resumed\""}, {"id": "_pytest.capture.FDCaptureBinary.writeorg", "kind": "function", "range": [588, 4, 590, 42, 19115, 19234], "file_path": "src/_pytest/capture.py", "content": "def writeorg(self, data):\n        \"\"\" write to original file descriptor. \"\"\"\n        os.write(self.targetfd_save, data)"}, {"id": "_pytest.capture.FDCapture", "kind": "class", "range": [593, 0, 612, 42, 19237, 19845], "file_path": "src/_pytest/capture.py", "content": "class FDCapture(FDCaptureBinary):\n    \"\"\"Capture IO to/from a given os-level filedescriptor.\n\n    snap() produces text\n    \"\"\"\n\n    # Ignore type because it doesn't match the type in the superclass (bytes).\n    EMPTY_BUFFER = \"\"  # type: ignore\n\n    def snap(self):\n        self.tmpfile.seek(0)\n        res = self.tmpfile.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def writeorg(self, data):\n        \"\"\" write to original file descriptor. \"\"\"\n        data = data.encode(\"utf-8\")  # XXX use encoding of original stream\n        os.write(self.targetfd_save, data)"}, {"id": "_pytest.capture.FDCapture.EMPTY_BUFFER", "kind": "variable", "range": [600, 4, 600, 21, 19448, 19465], "file_path": "src/_pytest/capture.py", "content": "EMPTY_BUFFER = \"\""}, {"id": "_pytest.capture.FDCapture.snap", "kind": "function", "range": [602, 4, 607, 18, 19487, 19645], "file_path": "src/_pytest/capture.py", "content": "def snap(self):\n        self.tmpfile.seek(0)\n        res = self.tmpfile.read()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res"}, {"id": "_pytest.capture.FDCapture.writeorg", "kind": "function", "range": [609, 4, 612, 42, 19651, 19845], "file_path": "src/_pytest/capture.py", "content": "def writeorg(self, data):\n        \"\"\" write to original file descriptor. \"\"\"\n        data = data.encode(\"utf-8\")  # XXX use encoding of original stream\n        os.write(self.targetfd_save, data)"}, {"id": "_pytest.capture.SysCaptureBinary", "kind": "class", "range": [615, 0, 667, 32, 19848, 21244], "file_path": "src/_pytest/capture.py", "content": "class SysCaptureBinary:\n\n    EMPTY_BUFFER = b\"\"\n    _state = None\n\n    def __init__(self, fd, tmpfile=None):\n        name = patchsysdict[fd]\n        self._old = getattr(sys, name)\n        self.name = name\n        if tmpfile is None:\n            if name == \"stdin\":\n                tmpfile = DontReadFromInput()\n            else:\n                tmpfile = CaptureIO()\n        self.tmpfile = tmpfile\n\n    def __repr__(self):\n        return \"<{} {} _old={} _state={!r} tmpfile={!r}>\".format(\n            self.__class__.__name__,\n            self.name,\n            hasattr(self, \"_old\") and repr(self._old) or \"<UNSET>\",\n            self._state,\n            self.tmpfile,\n        )\n\n    def start(self):\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"started\"\n\n    def snap(self):\n        res = self.tmpfile.buffer.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def done(self):\n        setattr(sys, self.name, self._old)\n        del self._old\n        self.tmpfile.close()\n        self._state = \"done\"\n\n    def suspend(self):\n        setattr(sys, self.name, self._old)\n        self._state = \"suspended\"\n\n    def resume(self):\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"resumed\"\n\n    def writeorg(self, data):\n        self._old.flush()\n        self._old.buffer.write(data)\n        self._old.buffer.flush()"}, {"id": "_pytest.capture.SysCaptureBinary.EMPTY_BUFFER", "kind": "variable", "range": [617, 4, 617, 22, 19877, 19895], "file_path": "src/_pytest/capture.py", "content": "EMPTY_BUFFER = b\"\""}, {"id": "_pytest.capture.SysCaptureBinary._state", "kind": "variable", "range": [618, 4, 618, 17, 19900, 19913], "file_path": "src/_pytest/capture.py", "content": "_state = None"}, {"id": "_pytest.capture.SysCaptureBinary.__init__", "kind": "function", "range": [620, 4, 629, 30, 19919, 20245], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, fd, tmpfile=None):\n        name = patchsysdict[fd]\n        self._old = getattr(sys, name)\n        self.name = name\n        if tmpfile is None:\n            if name == \"stdin\":\n                tmpfile = DontReadFromInput()\n            else:\n                tmpfile = CaptureIO()\n        self.tmpfile = tmpfile"}, {"id": "_pytest.capture.SysCaptureBinary.__repr__", "kind": "function", "range": [631, 4, 638, 9, 20251, 20525], "file_path": "src/_pytest/capture.py", "content": "def __repr__(self):\n        return \"<{} {} _old={} _state={!r} tmpfile={!r}>\".format(\n            self.__class__.__name__,\n            self.name,\n            hasattr(self, \"_old\") and repr(self._old) or \"<UNSET>\",\n            self._state,\n            self.tmpfile,\n        )"}, {"id": "_pytest.capture.SysCaptureBinary.start", "kind": "function", "range": [640, 4, 642, 31, 20531, 20625], "file_path": "src/_pytest/capture.py", "content": "def start(self):\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"started\""}, {"id": "_pytest.capture.SysCaptureBinary.snap", "kind": "function", "range": [644, 4, 648, 18, 20631, 20771], "file_path": "src/_pytest/capture.py", "content": "def snap(self):\n        res = self.tmpfile.buffer.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res"}, {"id": "_pytest.capture.SysCaptureBinary.done", "kind": "function", "range": [650, 4, 654, 28, 20777, 20915], "file_path": "src/_pytest/capture.py", "content": "def done(self):\n        setattr(sys, self.name, self._old)\n        del self._old\n        self.tmpfile.close()\n        self._state = \"done\""}, {"id": "_pytest.capture.SysCaptureBinary.suspend", "kind": "function", "range": [656, 4, 658, 33, 20921, 21016], "file_path": "src/_pytest/capture.py", "content": "def suspend(self):\n        setattr(sys, self.name, self._old)\n        self._state = \"suspended\""}, {"id": "_pytest.capture.SysCaptureBinary.resume", "kind": "function", "range": [660, 4, 662, 31, 21022, 21117], "file_path": "src/_pytest/capture.py", "content": "def resume(self):\n        setattr(sys, self.name, self.tmpfile)\n        self._state = \"resumed\""}, {"id": "_pytest.capture.SysCaptureBinary.writeorg", "kind": "function", "range": [664, 4, 667, 32, 21123, 21244], "file_path": "src/_pytest/capture.py", "content": "def writeorg(self, data):\n        self._old.flush()\n        self._old.buffer.write(data)\n        self._old.buffer.flush()"}, {"id": "_pytest.capture.SysCapture", "kind": "class", "range": [670, 0, 681, 25, 21247, 21572], "file_path": "src/_pytest/capture.py", "content": "class SysCapture(SysCaptureBinary):\n    EMPTY_BUFFER = \"\"  # type: ignore[assignment]  # noqa: F821\n\n    def snap(self):\n        res = self.tmpfile.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res\n\n    def writeorg(self, data):\n        self._old.write(data)\n        self._old.flush()"}, {"id": "_pytest.capture.SysCapture.EMPTY_BUFFER", "kind": "variable", "range": [671, 4, 671, 21, 21287, 21304], "file_path": "src/_pytest/capture.py", "content": "EMPTY_BUFFER = \"\""}, {"id": "_pytest.capture.SysCapture.snap", "kind": "function", "range": [673, 4, 677, 18, 21352, 21485], "file_path": "src/_pytest/capture.py", "content": "def snap(self):\n        res = self.tmpfile.getvalue()\n        self.tmpfile.seek(0)\n        self.tmpfile.truncate()\n        return res"}, {"id": "_pytest.capture.SysCapture.writeorg", "kind": "function", "range": [679, 4, 681, 25, 21491, 21572], "file_path": "src/_pytest/capture.py", "content": "def writeorg(self, data):\n        self._old.write(data)\n        self._old.flush()"}, {"id": "_pytest.capture.TeeSysCapture", "kind": "class", "range": [684, 0, 694, 30, 21575, 21950], "file_path": "src/_pytest/capture.py", "content": "class TeeSysCapture(SysCapture):\n    def __init__(self, fd, tmpfile=None):\n        name = patchsysdict[fd]\n        self._old = getattr(sys, name)\n        self.name = name\n        if tmpfile is None:\n            if name == \"stdin\":\n                tmpfile = DontReadFromInput()\n            else:\n                tmpfile = TeeCaptureIO(self._old)\n        self.tmpfile = tmpfile"}, {"id": "_pytest.capture.TeeSysCapture.__init__", "kind": "function", "range": [685, 4, 694, 30, 21612, 21950], "file_path": "src/_pytest/capture.py", "content": "def __init__(self, fd, tmpfile=None):\n        name = patchsysdict[fd]\n        self._old = getattr(sys, name)\n        self.name = name\n        if tmpfile is None:\n            if name == \"stdin\":\n                tmpfile = DontReadFromInput()\n            else:\n                tmpfile = TeeCaptureIO(self._old)\n        self.tmpfile = tmpfile"}, {"id": "_pytest.capture.map_fixname_class", "kind": "variable", "range": [697, 0, 702, 1, 21953, 22100], "file_path": "src/_pytest/capture.py", "content": "map_fixname_class = {\n    \"capfd\": FDCapture,\n    \"capfdbinary\": FDCaptureBinary,\n    \"capsys\": SysCapture,\n    \"capsysbinary\": SysCaptureBinary,\n}"}, {"id": "_pytest.capture.DontReadFromInput", "kind": "class", "range": [705, 0, 731, 19, 22103, 22649], "file_path": "src/_pytest/capture.py", "content": "class DontReadFromInput:\n    encoding = None\n\n    def read(self, *args):\n        raise OSError(\n            \"pytest: reading from stdin while output is captured!  Consider using `-s`.\"\n        )\n\n    readline = read\n    readlines = read\n    __next__ = read\n\n    def __iter__(self):\n        return self\n\n    def fileno(self):\n        raise UnsupportedOperation(\"redirected stdin is pseudofile, has no fileno()\")\n\n    def isatty(self):\n        return False\n\n    def close(self):\n        pass\n\n    @property\n    def buffer(self):\n        return self"}, {"id": "_pytest.capture.DontReadFromInput.encoding", "kind": "variable", "range": [706, 4, 706, 19, 22132, 22147], "file_path": "src/_pytest/capture.py", "content": "encoding = None"}, {"id": "_pytest.capture.DontReadFromInput.read", "kind": "function", "range": [708, 4, 711, 9, 22153, 22297], "file_path": "src/_pytest/capture.py", "content": "def read(self, *args):\n        raise OSError(\n            \"pytest: reading from stdin while output is captured!  Consider using `-s`.\"\n        )"}, {"id": "_pytest.capture.DontReadFromInput.readline", "kind": "variable", "range": [713, 4, 713, 19, 22303, 22318], "file_path": "src/_pytest/capture.py", "content": "readline = read"}, {"id": "_pytest.capture.DontReadFromInput.readlines", "kind": "variable", "range": [714, 4, 714, 20, 22323, 22339], "file_path": "src/_pytest/capture.py", "content": "readlines = read"}, {"id": "_pytest.capture.DontReadFromInput.__next__", "kind": "variable", "range": [715, 4, 715, 19, 22344, 22359], "file_path": "src/_pytest/capture.py", "content": "__next__ = read"}, {"id": "_pytest.capture.DontReadFromInput.__iter__", "kind": "function", "range": [717, 4, 718, 19, 22365, 22404], "file_path": "src/_pytest/capture.py", "content": "def __iter__(self):\n        return self"}, {"id": "_pytest.capture.DontReadFromInput.fileno", "kind": "function", "range": [720, 4, 721, 85, 22410, 22513], "file_path": "src/_pytest/capture.py", "content": "def fileno(self):\n        raise UnsupportedOperation(\"redirected stdin is pseudofile, has no fileno()\")"}, {"id": "_pytest.capture.DontReadFromInput.isatty", "kind": "function", "range": [723, 4, 724, 20, 22519, 22557], "file_path": "src/_pytest/capture.py", "content": "def isatty(self):\n        return False"}, {"id": "_pytest.capture.DontReadFromInput.close", "kind": "function", "range": [726, 4, 727, 12, 22563, 22592], "file_path": "src/_pytest/capture.py", "content": "def close(self):\n        pass"}, {"id": "_pytest.capture.DontReadFromInput.buffer", "kind": "function", "range": [729, 4, 731, 19, 22598, 22649], "file_path": "src/_pytest/capture.py", "content": "@property\n    def buffer(self):\n        return self"}, {"id": "_pytest.capture._colorama_workaround", "kind": "function", "range": [734, 0, 747, 16, 22652, 23104], "file_path": "src/_pytest/capture.py", "content": "def _colorama_workaround():\n    \"\"\"\n    Ensure colorama is imported so that it attaches to the correct stdio\n    handles on Windows.\n\n    colorama uses the terminal on import time. So if something does the\n    first import of colorama while I/O capture is active, colorama will\n    fail in various ways.\n    \"\"\"\n    if sys.platform.startswith(\"win32\"):\n        try:\n            import colorama  # noqa: F401\n        except ImportError:\n            pass"}, {"id": "_pytest.capture._readline_workaround", "kind": "function", "range": [750, 0, 772, 16, 23107, 24124], "file_path": "src/_pytest/capture.py", "content": "def _readline_workaround():\n    \"\"\"\n    Ensure readline is imported so that it attaches to the correct stdio\n    handles on Windows.\n\n    Pdb uses readline support where available--when not running from the Python\n    prompt, the readline module is not imported until running the pdb REPL.  If\n    running pytest with the --pdb option this means the readline module is not\n    imported until after I/O capture has been started.\n\n    This is a problem for pyreadline, which is often used to implement readline\n    support on Windows, as it does not attach to the correct handles for stdout\n    and/or stdin if they have been redirected by the FDCapture mechanism.  This\n    workaround ensures that readline is imported before I/O capture is setup so\n    that it can attach to the actual stdin/out for the console.\n\n    See https://github.com/pytest-dev/pytest/pull/1281\n    \"\"\"\n    if sys.platform.startswith(\"win32\"):\n        try:\n            import readline  # noqa: F401\n        except ImportError:\n            pass"}, {"id": "_pytest.capture._py36_windowsconsoleio_workaround", "kind": "function", "range": [775, 0, 830, 48, 24127, 26111], "file_path": "src/_pytest/capture.py", "content": "def _py36_windowsconsoleio_workaround(stream):\n    \"\"\"\n    Python 3.6 implemented unicode console handling for Windows. This works\n    by reading/writing to the raw console handle using\n    ``{Read,Write}ConsoleW``.\n\n    The problem is that we are going to ``dup2`` over the stdio file\n    descriptors when doing ``FDCapture`` and this will ``CloseHandle`` the\n    handles used by Python to write to the console. Though there is still some\n    weirdness and the console handle seems to only be closed randomly and not\n    on the first call to ``CloseHandle``, or maybe it gets reopened with the\n    same handle value when we suspend capturing.\n\n    The workaround in this case will reopen stdio with a different fd which\n    also means a different handle by replicating the logic in\n    \"Py_lifecycle.c:initstdio/create_stdio\".\n\n    :param stream: in practice ``sys.stdout`` or ``sys.stderr``, but given\n        here as parameter for unittesting purposes.\n\n    See https://github.com/pytest-dev/py/issues/103\n    \"\"\"\n    if (\n        not sys.platform.startswith(\"win32\")\n        or sys.version_info[:2] < (3, 6)\n        or hasattr(sys, \"pypy_version_info\")\n    ):\n        return\n\n    # bail out if ``stream`` doesn't seem like a proper ``io`` stream (#2666)\n    if not hasattr(stream, \"buffer\"):\n        return\n\n    buffered = hasattr(stream.buffer, \"raw\")\n    raw_stdout = stream.buffer.raw if buffered else stream.buffer\n\n    if not isinstance(raw_stdout, io._WindowsConsoleIO):\n        return\n\n    def _reopen_stdio(f, mode):\n        if not buffered and mode[0] == \"w\":\n            buffering = 0\n        else:\n            buffering = -1\n\n        return io.TextIOWrapper(\n            open(os.dup(f.fileno()), mode, buffering),\n            f.encoding,\n            f.errors,\n            f.newlines,\n            f.line_buffering,\n        )\n\n    sys.stdin = _reopen_stdio(sys.stdin, \"rb\")\n    sys.stdout = _reopen_stdio(sys.stdout, \"wb\")\n    sys.stderr = _reopen_stdio(sys.stderr, \"wb\")"}, {"id": "_pytest.hookspec.hookspec", "kind": "variable", "range": [18, 0, 18, 35, 482, 517], "file_path": "src/_pytest/hookspec.py", "content": "hookspec = HookspecMarker(\"pytest\")"}, {"id": "_pytest.hookspec.pytest_addhooks", "kind": "function", "range": [25, 0, 35, 7, 720, 1093], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(historic=True)\ndef pytest_addhooks(pluginmanager):\n    \"\"\"called at plugin registration time to allow adding new hooks via a call to\n    ``pluginmanager.add_hookspecs(module_or_class, prefix)``.\n\n\n    :param _pytest.config.PytestPluginManager pluginmanager: pytest plugin manager\n\n    .. note::\n        This hook is incompatible with ``hookwrapper=True``.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_plugin_registered", "kind": "function", "range": [38, 0, 47, 7, 1096, 1422], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(historic=True)\ndef pytest_plugin_registered(plugin, manager):\n    \"\"\" a new pytest plugin got registered.\n\n    :param plugin: the plugin module or instance\n    :param _pytest.config.PytestPluginManager manager: pytest plugin manager\n\n    .. note::\n        This hook is incompatible with ``hookwrapper=True``.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_addoption", "kind": "function", "range": [50, 0, 85, 7, 1425, 3012], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(historic=True)\ndef pytest_addoption(parser, pluginmanager):\n    \"\"\"register argparse-style options and ini-style config values,\n    called once at the beginning of a test run.\n\n    .. note::\n\n        This function should be implemented only in plugins or ``conftest.py``\n        files situated at the tests root directory due to how pytest\n        :ref:`discovers plugins during startup <pluginorder>`.\n\n    :arg _pytest.config.argparsing.Parser parser: To add command line options, call\n        :py:func:`parser.addoption(...) <_pytest.config.argparsing.Parser.addoption>`.\n        To add ini-file values call :py:func:`parser.addini(...)\n        <_pytest.config.argparsing.Parser.addini>`.\n\n    :arg _pytest.config.PytestPluginManager pluginmanager: pytest plugin manager,\n        which can be used to install :py:func:`hookspec`'s or :py:func:`hookimpl`'s\n        and allow one plugin to call another plugin's hooks to change how\n        command line options are added.\n\n    Options can later be accessed through the\n    :py:class:`config <_pytest.config.Config>` object, respectively:\n\n    - :py:func:`config.getoption(name) <_pytest.config.Config.getoption>` to\n      retrieve the value of a command line option.\n\n    - :py:func:`config.getini(name) <_pytest.config.Config.getini>` to retrieve\n      a value read from an ini-style file.\n\n    The config object is passed around on many internal objects via the ``.config``\n    attribute or can be retrieved as the ``pytestconfig`` fixture.\n\n    .. note::\n        This hook is incompatible with ``hookwrapper=True``.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_configure", "kind": "function", "range": [88, 0, 103, 7, 3015, 3498], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(historic=True)\ndef pytest_configure(config):\n    \"\"\"\n    Allows plugins and conftest files to perform initial configuration.\n\n    This hook is called for every plugin and initial conftest file\n    after command line options have been parsed.\n\n    After that, the hook is called for other conftest files as they are\n    imported.\n\n    .. note::\n        This hook is incompatible with ``hookwrapper=True``.\n\n    :arg _pytest.config.Config config: pytest config object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_cmdline_parse", "kind": "function", "range": [112, 0, 124, 7, 3755, 4293], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_cmdline_parse(pluginmanager, args):\n    \"\"\"return initialized config object, parsing the specified args.\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    .. note::\n        This hook will only be called for plugin classes passed to the ``plugins`` arg when using `pytest.main`_ to\n        perform an in-process test run.\n\n    :param _pytest.config.PytestPluginManager pluginmanager: pytest plugin manager\n    :param list[str] args: list of arguments passed on the command line\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_cmdline_preparse", "kind": "function", "range": [127, 0, 138, 7, 4296, 4820], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_cmdline_preparse(config, args):\n    \"\"\"(**Deprecated**) modify command line arguments before option parsing.\n\n    This hook is considered deprecated and will be removed in a future pytest version. Consider\n    using :func:`pytest_load_initial_conftests` instead.\n\n    .. note::\n        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.\n\n    :param _pytest.config.Config config: pytest config object\n    :param list[str] args: list of arguments passed on the command line\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_cmdline_main", "kind": "function", "range": [141, 0, 152, 7, 4823, 5267], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_cmdline_main(config):\n    \"\"\" called for performing the main command line action. The default\n    implementation will invoke the configure hooks and runtest_mainloop.\n\n    .. note::\n        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    :param _pytest.config.Config config: pytest config object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_load_initial_conftests", "kind": "function", "range": [155, 0, 165, 7, 5270, 5768], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_load_initial_conftests(early_config, parser, args):\n    \"\"\" implements the loading of initial conftest files ahead\n    of command line option parsing.\n\n    .. note::\n        This hook will not be called for ``conftest.py`` files, only for setuptools plugins.\n\n    :param _pytest.config.Config early_config: pytest config object\n    :param list[str] args: list of arguments passed on the command line\n    :param _pytest.config.argparsing.Parser parser: to add command line options\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_collection", "kind": "function", "range": [173, 0, 195, 7, 5944, 6928], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_collection(session: \"Session\") -> Optional[Any]:\n    \"\"\"Perform the collection protocol for the given session.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    The return value is not used, but only stops further processing.\n\n    The hook is meant to set `session.items` to a sequence of items at least,\n    but normally should follow this procedure:\n\n      1. Call the pytest_collectstart hook.\n      2. Call the pytest_collectreport hook.\n      3. Call the pytest_collection_modifyitems hook.\n      4. Call the pytest_collection_finish hook.\n      5. Set session.testscollected to the amount of collect items.\n      6. Set `session.items` to a list of items.\n\n    You can implement this hook to only perform some action before collection,\n    for example the terminal plugin uses it to start displaying the collection\n    counter (and returns `None`).\n\n    :param _pytest.main.Session session: the pytest session object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_collection_modifyitems", "kind": "function", "range": [198, 0, 205, 7, 6931, 7290], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_collection_modifyitems(session, config, items):\n    \"\"\" called after collection has been performed, may filter or re-order\n    the items in-place.\n\n    :param _pytest.main.Session session: the pytest session object\n    :param _pytest.config.Config config: pytest config object\n    :param List[_pytest.nodes.Item] items: list of item objects\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_collection_finish", "kind": "function", "range": [208, 0, 212, 7, 7293, 7472], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_collection_finish(session):\n    \"\"\" called after collection has been performed and modified.\n\n    :param _pytest.main.Session session: the pytest session object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_ignore_collect", "kind": "function", "range": [215, 0, 225, 7, 7475, 7909], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_ignore_collect(path, config):\n    \"\"\" return True to prevent considering this path for collection.\n    This hook is consulted for all files and directories prior to calling\n    more specific hooks.\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    :param path: a :py:class:`py.path.local` - the path to analyze\n    :param _pytest.config.Config config: pytest config object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_collect_directory", "kind": "function", "range": [228, 0, 235, 7, 7912, 8223], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True, warn_on_impl=COLLECT_DIRECTORY_HOOK)\ndef pytest_collect_directory(path, parent):\n    \"\"\" called before traversing a directory for collection files.\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    :param path: a :py:class:`py.path.local` - the path to analyze\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_collect_file", "kind": "function", "range": [238, 0, 243, 7, 8226, 8468], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_collect_file(path, parent):\n    \"\"\" return collection Node or None for the given path. Any new node\n    needs to have the specified ``parent`` as a parent.\n\n    :param path: a :py:class:`py.path.local` - the path to collect\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_collectstart", "kind": "function", "range": [249, 0, 250, 40, 8504, 8580], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_collectstart(collector):\n    \"\"\" collector starts collecting. \"\"\""}, {"id": "_pytest.hookspec.pytest_itemcollected", "kind": "function", "range": [253, 0, 254, 42, 8583, 8657], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_itemcollected(item):\n    \"\"\" we just collected a test item. \"\"\""}, {"id": "_pytest.hookspec.pytest_collectreport", "kind": "function", "range": [257, 0, 258, 42, 8660, 8736], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_collectreport(report):\n    \"\"\" collector finished collecting. \"\"\""}, {"id": "_pytest.hookspec.pytest_deselected", "kind": "function", "range": [261, 0, 262, 62, 8739, 8831], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_deselected(items):\n    \"\"\" called for test items deselected, e.g. by keyword. \"\"\""}, {"id": "_pytest.hookspec.pytest_make_collect_report", "kind": "function", "range": [265, 0, 269, 62, 8834, 9036], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_make_collect_report(collector):\n    \"\"\" perform ``collector.collect()`` and return a CollectReport.\n\n    Stops at first non-None result, see :ref:`firstresult` \"\"\""}, {"id": "_pytest.hookspec.pytest_pycollect_makemodule", "kind": "function", "range": [277, 0, 287, 7, 9230, 9712], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_pycollect_makemodule(path, parent):\n    \"\"\" return a Module collector or None for the given path.\n    This hook will be called for each matching test module path.\n    The pytest_collect_file hook needs to be used if you want to\n    create test modules for files that do not match as a test module.\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    :param path: a :py:class:`py.path.local` - the path of module to collect\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_pycollect_makeitem", "kind": "function", "range": [290, 0, 294, 62, 9715, 9938], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_pycollect_makeitem(collector, name, obj):\n    \"\"\" return custom item/collector for a python object in a module, or None.\n\n    Stops at first non-None result, see :ref:`firstresult` \"\"\""}, {"id": "_pytest.hookspec.pytest_pyfunc_call", "kind": "function", "range": [297, 0, 301, 62, 9941, 10107], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_pyfunc_call(pyfuncitem):\n    \"\"\" call underlying test function.\n\n    Stops at first non-None result, see :ref:`firstresult` \"\"\""}, {"id": "_pytest.hookspec.pytest_generate_tests", "kind": "function", "range": [304, 0, 305, 69, 10110, 10216], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_generate_tests(metafunc):\n    \"\"\" generate (multiple) parametrized calls to a test function.\"\"\""}, {"id": "_pytest.hookspec.pytest_make_parametrize_id", "kind": "function", "range": [308, 0, 319, 7, 10219, 10789], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_make_parametrize_id(config, val, argname):\n    \"\"\"Return a user-friendly string representation of the given ``val`` that will be used\n    by @pytest.mark.parametrize calls. Return None if the hook doesn't know about ``val``.\n    The parameter name is available as ``argname``, if required.\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    :param _pytest.config.Config config: pytest config object\n    :param val: the parametrized value\n    :param str argname: the automatic parameter name produced by pytest\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_runtestloop", "kind": "function", "range": [327, 0, 335, 7, 10978, 11259], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_runtestloop(session):\n    \"\"\" called for performing the main runtest loop\n    (after collection finished).\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    :param _pytest.main.Session session: the pytest session object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_protocol", "kind": "function", "range": [338, 0, 353, 62, 11262, 11904], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_runtest_protocol(item, nextitem):\n    \"\"\" implements the runtest_setup/call/teardown protocol for\n    the given test item, including capturing exceptions and calling\n    reporting hooks.\n\n    :arg item: test item for which the runtest protocol is performed.\n\n    :arg nextitem: the scheduled-to-be-next test item (or None if this\n                   is the end my friend).  This argument is passed on to\n                   :py:func:`pytest_runtest_teardown`.\n\n    :return boolean: True if no further hook implementations should be invoked.\n\n\n    Stops at first non-None result, see :ref:`firstresult` \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_logstart", "kind": "function", "range": [356, 0, 364, 7, 11907, 12274], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_runtest_logstart(nodeid, location):\n    \"\"\" signal the start of running a single test item.\n\n    This hook will be called **before** :func:`pytest_runtest_setup`, :func:`pytest_runtest_call` and\n    :func:`pytest_runtest_teardown` hooks.\n\n    :param str nodeid: full id of the item\n    :param location: a triple of ``(filename, linenum, testname)``\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_logfinish", "kind": "function", "range": [367, 0, 375, 7, 12277, 12654], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_runtest_logfinish(nodeid, location):\n    \"\"\" signal the complete finish of running a single test item.\n\n    This hook will be called **after** :func:`pytest_runtest_setup`, :func:`pytest_runtest_call` and\n    :func:`pytest_runtest_teardown` hooks.\n\n    :param str nodeid: full id of the item\n    :param location: a triple of ``(filename, linenum, testname)``\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_setup", "kind": "function", "range": [378, 0, 379, 56, 12657, 12745], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_runtest_setup(item):\n    \"\"\" called before ``pytest_runtest_call(item)``. \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_call", "kind": "function", "range": [382, 0, 383, 48, 12748, 12827], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_runtest_call(item):\n    \"\"\" called to execute the test ``item``. \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_teardown", "kind": "function", "range": [386, 0, 393, 7, 12830, 13229], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_runtest_teardown(item, nextitem):\n    \"\"\" called after ``pytest_runtest_call``.\n\n    :arg nextitem: the scheduled-to-be-next test item (None if no further\n                   test item is scheduled).  This argument can be used to\n                   perform exact teardowns, i.e. calling just enough finalizers\n                   so that nextitem only needs to call setup-functions.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_makereport", "kind": "function", "range": [396, 0, 402, 62, 13232, 13535], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_runtest_makereport(item, call):\n    \"\"\" return a :py:class:`_pytest.runner.TestReport` object\n    for the given :py:class:`pytest.Item <_pytest.main.Item>` and\n    :py:class:`_pytest.runner.CallInfo`.\n\n    Stops at first non-None result, see :ref:`firstresult` \"\"\""}, {"id": "_pytest.hookspec.pytest_runtest_logreport", "kind": "function", "range": [405, 0, 407, 49, 13538, 13687], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_runtest_logreport(report):\n    \"\"\" process a test setup/call/teardown report relating to\n    the respective phase of executing a test. \"\"\""}, {"id": "_pytest.hookspec.pytest_report_to_serializable", "kind": "function", "range": [410, 0, 415, 7, 13690, 13909], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_report_to_serializable(config, report):\n    \"\"\"\n    Serializes the given report object into a data structure suitable for sending\n    over the wire, e.g. converted to JSON.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_report_from_serializable", "kind": "function", "range": [418, 0, 422, 7, 13912, 14095], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_report_from_serializable(config, data):\n    \"\"\"\n    Restores a report object previously serialized with pytest_report_to_serializable().\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_fixture_setup", "kind": "function", "range": [430, 0, 442, 7, 14276, 14736], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_fixture_setup(fixturedef, request):\n    \"\"\" performs fixture setup execution.\n\n    :return: The return value of the call to the fixture function\n\n    Stops at first non-None result, see :ref:`firstresult`\n\n    .. note::\n        If the fixture function returns None, other implementations of\n        this hook function will continue to be called, according to the\n        behavior of the :ref:`firstresult` option.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_fixture_post_finalizer", "kind": "function", "range": [445, 0, 448, 17, 14739, 14962], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_fixture_post_finalizer(fixturedef, request):\n    \"\"\"Called after fixture teardown, but before the cache is cleared, so\n    the fixture result ``fixturedef.cached_result`` is still available (not\n    ``None``).\"\"\""}, {"id": "_pytest.hookspec.pytest_sessionstart", "kind": "function", "range": [456, 0, 461, 7, 15148, 15387], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_sessionstart(session):\n    \"\"\" called after the ``Session`` object has been created and before performing collection\n    and entering the run test loop.\n\n    :param _pytest.main.Session session: the pytest session object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_sessionfinish", "kind": "function", "range": [464, 0, 469, 7, 15390, 15689], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_sessionfinish(session, exitstatus):\n    \"\"\" called after whole test run finished, right before returning the exit status to the system.\n\n    :param _pytest.main.Session session: the pytest session object\n    :param int exitstatus: the status which pytest will return to the system\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_unconfigure", "kind": "function", "range": [472, 0, 476, 7, 15692, 15840], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_unconfigure(config):\n    \"\"\" called before test process is exited.\n\n    :param _pytest.config.Config config: pytest config object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_assertrepr_compare", "kind": "function", "range": [484, 0, 493, 7, 16040, 16533], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_assertrepr_compare(config, op, left, right):\n    \"\"\"return explanation for comparisons in failing assert expressions.\n\n    Return None for no custom explanation, otherwise return a list\n    of strings.  The strings will be joined by newlines but any newlines\n    *in* a string will be escaped.  Note that all but the first line will\n    be indented slightly, the intention is for the first line to be a summary.\n\n    :param _pytest.config.Config config: pytest config object\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_assertion_pass", "kind": "function", "range": [496, 0, 531, 7, 16536, 17792], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_assertion_pass(item, lineno, orig, expl):\n    \"\"\"\n    **(Experimental)**\n\n    .. versionadded:: 5.0\n\n    Hook called whenever an assertion *passes*.\n\n    Use this hook to do some processing after a passing assertion.\n    The original assertion information is available in the `orig` string\n    and the pytest introspected assertion information is available in the\n    `expl` string.\n\n    This hook must be explicitly enabled by the ``enable_assertion_pass_hook``\n    ini-file option:\n\n    .. code-block:: ini\n\n        [pytest]\n        enable_assertion_pass_hook=true\n\n    You need to **clean the .pyc** files in your project directory and interpreter libraries\n    when enabling this option, as assertions will require to be re-written.\n\n    :param _pytest.nodes.Item item: pytest item object of current test\n    :param int lineno: line number of the assert statement\n    :param string orig: string with original assertion\n    :param string expl: string with assert explanation\n\n    .. note::\n\n        This hook is **experimental**, so its parameters or even the hook itself might\n        be changed/removed without warning in any future pytest release.\n\n        If you find this hook useful, please share your feedback opening an issue.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_report_header", "kind": "function", "range": [539, 0, 557, 7, 18015, 18740], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_report_header(config, startdir):\n    \"\"\" return a string or list of strings to be displayed as header info for terminal reporting.\n\n    :param _pytest.config.Config config: pytest config object\n    :param startdir: py.path object with the starting dir\n\n    .. note::\n\n        Lines returned by a plugin are displayed before those of plugins which\n        ran before it.\n        If you want to have your line(s) displayed first, use\n        :ref:`trylast=True <plugin-hookorder>`.\n\n    .. note::\n\n        This function should be implemented only in plugins or ``conftest.py``\n        files situated at the tests root directory due to how pytest\n        :ref:`discovers plugins during startup <pluginorder>`.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_report_collectionfinish", "kind": "function", "range": [560, 0, 578, 7, 18743, 19483], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_report_collectionfinish(config, startdir, items):\n    \"\"\"\n    .. versionadded:: 3.2\n\n    return a string or list of strings to be displayed after collection has finished successfully.\n\n    These strings will be displayed after the standard \"collected X items\" message.\n\n    :param _pytest.config.Config config: pytest config object\n    :param startdir: py.path object with the starting dir\n    :param items: list of pytest items that are going to be executed; this list should not be modified.\n\n    .. note::\n\n        Lines returned by a plugin are displayed before those of plugins which\n        ran before it.\n        If you want to have your line(s) displayed first, use\n        :ref:`trylast=True <plugin-hookorder>`.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_report_teststatus", "kind": "function", "range": [581, 0, 607, 7, 19486, 20519], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_report_teststatus(\n    report: \"BaseReport\", config: \"Config\"\n) -> Tuple[\n    str, str, Union[str, Mapping[str, bool]],\n]:\n    \"\"\"Return result-category, shortletter and verbose word for status\n    reporting.\n\n    The result-category is a category in which to count the result, for\n    example \"passed\", \"skipped\", \"error\" or the empty string.\n\n    The shortletter is shown as testing progresses, for example \".\", \"s\",\n    \"E\" or the empty string.\n\n    The verbose word is shown as testing progresses in verbose mode, for\n    example \"PASSED\", \"SKIPPED\", \"ERROR\" or the empty string.\n\n    pytest may style these implicitly according to the report outcome.\n    To provide explicit styling, return a tuple for the verbose word,\n    for example ``\"rerun\", \"R\", (\"RERUN\", {\"yellow\": True})``.\n\n    :param report: The report object whose status is to be returned.\n    :param _pytest.config.Config config: The pytest config object.\n\n    Stops at first non-None result, see :ref:`firstresult`.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_terminal_summary", "kind": "function", "range": [610, 0, 619, 7, 20522, 20953], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_terminal_summary(terminalreporter, exitstatus, config):\n    \"\"\"Add a section to terminal summary reporting.\n\n    :param _pytest.terminal.TerminalReporter terminalreporter: the internal terminal reporter object\n    :param int exitstatus: the exit status that will be reported back to the OS\n    :param _pytest.config.Config config: pytest config object\n\n    .. versionadded:: 4.2\n        The ``config`` parameter.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_warning_captured", "kind": "function", "range": [622, 0, 647, 7, 20956, 22137], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(historic=True)\ndef pytest_warning_captured(warning_message, when, item, location):\n    \"\"\"\n    Process a warning captured by the internal pytest warnings plugin.\n\n    :param warnings.WarningMessage warning_message:\n        The captured warning. This is the same object produced by :py:func:`warnings.catch_warnings`, and contains\n        the same attributes as the parameters of :py:func:`warnings.showwarning`.\n\n    :param str when:\n        Indicates when the warning was captured. Possible values:\n\n        * ``\"config\"``: during pytest configuration/initialization stage.\n        * ``\"collect\"``: during test collection.\n        * ``\"runtest\"``: during test execution.\n\n    :param pytest.Item|None item:\n        **DEPRECATED**: This parameter is incompatible with ``pytest-xdist``, and will always receive ``None``\n        in a future release.\n\n        The item being executed if ``when`` is ``\"runtest\"``, otherwise ``None``.\n\n    :param tuple location:\n        Holds information about the execution context of the captured warning (filename, linenumber, function).\n        ``function`` evaluates to <module> when the execution context is at the module level.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_doctest_prepare_content", "kind": "function", "range": [655, 0, 659, 62, 22310, 22499], "file_path": "src/_pytest/hookspec.py", "content": "@hookspec(firstresult=True)\ndef pytest_doctest_prepare_content(content):\n    \"\"\" return processed content for a given doctest\n\n    Stops at first non-None result, see :ref:`firstresult` \"\"\""}, {"id": "_pytest.hookspec.pytest_internalerror", "kind": "function", "range": [667, 0, 668, 39, 22702, 22785], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_internalerror(excrepr, excinfo):\n    \"\"\" called for internal errors. \"\"\""}, {"id": "_pytest.hookspec.pytest_keyboard_interrupt", "kind": "function", "range": [671, 0, 672, 42, 22788, 22870], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_keyboard_interrupt(excinfo):\n    \"\"\" called for keyboard interrupt. \"\"\""}, {"id": "_pytest.hookspec.pytest_exception_interact", "kind": "function", "range": [675, 0, 681, 7, 22873, 23146], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_exception_interact(node, call, report):\n    \"\"\"called when an exception was raised which can potentially be\n    interactively handled.\n\n    This hook is only called if an exception was raised\n    that is not an internal exception like ``skip.Exception``.\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_enter_pdb", "kind": "function", "range": [684, 0, 690, 7, 23149, 23438], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_enter_pdb(config, pdb):\n    \"\"\" called upon pdb.set_trace(), can be used by plugins to take special\n    action just before the python debugger enters in interactive mode.\n\n    :param _pytest.config.Config config: pytest config object\n    :param pdb.Pdb pdb: Pdb instance\n    \"\"\""}, {"id": "_pytest.hookspec.pytest_leave_pdb", "kind": "function", "range": [693, 0, 701, 7, 23441, 23770], "file_path": "src/_pytest/hookspec.py", "content": "def pytest_leave_pdb(config, pdb):\n    \"\"\" called when leaving pdb (e.g. with continue after pdb.set_trace()).\n\n    Can be used by plugins to take special action just after the python\n    debugger leaves interactive mode.\n\n    :param _pytest.config.Config config: pytest config object\n    :param pdb.Pdb pdb: Pdb instance\n    \"\"\""}, {"id": "_pytest._io._try_repr_or_str", "kind": "function", "range": [5, 0, 11, 57, 54, 256], "file_path": "src/_pytest/_io/saferepr.py", "content": "def _try_repr_or_str(obj):\n    try:\n        return repr(obj)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except BaseException:\n        return '{}(\"{}\")'.format(type(obj).__name__, obj)"}, {"id": "_pytest._io._format_repr_exception", "kind": "function", "range": [14, 0, 23, 5, 259, 665], "file_path": "src/_pytest/_io/saferepr.py", "content": "def _format_repr_exception(exc: BaseException, obj: Any) -> str:\n    try:\n        exc_info = _try_repr_or_str(exc)\n    except (KeyboardInterrupt, SystemExit):\n        raise\n    except BaseException as exc:\n        exc_info = \"unpresentable exception ({})\".format(_try_repr_or_str(exc))\n    return \"<[{} raised in repr()] {} object at 0x{:x}>\".format(\n        exc_info, obj.__class__.__name__, id(obj)\n    )"}, {"id": "_pytest._io._ellipsize", "kind": "function", "range": [26, 0, 31, 12, 668, 872], "file_path": "src/_pytest/_io/saferepr.py", "content": "def _ellipsize(s: str, maxsize: int) -> str:\n    if len(s) > maxsize:\n        i = max(0, (maxsize - 3) // 2)\n        j = max(0, maxsize - 3 - i)\n        return s[:i] + \"...\" + s[len(s) - j :]\n    return s"}, {"id": "_pytest._io.SafeRepr", "kind": "class", "range": [34, 0, 60, 42, 875, 1748], "file_path": "src/_pytest/_io/saferepr.py", "content": "class SafeRepr(reprlib.Repr):\n    \"\"\"subclass of repr.Repr that limits the resulting size of repr()\n    and includes information on exceptions raised during the call.\n    \"\"\"\n\n    def __init__(self, maxsize: int) -> None:\n        super().__init__()\n        self.maxstring = maxsize\n        self.maxsize = maxsize\n\n    def repr(self, x: Any) -> str:\n        try:\n            s = super().repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        return _ellipsize(s, self.maxsize)\n\n    def repr_instance(self, x: Any, level: int) -> str:\n        try:\n            s = repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        return _ellipsize(s, self.maxsize)"}, {"id": "_pytest._io.SafeRepr.__init__", "kind": "function", "range": [39, 4, 42, 30, 1055, 1187], "file_path": "src/_pytest/_io/saferepr.py", "content": "def __init__(self, maxsize: int) -> None:\n        super().__init__()\n        self.maxstring = maxsize\n        self.maxsize = maxsize"}, {"id": "_pytest._io.SafeRepr.repr", "kind": "function", "range": [44, 4, 51, 42, 1193, 1461], "file_path": "src/_pytest/_io/saferepr.py", "content": "def repr(self, x: Any) -> str:\n        try:\n            s = super().repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        return _ellipsize(s, self.maxsize)"}, {"id": "_pytest._io.SafeRepr.repr_instance", "kind": "function", "range": [53, 4, 60, 42, 1467, 1748], "file_path": "src/_pytest/_io/saferepr.py", "content": "def repr_instance(self, x: Any, level: int) -> str:\n        try:\n            s = repr(x)\n        except (KeyboardInterrupt, SystemExit):\n            raise\n        except BaseException as exc:\n            s = _format_repr_exception(exc, x)\n        return _ellipsize(s, self.maxsize)"}, {"id": "_pytest._io.safeformat", "kind": "function", "range": [63, 0, 71, 47, 1751, 2074], "file_path": "src/_pytest/_io/saferepr.py", "content": "def safeformat(obj: Any) -> str:\n    \"\"\"return a pretty printed string for the given object.\n    Failing __repr__ functions of user instances will be represented\n    with a short exception info.\n    \"\"\"\n    try:\n        return pprint.pformat(obj)\n    except Exception as exc:\n        return _format_repr_exception(exc, obj)"}, {"id": "_pytest._io.saferepr", "kind": "function", "range": [74, 0, 81, 38, 2077, 2512], "file_path": "src/_pytest/_io/saferepr.py", "content": "def saferepr(obj: Any, maxsize: int = 240) -> str:\n    \"\"\"return a size-limited safe repr-string for the given object.\n    Failing __repr__ functions of user instances will be represented\n    with a short exception info and 'saferepr' generally takes\n    care to never raise exceptions itself.  This function is a wrapper\n    around the Repr/reprlib functionality of the standard 2.6 lib.\n    \"\"\"\n    return SafeRepr(maxsize).repr(obj)"}, {"id": "_pytest._io.AlwaysDispatchingPrettyPrinter", "kind": "class", "range": [84, 0, 96, 26, 2515, 3061], "file_path": "src/_pytest/_io/saferepr.py", "content": "class AlwaysDispatchingPrettyPrinter(pprint.PrettyPrinter):\n    \"\"\"PrettyPrinter that always dispatches (regardless of width).\"\"\"\n\n    def _format(self, object, stream, indent, allowance, context, level):\n        p = self._dispatch.get(type(object).__repr__, None)\n\n        objid = id(object)\n        if objid in context or p is None:\n            return super()._format(object, stream, indent, allowance, context, level)\n\n        context[objid] = 1\n        p(self, object, stream, indent, allowance, context, level + 1)\n        del context[objid]"}, {"id": "_pytest._io.AlwaysDispatchingPrettyPrinter._format", "kind": "function", "range": [87, 4, 96, 26, 2650, 3061], "file_path": "src/_pytest/_io/saferepr.py", "content": "def _format(self, object, stream, indent, allowance, context, level):\n        p = self._dispatch.get(type(object).__repr__, None)\n\n        objid = id(object)\n        if objid in context or p is None:\n            return super()._format(object, stream, indent, allowance, context, level)\n\n        context[objid] = 1\n        p(self, object, stream, indent, allowance, context, level + 1)\n        del context[objid]"}, {"id": "_pytest._io._pformat_dispatch", "kind": "function", "range": [99, 0, 102, 21, 3064, 3274], "file_path": "src/_pytest/_io/saferepr.py", "content": "def _pformat_dispatch(object, indent=1, width=80, depth=None, *, compact=False):\n    return AlwaysDispatchingPrettyPrinter(\n        indent=indent, width=width, depth=depth, compact=compact\n    ).pformat(object)"}, {"id": "_pytest._io.TerminalWriter", "kind": "class", "range": [6, 0, 38, 81, 124, 1584], "file_path": "src/_pytest/_io/__init__.py", "content": "class TerminalWriter(BaseTerminalWriter):\n    def _write_source(self, lines: List[str], indents: Sequence[str] = ()) -> None:\n        \"\"\"Write lines of source code possibly highlighted.\n\n        Keeping this private for now because the API is clunky. We should discuss how\n        to evolve the terminal writer so we can have more precise color support, for example\n        being able to write part of a line in one color and the rest in another, and so on.\n        \"\"\"\n        if indents and len(indents) != len(lines):\n            raise ValueError(\n                \"indents size ({}) should have same size as lines ({})\".format(\n                    len(indents), len(lines)\n                )\n            )\n        if not indents:\n            indents = [\"\"] * len(lines)\n        source = \"\\n\".join(lines)\n        new_lines = self._highlight(source).splitlines()\n        for indent, new_line in zip(indents, new_lines):\n            self.line(indent + new_line)\n\n    def _highlight(self, source):\n        \"\"\"Highlight the given source code if we have markup support\"\"\"\n        if not self.hasmarkup:\n            return source\n        try:\n            from pygments.formatters.terminal import TerminalFormatter\n            from pygments.lexers.python import PythonLexer\n            from pygments import highlight\n        except ImportError:\n            return source\n        else:\n            return highlight(source, PythonLexer(), TerminalFormatter(bg=\"dark\"))"}, {"id": "_pytest._io.TerminalWriter._write_source", "kind": "function", "range": [7, 4, 25, 40, 170, 1084], "file_path": "src/_pytest/_io/__init__.py", "content": "def _write_source(self, lines: List[str], indents: Sequence[str] = ()) -> None:\n        \"\"\"Write lines of source code possibly highlighted.\n\n        Keeping this private for now because the API is clunky. We should discuss how\n        to evolve the terminal writer so we can have more precise color support, for example\n        being able to write part of a line in one color and the rest in another, and so on.\n        \"\"\"\n        if indents and len(indents) != len(lines):\n            raise ValueError(\n                \"indents size ({}) should have same size as lines ({})\".format(\n                    len(indents), len(lines)\n                )\n            )\n        if not indents:\n            indents = [\"\"] * len(lines)\n        source = \"\\n\".join(lines)\n        new_lines = self._highlight(source).splitlines()\n        for indent, new_line in zip(indents, new_lines):\n            self.line(indent + new_line)"}, {"id": "_pytest._io.TerminalWriter._highlight", "kind": "function", "range": [27, 4, 38, 81, 1090, 1584], "file_path": "src/_pytest/_io/__init__.py", "content": "def _highlight(self, source):\n        \"\"\"Highlight the given source code if we have markup support\"\"\"\n        if not self.hasmarkup:\n            return source\n        try:\n            from pygments.formatters.terminal import TerminalFormatter\n            from pygments.lexers.python import PythonLexer\n            from pygments import highlight\n        except ImportError:\n            return source\n        else:\n            return highlight(source, PythonLexer(), TerminalFormatter(bg=\"dark\"))"}, {"id": "_pytest.pytester.IGNORE_PAM", "kind": "variable", "range": [50, 0, 52, 1, 1261, 1371], "file_path": "src/_pytest/pytester.py", "content": "IGNORE_PAM = [  # filenames added when obtaining details about the current user\n    \"/var/lib/sss/mc/passwd\"\n]"}, {"id": "_pytest.pytester.pytest_addoption", "kind": "function", "range": [55, 0, 77, 5, 1374, 1985], "file_path": "src/_pytest/pytester.py", "content": "def pytest_addoption(parser):\n    parser.addoption(\n        \"--lsof\",\n        action=\"store_true\",\n        dest=\"lsof\",\n        default=False,\n        help=\"run FD checks if lsof is available\",\n    )\n\n    parser.addoption(\n        \"--runpytest\",\n        default=\"inprocess\",\n        dest=\"runpytest\",\n        choices=(\"inprocess\", \"subprocess\"),\n        help=(\n            \"run pytest sub runs in tests using an 'inprocess' \"\n            \"or 'subprocess' (python -m main) method\"\n        ),\n    )\n\n    parser.addini(\n        \"pytester_example_dir\", help=\"directory to take the pytester example files from\"\n    )"}, {"id": "_pytest.pytester.pytest_configure", "kind": "function", "range": [80, 0, 90, 5, 1988, 2364], "file_path": "src/_pytest/pytester.py", "content": "def pytest_configure(config):\n    if config.getvalue(\"lsof\"):\n        checker = LsofFdLeakChecker()\n        if checker.matching_platform():\n            config.pluginmanager.register(checker)\n\n    config.addinivalue_line(\n        \"markers\",\n        \"pytester_example_path(*path_segments): join the given path \"\n        \"segments to `pytester_example_dir` for this test.\",\n    )"}, {"id": "_pytest.pytester.LsofFdLeakChecker", "kind": "class", "range": [93, 0, 159, 61, 2367, 4680], "file_path": "src/_pytest/pytester.py", "content": "class LsofFdLeakChecker:\n    def get_open_files(self):\n        out = self._exec_lsof()\n        open_files = self._parse_lsof_output(out)\n        return open_files\n\n    def _exec_lsof(self):\n        pid = os.getpid()\n        # py3: use subprocess.DEVNULL directly.\n        with open(os.devnull, \"wb\") as devnull:\n            return subprocess.check_output(\n                (\"lsof\", \"-Ffn0\", \"-p\", str(pid)), stderr=devnull\n            ).decode()\n\n    def _parse_lsof_output(self, out):\n        def isopen(line):\n            return line.startswith(\"f\") and (\n                \"deleted\" not in line\n                and \"mem\" not in line\n                and \"txt\" not in line\n                and \"cwd\" not in line\n            )\n\n        open_files = []\n\n        for line in out.split(\"\\n\"):\n            if isopen(line):\n                fields = line.split(\"\\0\")\n                fd = fields[0][1:]\n                filename = fields[1][1:]\n                if filename in IGNORE_PAM:\n                    continue\n                if filename.startswith(\"/\"):\n                    open_files.append((fd, filename))\n\n        return open_files\n\n    def matching_platform(self):\n        try:\n            subprocess.check_output((\"lsof\", \"-v\"))\n        except (OSError, subprocess.CalledProcessError):\n            return False\n        else:\n            return True\n\n    @pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_runtest_protocol(self, item):\n        lines1 = self.get_open_files()\n        yield\n        if hasattr(sys, \"pypy_version_info\"):\n            gc.collect()\n        lines2 = self.get_open_files()\n\n        new_fds = {t[0] for t in lines2} - {t[0] for t in lines1}\n        leaked_files = [t for t in lines2 if t[0] in new_fds]\n        if leaked_files:\n            error = []\n            error.append(\"***** %s FD leakage detected\" % len(leaked_files))\n            error.extend([str(f) for f in leaked_files])\n            error.append(\"*** Before:\")\n            error.extend([str(f) for f in lines1])\n            error.append(\"*** After:\")\n            error.extend([str(f) for f in lines2])\n            error.append(error[0])\n            error.append(\"*** function %s:%s: %s \" % item.location)\n            error.append(\"See issue #2366\")\n            item.warn(pytest.PytestWarning(\"\\n\".join(error)))"}, {"id": "_pytest.pytester.LsofFdLeakChecker.get_open_files", "kind": "function", "range": [94, 4, 97, 25, 2396, 2529], "file_path": "src/_pytest/pytester.py", "content": "def get_open_files(self):\n        out = self._exec_lsof()\n        open_files = self._parse_lsof_output(out)\n        return open_files"}, {"id": "_pytest.pytester.LsofFdLeakChecker._exec_lsof", "kind": "function", "range": [99, 4, 105, 22, 2535, 2811], "file_path": "src/_pytest/pytester.py", "content": "def _exec_lsof(self):\n        pid = os.getpid()\n        # py3: use subprocess.DEVNULL directly.\n        with open(os.devnull, \"wb\") as devnull:\n            return subprocess.check_output(\n                (\"lsof\", \"-Ffn0\", \"-p\", str(pid)), stderr=devnull\n            ).decode()"}, {"id": "_pytest.pytester.LsofFdLeakChecker._parse_lsof_output", "kind": "function", "range": [107, 4, 128, 25, 2817, 3497], "file_path": "src/_pytest/pytester.py", "content": "def _parse_lsof_output(self, out):\n        def isopen(line):\n            return line.startswith(\"f\") and (\n                \"deleted\" not in line\n                and \"mem\" not in line\n                and \"txt\" not in line\n                and \"cwd\" not in line\n            )\n\n        open_files = []\n\n        for line in out.split(\"\\n\"):\n            if isopen(line):\n                fields = line.split(\"\\0\")\n                fd = fields[0][1:]\n                filename = fields[1][1:]\n                if filename in IGNORE_PAM:\n                    continue\n                if filename.startswith(\"/\"):\n                    open_files.append((fd, filename))\n\n        return open_files"}, {"id": "_pytest.pytester.LsofFdLeakChecker.matching_platform", "kind": "function", "range": [130, 4, 136, 23, 3503, 3716], "file_path": "src/_pytest/pytester.py", "content": "def matching_platform(self):\n        try:\n            subprocess.check_output((\"lsof\", \"-v\"))\n        except (OSError, subprocess.CalledProcessError):\n            return False\n        else:\n            return True"}, {"id": "_pytest.pytester.LsofFdLeakChecker.pytest_runtest_protocol", "kind": "function", "range": [138, 4, 159, 61, 3722, 4680], "file_path": "src/_pytest/pytester.py", "content": "@pytest.hookimpl(hookwrapper=True, tryfirst=True)\n    def pytest_runtest_protocol(self, item):\n        lines1 = self.get_open_files()\n        yield\n        if hasattr(sys, \"pypy_version_info\"):\n            gc.collect()\n        lines2 = self.get_open_files()\n\n        new_fds = {t[0] for t in lines2} - {t[0] for t in lines1}\n        leaked_files = [t for t in lines2 if t[0] in new_fds]\n        if leaked_files:\n            error = []\n            error.append(\"***** %s FD leakage detected\" % len(leaked_files))\n            error.extend([str(f) for f in leaked_files])\n            error.append(\"*** Before:\")\n            error.extend([str(f) for f in lines1])\n            error.append(\"*** After:\")\n            error.extend([str(f) for f in lines2])\n            error.append(error[0])\n            error.append(\"*** function %s:%s: %s \" % item.location)\n            error.append(\"See issue #2366\")\n            item.warn(pytest.PytestWarning(\"\\n\".join(error)))"}, {"id": "_pytest.pytester._pytest", "kind": "function", "range": [165, 0, 172, 29, 4724, 4995], "file_path": "src/_pytest/pytester.py", "content": "@pytest.fixture\ndef _pytest(request: FixtureRequest) -> \"PytestArg\":\n    \"\"\"Return a helper which offers a gethookrecorder(hook) method which\n    returns a HookRecorder instance which helps to make assertions about called\n    hooks.\n\n    \"\"\"\n    return PytestArg(request)"}, {"id": "_pytest.pytester.PytestArg", "kind": "class", "range": [175, 0, 182, 27, 4998, 5297], "file_path": "src/_pytest/pytester.py", "content": "class PytestArg:\n    def __init__(self, request: FixtureRequest) -> None:\n        self.request = request\n\n    def gethookrecorder(self, hook) -> \"HookRecorder\":\n        hookrecorder = HookRecorder(hook._pm)\n        self.request.addfinalizer(hookrecorder.finish_recording)\n        return hookrecorder"}, {"id": "_pytest.pytester.PytestArg.__init__", "kind": "function", "range": [176, 4, 177, 30, 5019, 5102], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self, request: FixtureRequest) -> None:\n        self.request = request"}, {"id": "_pytest.pytester.PytestArg.gethookrecorder", "kind": "function", "range": [179, 4, 182, 27, 5108, 5297], "file_path": "src/_pytest/pytester.py", "content": "def gethookrecorder(self, hook) -> \"HookRecorder\":\n        hookrecorder = HookRecorder(hook._pm)\n        self.request.addfinalizer(hookrecorder.finish_recording)\n        return hookrecorder"}, {"id": "_pytest.pytester.get_public_names", "kind": "function", "range": [185, 0, 187, 45, 5300, 5454], "file_path": "src/_pytest/pytester.py", "content": "def get_public_names(values):\n    \"\"\"Only return names from iterator values without a leading underscore.\"\"\"\n    return [x for x in values if x[0] != \"_\"]"}, {"id": "_pytest.pytester.ParsedCall", "kind": "class", "range": [190, 0, 203, 39, 5457, 5895], "file_path": "src/_pytest/pytester.py", "content": "class ParsedCall:\n    def __init__(self, name, kwargs):\n        self.__dict__.update(kwargs)\n        self._name = name\n\n    def __repr__(self):\n        d = self.__dict__.copy()\n        del d[\"_name\"]\n        return \"<ParsedCall {!r}(**{!r})>\".format(self._name, d)\n\n    if TYPE_CHECKING:\n        # The class has undetermined attributes, this tells mypy about it.\n        def __getattr__(self, key):\n            raise NotImplementedError()"}, {"id": "_pytest.pytester.ParsedCall.__init__", "kind": "function", "range": [191, 4, 193, 25, 5479, 5575], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self, name, kwargs):\n        self.__dict__.update(kwargs)\n        self._name = name"}, {"id": "_pytest.pytester.ParsedCall.__repr__", "kind": "function", "range": [195, 4, 198, 64, 5581, 5721], "file_path": "src/_pytest/pytester.py", "content": "def __repr__(self):\n        d = self.__dict__.copy()\n        del d[\"_name\"]\n        return \"<ParsedCall {!r}(**{!r})>\".format(self._name, d)"}, {"id": "_pytest.pytester.HookRecorder", "kind": "class", "range": [206, 0, 356, 26, 5898, 11172], "file_path": "src/_pytest/pytester.py", "content": "class HookRecorder:\n    \"\"\"Record all hooks called in a plugin manager.\n\n    This wraps all the hook calls in the plugin manager, recording each call\n    before propagating the normal calls.\n\n    \"\"\"\n\n    def __init__(self, pluginmanager) -> None:\n        self._pluginmanager = pluginmanager\n        self.calls = []  # type: List[ParsedCall]\n\n        def before(hook_name: str, hook_impls, kwargs) -> None:\n            self.calls.append(ParsedCall(hook_name, kwargs))\n\n        def after(outcome, hook_name: str, hook_impls, kwargs) -> None:\n            pass\n\n        self._undo_wrapping = pluginmanager.add_hookcall_monitoring(before, after)\n\n    def finish_recording(self) -> None:\n        self._undo_wrapping()\n\n    def getcalls(self, names: Union[str, Iterable[str]]) -> List[ParsedCall]:\n        if isinstance(names, str):\n            names = names.split()\n        return [call for call in self.calls if call._name in names]\n\n    def assert_contains(self, entries) -> None:\n        __tracebackhide__ = True\n        i = 0\n        entries = list(entries)\n        backlocals = sys._getframe(1).f_locals\n        while entries:\n            name, check = entries.pop(0)\n            for ind, call in enumerate(self.calls[i:]):\n                if call._name == name:\n                    print(\"NAMEMATCH\", name, call)\n                    if eval(check, backlocals, call.__dict__):\n                        print(\"CHECKERMATCH\", repr(check), \"->\", call)\n                    else:\n                        print(\"NOCHECKERMATCH\", repr(check), \"-\", call)\n                        continue\n                    i += ind + 1\n                    break\n                print(\"NONAMEMATCH\", name, \"with\", call)\n            else:\n                pytest.fail(\"could not find {!r} check {!r}\".format(name, check))\n\n    def popcall(self, name: str) -> ParsedCall:\n        __tracebackhide__ = True\n        for i, call in enumerate(self.calls):\n            if call._name == name:\n                del self.calls[i]\n                return call\n        lines = [\"could not find call {!r}, in:\".format(name)]\n        lines.extend([\"  %s\" % x for x in self.calls])\n        pytest.fail(\"\\n\".join(lines))\n\n    def getcall(self, name: str) -> ParsedCall:\n        values = self.getcalls(name)\n        assert len(values) == 1, (name, values)\n        return values[0]\n\n    # functionality for test reports\n\n    def getreports(\n        self,\n        names: Union[\n            str, Iterable[str]\n        ] = \"pytest_runtest_logreport pytest_collectreport\",\n    ) -> List[TestReport]:\n        return [x.report for x in self.getcalls(names)]\n\n    def matchreport(\n        self,\n        inamepart: str = \"\",\n        names: Union[\n            str, Iterable[str]\n        ] = \"pytest_runtest_logreport pytest_collectreport\",\n        when=None,\n    ):\n        \"\"\"return a testreport whose dotted import path matches\"\"\"\n        values = []\n        for rep in self.getreports(names=names):\n            if not when and rep.when != \"call\" and rep.passed:\n                # setup/teardown passing reports - let's ignore those\n                continue\n            if when and rep.when != when:\n                continue\n            if not inamepart or inamepart in rep.nodeid.split(\"::\"):\n                values.append(rep)\n        if not values:\n            raise ValueError(\n                \"could not find test report matching %r: \"\n                \"no test reports at all!\" % (inamepart,)\n            )\n        if len(values) > 1:\n            raise ValueError(\n                \"found 2 or more testreports matching {!r}: {}\".format(\n                    inamepart, values\n                )\n            )\n        return values[0]\n\n    def getfailures(\n        self,\n        names: Union[\n            str, Iterable[str]\n        ] = \"pytest_runtest_logreport pytest_collectreport\",\n    ) -> List[TestReport]:\n        return [rep for rep in self.getreports(names) if rep.failed]\n\n    def getfailedcollections(self) -> List[TestReport]:\n        return self.getfailures(\"pytest_collectreport\")\n\n    def listoutcomes(\n        self,\n    ) -> Tuple[List[TestReport], List[TestReport], List[TestReport]]:\n        passed = []\n        skipped = []\n        failed = []\n        for rep in self.getreports(\"pytest_collectreport pytest_runtest_logreport\"):\n            if rep.passed:\n                if rep.when == \"call\":\n                    passed.append(rep)\n            elif rep.skipped:\n                skipped.append(rep)\n            else:\n                assert rep.failed, \"Unexpected outcome: {!r}\".format(rep)\n                failed.append(rep)\n        return passed, skipped, failed\n\n    def countoutcomes(self) -> List[int]:\n        return [len(x) for x in self.listoutcomes()]\n\n    def assertoutcome(self, passed: int = 0, skipped: int = 0, failed: int = 0) -> None:\n        __tracebackhide__ = True\n\n        outcomes = self.listoutcomes()\n        realpassed, realskipped, realfailed = outcomes\n        obtained = {\n            \"passed\": len(realpassed),\n            \"skipped\": len(realskipped),\n            \"failed\": len(realfailed),\n        }\n        expected = {\"passed\": passed, \"skipped\": skipped, \"failed\": failed}\n        assert obtained == expected, outcomes\n\n    def clear(self) -> None:\n        self.calls[:] = []"}, {"id": "_pytest.pytester.HookRecorder.__init__", "kind": "function", "range": [214, 4, 224, 82, 6103, 6539], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self, pluginmanager) -> None:\n        self._pluginmanager = pluginmanager\n        self.calls = []  # type: List[ParsedCall]\n\n        def before(hook_name: str, hook_impls, kwargs) -> None:\n            self.calls.append(ParsedCall(hook_name, kwargs))\n\n        def after(outcome, hook_name: str, hook_impls, kwargs) -> None:\n            pass\n\n        self._undo_wrapping = pluginmanager.add_hookcall_monitoring(before, after)"}, {"id": "_pytest.pytester.HookRecorder.finish_recording", "kind": "function", "range": [226, 4, 227, 29, 6545, 6610], "file_path": "src/_pytest/pytester.py", "content": "def finish_recording(self) -> None:\n        self._undo_wrapping()"}, {"id": "_pytest.pytester.HookRecorder.getcalls", "kind": "function", "range": [229, 4, 232, 67, 6616, 6826], "file_path": "src/_pytest/pytester.py", "content": "def getcalls(self, names: Union[str, Iterable[str]]) -> List[ParsedCall]:\n        if isinstance(names, str):\n            names = names.split()\n        return [call for call in self.calls if call._name in names]"}, {"id": "_pytest.pytester.HookRecorder.assert_contains", "kind": "function", "range": [234, 4, 253, 81, 6832, 7692], "file_path": "src/_pytest/pytester.py", "content": "def assert_contains(self, entries) -> None:\n        __tracebackhide__ = True\n        i = 0\n        entries = list(entries)\n        backlocals = sys._getframe(1).f_locals\n        while entries:\n            name, check = entries.pop(0)\n            for ind, call in enumerate(self.calls[i:]):\n                if call._name == name:\n                    print(\"NAMEMATCH\", name, call)\n                    if eval(check, backlocals, call.__dict__):\n                        print(\"CHECKERMATCH\", repr(check), \"->\", call)\n                    else:\n                        print(\"NOCHECKERMATCH\", repr(check), \"-\", call)\n                        continue\n                    i += ind + 1\n                    break\n                print(\"NONAMEMATCH\", name, \"with\", call)\n            else:\n                pytest.fail(\"could not find {!r} check {!r}\".format(name, check))"}, {"id": "_pytest.pytester.HookRecorder.popcall", "kind": "function", "range": [255, 4, 263, 37, 7698, 8073], "file_path": "src/_pytest/pytester.py", "content": "def popcall(self, name: str) -> ParsedCall:\n        __tracebackhide__ = True\n        for i, call in enumerate(self.calls):\n            if call._name == name:\n                del self.calls[i]\n                return call\n        lines = [\"could not find call {!r}, in:\".format(name)]\n        lines.extend([\"  %s\" % x for x in self.calls])\n        pytest.fail(\"\\n\".join(lines))"}, {"id": "_pytest.pytester.HookRecorder.getcall", "kind": "function", "range": [265, 4, 268, 24, 8079, 8232], "file_path": "src/_pytest/pytester.py", "content": "def getcall(self, name: str) -> ParsedCall:\n        values = self.getcalls(name)\n        assert len(values) == 1, (name, values)\n        return values[0]"}, {"id": "_pytest.pytester.HookRecorder.getreports", "kind": "function", "range": [272, 4, 278, 55, 8276, 8502], "file_path": "src/_pytest/pytester.py", "content": "def getreports(\n        self,\n        names: Union[\n            str, Iterable[str]\n        ] = \"pytest_runtest_logreport pytest_collectreport\",\n    ) -> List[TestReport]:\n        return [x.report for x in self.getcalls(names)]"}, {"id": "_pytest.pytester.HookRecorder.matchreport", "kind": "function", "range": [280, 4, 309, 24, 8508, 9580], "file_path": "src/_pytest/pytester.py", "content": "def matchreport(\n        self,\n        inamepart: str = \"\",\n        names: Union[\n            str, Iterable[str]\n        ] = \"pytest_runtest_logreport pytest_collectreport\",\n        when=None,\n    ):\n        \"\"\"return a testreport whose dotted import path matches\"\"\"\n        values = []\n        for rep in self.getreports(names=names):\n            if not when and rep.when != \"call\" and rep.passed:\n                # setup/teardown passing reports - let's ignore those\n                continue\n            if when and rep.when != when:\n                continue\n            if not inamepart or inamepart in rep.nodeid.split(\"::\"):\n                values.append(rep)\n        if not values:\n            raise ValueError(\n                \"could not find test report matching %r: \"\n                \"no test reports at all!\" % (inamepart,)\n            )\n        if len(values) > 1:\n            raise ValueError(\n                \"found 2 or more testreports matching {!r}: {}\".format(\n                    inamepart, values\n                )\n            )\n        return values[0]"}, {"id": "_pytest.pytester.HookRecorder.getfailures", "kind": "function", "range": [311, 4, 317, 68, 9586, 9826], "file_path": "src/_pytest/pytester.py", "content": "def getfailures(\n        self,\n        names: Union[\n            str, Iterable[str]\n        ] = \"pytest_runtest_logreport pytest_collectreport\",\n    ) -> List[TestReport]:\n        return [rep for rep in self.getreports(names) if rep.failed]"}, {"id": "_pytest.pytester.HookRecorder.getfailedcollections", "kind": "function", "range": [319, 4, 320, 55, 9832, 9939], "file_path": "src/_pytest/pytester.py", "content": "def getfailedcollections(self) -> List[TestReport]:\n        return self.getfailures(\"pytest_collectreport\")"}, {"id": "_pytest.pytester.HookRecorder.listoutcomes", "kind": "function", "range": [322, 4, 337, 38, 9945, 10529], "file_path": "src/_pytest/pytester.py", "content": "def listoutcomes(\n        self,\n    ) -> Tuple[List[TestReport], List[TestReport], List[TestReport]]:\n        passed = []\n        skipped = []\n        failed = []\n        for rep in self.getreports(\"pytest_collectreport pytest_runtest_logreport\"):\n            if rep.passed:\n                if rep.when == \"call\":\n                    passed.append(rep)\n            elif rep.skipped:\n                skipped.append(rep)\n            else:\n                assert rep.failed, \"Unexpected outcome: {!r}\".format(rep)\n                failed.append(rep)\n        return passed, skipped, failed"}, {"id": "_pytest.pytester.HookRecorder.countoutcomes", "kind": "function", "range": [339, 4, 340, 52, 10535, 10625], "file_path": "src/_pytest/pytester.py", "content": "def countoutcomes(self) -> List[int]:\n        return [len(x) for x in self.listoutcomes()]"}, {"id": "_pytest.pytester.HookRecorder.assertoutcome", "kind": "function", "range": [342, 4, 353, 45, 10631, 11115], "file_path": "src/_pytest/pytester.py", "content": "def assertoutcome(self, passed: int = 0, skipped: int = 0, failed: int = 0) -> None:\n        __tracebackhide__ = True\n\n        outcomes = self.listoutcomes()\n        realpassed, realskipped, realfailed = outcomes\n        obtained = {\n            \"passed\": len(realpassed),\n            \"skipped\": len(realskipped),\n            \"failed\": len(realfailed),\n        }\n        expected = {\"passed\": passed, \"skipped\": skipped, \"failed\": failed}\n        assert obtained == expected, outcomes"}, {"id": "_pytest.pytester.HookRecorder.clear", "kind": "function", "range": [355, 4, 356, 26, 11121, 11172], "file_path": "src/_pytest/pytester.py", "content": "def clear(self) -> None:\n        self.calls[:] = []"}, {"id": "_pytest.pytester.linecomp", "kind": "function", "range": [359, 0, 365, 21, 11175, 11364], "file_path": "src/_pytest/pytester.py", "content": "@pytest.fixture\ndef linecomp() -> \"LineComp\":\n    \"\"\"\n    A :class: `LineComp` instance for checking that an input linearly\n    contains a sequence of strings.\n    \"\"\"\n    return LineComp()"}, {"id": "_pytest.pytester.LineMatcher_fixture", "kind": "function", "range": [368, 0, 376, 22, 11367, 11718], "file_path": "src/_pytest/pytester.py", "content": "@pytest.fixture(name=\"LineMatcher\")\ndef LineMatcher_fixture(request: FixtureRequest) -> \"Type[LineMatcher]\":\n    \"\"\"\n    A reference to the :class: `LineMatcher`.\n\n    This is instantiable with a list of lines (without their trailing newlines).\n    This is useful for testing large texts, such as the output of commands.\n    \"\"\"\n    return LineMatcher"}, {"id": "_pytest.pytester.testdir", "kind": "function", "range": [379, 0, 388, 43, 11721, 12097], "file_path": "src/_pytest/pytester.py", "content": "@pytest.fixture\ndef testdir(request: FixtureRequest, tmpdir_factory) -> \"Testdir\":\n    \"\"\"\n    A :class: `TestDir` instance, that can be used to run and test pytest itself.\n\n    It is particularly useful for testing plugins. It is similar to the `tmpdir` fixture\n    but provides methods which aid in testing pytest itself.\n\n    \"\"\"\n    return Testdir(request, tmpdir_factory)"}, {"id": "_pytest.pytester._sys_snapshot", "kind": "function", "range": [391, 0, 397, 23, 12100, 12264], "file_path": "src/_pytest/pytester.py", "content": "@pytest.fixture\ndef _sys_snapshot():\n    snappaths = SysPathsSnapshot()\n    snapmods = SysModulesSnapshot()\n    yield\n    snapmods.restore()\n    snappaths.restore()"}, {"id": "_pytest.pytester._config_for_test", "kind": "function", "range": [400, 0, 406, 74, 12267, 12467], "file_path": "src/_pytest/pytester.py", "content": "@pytest.fixture\ndef _config_for_test():\n    from _pytest.config import get_config\n\n    config = get_config()\n    yield config\n    config._ensure_unconfigure()  # cleanup, e.g. capman closing tmpfiles."}, {"id": "_pytest.pytester.rex_session_duration", "kind": "variable", "range": [410, 0, 410, 48, 12540, 12588], "file_path": "src/_pytest/pytester.py", "content": "rex_session_duration = re.compile(r\"\\d+\\.\\d\\ds\")"}, {"id": "_pytest.pytester.rex_outcome", "kind": "variable", "range": [412, 0, 412, 40, 12679, 12719], "file_path": "src/_pytest/pytester.py", "content": "rex_outcome = re.compile(r\"(\\d+) (\\w+)\")"}, {"id": "_pytest.pytester.RunResult", "kind": "class", "range": [415, 0, 499, 35, 12722, 15579], "file_path": "src/_pytest/pytester.py", "content": "class RunResult:\n    \"\"\"The result of running a command.\"\"\"\n\n    def __init__(\n        self,\n        ret: Union[int, ExitCode],\n        outlines: List[str],\n        errlines: List[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret = pytest.ExitCode(ret)  # type: Union[int, ExitCode]\n            \"\"\"the return value\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"list of lines captured from stdout\"\"\"\n        self.errlines = errlines\n        \"\"\"list of lines captured from stderr\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`LineMatcher` of stdout.\n\n        Use e.g. :func:`stdout.str() <LineMatcher.str()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`LineMatcher` of stderr\"\"\"\n        self.duration = duration\n        \"\"\"duration in seconds\"\"\"\n\n    def __repr__(self) -> str:\n        return (\n            \"<RunResult ret=%s len(stdout.lines)=%d len(stderr.lines)=%d duration=%.2fs>\"\n            % (self.ret, len(self.stdout.lines), len(self.stderr.lines), self.duration)\n        )\n\n    def parseoutcomes(self) -> Dict[str, int]:\n        \"\"\"Return a dictionary of outcomestring->num from parsing the terminal\n        output that the test process produced.\n\n        \"\"\"\n        for line in reversed(self.outlines):\n            if rex_session_duration.search(line):\n                outcomes = rex_outcome.findall(line)\n                ret = {noun: int(count) for (count, noun) in outcomes}\n                break\n        else:\n            raise ValueError(\"Pytest terminal summary report not found\")\n        if \"errors\" in ret:\n            assert \"error\" not in ret\n            ret[\"error\"] = ret.pop(\"errors\")\n        return ret\n\n    def assert_outcomes(\n        self,\n        passed: int = 0,\n        skipped: int = 0,\n        failed: int = 0,\n        error: int = 0,\n        xpassed: int = 0,\n        xfailed: int = 0,\n    ) -> None:\n        \"\"\"Assert that the specified outcomes appear with the respective\n        numbers (0 means it didn't occur) in the text output from a test run.\n        \"\"\"\n        __tracebackhide__ = True\n\n        d = self.parseoutcomes()\n        obtained = {\n            \"passed\": d.get(\"passed\", 0),\n            \"skipped\": d.get(\"skipped\", 0),\n            \"failed\": d.get(\"failed\", 0),\n            \"error\": d.get(\"error\", 0),\n            \"xpassed\": d.get(\"xpassed\", 0),\n            \"xfailed\": d.get(\"xfailed\", 0),\n        }\n        expected = {\n            \"passed\": passed,\n            \"skipped\": skipped,\n            \"failed\": failed,\n            \"error\": error,\n            \"xpassed\": xpassed,\n            \"xfailed\": xfailed,\n        }\n        assert obtained == expected"}, {"id": "_pytest.pytester.RunResult.__init__", "kind": "function", "range": [418, 4, 443, 33, 12787, 13722], "file_path": "src/_pytest/pytester.py", "content": "def __init__(\n        self,\n        ret: Union[int, ExitCode],\n        outlines: List[str],\n        errlines: List[str],\n        duration: float,\n    ) -> None:\n        try:\n            self.ret = pytest.ExitCode(ret)  # type: Union[int, ExitCode]\n            \"\"\"the return value\"\"\"\n        except ValueError:\n            self.ret = ret\n        self.outlines = outlines\n        \"\"\"list of lines captured from stdout\"\"\"\n        self.errlines = errlines\n        \"\"\"list of lines captured from stderr\"\"\"\n        self.stdout = LineMatcher(outlines)\n        \"\"\":class:`LineMatcher` of stdout.\n\n        Use e.g. :func:`stdout.str() <LineMatcher.str()>` to reconstruct stdout, or the commonly used\n        :func:`stdout.fnmatch_lines() <LineMatcher.fnmatch_lines()>` method.\n        \"\"\"\n        self.stderr = LineMatcher(errlines)\n        \"\"\":class:`LineMatcher` of stderr\"\"\"\n        self.duration = duration\n        \"\"\"duration in seconds\"\"\""}, {"id": "_pytest.pytester.RunResult.__repr__", "kind": "function", "range": [445, 4, 449, 9, 13728, 13959], "file_path": "src/_pytest/pytester.py", "content": "def __repr__(self) -> str:\n        return (\n            \"<RunResult ret=%s len(stdout.lines)=%d len(stderr.lines)=%d duration=%.2fs>\"\n            % (self.ret, len(self.stdout.lines), len(self.stderr.lines), self.duration)\n        )"}, {"id": "_pytest.pytester.RunResult.parseoutcomes", "kind": "function", "range": [451, 4, 466, 18, 13965, 14604], "file_path": "src/_pytest/pytester.py", "content": "def parseoutcomes(self) -> Dict[str, int]:\n        \"\"\"Return a dictionary of outcomestring->num from parsing the terminal\n        output that the test process produced.\n\n        \"\"\"\n        for line in reversed(self.outlines):\n            if rex_session_duration.search(line):\n                outcomes = rex_outcome.findall(line)\n                ret = {noun: int(count) for (count, noun) in outcomes}\n                break\n        else:\n            raise ValueError(\"Pytest terminal summary report not found\")\n        if \"errors\" in ret:\n            assert \"error\" not in ret\n            ret[\"error\"] = ret.pop(\"errors\")\n        return ret"}, {"id": "_pytest.pytester.RunResult.assert_outcomes", "kind": "function", "range": [468, 4, 499, 35, 14610, 15579], "file_path": "src/_pytest/pytester.py", "content": "def assert_outcomes(\n        self,\n        passed: int = 0,\n        skipped: int = 0,\n        failed: int = 0,\n        error: int = 0,\n        xpassed: int = 0,\n        xfailed: int = 0,\n    ) -> None:\n        \"\"\"Assert that the specified outcomes appear with the respective\n        numbers (0 means it didn't occur) in the text output from a test run.\n        \"\"\"\n        __tracebackhide__ = True\n\n        d = self.parseoutcomes()\n        obtained = {\n            \"passed\": d.get(\"passed\", 0),\n            \"skipped\": d.get(\"skipped\", 0),\n            \"failed\": d.get(\"failed\", 0),\n            \"error\": d.get(\"error\", 0),\n            \"xpassed\": d.get(\"xpassed\", 0),\n            \"xfailed\": d.get(\"xfailed\", 0),\n        }\n        expected = {\n            \"passed\": passed,\n            \"skipped\": skipped,\n            \"failed\": failed,\n            \"error\": error,\n            \"xpassed\": xpassed,\n            \"xfailed\": xfailed,\n        }\n        assert obtained == expected"}, {"id": "_pytest.pytester.CwdSnapshot", "kind": "class", "range": [502, 0, 507, 30, 15582, 15730], "file_path": "src/_pytest/pytester.py", "content": "class CwdSnapshot:\n    def __init__(self) -> None:\n        self.__saved = os.getcwd()\n\n    def restore(self) -> None:\n        os.chdir(self.__saved)"}, {"id": "_pytest.pytester.CwdSnapshot.__init__", "kind": "function", "range": [503, 4, 504, 34, 15605, 15667], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self) -> None:\n        self.__saved = os.getcwd()"}, {"id": "_pytest.pytester.CwdSnapshot.restore", "kind": "function", "range": [506, 4, 507, 30, 15673, 15730], "file_path": "src/_pytest/pytester.py", "content": "def restore(self) -> None:\n        os.chdir(self.__saved)"}, {"id": "_pytest.pytester.SysModulesSnapshot", "kind": "class", "range": [510, 0, 521, 40, 15733, 16161], "file_path": "src/_pytest/pytester.py", "content": "class SysModulesSnapshot:\n    def __init__(self, preserve: Optional[Callable[[str], bool]] = None):\n        self.__preserve = preserve\n        self.__saved = dict(sys.modules)\n\n    def restore(self) -> None:\n        if self.__preserve:\n            self.__saved.update(\n                (k, m) for k, m in sys.modules.items() if self.__preserve(k)\n            )\n        sys.modules.clear()\n        sys.modules.update(self.__saved)"}, {"id": "_pytest.pytester.SysModulesSnapshot.__init__", "kind": "function", "range": [511, 4, 513, 40, 15763, 15908], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self, preserve: Optional[Callable[[str], bool]] = None):\n        self.__preserve = preserve\n        self.__saved = dict(sys.modules)"}, {"id": "_pytest.pytester.SysModulesSnapshot.restore", "kind": "function", "range": [515, 4, 521, 40, 15914, 16161], "file_path": "src/_pytest/pytester.py", "content": "def restore(self) -> None:\n        if self.__preserve:\n            self.__saved.update(\n                (k, m) for k, m in sys.modules.items() if self.__preserve(k)\n            )\n        sys.modules.clear()\n        sys.modules.update(self.__saved)"}, {"id": "_pytest.pytester.SysPathsSnapshot", "kind": "class", "range": [524, 0, 529, 52, 16164, 16363], "file_path": "src/_pytest/pytester.py", "content": "class SysPathsSnapshot:\n    def __init__(self) -> None:\n        self.__saved = list(sys.path), list(sys.meta_path)\n\n    def restore(self) -> None:\n        sys.path[:], sys.meta_path[:] = self.__saved"}, {"id": "_pytest.pytester.SysPathsSnapshot.__init__", "kind": "function", "range": [525, 4, 526, 58, 16192, 16278], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self) -> None:\n        self.__saved = list(sys.path), list(sys.meta_path)"}, {"id": "_pytest.pytester.SysPathsSnapshot.restore", "kind": "function", "range": [528, 4, 529, 52, 16284, 16363], "file_path": "src/_pytest/pytester.py", "content": "def restore(self) -> None:\n        sys.path[:], sys.meta_path[:] = self.__saved"}, {"id": "_pytest.pytester.Testdir", "kind": "class", "range": [532, 0, 1300, 20, 16366, 44351], "file_path": "src/_pytest/pytester.py", "content": "class Testdir:\n    \"\"\"Temporary test directory with tools to test/run pytest itself.\n\n    This is based on the ``tmpdir`` fixture but provides a number of methods\n    which aid with testing pytest itself.  Unless :py:meth:`chdir` is used all\n    methods will use :py:attr:`tmpdir` as their current working directory.\n\n    Attributes:\n\n    :ivar tmpdir: The :py:class:`py.path.local` instance of the temporary directory.\n\n    :ivar plugins: A list of plugins to use with :py:meth:`parseconfig` and\n       :py:meth:`runpytest`.  Initially this is an empty list but plugins can\n       be added to the list.  The type of items to add to the list depends on\n       the method using them so refer to them for details.\n\n    \"\"\"\n\n    __test__ = False\n\n    CLOSE_STDIN = object\n\n    class TimeoutExpired(Exception):\n        pass\n\n    def __init__(self, request: FixtureRequest, tmpdir_factory: TempdirFactory) -> None:\n        self.request = request\n        self._mod_collections = (\n            WeakKeyDictionary()\n        )  # type: WeakKeyDictionary[Module, List[Union[Item, Collector]]]\n        if request.function:\n            name = request.function.__name__  # type: str\n        else:\n            name = request.node.name\n        self._name = name\n        self.tmpdir = tmpdir_factory.mktemp(name, numbered=True)\n        self.test_tmproot = tmpdir_factory.mktemp(\"tmp-\" + name, numbered=True)\n        self.plugins = []  # type: List[Union[str, _PluggyPlugin]]\n        self._cwd_snapshot = CwdSnapshot()\n        self._sys_path_snapshot = SysPathsSnapshot()\n        self._sys_modules_snapshot = self.__take_sys_modules_snapshot()\n        self.chdir()\n        self.request.addfinalizer(self.finalize)\n        self._method = self.request.config.getoption(\"--runpytest\")\n\n        mp = self.monkeypatch = MonkeyPatch()\n        mp.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(self.test_tmproot))\n        # Ensure no unexpected caching via tox.\n        mp.delenv(\"TOX_ENV_DIR\", raising=False)\n        # Discard outer pytest options.\n        mp.delenv(\"PYTEST_ADDOPTS\", raising=False)\n        # Ensure no user config is used.\n        tmphome = str(self.tmpdir)\n        mp.setenv(\"HOME\", tmphome)\n        mp.setenv(\"USERPROFILE\", tmphome)\n        # Do not use colors for inner runs by default.\n        mp.setenv(\"PY_COLORS\", \"0\")\n\n    def __repr__(self):\n        return \"<Testdir {!r}>\".format(self.tmpdir)\n\n    def __str__(self):\n        return str(self.tmpdir)\n\n    def finalize(self):\n        \"\"\"Clean up global state artifacts.\n\n        Some methods modify the global interpreter state and this tries to\n        clean this up.  It does not remove the temporary directory however so\n        it can be looked at after the test run has finished.\n\n        \"\"\"\n        self._sys_modules_snapshot.restore()\n        self._sys_path_snapshot.restore()\n        self._cwd_snapshot.restore()\n        self.monkeypatch.undo()\n\n    def __take_sys_modules_snapshot(self):\n        # some zope modules used by twisted-related tests keep internal state\n        # and can't be deleted; we had some trouble in the past with\n        # `zope.interface` for example\n        def preserve_module(name):\n            return name.startswith(\"zope\")\n\n        return SysModulesSnapshot(preserve=preserve_module)\n\n    def make_hook_recorder(self, pluginmanager):\n        \"\"\"Create a new :py:class:`HookRecorder` for a PluginManager.\"\"\"\n        pluginmanager.reprec = reprec = HookRecorder(pluginmanager)\n        self.request.addfinalizer(reprec.finish_recording)\n        return reprec\n\n    def chdir(self):\n        \"\"\"Cd into the temporary directory.\n\n        This is done automatically upon instantiation.\n\n        \"\"\"\n        self.tmpdir.chdir()\n\n    def _makefile(self, ext, lines, files, encoding=\"utf-8\"):\n        items = list(files.items())\n\n        def to_text(s):\n            return s.decode(encoding) if isinstance(s, bytes) else str(s)\n\n        if lines:\n            source = \"\\n\".join(to_text(x) for x in lines)\n            basename = self._name\n            items.insert(0, (basename, source))\n\n        ret = None\n        for basename, value in items:\n            p = self.tmpdir.join(basename).new(ext=ext)\n            p.dirpath().ensure_dir()\n            source = Source(value)\n            source = \"\\n\".join(to_text(line) for line in source.lines)\n            p.write(source.strip().encode(encoding), \"wb\")\n            if ret is None:\n                ret = p\n        return ret\n\n    def makefile(self, ext, *args, **kwargs):\n        r\"\"\"Create new file(s) in the testdir.\n\n        :param str ext: The extension the file(s) should use, including the dot, e.g. `.py`.\n        :param list[str] args: All args will be treated as strings and joined using newlines.\n           The result will be written as contents to the file.  The name of the\n           file will be based on the test function requesting this fixture.\n        :param kwargs: Each keyword is the name of a file, while the value of it will\n           be written as contents of the file.\n\n        Examples:\n\n        .. code-block:: python\n\n            testdir.makefile(\".txt\", \"line1\", \"line2\")\n\n            testdir.makefile(\".ini\", pytest=\"[pytest]\\naddopts=-rs\\n\")\n\n        \"\"\"\n        return self._makefile(ext, args, kwargs)\n\n    def makeconftest(self, source):\n        \"\"\"Write a contest.py file with 'source' as contents.\"\"\"\n        return self.makepyfile(conftest=source)\n\n    def makeini(self, source):\n        \"\"\"Write a tox.ini file with 'source' as contents.\"\"\"\n        return self.makefile(\".ini\", tox=source)\n\n    def getinicfg(self, source):\n        \"\"\"Return the pytest section from the tox.ini config file.\"\"\"\n        p = self.makeini(source)\n        return py.iniconfig.IniConfig(p)[\"pytest\"]\n\n    def makepyfile(self, *args, **kwargs):\n        \"\"\"Shortcut for .makefile() with a .py extension.\"\"\"\n        return self._makefile(\".py\", args, kwargs)\n\n    def maketxtfile(self, *args, **kwargs):\n        \"\"\"Shortcut for .makefile() with a .txt extension.\"\"\"\n        return self._makefile(\".txt\", args, kwargs)\n\n    def syspathinsert(self, path=None):\n        \"\"\"Prepend a directory to sys.path, defaults to :py:attr:`tmpdir`.\n\n        This is undone automatically when this object dies at the end of each\n        test.\n        \"\"\"\n        if path is None:\n            path = self.tmpdir\n\n        self.monkeypatch.syspath_prepend(str(path))\n\n    def mkdir(self, name):\n        \"\"\"Create a new (sub)directory.\"\"\"\n        return self.tmpdir.mkdir(name)\n\n    def mkpydir(self, name):\n        \"\"\"Create a new python package.\n\n        This creates a (sub)directory with an empty ``__init__.py`` file so it\n        gets recognised as a python package.\n\n        \"\"\"\n        p = self.mkdir(name)\n        p.ensure(\"__init__.py\")\n        return p\n\n    def copy_example(self, name=None):\n        \"\"\"Copy file from project's directory into the testdir.\n\n        :param str name: The name of the file to copy.\n        :return: path to the copied directory (inside ``self.tmpdir``).\n\n        \"\"\"\n        import warnings\n        from _pytest.warning_types import PYTESTER_COPY_EXAMPLE\n\n        warnings.warn(PYTESTER_COPY_EXAMPLE, stacklevel=2)\n        example_dir = self.request.config.getini(\"pytester_example_dir\")\n        if example_dir is None:\n            raise ValueError(\"pytester_example_dir is unset, can't copy examples\")\n        example_dir = self.request.config.rootdir.join(example_dir)\n\n        for extra_element in self.request.node.iter_markers(\"pytester_example_path\"):\n            assert extra_element.args\n            example_dir = example_dir.join(*extra_element.args)\n\n        if name is None:\n            func_name = self._name\n            maybe_dir = example_dir / func_name\n            maybe_file = example_dir / (func_name + \".py\")\n\n            if maybe_dir.isdir():\n                example_path = maybe_dir\n            elif maybe_file.isfile():\n                example_path = maybe_file\n            else:\n                raise LookupError(\n                    \"{} cant be found as module or package in {}\".format(\n                        func_name, example_dir.bestrelpath(self.request.config.rootdir)\n                    )\n                )\n        else:\n            example_path = example_dir.join(name)\n\n        if example_path.isdir() and not example_path.join(\"__init__.py\").isfile():\n            example_path.copy(self.tmpdir)\n            return self.tmpdir\n        elif example_path.isfile():\n            result = self.tmpdir.join(example_path.basename)\n            example_path.copy(result)\n            return result\n        else:\n            raise LookupError(\n                'example \"{}\" is not found as a file or directory'.format(example_path)\n            )\n\n    Session = Session\n\n    def getnode(self, config, arg):\n        \"\"\"Return the collection node of a file.\n\n        :param config: :py:class:`_pytest.config.Config` instance, see\n           :py:meth:`parseconfig` and :py:meth:`parseconfigure` to create the\n           configuration\n\n        :param arg: a :py:class:`py.path.local` instance of the file\n\n        \"\"\"\n        session = Session.from_config(config)\n        assert \"::\" not in str(arg)\n        p = py.path.local(arg)\n        config.hook.pytest_sessionstart(session=session)\n        res = session.perform_collect([str(p)], genitems=False)[0]\n        config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)\n        return res\n\n    def getpathnode(self, path):\n        \"\"\"Return the collection node of a file.\n\n        This is like :py:meth:`getnode` but uses :py:meth:`parseconfigure` to\n        create the (configured) pytest Config instance.\n\n        :param path: a :py:class:`py.path.local` instance of the file\n\n        \"\"\"\n        config = self.parseconfigure(path)\n        session = Session.from_config(config)\n        x = session.fspath.bestrelpath(path)\n        config.hook.pytest_sessionstart(session=session)\n        res = session.perform_collect([x], genitems=False)[0]\n        config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)\n        return res\n\n    def genitems(self, colitems):\n        \"\"\"Generate all test items from a collection node.\n\n        This recurses into the collection node and returns a list of all the\n        test items contained within.\n\n        \"\"\"\n        session = colitems[0].session\n        result = []\n        for colitem in colitems:\n            result.extend(session.genitems(colitem))\n        return result\n\n    def runitem(self, source):\n        \"\"\"Run the \"test_func\" Item.\n\n        The calling test instance (class containing the test method) must\n        provide a ``.getrunner()`` method which should return a runner which\n        can run the test protocol for a single item, e.g.\n        :py:func:`_pytest.runner.runtestprotocol`.\n\n        \"\"\"\n        # used from runner functional tests\n        item = self.getitem(source)\n        # the test class where we are called from wants to provide the runner\n        testclassinstance = self.request.instance\n        runner = testclassinstance.getrunner()\n        return runner(item)\n\n    def inline_runsource(self, source, *cmdlineargs):\n        \"\"\"Run a test module in process using ``pytest.main()``.\n\n        This run writes \"source\" into a temporary file and runs\n        ``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance\n        for the result.\n\n        :param source: the source code of the test module\n\n        :param cmdlineargs: any extra command line arguments to use\n\n        :return: :py:class:`HookRecorder` instance of the result\n\n        \"\"\"\n        p = self.makepyfile(source)\n        values = list(cmdlineargs) + [p]\n        return self.inline_run(*values)\n\n    def inline_genitems(self, *args):\n        \"\"\"Run ``pytest.main(['--collectonly'])`` in-process.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself like :py:meth:`inline_run`, but returns a\n        tuple of the collected items and a :py:class:`HookRecorder` instance.\n\n        \"\"\"\n        rec = self.inline_run(\"--collect-only\", *args)\n        items = [x.item for x in rec.getcalls(\"pytest_itemcollected\")]\n        return items, rec\n\n    def inline_run(self, *args, plugins=(), no_reraise_ctrlc: bool = False):\n        \"\"\"Run ``pytest.main()`` in-process, returning a HookRecorder.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself.  This means it can return a\n        :py:class:`HookRecorder` instance which gives more detailed results\n        from that run than can be done by matching stdout/stderr from\n        :py:meth:`runpytest`.\n\n        :param args: command line arguments to pass to :py:func:`pytest.main`\n\n        :kwarg plugins: extra plugin instances the ``pytest.main()`` instance should use.\n\n        :kwarg no_reraise_ctrlc: typically we reraise keyboard interrupts from the child run. If\n            True, the KeyboardInterrupt exception is captured.\n\n        :return: a :py:class:`HookRecorder` instance\n        \"\"\"\n        # (maybe a cpython bug?) the importlib cache sometimes isn't updated\n        # properly between file creation and inline_run (especially if imports\n        # are interspersed with file creation)\n        importlib.invalidate_caches()\n\n        plugins = list(plugins)\n        finalizers = []\n        try:\n            # Any sys.module or sys.path changes done while running pytest\n            # inline should be reverted after the test run completes to avoid\n            # clashing with later inline tests run within the same pytest test,\n            # e.g. just because they use matching test module names.\n            finalizers.append(self.__take_sys_modules_snapshot().restore)\n            finalizers.append(SysPathsSnapshot().restore)\n\n            # Important note:\n            # - our tests should not leave any other references/registrations\n            #   laying around other than possibly loaded test modules\n            #   referenced from sys.modules, as nothing will clean those up\n            #   automatically\n\n            rec = []\n\n            class Collect:\n                def pytest_configure(x, config):\n                    rec.append(self.make_hook_recorder(config.pluginmanager))\n\n            plugins.append(Collect())\n            ret = pytest.main(list(args), plugins=plugins)\n            if len(rec) == 1:\n                reprec = rec.pop()\n            else:\n\n                class reprec:  # type: ignore\n                    pass\n\n            reprec.ret = ret\n\n            # typically we reraise keyboard interrupts from the child run\n            # because it's our user requesting interruption of the testing\n            if ret == ExitCode.INTERRUPTED and not no_reraise_ctrlc:\n                calls = reprec.getcalls(\"pytest_keyboard_interrupt\")\n                if calls and calls[-1].excinfo.type == KeyboardInterrupt:\n                    raise KeyboardInterrupt()\n            return reprec\n        finally:\n            for finalizer in finalizers:\n                finalizer()\n\n    def runpytest_inprocess(self, *args, **kwargs) -> RunResult:\n        \"\"\"Return result of running pytest in-process, providing a similar\n        interface to what self.runpytest() provides.\n        \"\"\"\n        syspathinsert = kwargs.pop(\"syspathinsert\", False)\n\n        if syspathinsert:\n            self.syspathinsert()\n        now = time.time()\n        capture = MultiCapture(Capture=SysCapture)\n        capture.start_capturing()\n        try:\n            try:\n                reprec = self.inline_run(*args, **kwargs)\n            except SystemExit as e:\n                ret = e.args[0]\n                try:\n                    ret = ExitCode(e.args[0])\n                except ValueError:\n                    pass\n\n                class reprec:  # type: ignore\n                    ret = ret\n\n            except Exception:\n                traceback.print_exc()\n\n                class reprec:  # type: ignore\n                    ret = ExitCode(3)\n\n        finally:\n            out, err = capture.readouterr()\n            capture.stop_capturing()\n            sys.stdout.write(out)\n            sys.stderr.write(err)\n\n        res = RunResult(\n            reprec.ret, out.splitlines(), err.splitlines(), time.time() - now\n        )\n        res.reprec = reprec  # type: ignore\n        return res\n\n    def runpytest(self, *args, **kwargs) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`RunResult`.\n\n        \"\"\"\n        args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*args, **kwargs)\n        raise RuntimeError(\"Unrecognized runpytest option: {}\".format(self._method))\n\n    def _ensure_basetemp(self, args):\n        args = list(args)\n        for x in args:\n            if str(x).startswith(\"--basetemp\"):\n                break\n        else:\n            args.append(\"--basetemp=%s\" % self.tmpdir.dirpath(\"basetemp\"))\n        return args\n\n    def parseconfig(self, *args: Union[str, py.path.local]) -> Config:\n        \"\"\"Return a new pytest Config instance from given commandline args.\n\n        This invokes the pytest bootstrapping code in _pytest.config to create\n        a new :py:class:`_pytest.core.PluginManager` and call the\n        pytest_cmdline_parse hook to create a new\n        :py:class:`_pytest.config.Config` instance.\n\n        If :py:attr:`plugins` has been populated they should be plugin modules\n        to be registered with the PluginManager.\n\n        \"\"\"\n        args = self._ensure_basetemp(args)\n\n        import _pytest.config\n\n        config = _pytest.config._prepareconfig(args, self.plugins)  # type: Config\n        # we don't know what the test will do with this half-setup config\n        # object and thus we make sure it gets unconfigured properly in any\n        # case (otherwise capturing could still be active, for example)\n        self.request.addfinalizer(config._ensure_unconfigure)\n        return config\n\n    def parseconfigure(self, *args):\n        \"\"\"Return a new pytest configured Config instance.\n\n        This returns a new :py:class:`_pytest.config.Config` instance like\n        :py:meth:`parseconfig`, but also calls the pytest_configure hook.\n        \"\"\"\n        config = self.parseconfig(*args)\n        config._do_configure()\n        return config\n\n    def getitem(self, source, funcname=\"test_func\"):\n        \"\"\"Return the test item for a test function.\n\n        This writes the source to a python file and runs pytest's collection on\n        the resulting module, returning the test item for the requested\n        function name.\n\n        :param source: the module source\n\n        :param funcname: the name of the test function for which to return a\n            test item\n\n        \"\"\"\n        items = self.getitems(source)\n        for item in items:\n            if item.name == funcname:\n                return item\n        assert 0, \"{!r} item not found in module:\\n{}\\nitems: {}\".format(\n            funcname, source, items\n        )\n\n    def getitems(self, source):\n        \"\"\"Return all test items collected from the module.\n\n        This writes the source to a python file and runs pytest's collection on\n        the resulting module, returning all test items contained within.\n\n        \"\"\"\n        modcol = self.getmodulecol(source)\n        return self.genitems([modcol])\n\n    def getmodulecol(self, source, configargs=(), withinit=False):\n        \"\"\"Return the module collection node for ``source``.\n\n        This writes ``source`` to a file using :py:meth:`makepyfile` and then\n        runs the pytest collection on it, returning the collection node for the\n        test module.\n\n        :param source: the source code of the module to collect\n\n        :param configargs: any extra arguments to pass to\n            :py:meth:`parseconfigure`\n\n        :param withinit: whether to also write an ``__init__.py`` file to the\n            same directory to ensure it is a package\n\n        \"\"\"\n        if isinstance(source, Path):\n            path = self.tmpdir.join(str(source))\n            assert not withinit, \"not supported for paths\"\n        else:\n            kw = {self._name: Source(source).strip()}\n            path = self.makepyfile(**kw)\n        if withinit:\n            self.makepyfile(__init__=\"#\")\n        self.config = config = self.parseconfigure(path, *configargs)\n        return self.getnode(config, path)\n\n    def collect_by_name(\n        self, modcol: Module, name: str\n    ) -> Optional[Union[Item, Collector]]:\n        \"\"\"Return the collection node for name from the module collection.\n\n        This will search a module collection node for a collection node\n        matching the given name.\n\n        :param modcol: a module collection node; see :py:meth:`getmodulecol`\n\n        :param name: the name of the node to return\n        \"\"\"\n        if modcol not in self._mod_collections:\n            self._mod_collections[modcol] = list(modcol.collect())\n        for colitem in self._mod_collections[modcol]:\n            if colitem.name == name:\n                return colitem\n        return None\n\n    def popen(\n        self,\n        cmdargs,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        stdin=CLOSE_STDIN,\n        **kw\n    ):\n        \"\"\"Invoke subprocess.Popen.\n\n        This calls subprocess.Popen making sure the current working directory\n        is in the PYTHONPATH.\n\n        You probably want to use :py:meth:`run` instead.\n\n        \"\"\"\n        env = os.environ.copy()\n        env[\"PYTHONPATH\"] = os.pathsep.join(\n            filter(None, [os.getcwd(), env.get(\"PYTHONPATH\", \"\")])\n        )\n        kw[\"env\"] = env\n\n        if stdin is Testdir.CLOSE_STDIN:\n            kw[\"stdin\"] = subprocess.PIPE\n        elif isinstance(stdin, bytes):\n            kw[\"stdin\"] = subprocess.PIPE\n        else:\n            kw[\"stdin\"] = stdin\n\n        popen = subprocess.Popen(cmdargs, stdout=stdout, stderr=stderr, **kw)\n        if stdin is Testdir.CLOSE_STDIN:\n            popen.stdin.close()\n        elif isinstance(stdin, bytes):\n            popen.stdin.write(stdin)\n\n        return popen\n\n    def run(self, *cmdargs, timeout=None, stdin=CLOSE_STDIN) -> RunResult:\n        \"\"\"Run a command with arguments.\n\n        Run a process using subprocess.Popen saving the stdout and stderr.\n\n        :param args: the sequence of arguments to pass to `subprocess.Popen()`\n        :kwarg timeout: the period in seconds after which to timeout and raise\n            :py:class:`Testdir.TimeoutExpired`\n        :kwarg stdin: optional standard input.  Bytes are being send, closing\n            the pipe, otherwise it is passed through to ``popen``.\n            Defaults to ``CLOSE_STDIN``, which translates to using a pipe\n            (``subprocess.PIPE``) that gets closed.\n\n        Returns a :py:class:`RunResult`.\n\n        \"\"\"\n        __tracebackhide__ = True\n\n        cmdargs = tuple(\n            str(arg) if isinstance(arg, py.path.local) else arg for arg in cmdargs\n        )\n        p1 = self.tmpdir.join(\"stdout\")\n        p2 = self.tmpdir.join(\"stderr\")\n        print(\"running:\", *cmdargs)\n        print(\"     in:\", py.path.local())\n        f1 = open(str(p1), \"w\", encoding=\"utf8\")\n        f2 = open(str(p2), \"w\", encoding=\"utf8\")\n        try:\n            now = time.time()\n            popen = self.popen(\n                cmdargs,\n                stdin=stdin,\n                stdout=f1,\n                stderr=f2,\n                close_fds=(sys.platform != \"win32\"),\n            )\n            if isinstance(stdin, bytes):\n                popen.stdin.close()\n\n            def handle_timeout():\n                __tracebackhide__ = True\n\n                timeout_message = (\n                    \"{seconds} second timeout expired running:\"\n                    \" {command}\".format(seconds=timeout, command=cmdargs)\n                )\n\n                popen.kill()\n                popen.wait()\n                raise self.TimeoutExpired(timeout_message)\n\n            if timeout is None:\n                ret = popen.wait()\n            else:\n                try:\n                    ret = popen.wait(timeout)\n                except subprocess.TimeoutExpired:\n                    handle_timeout()\n        finally:\n            f1.close()\n            f2.close()\n        f1 = open(str(p1), encoding=\"utf8\")\n        f2 = open(str(p2), encoding=\"utf8\")\n        try:\n            out = f1.read().splitlines()\n            err = f2.read().splitlines()\n        finally:\n            f1.close()\n            f2.close()\n        self._dump_lines(out, sys.stdout)\n        self._dump_lines(err, sys.stderr)\n        try:\n            ret = ExitCode(ret)\n        except ValueError:\n            pass\n        return RunResult(ret, out, err, time.time() - now)\n\n    def _dump_lines(self, lines, fp):\n        try:\n            for line in lines:\n                print(line, file=fp)\n        except UnicodeEncodeError:\n            print(\"couldn't print to {} because of encoding\".format(fp))\n\n    def _getpytestargs(self):\n        return sys.executable, \"-mpytest\"\n\n    def runpython(self, script) -> RunResult:\n        \"\"\"Run a python script using sys.executable as interpreter.\n\n        Returns a :py:class:`RunResult`.\n\n        \"\"\"\n        return self.run(sys.executable, script)\n\n    def runpython_c(self, command):\n        \"\"\"Run python -c \"command\", return a :py:class:`RunResult`.\"\"\"\n        return self.run(sys.executable, \"-c\", command)\n\n    def runpytest_subprocess(self, *args, timeout=None) -> RunResult:\n        \"\"\"Run pytest as a subprocess with given arguments.\n\n        Any plugins added to the :py:attr:`plugins` list will be added using the\n        ``-p`` command line option.  Additionally ``--basetemp`` is used to put\n        any temporary files and directories in a numbered directory prefixed\n        with \"runpytest-\" to not conflict with the normal numbered pytest\n        location for temporary files and directories.\n\n        :param args: the sequence of arguments to pass to the pytest subprocess\n        :param timeout: the period in seconds after which to timeout and raise\n            :py:class:`Testdir.TimeoutExpired`\n\n        Returns a :py:class:`RunResult`.\n        \"\"\"\n        __tracebackhide__ = True\n        p = make_numbered_dir(root=Path(self.tmpdir), prefix=\"runpytest-\")\n        args = (\"--basetemp=%s\" % p,) + args\n        plugins = [x for x in self.plugins if isinstance(x, str)]\n        if plugins:\n            args = (\"-p\", plugins[0]) + args\n        args = self._getpytestargs() + args\n        return self.run(*args, timeout=timeout)\n\n    def spawn_pytest(\n        self, string: str, expect_timeout: float = 10.0\n    ) -> \"pexpect.spawn\":\n        \"\"\"Run pytest using pexpect.\n\n        This makes sure to use the right pytest and sets up the temporary\n        directory locations.\n\n        The pexpect child is returned.\n\n        \"\"\"\n        basetemp = self.tmpdir.mkdir(\"temp-pexpect\")\n        invoke = \" \".join(map(str, self._getpytestargs()))\n        cmd = \"{} --basetemp={} {}\".format(invoke, basetemp, string)\n        return self.spawn(cmd, expect_timeout=expect_timeout)\n\n    def spawn(self, cmd: str, expect_timeout: float = 10.0) -> \"pexpect.spawn\":\n        \"\"\"Run a command using pexpect.\n\n        The pexpect child is returned.\n\n        \"\"\"\n        pexpect = pytest.importorskip(\"pexpect\", \"3.0\")\n        if hasattr(sys, \"pypy_version_info\") and \"64\" in platform.machine():\n            pytest.skip(\"pypy-64 bit not supported\")\n        if not hasattr(pexpect, \"spawn\"):\n            pytest.skip(\"pexpect.spawn not available\")\n        logfile = self.tmpdir.join(\"spawn.out\").open(\"wb\")\n\n        child = pexpect.spawn(cmd, logfile=logfile)\n        self.request.addfinalizer(logfile.close)\n        child.timeout = expect_timeout\n        return child"}, {"id": "_pytest.pytester.Testdir.__test__", "kind": "variable", "range": [550, 4, 550, 20, 17092, 17108], "file_path": "src/_pytest/pytester.py", "content": "__test__ = False"}, {"id": "_pytest.pytester.Testdir.CLOSE_STDIN", "kind": "variable", "range": [552, 4, 552, 24, 17114, 17134], "file_path": "src/_pytest/pytester.py", "content": "CLOSE_STDIN = object"}, {"id": "_pytest.pytester.Testdir.TimeoutExpired", "kind": "class", "range": [554, 4, 555, 12, 17140, 17185], "file_path": "src/_pytest/pytester.py", "content": "class TimeoutExpired(Exception):\n        pass"}, {"id": "_pytest.pytester.Testdir.__init__", "kind": "function", "range": [557, 4, 588, 35, 17191, 18674], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self, request: FixtureRequest, tmpdir_factory: TempdirFactory) -> None:\n        self.request = request\n        self._mod_collections = (\n            WeakKeyDictionary()\n        )  # type: WeakKeyDictionary[Module, List[Union[Item, Collector]]]\n        if request.function:\n            name = request.function.__name__  # type: str\n        else:\n            name = request.node.name\n        self._name = name\n        self.tmpdir = tmpdir_factory.mktemp(name, numbered=True)\n        self.test_tmproot = tmpdir_factory.mktemp(\"tmp-\" + name, numbered=True)\n        self.plugins = []  # type: List[Union[str, _PluggyPlugin]]\n        self._cwd_snapshot = CwdSnapshot()\n        self._sys_path_snapshot = SysPathsSnapshot()\n        self._sys_modules_snapshot = self.__take_sys_modules_snapshot()\n        self.chdir()\n        self.request.addfinalizer(self.finalize)\n        self._method = self.request.config.getoption(\"--runpytest\")\n\n        mp = self.monkeypatch = MonkeyPatch()\n        mp.setenv(\"PYTEST_DEBUG_TEMPROOT\", str(self.test_tmproot))\n        # Ensure no unexpected caching via tox.\n        mp.delenv(\"TOX_ENV_DIR\", raising=False)\n        # Discard outer pytest options.\n        mp.delenv(\"PYTEST_ADDOPTS\", raising=False)\n        # Ensure no user config is used.\n        tmphome = str(self.tmpdir)\n        mp.setenv(\"HOME\", tmphome)\n        mp.setenv(\"USERPROFILE\", tmphome)\n        # Do not use colors for inner runs by default.\n        mp.setenv(\"PY_COLORS\", \"0\")"}, {"id": "_pytest.pytester.Testdir.__repr__", "kind": "function", "range": [590, 4, 591, 51, 18680, 18751], "file_path": "src/_pytest/pytester.py", "content": "def __repr__(self):\n        return \"<Testdir {!r}>\".format(self.tmpdir)"}, {"id": "_pytest.pytester.Testdir.__str__", "kind": "function", "range": [593, 4, 594, 31, 18757, 18807], "file_path": "src/_pytest/pytester.py", "content": "def __str__(self):\n        return str(self.tmpdir)"}, {"id": "_pytest.pytester.Testdir.finalize", "kind": "function", "range": [596, 4, 607, 31, 18813, 19260], "file_path": "src/_pytest/pytester.py", "content": "def finalize(self):\n        \"\"\"Clean up global state artifacts.\n\n        Some methods modify the global interpreter state and this tries to\n        clean this up.  It does not remove the temporary directory however so\n        it can be looked at after the test run has finished.\n\n        \"\"\"\n        self._sys_modules_snapshot.restore()\n        self._sys_path_snapshot.restore()\n        self._cwd_snapshot.restore()\n        self.monkeypatch.undo()"}, {"id": "_pytest.pytester.Testdir.__take_sys_modules_snapshot", "kind": "function", "range": [609, 4, 616, 59, 19266, 19629], "file_path": "src/_pytest/pytester.py", "content": "def __take_sys_modules_snapshot(self):\n        # some zope modules used by twisted-related tests keep internal state\n        # and can't be deleted; we had some trouble in the past with\n        # `zope.interface` for example\n        def preserve_module(name):\n            return name.startswith(\"zope\")\n\n        return SysModulesSnapshot(preserve=preserve_module)"}, {"id": "_pytest.pytester.Testdir.make_hook_recorder", "kind": "function", "range": [618, 4, 622, 21, 19635, 19901], "file_path": "src/_pytest/pytester.py", "content": "def make_hook_recorder(self, pluginmanager):\n        \"\"\"Create a new :py:class:`HookRecorder` for a PluginManager.\"\"\"\n        pluginmanager.reprec = reprec = HookRecorder(pluginmanager)\n        self.request.addfinalizer(reprec.finish_recording)\n        return reprec"}, {"id": "_pytest.pytester.Testdir.chdir", "kind": "function", "range": [624, 4, 630, 27, 19907, 20064], "file_path": "src/_pytest/pytester.py", "content": "def chdir(self):\n        \"\"\"Cd into the temporary directory.\n\n        This is done automatically upon instantiation.\n\n        \"\"\"\n        self.tmpdir.chdir()"}, {"id": "_pytest.pytester.Testdir._makefile", "kind": "function", "range": [632, 4, 652, 18, 20070, 20808], "file_path": "src/_pytest/pytester.py", "content": "def _makefile(self, ext, lines, files, encoding=\"utf-8\"):\n        items = list(files.items())\n\n        def to_text(s):\n            return s.decode(encoding) if isinstance(s, bytes) else str(s)\n\n        if lines:\n            source = \"\\n\".join(to_text(x) for x in lines)\n            basename = self._name\n            items.insert(0, (basename, source))\n\n        ret = None\n        for basename, value in items:\n            p = self.tmpdir.join(basename).new(ext=ext)\n            p.dirpath().ensure_dir()\n            source = Source(value)\n            source = \"\\n\".join(to_text(line) for line in source.lines)\n            p.write(source.strip().encode(encoding), \"wb\")\n            if ret is None:\n                ret = p\n        return ret"}, {"id": "_pytest.pytester.Testdir.makefile", "kind": "function", "range": [654, 4, 673, 48, 20814, 21620], "file_path": "src/_pytest/pytester.py", "content": "def makefile(self, ext, *args, **kwargs):\n        r\"\"\"Create new file(s) in the testdir.\n\n        :param str ext: The extension the file(s) should use, including the dot, e.g. `.py`.\n        :param list[str] args: All args will be treated as strings and joined using newlines.\n           The result will be written as contents to the file.  The name of the\n           file will be based on the test function requesting this fixture.\n        :param kwargs: Each keyword is the name of a file, while the value of it will\n           be written as contents of the file.\n\n        Examples:\n\n        .. code-block:: python\n\n            testdir.makefile(\".txt\", \"line1\", \"line2\")\n\n            testdir.makefile(\".ini\", pytest=\"[pytest]\\naddopts=-rs\\n\")\n\n        \"\"\"\n        return self._makefile(ext, args, kwargs)"}, {"id": "_pytest.pytester.Testdir.makeconftest", "kind": "function", "range": [675, 4, 677, 47, 21626, 21770], "file_path": "src/_pytest/pytester.py", "content": "def makeconftest(self, source):\n        \"\"\"Write a contest.py file with 'source' as contents.\"\"\"\n        return self.makepyfile(conftest=source)"}, {"id": "_pytest.pytester.Testdir.makeini", "kind": "function", "range": [679, 4, 681, 48, 21776, 21913], "file_path": "src/_pytest/pytester.py", "content": "def makeini(self, source):\n        \"\"\"Write a tox.ini file with 'source' as contents.\"\"\"\n        return self.makefile(\".ini\", tox=source)"}, {"id": "_pytest.pytester.Testdir.getinicfg", "kind": "function", "range": [683, 4, 686, 50, 21919, 22101], "file_path": "src/_pytest/pytester.py", "content": "def getinicfg(self, source):\n        \"\"\"Return the pytest section from the tox.ini config file.\"\"\"\n        p = self.makeini(source)\n        return py.iniconfig.IniConfig(p)[\"pytest\"]"}, {"id": "_pytest.pytester.Testdir.makepyfile", "kind": "function", "range": [688, 4, 690, 50, 22107, 22257], "file_path": "src/_pytest/pytester.py", "content": "def makepyfile(self, *args, **kwargs):\n        \"\"\"Shortcut for .makefile() with a .py extension.\"\"\"\n        return self._makefile(\".py\", args, kwargs)"}, {"id": "_pytest.pytester.Testdir.maketxtfile", "kind": "function", "range": [692, 4, 694, 51, 22263, 22416], "file_path": "src/_pytest/pytester.py", "content": "def maketxtfile(self, *args, **kwargs):\n        \"\"\"Shortcut for .makefile() with a .txt extension.\"\"\"\n        return self._makefile(\".txt\", args, kwargs)"}, {"id": "_pytest.pytester.Testdir.syspathinsert", "kind": "function", "range": [696, 4, 705, 51, 22422, 22746], "file_path": "src/_pytest/pytester.py", "content": "def syspathinsert(self, path=None):\n        \"\"\"Prepend a directory to sys.path, defaults to :py:attr:`tmpdir`.\n\n        This is undone automatically when this object dies at the end of each\n        test.\n        \"\"\"\n        if path is None:\n            path = self.tmpdir\n\n        self.monkeypatch.syspath_prepend(str(path))"}, {"id": "_pytest.pytester.Testdir.mkdir", "kind": "function", "range": [707, 4, 709, 38, 22752, 22856], "file_path": "src/_pytest/pytester.py", "content": "def mkdir(self, name):\n        \"\"\"Create a new (sub)directory.\"\"\"\n        return self.tmpdir.mkdir(name)"}, {"id": "_pytest.pytester.Testdir.mkpydir", "kind": "function", "range": [711, 4, 720, 16, 22862, 23142], "file_path": "src/_pytest/pytester.py", "content": "def mkpydir(self, name):\n        \"\"\"Create a new python package.\n\n        This creates a (sub)directory with an empty ``__init__.py`` file so it\n        gets recognised as a python package.\n\n        \"\"\"\n        p = self.mkdir(name)\n        p.ensure(\"__init__.py\")\n        return p"}, {"id": "_pytest.pytester.Testdir.copy_example", "kind": "function", "range": [722, 4, 770, 13, 23148, 25089], "file_path": "src/_pytest/pytester.py", "content": "def copy_example(self, name=None):\n        \"\"\"Copy file from project's directory into the testdir.\n\n        :param str name: The name of the file to copy.\n        :return: path to the copied directory (inside ``self.tmpdir``).\n\n        \"\"\"\n        import warnings\n        from _pytest.warning_types import PYTESTER_COPY_EXAMPLE\n\n        warnings.warn(PYTESTER_COPY_EXAMPLE, stacklevel=2)\n        example_dir = self.request.config.getini(\"pytester_example_dir\")\n        if example_dir is None:\n            raise ValueError(\"pytester_example_dir is unset, can't copy examples\")\n        example_dir = self.request.config.rootdir.join(example_dir)\n\n        for extra_element in self.request.node.iter_markers(\"pytester_example_path\"):\n            assert extra_element.args\n            example_dir = example_dir.join(*extra_element.args)\n\n        if name is None:\n            func_name = self._name\n            maybe_dir = example_dir / func_name\n            maybe_file = example_dir / (func_name + \".py\")\n\n            if maybe_dir.isdir():\n                example_path = maybe_dir\n            elif maybe_file.isfile():\n                example_path = maybe_file\n            else:\n                raise LookupError(\n                    \"{} cant be found as module or package in {}\".format(\n                        func_name, example_dir.bestrelpath(self.request.config.rootdir)\n                    )\n                )\n        else:\n            example_path = example_dir.join(name)\n\n        if example_path.isdir() and not example_path.join(\"__init__.py\").isfile():\n            example_path.copy(self.tmpdir)\n            return self.tmpdir\n        elif example_path.isfile():\n            result = self.tmpdir.join(example_path.basename)\n            example_path.copy(result)\n            return result\n        else:\n            raise LookupError(\n                'example \"{}\" is not found as a file or directory'.format(example_path)\n            )"}, {"id": "_pytest.pytester.Testdir.Session", "kind": "variable", "range": [772, 4, 772, 21, 25095, 25112], "file_path": "src/_pytest/pytester.py", "content": "Session = Session"}, {"id": "_pytest.pytester.Testdir.getnode", "kind": "function", "range": [774, 4, 790, 18, 25118, 25794], "file_path": "src/_pytest/pytester.py", "content": "def getnode(self, config, arg):\n        \"\"\"Return the collection node of a file.\n\n        :param config: :py:class:`_pytest.config.Config` instance, see\n           :py:meth:`parseconfig` and :py:meth:`parseconfigure` to create the\n           configuration\n\n        :param arg: a :py:class:`py.path.local` instance of the file\n\n        \"\"\"\n        session = Session.from_config(config)\n        assert \"::\" not in str(arg)\n        p = py.path.local(arg)\n        config.hook.pytest_sessionstart(session=session)\n        res = session.perform_collect([str(p)], genitems=False)[0]\n        config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)\n        return res"}, {"id": "_pytest.pytester.Testdir.getpathnode", "kind": "function", "range": [792, 4, 807, 18, 25800, 26450], "file_path": "src/_pytest/pytester.py", "content": "def getpathnode(self, path):\n        \"\"\"Return the collection node of a file.\n\n        This is like :py:meth:`getnode` but uses :py:meth:`parseconfigure` to\n        create the (configured) pytest Config instance.\n\n        :param path: a :py:class:`py.path.local` instance of the file\n\n        \"\"\"\n        config = self.parseconfigure(path)\n        session = Session.from_config(config)\n        x = session.fspath.bestrelpath(path)\n        config.hook.pytest_sessionstart(session=session)\n        res = session.perform_collect([x], genitems=False)[0]\n        config.hook.pytest_sessionfinish(session=session, exitstatus=ExitCode.OK)\n        return res"}, {"id": "_pytest.pytester.Testdir.genitems", "kind": "function", "range": [809, 4, 820, 21, 26456, 26838], "file_path": "src/_pytest/pytester.py", "content": "def genitems(self, colitems):\n        \"\"\"Generate all test items from a collection node.\n\n        This recurses into the collection node and returns a list of all the\n        test items contained within.\n\n        \"\"\"\n        session = colitems[0].session\n        result = []\n        for colitem in colitems:\n            result.extend(session.genitems(colitem))\n        return result"}, {"id": "_pytest.pytester.Testdir.runitem", "kind": "function", "range": [822, 4, 836, 27, 26844, 27464], "file_path": "src/_pytest/pytester.py", "content": "def runitem(self, source):\n        \"\"\"Run the \"test_func\" Item.\n\n        The calling test instance (class containing the test method) must\n        provide a ``.getrunner()`` method which should return a runner which\n        can run the test protocol for a single item, e.g.\n        :py:func:`_pytest.runner.runtestprotocol`.\n\n        \"\"\"\n        # used from runner functional tests\n        item = self.getitem(source)\n        # the test class where we are called from wants to provide the runner\n        testclassinstance = self.request.instance\n        runner = testclassinstance.getrunner()\n        return runner(item)"}, {"id": "_pytest.pytester.Testdir.inline_runsource", "kind": "function", "range": [838, 4, 854, 39, 27470, 28076], "file_path": "src/_pytest/pytester.py", "content": "def inline_runsource(self, source, *cmdlineargs):\n        \"\"\"Run a test module in process using ``pytest.main()``.\n\n        This run writes \"source\" into a temporary file and runs\n        ``pytest.main()`` on it, returning a :py:class:`HookRecorder` instance\n        for the result.\n\n        :param source: the source code of the test module\n\n        :param cmdlineargs: any extra command line arguments to use\n\n        :return: :py:class:`HookRecorder` instance of the result\n\n        \"\"\"\n        p = self.makepyfile(source)\n        values = list(cmdlineargs) + [p]\n        return self.inline_run(*values)"}, {"id": "_pytest.pytester.Testdir.inline_genitems", "kind": "function", "range": [856, 4, 866, 25, 28082, 28572], "file_path": "src/_pytest/pytester.py", "content": "def inline_genitems(self, *args):\n        \"\"\"Run ``pytest.main(['--collectonly'])`` in-process.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself like :py:meth:`inline_run`, but returns a\n        tuple of the collected items and a :py:class:`HookRecorder` instance.\n\n        \"\"\"\n        rec = self.inline_run(\"--collect-only\", *args)\n        items = [x.item for x in rec.getcalls(\"pytest_itemcollected\")]\n        return items, rec"}, {"id": "_pytest.pytester.Testdir.inline_run", "kind": "function", "range": [868, 4, 933, 27, 28578, 31443], "file_path": "src/_pytest/pytester.py", "content": "def inline_run(self, *args, plugins=(), no_reraise_ctrlc: bool = False):\n        \"\"\"Run ``pytest.main()`` in-process, returning a HookRecorder.\n\n        Runs the :py:func:`pytest.main` function to run all of pytest inside\n        the test process itself.  This means it can return a\n        :py:class:`HookRecorder` instance which gives more detailed results\n        from that run than can be done by matching stdout/stderr from\n        :py:meth:`runpytest`.\n\n        :param args: command line arguments to pass to :py:func:`pytest.main`\n\n        :kwarg plugins: extra plugin instances the ``pytest.main()`` instance should use.\n\n        :kwarg no_reraise_ctrlc: typically we reraise keyboard interrupts from the child run. If\n            True, the KeyboardInterrupt exception is captured.\n\n        :return: a :py:class:`HookRecorder` instance\n        \"\"\"\n        # (maybe a cpython bug?) the importlib cache sometimes isn't updated\n        # properly between file creation and inline_run (especially if imports\n        # are interspersed with file creation)\n        importlib.invalidate_caches()\n\n        plugins = list(plugins)\n        finalizers = []\n        try:\n            # Any sys.module or sys.path changes done while running pytest\n            # inline should be reverted after the test run completes to avoid\n            # clashing with later inline tests run within the same pytest test,\n            # e.g. just because they use matching test module names.\n            finalizers.append(self.__take_sys_modules_snapshot().restore)\n            finalizers.append(SysPathsSnapshot().restore)\n\n            # Important note:\n            # - our tests should not leave any other references/registrations\n            #   laying around other than possibly loaded test modules\n            #   referenced from sys.modules, as nothing will clean those up\n            #   automatically\n\n            rec = []\n\n            class Collect:\n                def pytest_configure(x, config):\n                    rec.append(self.make_hook_recorder(config.pluginmanager))\n\n            plugins.append(Collect())\n            ret = pytest.main(list(args), plugins=plugins)\n            if len(rec) == 1:\n                reprec = rec.pop()\n            else:\n\n                class reprec:  # type: ignore\n                    pass\n\n            reprec.ret = ret\n\n            # typically we reraise keyboard interrupts from the child run\n            # because it's our user requesting interruption of the testing\n            if ret == ExitCode.INTERRUPTED and not no_reraise_ctrlc:\n                calls = reprec.getcalls(\"pytest_keyboard_interrupt\")\n                if calls and calls[-1].excinfo.type == KeyboardInterrupt:\n                    raise KeyboardInterrupt()\n            return reprec\n        finally:\n            for finalizer in finalizers:\n                finalizer()"}, {"id": "_pytest.pytester.Testdir.runpytest_inprocess", "kind": "function", "range": [935, 4, 975, 18, 31449, 32737], "file_path": "src/_pytest/pytester.py", "content": "def runpytest_inprocess(self, *args, **kwargs) -> RunResult:\n        \"\"\"Return result of running pytest in-process, providing a similar\n        interface to what self.runpytest() provides.\n        \"\"\"\n        syspathinsert = kwargs.pop(\"syspathinsert\", False)\n\n        if syspathinsert:\n            self.syspathinsert()\n        now = time.time()\n        capture = MultiCapture(Capture=SysCapture)\n        capture.start_capturing()\n        try:\n            try:\n                reprec = self.inline_run(*args, **kwargs)\n            except SystemExit as e:\n                ret = e.args[0]\n                try:\n                    ret = ExitCode(e.args[0])\n                except ValueError:\n                    pass\n\n                class reprec:  # type: ignore\n                    ret = ret\n\n            except Exception:\n                traceback.print_exc()\n\n                class reprec:  # type: ignore\n                    ret = ExitCode(3)\n\n        finally:\n            out, err = capture.readouterr()\n            capture.stop_capturing()\n            sys.stdout.write(out)\n            sys.stderr.write(err)\n\n        res = RunResult(\n            reprec.ret, out.splitlines(), err.splitlines(), time.time() - now\n        )\n        res.reprec = reprec  # type: ignore\n        return res"}, {"id": "_pytest.pytester.Testdir.runpytest", "kind": "function", "range": [977, 4, 987, 84, 32743, 33284], "file_path": "src/_pytest/pytester.py", "content": "def runpytest(self, *args, **kwargs) -> RunResult:\n        \"\"\"Run pytest inline or in a subprocess, depending on the command line\n        option \"--runpytest\" and return a :py:class:`RunResult`.\n\n        \"\"\"\n        args = self._ensure_basetemp(args)\n        if self._method == \"inprocess\":\n            return self.runpytest_inprocess(*args, **kwargs)\n        elif self._method == \"subprocess\":\n            return self.runpytest_subprocess(*args, **kwargs)\n        raise RuntimeError(\"Unrecognized runpytest option: {}\".format(self._method))"}, {"id": "_pytest.pytester.Testdir._ensure_basetemp", "kind": "function", "range": [989, 4, 996, 19, 33290, 33551], "file_path": "src/_pytest/pytester.py", "content": "def _ensure_basetemp(self, args):\n        args = list(args)\n        for x in args:\n            if str(x).startswith(\"--basetemp\"):\n                break\n        else:\n            args.append(\"--basetemp=%s\" % self.tmpdir.dirpath(\"basetemp\"))\n        return args"}, {"id": "_pytest.pytester.Testdir.parseconfig", "kind": "function", "range": [998, 4, 1019, 21, 33557, 34553], "file_path": "src/_pytest/pytester.py", "content": "def parseconfig(self, *args: Union[str, py.path.local]) -> Config:\n        \"\"\"Return a new pytest Config instance from given commandline args.\n\n        This invokes the pytest bootstrapping code in _pytest.config to create\n        a new :py:class:`_pytest.core.PluginManager` and call the\n        pytest_cmdline_parse hook to create a new\n        :py:class:`_pytest.config.Config` instance.\n\n        If :py:attr:`plugins` has been populated they should be plugin modules\n        to be registered with the PluginManager.\n\n        \"\"\"\n        args = self._ensure_basetemp(args)\n\n        import _pytest.config\n\n        config = _pytest.config._prepareconfig(args, self.plugins)  # type: Config\n        # we don't know what the test will do with this half-setup config\n        # object and thus we make sure it gets unconfigured properly in any\n        # case (otherwise capturing could still be active, for example)\n        self.request.addfinalizer(config._ensure_unconfigure)\n        return config"}, {"id": "_pytest.pytester.Testdir.parseconfigure", "kind": "function", "range": [1021, 4, 1029, 21, 34559, 34906], "file_path": "src/_pytest/pytester.py", "content": "def parseconfigure(self, *args):\n        \"\"\"Return a new pytest configured Config instance.\n\n        This returns a new :py:class:`_pytest.config.Config` instance like\n        :py:meth:`parseconfig`, but also calls the pytest_configure hook.\n        \"\"\"\n        config = self.parseconfig(*args)\n        config._do_configure()\n        return config"}, {"id": "_pytest.pytester.Testdir.getitem", "kind": "function", "range": [1031, 4, 1050, 9, 34912, 35595], "file_path": "src/_pytest/pytester.py", "content": "def getitem(self, source, funcname=\"test_func\"):\n        \"\"\"Return the test item for a test function.\n\n        This writes the source to a python file and runs pytest's collection on\n        the resulting module, returning the test item for the requested\n        function name.\n\n        :param source: the module source\n\n        :param funcname: the name of the test function for which to return a\n            test item\n\n        \"\"\"\n        items = self.getitems(source)\n        for item in items:\n            if item.name == funcname:\n                return item\n        assert 0, \"{!r} item not found in module:\\n{}\\nitems: {}\".format(\n            funcname, source, items\n        )"}, {"id": "_pytest.pytester.Testdir.getitems", "kind": "function", "range": [1052, 4, 1060, 38, 35601, 35937], "file_path": "src/_pytest/pytester.py", "content": "def getitems(self, source):\n        \"\"\"Return all test items collected from the module.\n\n        This writes the source to a python file and runs pytest's collection on\n        the resulting module, returning all test items contained within.\n\n        \"\"\"\n        modcol = self.getmodulecol(source)\n        return self.genitems([modcol])"}, {"id": "_pytest.pytester.Testdir.getmodulecol", "kind": "function", "range": [1062, 4, 1087, 41, 35943, 36982], "file_path": "src/_pytest/pytester.py", "content": "def getmodulecol(self, source, configargs=(), withinit=False):\n        \"\"\"Return the module collection node for ``source``.\n\n        This writes ``source`` to a file using :py:meth:`makepyfile` and then\n        runs the pytest collection on it, returning the collection node for the\n        test module.\n\n        :param source: the source code of the module to collect\n\n        :param configargs: any extra arguments to pass to\n            :py:meth:`parseconfigure`\n\n        :param withinit: whether to also write an ``__init__.py`` file to the\n            same directory to ensure it is a package\n\n        \"\"\"\n        if isinstance(source, Path):\n            path = self.tmpdir.join(str(source))\n            assert not withinit, \"not supported for paths\"\n        else:\n            kw = {self._name: Source(source).strip()}\n            path = self.makepyfile(**kw)\n        if withinit:\n            self.makepyfile(__init__=\"#\")\n        self.config = config = self.parseconfigure(path, *configargs)\n        return self.getnode(config, path)"}, {"id": "_pytest.pytester.Testdir.collect_by_name", "kind": "function", "range": [1089, 4, 1106, 19, 36988, 37672], "file_path": "src/_pytest/pytester.py", "content": "def collect_by_name(\n        self, modcol: Module, name: str\n    ) -> Optional[Union[Item, Collector]]:\n        \"\"\"Return the collection node for name from the module collection.\n\n        This will search a module collection node for a collection node\n        matching the given name.\n\n        :param modcol: a module collection node; see :py:meth:`getmodulecol`\n\n        :param name: the name of the node to return\n        \"\"\"\n        if modcol not in self._mod_collections:\n            self._mod_collections[modcol] = list(modcol.collect())\n        for colitem in self._mod_collections[modcol]:\n            if colitem.name == name:\n                return colitem\n        return None"}, {"id": "_pytest.pytester.Testdir.popen", "kind": "function", "range": [1108, 4, 1143, 20, 37678, 38685], "file_path": "src/_pytest/pytester.py", "content": "def popen(\n        self,\n        cmdargs,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        stdin=CLOSE_STDIN,\n        **kw\n    ):\n        \"\"\"Invoke subprocess.Popen.\n\n        This calls subprocess.Popen making sure the current working directory\n        is in the PYTHONPATH.\n\n        You probably want to use :py:meth:`run` instead.\n\n        \"\"\"\n        env = os.environ.copy()\n        env[\"PYTHONPATH\"] = os.pathsep.join(\n            filter(None, [os.getcwd(), env.get(\"PYTHONPATH\", \"\")])\n        )\n        kw[\"env\"] = env\n\n        if stdin is Testdir.CLOSE_STDIN:\n            kw[\"stdin\"] = subprocess.PIPE\n        elif isinstance(stdin, bytes):\n            kw[\"stdin\"] = subprocess.PIPE\n        else:\n            kw[\"stdin\"] = stdin\n\n        popen = subprocess.Popen(cmdargs, stdout=stdout, stderr=stderr, **kw)\n        if stdin is Testdir.CLOSE_STDIN:\n            popen.stdin.close()\n        elif isinstance(stdin, bytes):\n            popen.stdin.write(stdin)\n\n        return popen"}, {"id": "_pytest.pytester.Testdir.run", "kind": "function", "range": [1145, 4, 1220, 58, 38691, 41314], "file_path": "src/_pytest/pytester.py", "content": "def run(self, *cmdargs, timeout=None, stdin=CLOSE_STDIN) -> RunResult:\n        \"\"\"Run a command with arguments.\n\n        Run a process using subprocess.Popen saving the stdout and stderr.\n\n        :param args: the sequence of arguments to pass to `subprocess.Popen()`\n        :kwarg timeout: the period in seconds after which to timeout and raise\n            :py:class:`Testdir.TimeoutExpired`\n        :kwarg stdin: optional standard input.  Bytes are being send, closing\n            the pipe, otherwise it is passed through to ``popen``.\n            Defaults to ``CLOSE_STDIN``, which translates to using a pipe\n            (``subprocess.PIPE``) that gets closed.\n\n        Returns a :py:class:`RunResult`.\n\n        \"\"\"\n        __tracebackhide__ = True\n\n        cmdargs = tuple(\n            str(arg) if isinstance(arg, py.path.local) else arg for arg in cmdargs\n        )\n        p1 = self.tmpdir.join(\"stdout\")\n        p2 = self.tmpdir.join(\"stderr\")\n        print(\"running:\", *cmdargs)\n        print(\"     in:\", py.path.local())\n        f1 = open(str(p1), \"w\", encoding=\"utf8\")\n        f2 = open(str(p2), \"w\", encoding=\"utf8\")\n        try:\n            now = time.time()\n            popen = self.popen(\n                cmdargs,\n                stdin=stdin,\n                stdout=f1,\n                stderr=f2,\n                close_fds=(sys.platform != \"win32\"),\n            )\n            if isinstance(stdin, bytes):\n                popen.stdin.close()\n\n            def handle_timeout():\n                __tracebackhide__ = True\n\n                timeout_message = (\n                    \"{seconds} second timeout expired running:\"\n                    \" {command}\".format(seconds=timeout, command=cmdargs)\n                )\n\n                popen.kill()\n                popen.wait()\n                raise self.TimeoutExpired(timeout_message)\n\n            if timeout is None:\n                ret = popen.wait()\n            else:\n                try:\n                    ret = popen.wait(timeout)\n                except subprocess.TimeoutExpired:\n                    handle_timeout()\n        finally:\n            f1.close()\n            f2.close()\n        f1 = open(str(p1), encoding=\"utf8\")\n        f2 = open(str(p2), encoding=\"utf8\")\n        try:\n            out = f1.read().splitlines()\n            err = f2.read().splitlines()\n        finally:\n            f1.close()\n            f2.close()\n        self._dump_lines(out, sys.stdout)\n        self._dump_lines(err, sys.stderr)\n        try:\n            ret = ExitCode(ret)\n        except ValueError:\n            pass\n        return RunResult(ret, out, err, time.time() - now)"}, {"id": "_pytest.pytester.Testdir._dump_lines", "kind": "function", "range": [1222, 4, 1227, 72, 41320, 41542], "file_path": "src/_pytest/pytester.py", "content": "def _dump_lines(self, lines, fp):\n        try:\n            for line in lines:\n                print(line, file=fp)\n        except UnicodeEncodeError:\n            print(\"couldn't print to {} because of encoding\".format(fp))"}, {"id": "_pytest.pytester.Testdir._getpytestargs", "kind": "function", "range": [1229, 4, 1230, 41, 41548, 41615], "file_path": "src/_pytest/pytester.py", "content": "def _getpytestargs(self):\n        return sys.executable, \"-mpytest\""}, {"id": "_pytest.pytester.Testdir.runpython", "kind": "function", "range": [1232, 4, 1238, 47, 41621, 41833], "file_path": "src/_pytest/pytester.py", "content": "def runpython(self, script) -> RunResult:\n        \"\"\"Run a python script using sys.executable as interpreter.\n\n        Returns a :py:class:`RunResult`.\n\n        \"\"\"\n        return self.run(sys.executable, script)"}, {"id": "_pytest.pytester.Testdir.runpython_c", "kind": "function", "range": [1240, 4, 1242, 54, 41839, 41996], "file_path": "src/_pytest/pytester.py", "content": "def runpython_c(self, command):\n        \"\"\"Run python -c \"command\", return a :py:class:`RunResult`.\"\"\"\n        return self.run(sys.executable, \"-c\", command)"}, {"id": "_pytest.pytester.Testdir.runpytest_subprocess", "kind": "function", "range": [1244, 4, 1266, 47, 42002, 43131], "file_path": "src/_pytest/pytester.py", "content": "def runpytest_subprocess(self, *args, timeout=None) -> RunResult:\n        \"\"\"Run pytest as a subprocess with given arguments.\n\n        Any plugins added to the :py:attr:`plugins` list will be added using the\n        ``-p`` command line option.  Additionally ``--basetemp`` is used to put\n        any temporary files and directories in a numbered directory prefixed\n        with \"runpytest-\" to not conflict with the normal numbered pytest\n        location for temporary files and directories.\n\n        :param args: the sequence of arguments to pass to the pytest subprocess\n        :param timeout: the period in seconds after which to timeout and raise\n            :py:class:`Testdir.TimeoutExpired`\n\n        Returns a :py:class:`RunResult`.\n        \"\"\"\n        __tracebackhide__ = True\n        p = make_numbered_dir(root=Path(self.tmpdir), prefix=\"runpytest-\")\n        args = (\"--basetemp=%s\" % p,) + args\n        plugins = [x for x in self.plugins if isinstance(x, str)]\n        if plugins:\n            args = (\"-p\", plugins[0]) + args\n        args = self._getpytestargs() + args\n        return self.run(*args, timeout=timeout)"}, {"id": "_pytest.pytester.Testdir.spawn_pytest", "kind": "function", "range": [1268, 4, 1282, 61, 43137, 43673], "file_path": "src/_pytest/pytester.py", "content": "def spawn_pytest(\n        self, string: str, expect_timeout: float = 10.0\n    ) -> \"pexpect.spawn\":\n        \"\"\"Run pytest using pexpect.\n\n        This makes sure to use the right pytest and sets up the temporary\n        directory locations.\n\n        The pexpect child is returned.\n\n        \"\"\"\n        basetemp = self.tmpdir.mkdir(\"temp-pexpect\")\n        invoke = \" \".join(map(str, self._getpytestargs()))\n        cmd = \"{} --basetemp={} {}\".format(invoke, basetemp, string)\n        return self.spawn(cmd, expect_timeout=expect_timeout)"}, {"id": "_pytest.pytester.Testdir.spawn", "kind": "function", "range": [1284, 4, 1300, 20, 43679, 44351], "file_path": "src/_pytest/pytester.py", "content": "def spawn(self, cmd: str, expect_timeout: float = 10.0) -> \"pexpect.spawn\":\n        \"\"\"Run a command using pexpect.\n\n        The pexpect child is returned.\n\n        \"\"\"\n        pexpect = pytest.importorskip(\"pexpect\", \"3.0\")\n        if hasattr(sys, \"pypy_version_info\") and \"64\" in platform.machine():\n            pytest.skip(\"pypy-64 bit not supported\")\n        if not hasattr(pexpect, \"spawn\"):\n            pytest.skip(\"pexpect.spawn not available\")\n        logfile = self.tmpdir.join(\"spawn.out\").open(\"wb\")\n\n        child = pexpect.spawn(cmd, logfile=logfile)\n        self.request.addfinalizer(logfile.close)\n        child.timeout = expect_timeout\n        return child"}, {"id": "_pytest.pytester.LineComp", "kind": "class", "range": [1303, 0, 1318, 49, 44354, 44961], "file_path": "src/_pytest/pytester.py", "content": "class LineComp:\n    def __init__(self) -> None:\n        self.stringio = StringIO()\n        \"\"\":class:`python:io.StringIO()` instance used for input.\"\"\"\n\n    def assert_contains_lines(self, lines2: Sequence[str]) -> None:\n        \"\"\"Assert that ``lines2`` are contained (linearly) in :attr:`stringio`'s value.\n\n        Lines are matched using :func:`LineMatcher.fnmatch_lines`.\n        \"\"\"\n        __tracebackhide__ = True\n        val = self.stringio.getvalue()\n        self.stringio.truncate(0)\n        self.stringio.seek(0)\n        lines1 = val.split(\"\\n\")\n        LineMatcher(lines1).fnmatch_lines(lines2)"}, {"id": "_pytest.pytester.LineComp.__init__", "kind": "function", "range": [1304, 4, 1306, 68, 44374, 44505], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self) -> None:\n        self.stringio = StringIO()\n        \"\"\":class:`python:io.StringIO()` instance used for input.\"\"\""}, {"id": "_pytest.pytester.LineComp.assert_contains_lines", "kind": "function", "range": [1308, 4, 1318, 49, 44511, 44961], "file_path": "src/_pytest/pytester.py", "content": "def assert_contains_lines(self, lines2: Sequence[str]) -> None:\n        \"\"\"Assert that ``lines2`` are contained (linearly) in :attr:`stringio`'s value.\n\n        Lines are matched using :func:`LineMatcher.fnmatch_lines`.\n        \"\"\"\n        __tracebackhide__ = True\n        val = self.stringio.getvalue()\n        self.stringio.truncate(0)\n        self.stringio.seek(0)\n        lines1 = val.split(\"\\n\")\n        LineMatcher(lines1).fnmatch_lines(lines2)"}, {"id": "_pytest.pytester.LineMatcher", "kind": "class", "range": [1321, 0, 1535, 36, 44964, 53199], "file_path": "src/_pytest/pytester.py", "content": "class LineMatcher:\n    \"\"\"Flexible matching of text.\n\n    This is a convenience class to test large texts like the output of\n    commands.\n\n    The constructor takes a list of lines without their trailing newlines, i.e.\n    ``text.splitlines()``.\n    \"\"\"\n\n    def __init__(self, lines: List[str]) -> None:\n        self.lines = lines\n        self._log_output = []  # type: List[str]\n\n    def _getlines(self, lines2: Union[str, Sequence[str], Source]) -> Sequence[str]:\n        if isinstance(lines2, str):\n            lines2 = Source(lines2)\n        if isinstance(lines2, Source):\n            lines2 = lines2.strip().lines\n        return lines2\n\n    def fnmatch_lines_random(self, lines2: Sequence[str]) -> None:\n        \"\"\"Check lines exist in the output in any order (using :func:`python:fnmatch.fnmatch`).\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines_random(lines2, fnmatch)\n\n    def re_match_lines_random(self, lines2: Sequence[str]) -> None:\n        \"\"\"Check lines exist in the output in any order (using :func:`python:re.match`).\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines_random(lines2, lambda name, pat: bool(re.match(pat, name)))\n\n    def _match_lines_random(\n        self, lines2: Sequence[str], match_func: Callable[[str, str], bool]\n    ) -> None:\n        __tracebackhide__ = True\n        lines2 = self._getlines(lines2)\n        for line in lines2:\n            for x in self.lines:\n                if line == x or match_func(x, line):\n                    self._log(\"matched: \", repr(line))\n                    break\n            else:\n                msg = \"line %r not found in output\" % line\n                self._log(msg)\n                self._fail(msg)\n\n    def get_lines_after(self, fnline: str) -> Sequence[str]:\n        \"\"\"Return all lines following the given line in the text.\n\n        The given line can contain glob wildcards.\n        \"\"\"\n        for i, line in enumerate(self.lines):\n            if fnline == line or fnmatch(line, fnline):\n                return self.lines[i + 1 :]\n        raise ValueError(\"line %r not found in output\" % fnline)\n\n    def _log(self, *args) -> None:\n        self._log_output.append(\" \".join(str(x) for x in args))\n\n    @property\n    def _log_text(self) -> str:\n        return \"\\n\".join(self._log_output)\n\n    def fnmatch_lines(\n        self, lines2: Sequence[str], *, consecutive: bool = False\n    ) -> None:\n        \"\"\"Check lines exist in the output (using :func:`python:fnmatch.fnmatch`).\n\n        The argument is a list of lines which have to match and can use glob\n        wildcards.  If they do not match a pytest.fail() is called.  The\n        matches and non-matches are also shown as part of the error message.\n\n        :param lines2: string patterns to match.\n        :param consecutive: match lines consecutive?\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines(lines2, fnmatch, \"fnmatch\", consecutive=consecutive)\n\n    def re_match_lines(\n        self, lines2: Sequence[str], *, consecutive: bool = False\n    ) -> None:\n        \"\"\"Check lines exist in the output (using :func:`python:re.match`).\n\n        The argument is a list of lines which have to match using ``re.match``.\n        If they do not match a pytest.fail() is called.\n\n        The matches and non-matches are also shown as part of the error message.\n\n        :param lines2: string patterns to match.\n        :param consecutive: match lines consecutively?\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines(\n            lines2,\n            lambda name, pat: bool(re.match(pat, name)),\n            \"re.match\",\n            consecutive=consecutive,\n        )\n\n    def _match_lines(\n        self,\n        lines2: Sequence[str],\n        match_func: Callable[[str, str], bool],\n        match_nickname: str,\n        *,\n        consecutive: bool = False\n    ) -> None:\n        \"\"\"Underlying implementation of ``fnmatch_lines`` and ``re_match_lines``.\n\n        :param list[str] lines2: list of string patterns to match. The actual\n            format depends on ``match_func``\n        :param match_func: a callable ``match_func(line, pattern)`` where line\n            is the captured line from stdout/stderr and pattern is the matching\n            pattern\n        :param str match_nickname: the nickname for the match function that\n            will be logged to stdout when a match occurs\n        :param consecutive: match lines consecutively?\n        \"\"\"\n        if not isinstance(lines2, collections.abc.Sequence):\n            raise TypeError(\"invalid type for lines2: {}\".format(type(lines2).__name__))\n        lines2 = self._getlines(lines2)\n        lines1 = self.lines[:]\n        nextline = None\n        extralines = []\n        __tracebackhide__ = True\n        wnick = len(match_nickname) + 1\n        started = False\n        for line in lines2:\n            nomatchprinted = False\n            while lines1:\n                nextline = lines1.pop(0)\n                if line == nextline:\n                    self._log(\"exact match:\", repr(line))\n                    started = True\n                    break\n                elif match_func(nextline, line):\n                    self._log(\"%s:\" % match_nickname, repr(line))\n                    self._log(\n                        \"{:>{width}}\".format(\"with:\", width=wnick), repr(nextline)\n                    )\n                    started = True\n                    break\n                else:\n                    if consecutive and started:\n                        msg = \"no consecutive match: {!r}\".format(line)\n                        self._log(msg)\n                        self._log(\n                            \"{:>{width}}\".format(\"with:\", width=wnick), repr(nextline)\n                        )\n                        self._fail(msg)\n                    if not nomatchprinted:\n                        self._log(\n                            \"{:>{width}}\".format(\"nomatch:\", width=wnick), repr(line)\n                        )\n                        nomatchprinted = True\n                    self._log(\"{:>{width}}\".format(\"and:\", width=wnick), repr(nextline))\n                extralines.append(nextline)\n            else:\n                msg = \"remains unmatched: {!r}\".format(line)\n                self._log(msg)\n                self._fail(msg)\n        self._log_output = []\n\n    def no_fnmatch_line(self, pat: str) -> None:\n        \"\"\"Ensure captured lines do not match the given pattern, using ``fnmatch.fnmatch``.\n\n        :param str pat: the pattern to match lines.\n        \"\"\"\n        __tracebackhide__ = True\n        self._no_match_line(pat, fnmatch, \"fnmatch\")\n\n    def no_re_match_line(self, pat: str) -> None:\n        \"\"\"Ensure captured lines do not match the given pattern, using ``re.match``.\n\n        :param str pat: the regular expression to match lines.\n        \"\"\"\n        __tracebackhide__ = True\n        self._no_match_line(\n            pat, lambda name, pat: bool(re.match(pat, name)), \"re.match\"\n        )\n\n    def _no_match_line(\n        self, pat: str, match_func: Callable[[str, str], bool], match_nickname: str\n    ) -> None:\n        \"\"\"Ensure captured lines does not have a the given pattern, using ``fnmatch.fnmatch``\n\n        :param str pat: the pattern to match lines\n        \"\"\"\n        __tracebackhide__ = True\n        nomatch_printed = False\n        wnick = len(match_nickname) + 1\n        for line in self.lines:\n            if match_func(line, pat):\n                msg = \"{}: {!r}\".format(match_nickname, pat)\n                self._log(msg)\n                self._log(\"{:>{width}}\".format(\"with:\", width=wnick), repr(line))\n                self._fail(msg)\n            else:\n                if not nomatch_printed:\n                    self._log(\"{:>{width}}\".format(\"nomatch:\", width=wnick), repr(pat))\n                    nomatch_printed = True\n                self._log(\"{:>{width}}\".format(\"and:\", width=wnick), repr(line))\n        self._log_output = []\n\n    def _fail(self, msg: str) -> None:\n        __tracebackhide__ = True\n        log_text = self._log_text\n        self._log_output = []\n        pytest.fail(log_text)\n\n    def str(self) -> str:\n        \"\"\"Return the entire original text.\"\"\"\n        return \"\\n\".join(self.lines)"}, {"id": "_pytest.pytester.LineMatcher.__init__", "kind": "function", "range": [1331, 4, 1333, 48, 45224, 45345], "file_path": "src/_pytest/pytester.py", "content": "def __init__(self, lines: List[str]) -> None:\n        self.lines = lines\n        self._log_output = []  # type: List[str]"}, {"id": "_pytest.pytester.LineMatcher._getlines", "kind": "function", "range": [1335, 4, 1340, 21, 45351, 45606], "file_path": "src/_pytest/pytester.py", "content": "def _getlines(self, lines2: Union[str, Sequence[str], Source]) -> Sequence[str]:\n        if isinstance(lines2, str):\n            lines2 = Source(lines2)\n        if isinstance(lines2, Source):\n            lines2 = lines2.strip().lines\n        return lines2"}, {"id": "_pytest.pytester.LineMatcher.fnmatch_lines_random", "kind": "function", "range": [1342, 4, 1346, 49, 45612, 45865], "file_path": "src/_pytest/pytester.py", "content": "def fnmatch_lines_random(self, lines2: Sequence[str]) -> None:\n        \"\"\"Check lines exist in the output in any order (using :func:`python:fnmatch.fnmatch`).\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines_random(lines2, fnmatch)"}, {"id": "_pytest.pytester.LineMatcher.re_match_lines_random", "kind": "function", "range": [1348, 4, 1352, 85, 45871, 46154], "file_path": "src/_pytest/pytester.py", "content": "def re_match_lines_random(self, lines2: Sequence[str]) -> None:\n        \"\"\"Check lines exist in the output in any order (using :func:`python:re.match`).\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines_random(lines2, lambda name, pat: bool(re.match(pat, name)))"}, {"id": "_pytest.pytester.LineMatcher._match_lines_random", "kind": "function", "range": [1354, 4, 1367, 31, 46160, 46683], "file_path": "src/_pytest/pytester.py", "content": "def _match_lines_random(\n        self, lines2: Sequence[str], match_func: Callable[[str, str], bool]\n    ) -> None:\n        __tracebackhide__ = True\n        lines2 = self._getlines(lines2)\n        for line in lines2:\n            for x in self.lines:\n                if line == x or match_func(x, line):\n                    self._log(\"matched: \", repr(line))\n                    break\n            else:\n                msg = \"line %r not found in output\" % line\n                self._log(msg)\n                self._fail(msg)"}, {"id": "_pytest.pytester.LineMatcher.get_lines_after", "kind": "function", "range": [1369, 4, 1377, 64, 46689, 47085], "file_path": "src/_pytest/pytester.py", "content": "def get_lines_after(self, fnline: str) -> Sequence[str]:\n        \"\"\"Return all lines following the given line in the text.\n\n        The given line can contain glob wildcards.\n        \"\"\"\n        for i, line in enumerate(self.lines):\n            if fnline == line or fnmatch(line, fnline):\n                return self.lines[i + 1 :]\n        raise ValueError(\"line %r not found in output\" % fnline)"}, {"id": "_pytest.pytester.LineMatcher._log", "kind": "function", "range": [1379, 4, 1380, 63, 47091, 47185], "file_path": "src/_pytest/pytester.py", "content": "def _log(self, *args) -> None:\n        self._log_output.append(\" \".join(str(x) for x in args))"}, {"id": "_pytest.pytester.LineMatcher._log_text", "kind": "function", "range": [1382, 4, 1384, 42, 47191, 47275], "file_path": "src/_pytest/pytester.py", "content": "@property\n    def _log_text(self) -> str:\n        return \"\\n\".join(self._log_output)"}, {"id": "_pytest.pytester.LineMatcher.fnmatch_lines", "kind": "function", "range": [1386, 4, 1399, 78, 47281, 47918], "file_path": "src/_pytest/pytester.py", "content": "def fnmatch_lines(\n        self, lines2: Sequence[str], *, consecutive: bool = False\n    ) -> None:\n        \"\"\"Check lines exist in the output (using :func:`python:fnmatch.fnmatch`).\n\n        The argument is a list of lines which have to match and can use glob\n        wildcards.  If they do not match a pytest.fail() is called.  The\n        matches and non-matches are also shown as part of the error message.\n\n        :param lines2: string patterns to match.\n        :param consecutive: match lines consecutive?\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines(lines2, fnmatch, \"fnmatch\", consecutive=consecutive)"}, {"id": "_pytest.pytester.LineMatcher.re_match_lines", "kind": "function", "range": [1401, 4, 1420, 9, 47924, 48644], "file_path": "src/_pytest/pytester.py", "content": "def re_match_lines(\n        self, lines2: Sequence[str], *, consecutive: bool = False\n    ) -> None:\n        \"\"\"Check lines exist in the output (using :func:`python:re.match`).\n\n        The argument is a list of lines which have to match using ``re.match``.\n        If they do not match a pytest.fail() is called.\n\n        The matches and non-matches are also shown as part of the error message.\n\n        :param lines2: string patterns to match.\n        :param consecutive: match lines consecutively?\n        \"\"\"\n        __tracebackhide__ = True\n        self._match_lines(\n            lines2,\n            lambda name, pat: bool(re.match(pat, name)),\n            \"re.match\",\n            consecutive=consecutive,\n        )"}, {"id": "_pytest.pytester.LineMatcher._match_lines", "kind": "function", "range": [1422, 4, 1484, 29, 48650, 51308], "file_path": "src/_pytest/pytester.py", "content": "def _match_lines(\n        self,\n        lines2: Sequence[str],\n        match_func: Callable[[str, str], bool],\n        match_nickname: str,\n        *,\n        consecutive: bool = False\n    ) -> None:\n        \"\"\"Underlying implementation of ``fnmatch_lines`` and ``re_match_lines``.\n\n        :param list[str] lines2: list of string patterns to match. The actual\n            format depends on ``match_func``\n        :param match_func: a callable ``match_func(line, pattern)`` where line\n            is the captured line from stdout/stderr and pattern is the matching\n            pattern\n        :param str match_nickname: the nickname for the match function that\n            will be logged to stdout when a match occurs\n        :param consecutive: match lines consecutively?\n        \"\"\"\n        if not isinstance(lines2, collections.abc.Sequence):\n            raise TypeError(\"invalid type for lines2: {}\".format(type(lines2).__name__))\n        lines2 = self._getlines(lines2)\n        lines1 = self.lines[:]\n        nextline = None\n        extralines = []\n        __tracebackhide__ = True\n        wnick = len(match_nickname) + 1\n        started = False\n        for line in lines2:\n            nomatchprinted = False\n            while lines1:\n                nextline = lines1.pop(0)\n                if line == nextline:\n                    self._log(\"exact match:\", repr(line))\n                    started = True\n                    break\n                elif match_func(nextline, line):\n                    self._log(\"%s:\" % match_nickname, repr(line))\n                    self._log(\n                        \"{:>{width}}\".format(\"with:\", width=wnick), repr(nextline)\n                    )\n                    started = True\n                    break\n                else:\n                    if consecutive and started:\n                        msg = \"no consecutive match: {!r}\".format(line)\n                        self._log(msg)\n                        self._log(\n                            \"{:>{width}}\".format(\"with:\", width=wnick), repr(nextline)\n                        )\n                        self._fail(msg)\n                    if not nomatchprinted:\n                        self._log(\n                            \"{:>{width}}\".format(\"nomatch:\", width=wnick), repr(line)\n                        )\n                        nomatchprinted = True\n                    self._log(\"{:>{width}}\".format(\"and:\", width=wnick), repr(nextline))\n                extralines.append(nextline)\n            else:\n                msg = \"remains unmatched: {!r}\".format(line)\n                self._log(msg)\n                self._fail(msg)\n        self._log_output = []"}, {"id": "_pytest.pytester.LineMatcher.no_fnmatch_line", "kind": "function", "range": [1486, 4, 1492, 52, 51314, 51601], "file_path": "src/_pytest/pytester.py", "content": "def no_fnmatch_line(self, pat: str) -> None:\n        \"\"\"Ensure captured lines do not match the given pattern, using ``fnmatch.fnmatch``.\n\n        :param str pat: the pattern to match lines.\n        \"\"\"\n        __tracebackhide__ = True\n        self._no_match_line(pat, fnmatch, \"fnmatch\")"}, {"id": "_pytest.pytester.LineMatcher.no_re_match_line", "kind": "function", "range": [1494, 4, 1502, 9, 51607, 51958], "file_path": "src/_pytest/pytester.py", "content": "def no_re_match_line(self, pat: str) -> None:\n        \"\"\"Ensure captured lines do not match the given pattern, using ``re.match``.\n\n        :param str pat: the regular expression to match lines.\n        \"\"\"\n        __tracebackhide__ = True\n        self._no_match_line(\n            pat, lambda name, pat: bool(re.match(pat, name)), \"re.match\"\n        )"}, {"id": "_pytest.pytester.LineMatcher._no_match_line", "kind": "function", "range": [1504, 4, 1525, 29, 51964, 52921], "file_path": "src/_pytest/pytester.py", "content": "def _no_match_line(\n        self, pat: str, match_func: Callable[[str, str], bool], match_nickname: str\n    ) -> None:\n        \"\"\"Ensure captured lines does not have a the given pattern, using ``fnmatch.fnmatch``\n\n        :param str pat: the pattern to match lines\n        \"\"\"\n        __tracebackhide__ = True\n        nomatch_printed = False\n        wnick = len(match_nickname) + 1\n        for line in self.lines:\n            if match_func(line, pat):\n                msg = \"{}: {!r}\".format(match_nickname, pat)\n                self._log(msg)\n                self._log(\"{:>{width}}\".format(\"with:\", width=wnick), repr(line))\n                self._fail(msg)\n            else:\n                if not nomatch_printed:\n                    self._log(\"{:>{width}}\".format(\"nomatch:\", width=wnick), repr(pat))\n                    nomatch_printed = True\n                self._log(\"{:>{width}}\".format(\"and:\", width=wnick), repr(line))\n        self._log_output = []"}, {"id": "_pytest.pytester.LineMatcher._fail", "kind": "function", "range": [1527, 4, 1531, 29, 52927, 53088], "file_path": "src/_pytest/pytester.py", "content": "def _fail(self, msg: str) -> None:\n        __tracebackhide__ = True\n        log_text = self._log_text\n        self._log_output = []\n        pytest.fail(log_text)"}, {"id": "_pytest.pytester.LineMatcher.str", "kind": "function", "range": [1533, 4, 1535, 36, 53094, 53199], "file_path": "src/_pytest/pytester.py", "content": "def str(self) -> str:\n        \"\"\"Return the entire original text.\"\"\"\n        return \"\\n\".join(self.lines)"}, {"id": "_pytest.faulthandler.fault_handler_stderr_key", "kind": "variable", "range": [9, 0, 9, 45, 109, 154], "file_path": "src/_pytest/faulthandler.py", "content": "fault_handler_stderr_key = StoreKey[TextIO]()"}, {"id": "_pytest.faulthandler.pytest_addoption", "kind": "function", "range": [12, 0, 17, 60, 157, 374], "file_path": "src/_pytest/faulthandler.py", "content": "def pytest_addoption(parser):\n    help = (\n        \"Dump the traceback of all threads if a test takes \"\n        \"more than TIMEOUT seconds to finish.\"\n    )\n    parser.addini(\"faulthandler_timeout\", help, default=0.0)"}, {"id": "_pytest.faulthandler.pytest_configure", "kind": "function", "range": [20, 0, 41, 13, 377, 1315], "file_path": "src/_pytest/faulthandler.py", "content": "def pytest_configure(config):\n    import faulthandler\n\n    if not faulthandler.is_enabled():\n        # faulthhandler is not enabled, so install plugin that does the actual work\n        # of enabling faulthandler before each test executes.\n        config.pluginmanager.register(FaultHandlerHooks(), \"faulthandler-hooks\")\n    else:\n        from _pytest.warnings import _issue_warning_captured\n\n        # Do not handle dumping to stderr if faulthandler is already enabled, so warn\n        # users that the option is being ignored.\n        timeout = FaultHandlerHooks.get_timeout_config_value(config)\n        if timeout > 0:\n            _issue_warning_captured(\n                pytest.PytestConfigWarning(\n                    \"faulthandler module enabled before pytest configuration step, \"\n                    \"'faulthandler_timeout' option ignored\"\n                ),\n                config.hook,\n                stacklevel=2,\n            )"}, {"id": "_pytest.faulthandler.FaultHandlerHooks", "kind": "class", "range": [44, 0, 111, 50, 1318, 3920], "file_path": "src/_pytest/faulthandler.py", "content": "class FaultHandlerHooks:\n    \"\"\"Implements hooks that will actually install fault handler before tests execute,\n    as well as correctly handle pdb and internal errors.\"\"\"\n\n    def pytest_configure(self, config):\n        import faulthandler\n\n        stderr_fd_copy = os.dup(self._get_stderr_fileno())\n        config._store[fault_handler_stderr_key] = open(stderr_fd_copy, \"w\")\n        faulthandler.enable(file=config._store[fault_handler_stderr_key])\n\n    def pytest_unconfigure(self, config):\n        import faulthandler\n\n        faulthandler.disable()\n        # close our dup file installed during pytest_configure\n        # re-enable the faulthandler, attaching it to the default sys.stderr\n        # so we can see crashes after pytest has finished, usually during\n        # garbage collection during interpreter shutdown\n        config._store[fault_handler_stderr_key].close()\n        del config._store[fault_handler_stderr_key]\n        faulthandler.enable(file=self._get_stderr_fileno())\n\n    @staticmethod\n    def _get_stderr_fileno():\n        try:\n            return sys.stderr.fileno()\n        except (AttributeError, io.UnsupportedOperation):\n            # pytest-xdist monkeypatches sys.stderr with an object that is not an actual file.\n            # https://docs.python.org/3/library/faulthandler.html#issue-with-file-descriptors\n            # This is potentially dangerous, but the best we can do.\n            return sys.__stderr__.fileno()\n\n    @staticmethod\n    def get_timeout_config_value(config):\n        return float(config.getini(\"faulthandler_timeout\") or 0.0)\n\n    @pytest.hookimpl(hookwrapper=True, trylast=True)\n    def pytest_runtest_protocol(self, item):\n        timeout = self.get_timeout_config_value(item.config)\n        stderr = item.config._store[fault_handler_stderr_key]\n        if timeout > 0 and stderr is not None:\n            import faulthandler\n\n            faulthandler.dump_traceback_later(timeout, file=stderr)\n            try:\n                yield\n            finally:\n                faulthandler.cancel_dump_traceback_later()\n        else:\n            yield\n\n    @pytest.hookimpl(tryfirst=True)\n    def pytest_enter_pdb(self):\n        \"\"\"Cancel any traceback dumping due to timeout before entering pdb.\n        \"\"\"\n        import faulthandler\n\n        faulthandler.cancel_dump_traceback_later()\n\n    @pytest.hookimpl(tryfirst=True)\n    def pytest_exception_interact(self):\n        \"\"\"Cancel any traceback dumping due to an interactive exception being\n        raised.\n        \"\"\"\n        import faulthandler\n\n        faulthandler.cancel_dump_traceback_later()"}, {"id": "_pytest.faulthandler.FaultHandlerHooks.pytest_configure", "kind": "function", "range": [48, 4, 53, 73, 1495, 1768], "file_path": "src/_pytest/faulthandler.py", "content": "def pytest_configure(self, config):\n        import faulthandler\n\n        stderr_fd_copy = os.dup(self._get_stderr_fileno())\n        config._store[fault_handler_stderr_key] = open(stderr_fd_copy, \"w\")\n        faulthandler.enable(file=config._store[fault_handler_stderr_key])"}, {"id": "_pytest.faulthandler.FaultHandlerHooks.pytest_unconfigure", "kind": "function", "range": [55, 4, 65, 59, 1774, 2310], "file_path": "src/_pytest/faulthandler.py", "content": "def pytest_unconfigure(self, config):\n        import faulthandler\n\n        faulthandler.disable()\n        # close our dup file installed during pytest_configure\n        # re-enable the faulthandler, attaching it to the default sys.stderr\n        # so we can see crashes after pytest has finished, usually during\n        # garbage collection during interpreter shutdown\n        config._store[fault_handler_stderr_key].close()\n        del config._store[fault_handler_stderr_key]\n        faulthandler.enable(file=self._get_stderr_fileno())"}, {"id": "_pytest.faulthandler.FaultHandlerHooks._get_stderr_fileno", "kind": "function", "range": [67, 4, 75, 42, 2316, 2770], "file_path": "src/_pytest/faulthandler.py", "content": "@staticmethod\n    def _get_stderr_fileno():\n        try:\n            return sys.stderr.fileno()\n        except (AttributeError, io.UnsupportedOperation):\n            # pytest-xdist monkeypatches sys.stderr with an object that is not an actual file.\n            # https://docs.python.org/3/library/faulthandler.html#issue-with-file-descriptors\n            # This is potentially dangerous, but the best we can do.\n            return sys.__stderr__.fileno()"}, {"id": "_pytest.faulthandler.FaultHandlerHooks.get_timeout_config_value", "kind": "function", "range": [77, 4, 79, 66, 2776, 2898], "file_path": "src/_pytest/faulthandler.py", "content": "@staticmethod\n    def get_timeout_config_value(config):\n        return float(config.getini(\"faulthandler_timeout\") or 0.0)"}, {"id": "_pytest.faulthandler.FaultHandlerHooks.pytest_runtest_protocol", "kind": "function", "range": [81, 4, 94, 17, 2904, 3419], "file_path": "src/_pytest/faulthandler.py", "content": "@pytest.hookimpl(hookwrapper=True, trylast=True)\n    def pytest_runtest_protocol(self, item):\n        timeout = self.get_timeout_config_value(item.config)\n        stderr = item.config._store[fault_handler_stderr_key]\n        if timeout > 0 and stderr is not None:\n            import faulthandler\n\n            faulthandler.dump_traceback_later(timeout, file=stderr)\n            try:\n                yield\n            finally:\n                faulthandler.cancel_dump_traceback_later()\n        else:\n            yield"}, {"id": "_pytest.faulthandler.FaultHandlerHooks.pytest_enter_pdb", "kind": "function", "range": [96, 4, 102, 50, 3425, 3656], "file_path": "src/_pytest/faulthandler.py", "content": "@pytest.hookimpl(tryfirst=True)\n    def pytest_enter_pdb(self):\n        \"\"\"Cancel any traceback dumping due to timeout before entering pdb.\n        \"\"\"\n        import faulthandler\n\n        faulthandler.cancel_dump_traceback_later()"}, {"id": "_pytest.faulthandler.FaultHandlerHooks.pytest_exception_interact", "kind": "function", "range": [104, 4, 111, 50, 3662, 3920], "file_path": "src/_pytest/faulthandler.py", "content": "@pytest.hookimpl(tryfirst=True)\n    def pytest_exception_interact(self):\n        \"\"\"Cancel any traceback dumping due to an interactive exception being\n        raised.\n        \"\"\"\n        import faulthandler\n\n        faulthandler.cancel_dump_traceback_later()"}, {"id": "_pytest.outcomes.TYPE_CHECKING", "kind": "variable", "range": [13, 0, 13, 21, 279, 300], "file_path": "src/_pytest/outcomes.py", "content": "TYPE_CHECKING = False"}, {"id": "_pytest.outcomes.OutcomeException", "kind": "class", "range": [28, 0, 49, 22, 784, 1610], "file_path": "src/_pytest/outcomes.py", "content": "class OutcomeException(BaseException):\n    \"\"\" OutcomeException and its subclass instances indicate and\n        contain info about test and collection outcomes.\n    \"\"\"\n\n    def __init__(self, msg: Optional[str] = None, pytrace: bool = True) -> None:\n        if msg is not None and not isinstance(msg, str):\n            error_msg = (\n                \"{} expected string as 'msg' parameter, got '{}' instead.\\n\"\n                \"Perhaps you meant to use a mark?\"\n            )\n            raise TypeError(error_msg.format(type(self).__name__, type(msg).__name__))\n        BaseException.__init__(self, msg)\n        self.msg = msg\n        self.pytrace = pytrace\n\n    def __repr__(self) -> str:\n        if self.msg:\n            return self.msg\n        return \"<{} instance>\".format(self.__class__.__name__)\n\n    __str__ = __repr__"}, {"id": "_pytest.outcomes.OutcomeException.__init__", "kind": "function", "range": [33, 4, 42, 30, 958, 1442], "file_path": "src/_pytest/outcomes.py", "content": "def __init__(self, msg: Optional[str] = None, pytrace: bool = True) -> None:\n        if msg is not None and not isinstance(msg, str):\n            error_msg = (\n                \"{} expected string as 'msg' parameter, got '{}' instead.\\n\"\n                \"Perhaps you meant to use a mark?\"\n            )\n            raise TypeError(error_msg.format(type(self).__name__, type(msg).__name__))\n        BaseException.__init__(self, msg)\n        self.msg = msg\n        self.pytrace = pytrace"}, {"id": "_pytest.outcomes.OutcomeException.__repr__", "kind": "function", "range": [44, 4, 47, 62, 1448, 1586], "file_path": "src/_pytest/outcomes.py", "content": "def __repr__(self) -> str:\n        if self.msg:\n            return self.msg\n        return \"<{} instance>\".format(self.__class__.__name__)"}, {"id": "_pytest.outcomes.OutcomeException.__str__", "kind": "variable", "range": [49, 4, 49, 22, 1592, 1610], "file_path": "src/_pytest/outcomes.py", "content": "__str__ = __repr__"}, {"id": "_pytest.outcomes.TEST_OUTCOME", "kind": "variable", "range": [52, 0, 52, 44, 1613, 1657], "file_path": "src/_pytest/outcomes.py", "content": "TEST_OUTCOME = (OutcomeException, Exception)"}, {"id": "_pytest.outcomes.Skipped", "kind": "class", "range": [55, 0, 67, 52, 1660, 2115], "file_path": "src/_pytest/outcomes.py", "content": "class Skipped(OutcomeException):\n    # XXX hackish: on 3k we fake to live in the builtins\n    # in order to have Skipped exception printing shorter/nicer\n    __module__ = \"builtins\"\n\n    def __init__(\n        self,\n        msg: Optional[str] = None,\n        pytrace: bool = True,\n        allow_module_level: bool = False,\n    ) -> None:\n        OutcomeException.__init__(self, msg=msg, pytrace=pytrace)\n        self.allow_module_level = allow_module_level"}, {"id": "_pytest.outcomes.Skipped.__module__", "kind": "variable", "range": [58, 4, 58, 27, 1818, 1841], "file_path": "src/_pytest/outcomes.py", "content": "__module__ = \"builtins\""}, {"id": "_pytest.outcomes.Skipped.__init__", "kind": "function", "range": [60, 4, 67, 52, 1847, 2115], "file_path": "src/_pytest/outcomes.py", "content": "def __init__(\n        self,\n        msg: Optional[str] = None,\n        pytrace: bool = True,\n        allow_module_level: bool = False,\n    ) -> None:\n        OutcomeException.__init__(self, msg=msg, pytrace=pytrace)\n        self.allow_module_level = allow_module_level"}, {"id": "_pytest.outcomes.Failed", "kind": "class", "range": [70, 0, 73, 27, 2118, 2236], "file_path": "src/_pytest/outcomes.py", "content": "class Failed(OutcomeException):\n    \"\"\" raised from an explicit call to pytest.fail() \"\"\"\n\n    __module__ = \"builtins\""}, {"id": "_pytest.outcomes.Failed.__module__", "kind": "variable", "range": [73, 4, 73, 27, 2213, 2236], "file_path": "src/_pytest/outcomes.py", "content": "__module__ = \"builtins\""}, {"id": "_pytest.outcomes.Exit", "kind": "class", "range": [76, 0, 84, 29, 2239, 2533], "file_path": "src/_pytest/outcomes.py", "content": "class Exit(Exception):\n    \"\"\" raised for immediate program exits (no tracebacks/summaries)\"\"\"\n\n    def __init__(\n        self, msg: str = \"unknown reason\", returncode: Optional[int] = None\n    ) -> None:\n        self.msg = msg\n        self.returncode = returncode\n        super().__init__(msg)"}, {"id": "_pytest.outcomes.Exit.__init__", "kind": "function", "range": [79, 4, 84, 29, 2339, 2533], "file_path": "src/_pytest/outcomes.py", "content": "def __init__(\n        self, msg: str = \"unknown reason\", returncode: Optional[int] = None\n    ) -> None:\n        self.msg = msg\n        self.returncode = returncode\n        super().__init__(msg)"}, {"id": "_pytest.outcomes._F", "kind": "variable", "range": [90, 0, 90, 34, 2666, 2700], "file_path": "src/_pytest/outcomes.py", "content": "_F = TypeVar(\"_F\", bound=Callable)"}, {"id": "_pytest.outcomes._ET", "kind": "variable", "range": [91, 0, 91, 49, 2701, 2750], "file_path": "src/_pytest/outcomes.py", "content": "_ET = TypeVar(\"_ET\", bound=\"Type[BaseException]\")"}, {"id": "_pytest.outcomes._WithException", "kind": "class", "range": [94, 0, 96, 31, 2753, 2859], "file_path": "src/_pytest/outcomes.py", "content": "class _WithException(Protocol[_F, _ET]):\n    Exception = None  # type: _ET\n    __call__ = None  # type: _F"}, {"id": "_pytest.outcomes._WithException.Exception", "kind": "variable", "range": [95, 4, 95, 20, 2798, 2814], "file_path": "src/_pytest/outcomes.py", "content": "Exception = None"}, {"id": "_pytest.outcomes._WithException.__call__", "kind": "variable", "range": [96, 4, 96, 19, 2832, 2847], "file_path": "src/_pytest/outcomes.py", "content": "__call__ = None"}, {"id": "_pytest.outcomes._with_exception", "kind": "function", "range": [99, 0, 105, 19, 2862, 3178], "file_path": "src/_pytest/outcomes.py", "content": "def _with_exception(exception_type: _ET) -> Callable[[_F], _WithException[_F, _ET]]:\n    def decorate(func: _F) -> _WithException[_F, _ET]:\n        func_with_exception = cast(_WithException[_F, _ET], func)\n        func_with_exception.Exception = exception_type\n        return func_with_exception\n\n    return decorate"}, {"id": "_pytest.outcomes.exit", "kind": "function", "range": [111, 0, 120, 31, 3208, 3523], "file_path": "src/_pytest/outcomes.py", "content": "@_with_exception(Exit)\ndef exit(msg: str, returncode: Optional[int] = None) -> \"NoReturn\":\n    \"\"\"\n    Exit testing process.\n\n    :param str msg: message to display upon exit.\n    :param int returncode: return code to be used when exiting pytest.\n    \"\"\"\n    __tracebackhide__ = True\n    raise Exit(msg, returncode)"}, {"id": "_pytest.outcomes.skip", "kind": "function", "range": [123, 0, 144, 65, 3526, 4542], "file_path": "src/_pytest/outcomes.py", "content": "@_with_exception(Skipped)\ndef skip(msg: str = \"\", *, allow_module_level: bool = False) -> \"NoReturn\":\n    \"\"\"\n    Skip an executing test with the given message.\n\n    This function should be called only during testing (setup, call or teardown) or\n    during collection by using the ``allow_module_level`` flag.  This function can\n    be called in doctests as well.\n\n    :kwarg bool allow_module_level: allows this function to be called at\n        module level, skipping the rest of the module. Default to False.\n\n    .. note::\n        It is better to use the :ref:`pytest.mark.skipif ref` marker when possible to declare a test to be\n        skipped under certain conditions like mismatching platforms or\n        dependencies.\n        Similarly, use the ``# doctest: +SKIP`` directive (see `doctest.SKIP\n        <https://docs.python.org/3/library/doctest.html#doctest.SKIP>`_)\n        to skip a doctest statically.\n    \"\"\"\n    __tracebackhide__ = True\n    raise Skipped(msg=msg, allow_module_level=allow_module_level)"}, {"id": "_pytest.outcomes.fail", "kind": "function", "range": [147, 0, 157, 42, 4545, 4989], "file_path": "src/_pytest/outcomes.py", "content": "@_with_exception(Failed)\ndef fail(msg: str = \"\", pytrace: bool = True) -> \"NoReturn\":\n    \"\"\"\n    Explicitly fail an executing test with the given message.\n\n    :param str msg: the message to show the user as reason for the failure.\n    :param bool pytrace: if false the msg represents the full failure information and no\n        python traceback will be reported.\n    \"\"\"\n    __tracebackhide__ = True\n    raise Failed(msg=msg, pytrace=pytrace)"}, {"id": "_pytest.outcomes.XFailed", "kind": "class", "range": [160, 0, 161, 58, 4992, 5073], "file_path": "src/_pytest/outcomes.py", "content": "class XFailed(Failed):\n    \"\"\" raised from an explicit call to pytest.xfail() \"\"\""}, {"id": "_pytest.outcomes.xfail", "kind": "function", "range": [164, 0, 176, 25, 5076, 5580], "file_path": "src/_pytest/outcomes.py", "content": "@_with_exception(XFailed)\ndef xfail(reason: str = \"\") -> \"NoReturn\":\n    \"\"\"\n    Imperatively xfail an executing test or setup functions with the given reason.\n\n    This function should be called only during testing (setup, call or teardown).\n\n    .. note::\n        It is better to use the :ref:`pytest.mark.xfail ref` marker when possible to declare a test to be\n        xfailed under certain conditions like known bugs or missing features.\n    \"\"\"\n    __tracebackhide__ = True\n    raise XFailed(reason)"}, {"id": "_pytest.outcomes.importorskip", "kind": "function", "range": [179, 0, 225, 14, 5583, 7392], "file_path": "src/_pytest/outcomes.py", "content": "def importorskip(\n    modname: str, minversion: Optional[str] = None, reason: Optional[str] = None\n) -> Any:\n    \"\"\"Imports and returns the requested module ``modname``, or skip the\n    current test if the module cannot be imported.\n\n    :param str modname: the name of the module to import\n    :param str minversion: if given, the imported module's ``__version__``\n        attribute must be at least this minimal version, otherwise the test is\n        still skipped.\n    :param str reason: if given, this reason is shown as the message when the\n        module cannot be imported.\n    :returns: The imported module. This should be assigned to its canonical\n        name.\n\n    Example::\n\n        docutils = pytest.importorskip(\"docutils\")\n    \"\"\"\n    import warnings\n\n    __tracebackhide__ = True\n    compile(modname, \"\", \"eval\")  # to catch syntaxerrors\n\n    with warnings.catch_warnings():\n        # make sure to ignore ImportWarnings that might happen because\n        # of existing directories with the same name we're trying to\n        # import but without a __init__.py file\n        warnings.simplefilter(\"ignore\")\n        try:\n            __import__(modname)\n        except ImportError as exc:\n            if reason is None:\n                reason = \"could not import {!r}: {}\".format(modname, exc)\n            raise Skipped(reason, allow_module_level=True) from None\n    mod = sys.modules[modname]\n    if minversion is None:\n        return mod\n    verattr = getattr(mod, \"__version__\", None)\n    if minversion is not None:\n        if verattr is None or Version(verattr) < Version(minversion):\n            raise Skipped(\n                \"module %r has __version__ %r, required is: %r\"\n                % (modname, verattr, minversion),\n                allow_module_level=True,\n            )\n    return mod"}, {"id": "_pytest.stepwise.pytest_addoption", "kind": "function", "range": [3, 0, 17, 5, 16, 479], "file_path": "src/_pytest/stepwise.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--sw\",\n        \"--stepwise\",\n        action=\"store_true\",\n        dest=\"stepwise\",\n        help=\"exit on test failure and continue from last failing test next time\",\n    )\n    group.addoption(\n        \"--stepwise-skip\",\n        action=\"store_true\",\n        dest=\"stepwise_skip\",\n        help=\"ignore the first failing test but stop on the next failing test\",\n    )"}, {"id": "_pytest.stepwise.pytest_configure", "kind": "function", "range": [20, 0, 22, 75, 482, 604], "file_path": "src/_pytest/stepwise.py", "content": "@pytest.hookimpl\ndef pytest_configure(config):\n    config.pluginmanager.register(StepwisePlugin(config), \"stepwiseplugin\")"}, {"id": "_pytest.stepwise.StepwisePlugin", "kind": "class", "range": [25, 0, 107, 55, 607, 3579], "file_path": "src/_pytest/stepwise.py", "content": "class StepwisePlugin:\n    def __init__(self, config):\n        self.config = config\n        self.active = config.getvalue(\"stepwise\")\n        self.session = None\n        self.report_status = \"\"\n\n        if self.active:\n            self.lastfailed = config.cache.get(\"cache/stepwise\", None)\n            self.skip = config.getvalue(\"stepwise_skip\")\n\n    def pytest_sessionstart(self, session):\n        self.session = session\n\n    def pytest_collection_modifyitems(self, session, config, items):\n        if not self.active:\n            return\n        if not self.lastfailed:\n            self.report_status = \"no previously failed tests, not skipping.\"\n            return\n\n        already_passed = []\n        found = False\n\n        # Make a list of all tests that have been run before the last failing one.\n        for item in items:\n            if item.nodeid == self.lastfailed:\n                found = True\n                break\n            else:\n                already_passed.append(item)\n\n        # If the previously failed test was not found among the test items,\n        # do not skip any tests.\n        if not found:\n            self.report_status = \"previously failed test not found, not skipping.\"\n            already_passed = []\n        else:\n            self.report_status = \"skipping {} already passed items.\".format(\n                len(already_passed)\n            )\n\n        for item in already_passed:\n            items.remove(item)\n\n        config.hook.pytest_deselected(items=already_passed)\n\n    def pytest_runtest_logreport(self, report):\n        if not self.active:\n            return\n\n        if report.failed:\n            if self.skip:\n                # Remove test from the failed ones (if it exists) and unset the skip option\n                # to make sure the following tests will not be skipped.\n                if report.nodeid == self.lastfailed:\n                    self.lastfailed = None\n\n                self.skip = False\n            else:\n                # Mark test as the last failing and interrupt the test session.\n                self.lastfailed = report.nodeid\n                self.session.shouldstop = (\n                    \"Test failed, continuing from this test next run.\"\n                )\n\n        else:\n            # If the test was actually run and did pass.\n            if report.when == \"call\":\n                # Remove test from the failed ones, if exists.\n                if report.nodeid == self.lastfailed:\n                    self.lastfailed = None\n\n    def pytest_report_collectionfinish(self):\n        if self.active and self.config.getoption(\"verbose\") >= 0 and self.report_status:\n            return \"stepwise: %s\" % self.report_status\n\n    def pytest_sessionfinish(self, session):\n        if self.active:\n            self.config.cache.set(\"cache/stepwise\", self.lastfailed)\n        else:\n            # Clear the list of failing tests if the plugin is not active.\n            self.config.cache.set(\"cache/stepwise\", [])"}, {"id": "_pytest.stepwise.StepwisePlugin.__init__", "kind": "function", "range": [26, 4, 34, 56, 633, 952], "file_path": "src/_pytest/stepwise.py", "content": "def __init__(self, config):\n        self.config = config\n        self.active = config.getvalue(\"stepwise\")\n        self.session = None\n        self.report_status = \"\"\n\n        if self.active:\n            self.lastfailed = config.cache.get(\"cache/stepwise\", None)\n            self.skip = config.getvalue(\"stepwise_skip\")"}, {"id": "_pytest.stepwise.StepwisePlugin.pytest_sessionstart", "kind": "function", "range": [36, 4, 37, 30, 958, 1028], "file_path": "src/_pytest/stepwise.py", "content": "def pytest_sessionstart(self, session):\n        self.session = session"}, {"id": "_pytest.stepwise.StepwisePlugin.pytest_collection_modifyitems", "kind": "function", "range": [39, 4, 70, 59, 1034, 2112], "file_path": "src/_pytest/stepwise.py", "content": "def pytest_collection_modifyitems(self, session, config, items):\n        if not self.active:\n            return\n        if not self.lastfailed:\n            self.report_status = \"no previously failed tests, not skipping.\"\n            return\n\n        already_passed = []\n        found = False\n\n        # Make a list of all tests that have been run before the last failing one.\n        for item in items:\n            if item.nodeid == self.lastfailed:\n                found = True\n                break\n            else:\n                already_passed.append(item)\n\n        # If the previously failed test was not found among the test items,\n        # do not skip any tests.\n        if not found:\n            self.report_status = \"previously failed test not found, not skipping.\"\n            already_passed = []\n        else:\n            self.report_status = \"skipping {} already passed items.\".format(\n                len(already_passed)\n            )\n\n        for item in already_passed:\n            items.remove(item)\n\n        config.hook.pytest_deselected(items=already_passed)"}, {"id": "_pytest.stepwise.StepwisePlugin.pytest_runtest_logreport", "kind": "function", "range": [72, 4, 96, 42, 2118, 3104], "file_path": "src/_pytest/stepwise.py", "content": "def pytest_runtest_logreport(self, report):\n        if not self.active:\n            return\n\n        if report.failed:\n            if self.skip:\n                # Remove test from the failed ones (if it exists) and unset the skip option\n                # to make sure the following tests will not be skipped.\n                if report.nodeid == self.lastfailed:\n                    self.lastfailed = None\n\n                self.skip = False\n            else:\n                # Mark test as the last failing and interrupt the test session.\n                self.lastfailed = report.nodeid\n                self.session.shouldstop = (\n                    \"Test failed, continuing from this test next run.\"\n                )\n\n        else:\n            # If the test was actually run and did pass.\n            if report.when == \"call\":\n                # Remove test from the failed ones, if exists.\n                if report.nodeid == self.lastfailed:\n                    self.lastfailed = None"}, {"id": "_pytest.stepwise.StepwisePlugin.pytest_report_collectionfinish", "kind": "function", "range": [98, 4, 100, 54, 3110, 3295], "file_path": "src/_pytest/stepwise.py", "content": "def pytest_report_collectionfinish(self):\n        if self.active and self.config.getoption(\"verbose\") >= 0 and self.report_status:\n            return \"stepwise: %s\" % self.report_status"}, {"id": "_pytest.stepwise.StepwisePlugin.pytest_sessionfinish", "kind": "function", "range": [102, 4, 107, 55, 3301, 3579], "file_path": "src/_pytest/stepwise.py", "content": "def pytest_sessionfinish(self, session):\n        if self.active:\n            self.config.cache.set(\"cache/stepwise\", self.lastfailed)\n        else:\n            # Clear the list of failing tests if the plugin is not active.\n            self.config.cache.set(\"cache/stepwise\", [])"}, {"id": "_pytest.junitxml.xml_key", "kind": "variable", "range": [28, 0, 28, 30, 621, 651], "file_path": "src/_pytest/junitxml.py", "content": "xml_key = StoreKey[\"LogXML\"]()"}, {"id": "_pytest.junitxml.Junit", "kind": "class", "range": [31, 0, 32, 8, 654, 693], "file_path": "src/_pytest/junitxml.py", "content": "class Junit(py.xml.Namespace):\n    pass"}, {"id": "_pytest.junitxml._legal_chars", "kind": "variable", "range": [40, 0, 40, 33, 1018, 1051], "file_path": "src/_pytest/junitxml.py", "content": "_legal_chars = (0x09, 0x0A, 0x0D)"}, {"id": "_pytest.junitxml._legal_ranges", "kind": "variable", "range": [41, 0, 41, 85, 1052, 1137], "file_path": "src/_pytest/junitxml.py", "content": "_legal_ranges = ((0x20, 0x7E), (0x80, 0xD7FF), (0xE000, 0xFFFD), (0x10000, 0x10FFFF))"}, {"id": "_pytest.junitxml._legal_xml_re", "kind": "variable", "range": [42, 0, 46, 1, 1138, 1262], "file_path": "src/_pytest/junitxml.py", "content": "_legal_xml_re = [\n    \"{}-{}\".format(chr(low), chr(high))\n    for (low, high) in _legal_ranges\n    if low < sys.maxunicode\n]"}, {"id": "_pytest.junitxml._legal_xml_re", "kind": "variable", "range": [47, 0, 47, 62, 1263, 1325], "file_path": "src/_pytest/junitxml.py", "content": "_legal_xml_re = [chr(x) for x in _legal_chars] + _legal_xml_re"}, {"id": "_pytest.junitxml.illegal_xml_re", "kind": "variable", "range": [48, 0, 48, 61, 1326, 1387], "file_path": "src/_pytest/junitxml.py", "content": "illegal_xml_re = re.compile(\"[^%s]\" % \"\".join(_legal_xml_re))"}, {"id": "_pytest.junitxml._py_ext_re", "kind": "variable", "range": [53, 0, 53, 33, 1442, 1475], "file_path": "src/_pytest/junitxml.py", "content": "_py_ext_re = re.compile(r\"\\.py$\")"}, {"id": "_pytest.junitxml.bin_xml_escape", "kind": "function", "range": [56, 0, 64, 67, 1478, 1729], "file_path": "src/_pytest/junitxml.py", "content": "def bin_xml_escape(arg):\n    def repl(matchobj):\n        i = ord(matchobj.group())\n        if i <= 0xFF:\n            return \"#x%02X\" % i\n        else:\n            return \"#x%04X\" % i\n\n    return py.xml.raw(illegal_xml_re.sub(repl, py.xml.escape(arg)))"}, {"id": "_pytest.junitxml.merge_family", "kind": "function", "range": [67, 0, 74, 23, 1732, 1987], "file_path": "src/_pytest/junitxml.py", "content": "def merge_family(left, right):\n    result = {}\n    for kl, vl in left.items():\n        for kr, vr in right.items():\n            if not isinstance(vl, list):\n                raise TypeError(type(vl))\n            result[kl] = vl + vr\n    left.update(result)"}, {"id": "_pytest.junitxml.families", "kind": "variable", "range": [77, 0, 77, 13, 1990, 2003], "file_path": "src/_pytest/junitxml.py", "content": "families = {}"}, {"id": "_pytest.junitxml._NodeReporter", "kind": "class", "range": [89, 0, 259, 46, 2352, 8601], "file_path": "src/_pytest/junitxml.py", "content": "class _NodeReporter:\n    def __init__(self, nodeid, xml):\n        self.id = nodeid\n        self.xml = xml\n        self.add_stats = self.xml.add_stats\n        self.family = self.xml.family\n        self.duration = 0\n        self.properties = []\n        self.nodes = []\n        self.testcase = None\n        self.attrs = {}\n\n    def append(self, node):\n        self.xml.add_stats(type(node).__name__)\n        self.nodes.append(node)\n\n    def add_property(self, name, value):\n        self.properties.append((str(name), bin_xml_escape(value)))\n\n    def add_attribute(self, name, value):\n        self.attrs[str(name)] = bin_xml_escape(value)\n\n    def make_properties_node(self):\n        \"\"\"Return a Junit node containing custom properties, if any.\n        \"\"\"\n        if self.properties:\n            return Junit.properties(\n                [\n                    Junit.property(name=name, value=value)\n                    for name, value in self.properties\n                ]\n            )\n        return \"\"\n\n    def record_testreport(self, testreport):\n        assert not self.testcase\n        names = mangle_test_address(testreport.nodeid)\n        existing_attrs = self.attrs\n        classnames = names[:-1]\n        if self.xml.prefix:\n            classnames.insert(0, self.xml.prefix)\n        attrs = {\n            \"classname\": \".\".join(classnames),\n            \"name\": bin_xml_escape(names[-1]),\n            \"file\": testreport.location[0],\n        }\n        if testreport.location[1] is not None:\n            attrs[\"line\"] = testreport.location[1]\n        if hasattr(testreport, \"url\"):\n            attrs[\"url\"] = testreport.url\n        self.attrs = attrs\n        self.attrs.update(existing_attrs)  # restore any user-defined attributes\n\n        # Preserve legacy testcase behavior\n        if self.family == \"xunit1\":\n            return\n\n        # Filter out attributes not permitted by this test family.\n        # Including custom attributes because they are not valid here.\n        temp_attrs = {}\n        for key in self.attrs.keys():\n            if key in families[self.family][\"testcase\"]:\n                temp_attrs[key] = self.attrs[key]\n        self.attrs = temp_attrs\n\n    def to_xml(self):\n        testcase = Junit.testcase(time=\"%.3f\" % self.duration, **self.attrs)\n        testcase.append(self.make_properties_node())\n        for node in self.nodes:\n            testcase.append(node)\n        return testcase\n\n    def _add_simple(self, kind, message, data=None):\n        data = bin_xml_escape(data)\n        node = kind(data, message=message)\n        self.append(node)\n\n    def write_captured_output(self, report):\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n        if self.xml.logging == \"no\":\n            return\n        content_all = \"\"\n        if self.xml.logging in [\"log\", \"all\"]:\n            content_all = self._prepare_content(content_log, \" Captured Log \")\n        if self.xml.logging in [\"system-out\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_out, \" Captured Out \")\n            self._write_content(report, content_all, \"system-out\")\n            content_all = \"\"\n        if self.xml.logging in [\"system-err\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_err, \" Captured Err \")\n            self._write_content(report, content_all, \"system-err\")\n            content_all = \"\"\n        if content_all:\n            self._write_content(report, content_all, \"system-out\")\n\n    def _prepare_content(self, content, header):\n        return \"\\n\".join([header.center(80, \"-\"), content, \"\"])\n\n    def _write_content(self, report, content, jheader):\n        tag = getattr(Junit, jheader)\n        self.append(tag(bin_xml_escape(content)))\n\n    def append_pass(self, report):\n        self.add_stats(\"passed\")\n\n    def append_failure(self, report):\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        if hasattr(report, \"wasxfail\"):\n            self._add_simple(Junit.skipped, \"xfail-marked test passes unexpectedly\")\n        else:\n            if hasattr(report.longrepr, \"reprcrash\"):\n                message = report.longrepr.reprcrash.message\n            elif isinstance(report.longrepr, str):\n                message = report.longrepr\n            else:\n                message = str(report.longrepr)\n            message = bin_xml_escape(message)\n            fail = Junit.failure(message=message)\n            fail.append(bin_xml_escape(report.longrepr))\n            self.append(fail)\n\n    def append_collect_error(self, report):\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        self.append(\n            Junit.error(bin_xml_escape(report.longrepr), message=\"collection failure\")\n        )\n\n    def append_collect_skipped(self, report):\n        self._add_simple(Junit.skipped, \"collection skipped\", report.longrepr)\n\n    def append_error(self, report):\n        if report.when == \"teardown\":\n            msg = \"test teardown failure\"\n        else:\n            msg = \"test setup failure\"\n        self._add_simple(Junit.error, msg, report.longrepr)\n\n    def append_skipped(self, report):\n        if hasattr(report, \"wasxfail\"):\n            xfailreason = report.wasxfail\n            if xfailreason.startswith(\"reason: \"):\n                xfailreason = xfailreason[8:]\n            self.append(\n                Junit.skipped(\n                    \"\", type=\"pytest.xfail\", message=bin_xml_escape(xfailreason)\n                )\n            )\n        else:\n            filename, lineno, skipreason = report.longrepr\n            if skipreason.startswith(\"Skipped: \"):\n                skipreason = skipreason[9:]\n            details = \"{}:{}: {}\".format(filename, lineno, skipreason)\n\n            self.append(\n                Junit.skipped(\n                    bin_xml_escape(details),\n                    type=\"pytest.skip\",\n                    message=bin_xml_escape(skipreason),\n                )\n            )\n            self.write_captured_output(report)\n\n    def finalize(self):\n        data = self.to_xml().unicode(indent=0)\n        self.__dict__.clear()\n        self.to_xml = lambda: py.xml.raw(data)"}, {"id": "_pytest.junitxml._NodeReporter.__init__", "kind": "function", "range": [90, 4, 99, 23, 2377, 2671], "file_path": "src/_pytest/junitxml.py", "content": "def __init__(self, nodeid, xml):\n        self.id = nodeid\n        self.xml = xml\n        self.add_stats = self.xml.add_stats\n        self.family = self.xml.family\n        self.duration = 0\n        self.properties = []\n        self.nodes = []\n        self.testcase = None\n        self.attrs = {}"}, {"id": "_pytest.junitxml._NodeReporter.append", "kind": "function", "range": [101, 4, 103, 31, 2677, 2780], "file_path": "src/_pytest/junitxml.py", "content": "def append(self, node):\n        self.xml.add_stats(type(node).__name__)\n        self.nodes.append(node)"}, {"id": "_pytest.junitxml._NodeReporter.add_property", "kind": "function", "range": [105, 4, 106, 66, 2786, 2889], "file_path": "src/_pytest/junitxml.py", "content": "def add_property(self, name, value):\n        self.properties.append((str(name), bin_xml_escape(value)))"}, {"id": "_pytest.junitxml._NodeReporter.add_attribute", "kind": "function", "range": [108, 4, 109, 53, 2895, 2986], "file_path": "src/_pytest/junitxml.py", "content": "def add_attribute(self, name, value):\n        self.attrs[str(name)] = bin_xml_escape(value)"}, {"id": "_pytest.junitxml._NodeReporter.make_properties_node", "kind": "function", "range": [111, 4, 121, 17, 2992, 3351], "file_path": "src/_pytest/junitxml.py", "content": "def make_properties_node(self):\n        \"\"\"Return a Junit node containing custom properties, if any.\n        \"\"\"\n        if self.properties:\n            return Junit.properties(\n                [\n                    Junit.property(name=name, value=value)\n                    for name, value in self.properties\n                ]\n            )\n        return \"\""}, {"id": "_pytest.junitxml._NodeReporter.record_testreport", "kind": "function", "range": [123, 4, 152, 31, 3357, 4524], "file_path": "src/_pytest/junitxml.py", "content": "def record_testreport(self, testreport):\n        assert not self.testcase\n        names = mangle_test_address(testreport.nodeid)\n        existing_attrs = self.attrs\n        classnames = names[:-1]\n        if self.xml.prefix:\n            classnames.insert(0, self.xml.prefix)\n        attrs = {\n            \"classname\": \".\".join(classnames),\n            \"name\": bin_xml_escape(names[-1]),\n            \"file\": testreport.location[0],\n        }\n        if testreport.location[1] is not None:\n            attrs[\"line\"] = testreport.location[1]\n        if hasattr(testreport, \"url\"):\n            attrs[\"url\"] = testreport.url\n        self.attrs = attrs\n        self.attrs.update(existing_attrs)  # restore any user-defined attributes\n\n        # Preserve legacy testcase behavior\n        if self.family == \"xunit1\":\n            return\n\n        # Filter out attributes not permitted by this test family.\n        # Including custom attributes because they are not valid here.\n        temp_attrs = {}\n        for key in self.attrs.keys():\n            if key in families[self.family][\"testcase\"]:\n                temp_attrs[key] = self.attrs[key]\n        self.attrs = temp_attrs"}, {"id": "_pytest.junitxml._NodeReporter.to_xml", "kind": "function", "range": [154, 4, 159, 23, 4530, 4767], "file_path": "src/_pytest/junitxml.py", "content": "def to_xml(self):\n        testcase = Junit.testcase(time=\"%.3f\" % self.duration, **self.attrs)\n        testcase.append(self.make_properties_node())\n        for node in self.nodes:\n            testcase.append(node)\n        return testcase"}, {"id": "_pytest.junitxml._NodeReporter._add_simple", "kind": "function", "range": [161, 4, 164, 25, 4773, 4926], "file_path": "src/_pytest/junitxml.py", "content": "def _add_simple(self, kind, message, data=None):\n        data = bin_xml_escape(data)\n        node = kind(data, message=message)\n        self.append(node)"}, {"id": "_pytest.junitxml._NodeReporter.write_captured_output", "kind": "function", "range": [166, 4, 187, 66, 4932, 5947], "file_path": "src/_pytest/junitxml.py", "content": "def write_captured_output(self, report):\n        if not self.xml.log_passing_tests and report.passed:\n            return\n\n        content_out = report.capstdout\n        content_log = report.caplog\n        content_err = report.capstderr\n        if self.xml.logging == \"no\":\n            return\n        content_all = \"\"\n        if self.xml.logging in [\"log\", \"all\"]:\n            content_all = self._prepare_content(content_log, \" Captured Log \")\n        if self.xml.logging in [\"system-out\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_out, \" Captured Out \")\n            self._write_content(report, content_all, \"system-out\")\n            content_all = \"\"\n        if self.xml.logging in [\"system-err\", \"out-err\", \"all\"]:\n            content_all += self._prepare_content(content_err, \" Captured Err \")\n            self._write_content(report, content_all, \"system-err\")\n            content_all = \"\"\n        if content_all:\n            self._write_content(report, content_all, \"system-out\")"}, {"id": "_pytest.junitxml._NodeReporter._prepare_content", "kind": "function", "range": [189, 4, 190, 63, 5953, 6061], "file_path": "src/_pytest/junitxml.py", "content": "def _prepare_content(self, content, header):\n        return \"\\n\".join([header.center(80, \"-\"), content, \"\"])"}, {"id": "_pytest.junitxml._NodeReporter._write_content", "kind": "function", "range": [192, 4, 194, 49, 6067, 6206], "file_path": "src/_pytest/junitxml.py", "content": "def _write_content(self, report, content, jheader):\n        tag = getattr(Junit, jheader)\n        self.append(tag(bin_xml_escape(content)))"}, {"id": "_pytest.junitxml._NodeReporter.append_pass", "kind": "function", "range": [196, 4, 197, 32, 6212, 6275], "file_path": "src/_pytest/junitxml.py", "content": "def append_pass(self, report):\n        self.add_stats(\"passed\")"}, {"id": "_pytest.junitxml._NodeReporter.append_failure", "kind": "function", "range": [199, 4, 213, 29, 6281, 6969], "file_path": "src/_pytest/junitxml.py", "content": "def append_failure(self, report):\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        if hasattr(report, \"wasxfail\"):\n            self._add_simple(Junit.skipped, \"xfail-marked test passes unexpectedly\")\n        else:\n            if hasattr(report.longrepr, \"reprcrash\"):\n                message = report.longrepr.reprcrash.message\n            elif isinstance(report.longrepr, str):\n                message = report.longrepr\n            else:\n                message = str(report.longrepr)\n            message = bin_xml_escape(message)\n            fail = Junit.failure(message=message)\n            fail.append(bin_xml_escape(report.longrepr))\n            self.append(fail)"}, {"id": "_pytest.junitxml._NodeReporter.append_collect_error", "kind": "function", "range": [215, 4, 219, 9, 6975, 7193], "file_path": "src/_pytest/junitxml.py", "content": "def append_collect_error(self, report):\n        # msg = str(report.longrepr.reprtraceback.extraline)\n        self.append(\n            Junit.error(bin_xml_escape(report.longrepr), message=\"collection failure\")\n        )"}, {"id": "_pytest.junitxml._NodeReporter.append_collect_skipped", "kind": "function", "range": [221, 4, 222, 78, 7199, 7319], "file_path": "src/_pytest/junitxml.py", "content": "def append_collect_skipped(self, report):\n        self._add_simple(Junit.skipped, \"collection skipped\", report.longrepr)"}, {"id": "_pytest.junitxml._NodeReporter.append_error", "kind": "function", "range": [224, 4, 229, 59, 7325, 7549], "file_path": "src/_pytest/junitxml.py", "content": "def append_error(self, report):\n        if report.when == \"teardown\":\n            msg = \"test teardown failure\"\n        else:\n            msg = \"test setup failure\"\n        self._add_simple(Junit.error, msg, report.longrepr)"}, {"id": "_pytest.junitxml._NodeReporter.append_skipped", "kind": "function", "range": [231, 4, 254, 46, 7555, 8452], "file_path": "src/_pytest/junitxml.py", "content": "def append_skipped(self, report):\n        if hasattr(report, \"wasxfail\"):\n            xfailreason = report.wasxfail\n            if xfailreason.startswith(\"reason: \"):\n                xfailreason = xfailreason[8:]\n            self.append(\n                Junit.skipped(\n                    \"\", type=\"pytest.xfail\", message=bin_xml_escape(xfailreason)\n                )\n            )\n        else:\n            filename, lineno, skipreason = report.longrepr\n            if skipreason.startswith(\"Skipped: \"):\n                skipreason = skipreason[9:]\n            details = \"{}:{}: {}\".format(filename, lineno, skipreason)\n\n            self.append(\n                Junit.skipped(\n                    bin_xml_escape(details),\n                    type=\"pytest.skip\",\n                    message=bin_xml_escape(skipreason),\n                )\n            )\n            self.write_captured_output(report)"}, {"id": "_pytest.junitxml._NodeReporter.finalize", "kind": "function", "range": [256, 4, 259, 46, 8458, 8601], "file_path": "src/_pytest/junitxml.py", "content": "def finalize(self):\n        data = self.to_xml().unicode(indent=0)\n        self.__dict__.clear()\n        self.to_xml = lambda: py.xml.raw(data)"}, {"id": "_pytest.junitxml._warn_incompatibility_with_xunit2", "kind": "function", "range": [262, 0, 274, 9, 8604, 9212], "file_path": "src/_pytest/junitxml.py", "content": "def _warn_incompatibility_with_xunit2(request, fixture_name):\n    \"\"\"Emits a PytestWarning about the given fixture being incompatible with newer xunit revisions\"\"\"\n    from _pytest.warning_types import PytestWarning\n\n    xml = request.config._store.get(xml_key, None)\n    if xml is not None and xml.family not in (\"xunit1\", \"legacy\"):\n        request.node.warn(\n            PytestWarning(\n                \"{fixture_name} is incompatible with junit_family '{family}' (use 'legacy' or 'xunit1')\".format(\n                    fixture_name=fixture_name, family=xml.family\n                )\n            )\n        )"}, {"id": "_pytest.junitxml.record_property", "kind": "function", "range": [277, 0, 295, 26, 9215, 9833], "file_path": "src/_pytest/junitxml.py", "content": "@pytest.fixture\ndef record_property(request):\n    \"\"\"Add an extra properties the calling test.\n    User properties become part of the test report and are available to the\n    configured reporters, like JUnit XML.\n    The fixture is callable with ``(name, value)``, with value being automatically\n    xml-encoded.\n\n    Example::\n\n        def test_function(record_property):\n            record_property(\"example_key\", 1)\n    \"\"\"\n    _warn_incompatibility_with_xunit2(request, \"record_property\")\n\n    def append_property(name, value):\n        request.node.user_properties.append((name, value))\n\n    return append_property"}, {"id": "_pytest.junitxml.record_xml_attribute", "kind": "function", "range": [298, 0, 323, 20, 9836, 10624], "file_path": "src/_pytest/junitxml.py", "content": "@pytest.fixture\ndef record_xml_attribute(request):\n    \"\"\"Add extra xml attributes to the tag for the calling test.\n    The fixture is callable with ``(name, value)``, with value being\n    automatically xml-encoded\n    \"\"\"\n    from _pytest.warning_types import PytestExperimentalApiWarning\n\n    request.node.warn(\n        PytestExperimentalApiWarning(\"record_xml_attribute is an experimental feature\")\n    )\n\n    _warn_incompatibility_with_xunit2(request, \"record_xml_attribute\")\n\n    # Declare noop\n    def add_attr_noop(name, value):\n        pass\n\n    attr_func = add_attr_noop\n\n    xml = request.config._store.get(xml_key, None)\n    if xml is not None:\n        node_reporter = xml.node_reporter(request.node.nodeid)\n        attr_func = node_reporter.add_attribute\n\n    return attr_func"}, {"id": "_pytest.junitxml._check_record_param_type", "kind": "function", "range": [326, 0, 332, 68, 10627, 10974], "file_path": "src/_pytest/junitxml.py", "content": "def _check_record_param_type(param, v):\n    \"\"\"Used by record_testsuite_property to check that the given parameter name is of the proper\n    type\"\"\"\n    __tracebackhide__ = True\n    if not isinstance(v, str):\n        msg = \"{param} parameter needs to be a string, but {g} given\"\n        raise TypeError(msg.format(param=param, g=type(v).__name__))"}, {"id": "_pytest.junitxml.record_testsuite_property", "kind": "function", "range": [335, 0, 362, 22, 10977, 12034], "file_path": "src/_pytest/junitxml.py", "content": "@pytest.fixture(scope=\"session\")\ndef record_testsuite_property(request):\n    \"\"\"\n    Records a new ``<property>`` tag as child of the root ``<testsuite>``. This is suitable to\n    writing global information regarding the entire test suite, and is compatible with ``xunit2`` JUnit family.\n\n    This is a ``session``-scoped fixture which is called with ``(name, value)``. Example:\n\n    .. code-block:: python\n\n        def test_foo(record_testsuite_property):\n            record_testsuite_property(\"ARCH\", \"PPC\")\n            record_testsuite_property(\"STORAGE_TYPE\", \"CEPH\")\n\n    ``name`` must be a string, ``value`` will be converted to a string and properly xml-escaped.\n    \"\"\"\n\n    __tracebackhide__ = True\n\n    def record_func(name, value):\n        \"\"\"noop function in case --junitxml was not passed in the command-line\"\"\"\n        __tracebackhide__ = True\n        _check_record_param_type(\"name\", name)\n\n    xml = request.config._store.get(xml_key, None)\n    if xml is not None:\n        record_func = xml.add_global_property  # noqa\n    return record_func"}, {"id": "_pytest.junitxml.pytest_addoption", "kind": "function", "range": [365, 0, 407, 5, 12037, 13376], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"terminal reporting\")\n    group.addoption(\n        \"--junitxml\",\n        \"--junit-xml\",\n        action=\"store\",\n        dest=\"xmlpath\",\n        metavar=\"path\",\n        type=functools.partial(filename_arg, optname=\"--junitxml\"),\n        default=None,\n        help=\"create junit-xml style report file at given path.\",\n    )\n    group.addoption(\n        \"--junitprefix\",\n        \"--junit-prefix\",\n        action=\"store\",\n        metavar=\"str\",\n        default=None,\n        help=\"prepend prefix to classnames in junit-xml output\",\n    )\n    parser.addini(\n        \"junit_suite_name\", \"Test suite name for JUnit report\", default=\"pytest\"\n    )\n    parser.addini(\n        \"junit_logging\",\n        \"Write captured log messages to JUnit report: \"\n        \"one of no|log|system-out|system-err|out-err|all\",\n        default=\"no\",\n    )\n    parser.addini(\n        \"junit_log_passing_tests\",\n        \"Capture log information for passing tests to JUnit report: \",\n        type=\"bool\",\n        default=True,\n    )\n    parser.addini(\n        \"junit_duration_report\",\n        \"Duration time to report: one of total|call\",\n        default=\"total\",\n    )  # choices=['total', 'call'])\n    parser.addini(\n        \"junit_family\", \"Emit XML for schema: one of legacy|xunit1|xunit2\", default=None\n    )"}, {"id": "_pytest.junitxml.pytest_configure", "kind": "function", "range": [410, 0, 427, 61, 13379, 14153], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_configure(config):\n    xmlpath = config.option.xmlpath\n    # prevent opening xmllog on slave nodes (xdist)\n    if xmlpath and not hasattr(config, \"slaveinput\"):\n        junit_family = config.getini(\"junit_family\")\n        if not junit_family:\n            _issue_warning_captured(deprecated.JUNIT_XML_DEFAULT_FAMILY, config.hook, 2)\n            junit_family = \"xunit1\"\n        config._store[xml_key] = LogXML(\n            xmlpath,\n            config.option.junitprefix,\n            config.getini(\"junit_suite_name\"),\n            config.getini(\"junit_logging\"),\n            config.getini(\"junit_duration_report\"),\n            junit_family,\n            config.getini(\"junit_log_passing_tests\"),\n        )\n        config.pluginmanager.register(config._store[xml_key])"}, {"id": "_pytest.junitxml.pytest_unconfigure", "kind": "function", "range": [430, 0, 434, 44, 14156, 14322], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_unconfigure(config):\n    xml = config._store.get(xml_key, None)\n    if xml:\n        del config._store[xml_key]\n        config.pluginmanager.unregister(xml)"}, {"id": "_pytest.junitxml.mangle_test_address", "kind": "function", "range": [437, 0, 449, 16, 14325, 14746], "file_path": "src/_pytest/junitxml.py", "content": "def mangle_test_address(address):\n    path, possible_open_bracket, params = address.partition(\"[\")\n    names = path.split(\"::\")\n    try:\n        names.remove(\"()\")\n    except ValueError:\n        pass\n    # convert file path to dotted path\n    names[0] = names[0].replace(nodes.SEP, \".\")\n    names[0] = _py_ext_re.sub(\"\", names[0])\n    # put any params back\n    names[-1] += possible_open_bracket + params\n    return names"}, {"id": "_pytest.junitxml.LogXML", "kind": "class", "range": [452, 0, 681, 17, 14749, 23274], "file_path": "src/_pytest/junitxml.py", "content": "class LogXML:\n    def __init__(\n        self,\n        logfile,\n        prefix,\n        suite_name=\"pytest\",\n        logging=\"no\",\n        report_duration=\"total\",\n        family=\"xunit1\",\n        log_passing_tests=True,\n    ):\n        logfile = os.path.expanduser(os.path.expandvars(logfile))\n        self.logfile = os.path.normpath(os.path.abspath(logfile))\n        self.prefix = prefix\n        self.suite_name = suite_name\n        self.logging = logging\n        self.log_passing_tests = log_passing_tests\n        self.report_duration = report_duration\n        self.family = family\n        self.stats = dict.fromkeys([\"error\", \"passed\", \"failure\", \"skipped\"], 0)\n        self.node_reporters = {}  # nodeid -> _NodeReporter\n        self.node_reporters_ordered = []\n        self.global_properties = []\n\n        # List of reports that failed on call but teardown is pending.\n        self.open_reports = []\n        self.cnt_double_fail_tests = 0\n\n        # Replaces convenience family with real family\n        if self.family == \"legacy\":\n            self.family = \"xunit1\"\n\n    def finalize(self, report):\n        nodeid = getattr(report, \"nodeid\", report)\n        # local hack to handle xdist report order\n        slavenode = getattr(report, \"node\", None)\n        reporter = self.node_reporters.pop((nodeid, slavenode))\n        if reporter is not None:\n            reporter.finalize()\n\n    def node_reporter(self, report):\n        nodeid = getattr(report, \"nodeid\", report)\n        # local hack to handle xdist report order\n        slavenode = getattr(report, \"node\", None)\n\n        key = nodeid, slavenode\n\n        if key in self.node_reporters:\n            # TODO: breaks for --dist=each\n            return self.node_reporters[key]\n\n        reporter = _NodeReporter(nodeid, self)\n\n        self.node_reporters[key] = reporter\n        self.node_reporters_ordered.append(reporter)\n\n        return reporter\n\n    def add_stats(self, key):\n        if key in self.stats:\n            self.stats[key] += 1\n\n    def _opentestcase(self, report):\n        reporter = self.node_reporter(report)\n        reporter.record_testreport(report)\n        return reporter\n\n    def pytest_runtest_logreport(self, report):\n        \"\"\"handle a setup/call/teardown report, generating the appropriate\n        xml tags as necessary.\n\n        note: due to plugins like xdist, this hook may be called in interlaced\n        order with reports from other nodes. for example:\n\n        usual call order:\n            -> setup node1\n            -> call node1\n            -> teardown node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n\n        possible call order in xdist:\n            -> setup node1\n            -> call node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n            -> teardown node1\n        \"\"\"\n        close_report = None\n        if report.passed:\n            if report.when == \"call\":  # ignore setup/teardown\n                reporter = self._opentestcase(report)\n                reporter.append_pass(report)\n        elif report.failed:\n            if report.when == \"teardown\":\n                # The following vars are needed when xdist plugin is used\n                report_wid = getattr(report, \"worker_id\", None)\n                report_ii = getattr(report, \"item_index\", None)\n                close_report = next(\n                    (\n                        rep\n                        for rep in self.open_reports\n                        if (\n                            rep.nodeid == report.nodeid\n                            and getattr(rep, \"item_index\", None) == report_ii\n                            and getattr(rep, \"worker_id\", None) == report_wid\n                        )\n                    ),\n                    None,\n                )\n                if close_report:\n                    # We need to open new testcase in case we have failure in\n                    # call and error in teardown in order to follow junit\n                    # schema\n                    self.finalize(close_report)\n                    self.cnt_double_fail_tests += 1\n            reporter = self._opentestcase(report)\n            if report.when == \"call\":\n                reporter.append_failure(report)\n                self.open_reports.append(report)\n                if not self.log_passing_tests:\n                    reporter.write_captured_output(report)\n            else:\n                reporter.append_error(report)\n        elif report.skipped:\n            reporter = self._opentestcase(report)\n            reporter.append_skipped(report)\n        self.update_testcase_duration(report)\n        if report.when == \"teardown\":\n            reporter = self._opentestcase(report)\n            reporter.write_captured_output(report)\n\n            for propname, propvalue in report.user_properties:\n                reporter.add_property(propname, propvalue)\n\n            self.finalize(report)\n            report_wid = getattr(report, \"worker_id\", None)\n            report_ii = getattr(report, \"item_index\", None)\n            close_report = next(\n                (\n                    rep\n                    for rep in self.open_reports\n                    if (\n                        rep.nodeid == report.nodeid\n                        and getattr(rep, \"item_index\", None) == report_ii\n                        and getattr(rep, \"worker_id\", None) == report_wid\n                    )\n                ),\n                None,\n            )\n            if close_report:\n                self.open_reports.remove(close_report)\n\n    def update_testcase_duration(self, report):\n        \"\"\"accumulates total duration for nodeid from given report and updates\n        the Junit.testcase with the new total if already created.\n        \"\"\"\n        if self.report_duration == \"total\" or report.when == self.report_duration:\n            reporter = self.node_reporter(report)\n            reporter.duration += getattr(report, \"duration\", 0.0)\n\n    def pytest_collectreport(self, report):\n        if not report.passed:\n            reporter = self._opentestcase(report)\n            if report.failed:\n                reporter.append_collect_error(report)\n            else:\n                reporter.append_collect_skipped(report)\n\n    def pytest_internalerror(self, excrepr):\n        reporter = self.node_reporter(\"internal\")\n        reporter.attrs.update(classname=\"pytest\", name=\"internal\")\n        reporter._add_simple(Junit.error, \"internal error\", excrepr)\n\n    def pytest_sessionstart(self):\n        self.suite_start_time = time.time()\n\n    def pytest_sessionfinish(self):\n        dirname = os.path.dirname(os.path.abspath(self.logfile))\n        if not os.path.isdir(dirname):\n            os.makedirs(dirname)\n        logfile = open(self.logfile, \"w\", encoding=\"utf-8\")\n        suite_stop_time = time.time()\n        suite_time_delta = suite_stop_time - self.suite_start_time\n\n        numtests = (\n            self.stats[\"passed\"]\n            + self.stats[\"failure\"]\n            + self.stats[\"skipped\"]\n            + self.stats[\"error\"]\n            - self.cnt_double_fail_tests\n        )\n        logfile.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>')\n\n        suite_node = Junit.testsuite(\n            self._get_global_properties_node(),\n            [x.to_xml() for x in self.node_reporters_ordered],\n            name=self.suite_name,\n            errors=self.stats[\"error\"],\n            failures=self.stats[\"failure\"],\n            skipped=self.stats[\"skipped\"],\n            tests=numtests,\n            time=\"%.3f\" % suite_time_delta,\n            timestamp=datetime.fromtimestamp(self.suite_start_time).isoformat(),\n            hostname=platform.node(),\n        )\n        logfile.write(Junit.testsuites([suite_node]).unicode(indent=0))\n        logfile.close()\n\n    def pytest_terminal_summary(self, terminalreporter):\n        terminalreporter.write_sep(\"-\", \"generated xml file: %s\" % (self.logfile))\n\n    def add_global_property(self, name, value):\n        __tracebackhide__ = True\n        _check_record_param_type(\"name\", name)\n        self.global_properties.append((name, bin_xml_escape(value)))\n\n    def _get_global_properties_node(self):\n        \"\"\"Return a Junit node containing custom properties, if any.\n        \"\"\"\n        if self.global_properties:\n            return Junit.properties(\n                [\n                    Junit.property(name=name, value=value)\n                    for name, value in self.global_properties\n                ]\n            )\n        return \"\""}, {"id": "_pytest.junitxml.LogXML.__init__", "kind": "function", "range": [453, 4, 482, 34, 14767, 15818], "file_path": "src/_pytest/junitxml.py", "content": "def __init__(\n        self,\n        logfile,\n        prefix,\n        suite_name=\"pytest\",\n        logging=\"no\",\n        report_duration=\"total\",\n        family=\"xunit1\",\n        log_passing_tests=True,\n    ):\n        logfile = os.path.expanduser(os.path.expandvars(logfile))\n        self.logfile = os.path.normpath(os.path.abspath(logfile))\n        self.prefix = prefix\n        self.suite_name = suite_name\n        self.logging = logging\n        self.log_passing_tests = log_passing_tests\n        self.report_duration = report_duration\n        self.family = family\n        self.stats = dict.fromkeys([\"error\", \"passed\", \"failure\", \"skipped\"], 0)\n        self.node_reporters = {}  # nodeid -> _NodeReporter\n        self.node_reporters_ordered = []\n        self.global_properties = []\n\n        # List of reports that failed on call but teardown is pending.\n        self.open_reports = []\n        self.cnt_double_fail_tests = 0\n\n        # Replaces convenience family with real family\n        if self.family == \"legacy\":\n            self.family = \"xunit1\""}, {"id": "_pytest.junitxml.LogXML.finalize", "kind": "function", "range": [484, 4, 490, 31, 15824, 16131], "file_path": "src/_pytest/junitxml.py", "content": "def finalize(self, report):\n        nodeid = getattr(report, \"nodeid\", report)\n        # local hack to handle xdist report order\n        slavenode = getattr(report, \"node\", None)\n        reporter = self.node_reporters.pop((nodeid, slavenode))\n        if reporter is not None:\n            reporter.finalize()"}, {"id": "_pytest.junitxml.LogXML.node_reporter", "kind": "function", "range": [492, 4, 508, 23, 16137, 16651], "file_path": "src/_pytest/junitxml.py", "content": "def node_reporter(self, report):\n        nodeid = getattr(report, \"nodeid\", report)\n        # local hack to handle xdist report order\n        slavenode = getattr(report, \"node\", None)\n\n        key = nodeid, slavenode\n\n        if key in self.node_reporters:\n            # TODO: breaks for --dist=each\n            return self.node_reporters[key]\n\n        reporter = _NodeReporter(nodeid, self)\n\n        self.node_reporters[key] = reporter\n        self.node_reporters_ordered.append(reporter)\n\n        return reporter"}, {"id": "_pytest.junitxml.LogXML.add_stats", "kind": "function", "range": [510, 4, 512, 32, 16657, 16745], "file_path": "src/_pytest/junitxml.py", "content": "def add_stats(self, key):\n        if key in self.stats:\n            self.stats[key] += 1"}, {"id": "_pytest.junitxml.LogXML._opentestcase", "kind": "function", "range": [514, 4, 517, 23, 16751, 16896], "file_path": "src/_pytest/junitxml.py", "content": "def _opentestcase(self, report):\n        reporter = self.node_reporter(report)\n        reporter.record_testreport(report)\n        return reporter"}, {"id": "_pytest.junitxml.LogXML.pytest_runtest_logreport", "kind": "function", "range": [519, 4, 605, 54, 16902, 20326], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_runtest_logreport(self, report):\n        \"\"\"handle a setup/call/teardown report, generating the appropriate\n        xml tags as necessary.\n\n        note: due to plugins like xdist, this hook may be called in interlaced\n        order with reports from other nodes. for example:\n\n        usual call order:\n            -> setup node1\n            -> call node1\n            -> teardown node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n\n        possible call order in xdist:\n            -> setup node1\n            -> call node1\n            -> setup node2\n            -> call node2\n            -> teardown node2\n            -> teardown node1\n        \"\"\"\n        close_report = None\n        if report.passed:\n            if report.when == \"call\":  # ignore setup/teardown\n                reporter = self._opentestcase(report)\n                reporter.append_pass(report)\n        elif report.failed:\n            if report.when == \"teardown\":\n                # The following vars are needed when xdist plugin is used\n                report_wid = getattr(report, \"worker_id\", None)\n                report_ii = getattr(report, \"item_index\", None)\n                close_report = next(\n                    (\n                        rep\n                        for rep in self.open_reports\n                        if (\n                            rep.nodeid == report.nodeid\n                            and getattr(rep, \"item_index\", None) == report_ii\n                            and getattr(rep, \"worker_id\", None) == report_wid\n                        )\n                    ),\n                    None,\n                )\n                if close_report:\n                    # We need to open new testcase in case we have failure in\n                    # call and error in teardown in order to follow junit\n                    # schema\n                    self.finalize(close_report)\n                    self.cnt_double_fail_tests += 1\n            reporter = self._opentestcase(report)\n            if report.when == \"call\":\n                reporter.append_failure(report)\n                self.open_reports.append(report)\n                if not self.log_passing_tests:\n                    reporter.write_captured_output(report)\n            else:\n                reporter.append_error(report)\n        elif report.skipped:\n            reporter = self._opentestcase(report)\n            reporter.append_skipped(report)\n        self.update_testcase_duration(report)\n        if report.when == \"teardown\":\n            reporter = self._opentestcase(report)\n            reporter.write_captured_output(report)\n\n            for propname, propvalue in report.user_properties:\n                reporter.add_property(propname, propvalue)\n\n            self.finalize(report)\n            report_wid = getattr(report, \"worker_id\", None)\n            report_ii = getattr(report, \"item_index\", None)\n            close_report = next(\n                (\n                    rep\n                    for rep in self.open_reports\n                    if (\n                        rep.nodeid == report.nodeid\n                        and getattr(rep, \"item_index\", None) == report_ii\n                        and getattr(rep, \"worker_id\", None) == report_wid\n                    )\n                ),\n                None,\n            )\n            if close_report:\n                self.open_reports.remove(close_report)"}, {"id": "_pytest.junitxml.LogXML.update_testcase_duration", "kind": "function", "range": [607, 4, 613, 65, 20332, 20731], "file_path": "src/_pytest/junitxml.py", "content": "def update_testcase_duration(self, report):\n        \"\"\"accumulates total duration for nodeid from given report and updates\n        the Junit.testcase with the new total if already created.\n        \"\"\"\n        if self.report_duration == \"total\" or report.when == self.report_duration:\n            reporter = self.node_reporter(report)\n            reporter.duration += getattr(report, \"duration\", 0.0)"}, {"id": "_pytest.junitxml.LogXML.pytest_collectreport", "kind": "function", "range": [615, 4, 621, 55, 20737, 21014], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_collectreport(self, report):\n        if not report.passed:\n            reporter = self._opentestcase(report)\n            if report.failed:\n                reporter.append_collect_error(report)\n            else:\n                reporter.append_collect_skipped(report)"}, {"id": "_pytest.junitxml.LogXML.pytest_internalerror", "kind": "function", "range": [623, 4, 626, 68, 21020, 21246], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_internalerror(self, excrepr):\n        reporter = self.node_reporter(\"internal\")\n        reporter.attrs.update(classname=\"pytest\", name=\"internal\")\n        reporter._add_simple(Junit.error, \"internal error\", excrepr)"}, {"id": "_pytest.junitxml.LogXML.pytest_sessionstart", "kind": "function", "range": [628, 4, 629, 43, 21252, 21326], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_sessionstart(self):\n        self.suite_start_time = time.time()"}, {"id": "_pytest.junitxml.LogXML.pytest_sessionfinish", "kind": "function", "range": [631, 4, 661, 23, 21332, 22549], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_sessionfinish(self):\n        dirname = os.path.dirname(os.path.abspath(self.logfile))\n        if not os.path.isdir(dirname):\n            os.makedirs(dirname)\n        logfile = open(self.logfile, \"w\", encoding=\"utf-8\")\n        suite_stop_time = time.time()\n        suite_time_delta = suite_stop_time - self.suite_start_time\n\n        numtests = (\n            self.stats[\"passed\"]\n            + self.stats[\"failure\"]\n            + self.stats[\"skipped\"]\n            + self.stats[\"error\"]\n            - self.cnt_double_fail_tests\n        )\n        logfile.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>')\n\n        suite_node = Junit.testsuite(\n            self._get_global_properties_node(),\n            [x.to_xml() for x in self.node_reporters_ordered],\n            name=self.suite_name,\n            errors=self.stats[\"error\"],\n            failures=self.stats[\"failure\"],\n            skipped=self.stats[\"skipped\"],\n            tests=numtests,\n            time=\"%.3f\" % suite_time_delta,\n            timestamp=datetime.fromtimestamp(self.suite_start_time).isoformat(),\n            hostname=platform.node(),\n        )\n        logfile.write(Junit.testsuites([suite_node]).unicode(indent=0))\n        logfile.close()"}, {"id": "_pytest.junitxml.LogXML.pytest_terminal_summary", "kind": "function", "range": [663, 4, 664, 82, 22555, 22690], "file_path": "src/_pytest/junitxml.py", "content": "def pytest_terminal_summary(self, terminalreporter):\n        terminalreporter.write_sep(\"-\", \"generated xml file: %s\" % (self.logfile))"}, {"id": "_pytest.junitxml.LogXML.add_global_property", "kind": "function", "range": [666, 4, 669, 68, 22696, 22888], "file_path": "src/_pytest/junitxml.py", "content": "def add_global_property(self, name, value):\n        __tracebackhide__ = True\n        _check_record_param_type(\"name\", name)\n        self.global_properties.append((name, bin_xml_escape(value)))"}, {"id": "_pytest.junitxml.LogXML._get_global_properties_node", "kind": "function", "range": [671, 4, 681, 17, 22894, 23274], "file_path": "src/_pytest/junitxml.py", "content": "def _get_global_properties_node(self):\n        \"\"\"Return a Junit node containing custom properties, if any.\n        \"\"\"\n        if self.global_properties:\n            return Junit.properties(\n                [\n                    Junit.property(name=name, value=value)\n                    for name, value in self.global_properties\n                ]\n            )\n        return \"\""}, {"id": "_pytest.python.pyobj_property", "kind": "function", "range": [59, 0, 68, 41, 1882, 2201], "file_path": "src/_pytest/python.py", "content": "def pyobj_property(name):\n    def get(self):\n        node = self.getparent(getattr(__import__(\"pytest\"), name))\n        if node is not None:\n            return node.obj\n\n    doc = \"python {} object this node was collected from (can be None).\".format(\n        name.lower()\n    )\n    return property(get, None, None, doc)"}, {"id": "_pytest.python.pytest_addoption", "kind": "function", "range": [71, 0, 123, 5, 2204, 3879], "file_path": "src/_pytest/python.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--fixtures\",\n        \"--funcargs\",\n        action=\"store_true\",\n        dest=\"showfixtures\",\n        default=False,\n        help=\"show available fixtures, sorted by plugin appearance \"\n        \"(fixtures with leading '_' are only shown with '-v')\",\n    )\n    group.addoption(\n        \"--fixtures-per-test\",\n        action=\"store_true\",\n        dest=\"show_fixtures_per_test\",\n        default=False,\n        help=\"show fixtures per test\",\n    )\n    parser.addini(\n        \"python_files\",\n        type=\"args\",\n        # NOTE: default is also used in AssertionRewritingHook.\n        default=[\"test_*.py\", \"*_test.py\"],\n        help=\"glob-style file patterns for Python test module discovery\",\n    )\n    parser.addini(\n        \"python_classes\",\n        type=\"args\",\n        default=[\"Test\"],\n        help=\"prefixes or glob names for Python test class discovery\",\n    )\n    parser.addini(\n        \"python_functions\",\n        type=\"args\",\n        default=[\"test\"],\n        help=\"prefixes or glob names for Python test function and method discovery\",\n    )\n    parser.addini(\n        \"disable_test_id_escaping_and_forfeit_all_rights_to_community_support\",\n        type=\"bool\",\n        default=False,\n        help=\"disable string escape non-ascii characters, might cause unwanted \"\n        \"side effects(use at your own risk)\",\n    )\n\n    group.addoption(\n        \"--import-mode\",\n        default=\"prepend\",\n        choices=[\"prepend\", \"append\"],\n        dest=\"importmode\",\n        help=\"prepend/append to sys.path when importing test modules, \"\n        \"default is to prepend.\",\n    )"}, {"id": "_pytest.python.pytest_cmdline_main", "kind": "function", "range": [126, 0, 132, 16, 3882, 4096], "file_path": "src/_pytest/python.py", "content": "def pytest_cmdline_main(config):\n    if config.option.showfixtures:\n        showfixtures(config)\n        return 0\n    if config.option.show_fixtures_per_test:\n        show_fixtures_per_test(config)\n        return 0"}, {"id": "_pytest.python.pytest_generate_tests", "kind": "function", "range": [135, 0, 138, 114, 4099, 4401], "file_path": "src/_pytest/python.py", "content": "def pytest_generate_tests(metafunc: \"Metafunc\") -> None:\n    for marker in metafunc.definition.iter_markers(name=\"parametrize\"):\n        # TODO: Fix this type-ignore (overlapping kwargs).\n        metafunc.parametrize(*marker.args, **marker.kwargs, _param_mark=marker)  # type: ignore[misc] # noqa: F821"}, {"id": "_pytest.python.pytest_configure", "kind": "function", "range": [141, 0, 158, 5, 4404, 5304], "file_path": "src/_pytest/python.py", "content": "def pytest_configure(config):\n    config.addinivalue_line(\n        \"markers\",\n        \"parametrize(argnames, argvalues): call a test function multiple \"\n        \"times passing in different arguments in turn. argvalues generally \"\n        \"needs to be a list of values if argnames specifies only one name \"\n        \"or a list of tuples of values if argnames specifies multiple names. \"\n        \"Example: @parametrize('arg1', [1,2]) would lead to two calls of the \"\n        \"decorated test function, one with arg1=1 and another with arg1=2.\"\n        \"see https://docs.pytest.org/en/latest/parametrize.html for more info \"\n        \"and examples.\",\n    )\n    config.addinivalue_line(\n        \"markers\",\n        \"usefixtures(fixturename1, fixturename2, ...): mark tests as needing \"\n        \"all of the specified fixtures. see \"\n        \"https://docs.pytest.org/en/latest/fixture.html#usefixtures \",\n    )"}, {"id": "_pytest.python.async_warn_and_skip", "kind": "function", "range": [161, 0, 171, 79, 5307, 5828], "file_path": "src/_pytest/python.py", "content": "def async_warn_and_skip(nodeid: str) -> None:\n    msg = \"async def functions are not natively supported and have been skipped.\\n\"\n    msg += (\n        \"You need to install a suitable plugin for your async framework, for example:\\n\"\n    )\n    msg += \"  - pytest-asyncio\\n\"\n    msg += \"  - pytest-trio\\n\"\n    msg += \"  - pytest-tornasync\\n\"\n    msg += \"  - pytest-twisted\"\n    warnings.warn(PytestUnhandledCoroutineWarning(msg.format(nodeid)))\n    skip(msg=\"async def function and no async plugin installed (see warnings)\")"}, {"id": "_pytest.python.pytest_pyfunc_call", "kind": "function", "range": [174, 0, 184, 15, 5831, 6308], "file_path": "src/_pytest/python.py", "content": "@hookimpl(trylast=True)\ndef pytest_pyfunc_call(pyfuncitem: \"Function\"):\n    testfunction = pyfuncitem.obj\n    if is_async_function(testfunction):\n        async_warn_and_skip(pyfuncitem.nodeid)\n    funcargs = pyfuncitem.funcargs\n    testargs = {arg: funcargs[arg] for arg in pyfuncitem._fixtureinfo.argnames}\n    result = testfunction(**testargs)\n    if hasattr(result, \"__await__\") or hasattr(result, \"__aiter__\"):\n        async_warn_and_skip(pyfuncitem.nodeid)\n    return True"}, {"id": "_pytest.python.pytest_collect_file", "kind": "function", "range": [187, 0, 196, 74, 6311, 6719], "file_path": "src/_pytest/python.py", "content": "def pytest_collect_file(path, parent):\n    ext = path.ext\n    if ext == \".py\":\n        if not parent.session.isinitpath(path):\n            if not path_matches_patterns(\n                path, parent.config.getini(\"python_files\") + [\"__init__.py\"]\n            ):\n                return\n        ihook = parent.session.gethookproxy(path)\n        return ihook.pytest_pycollect_makemodule(path=path, parent=parent)"}, {"id": "_pytest.python.path_matches_patterns", "kind": "function", "range": [199, 0, 201, 61, 6722, 6931], "file_path": "src/_pytest/python.py", "content": "def path_matches_patterns(path, patterns):\n    \"\"\"Returns True if the given py.path.local matches one of the patterns in the list of globs given\"\"\"\n    return any(path.fnmatch(pattern) for pattern in patterns)"}, {"id": "_pytest.python.pytest_pycollect_makemodule", "kind": "function", "range": [204, 0, 207, 50, 6934, 7126], "file_path": "src/_pytest/python.py", "content": "def pytest_pycollect_makemodule(path, parent):\n    if path.basename == \"__init__.py\":\n        return Package.from_parent(parent, fspath=path)\n    return Module.from_parent(parent, fspath=path)"}, {"id": "_pytest.python.pytest_pycollect_makeitem", "kind": "function", "range": [210, 0, 246, 37, 7129, 8829], "file_path": "src/_pytest/python.py", "content": "@hookimpl(hookwrapper=True)\ndef pytest_pycollect_makeitem(collector, name, obj):\n    outcome = yield\n    res = outcome.get_result()\n    if res is not None:\n        return\n    # nothing was collected elsewhere, let's do it here\n    if safe_isclass(obj):\n        if collector.istestclass(obj, name):\n            outcome.force_result(Class.from_parent(collector, name=name, obj=obj))\n    elif collector.istestfunction(obj, name):\n        # mock seems to store unbound methods (issue473), normalize it\n        obj = getattr(obj, \"__func__\", obj)\n        # We need to try and unwrap the function if it's a functools.partial\n        # or a functools.wrapped.\n        # We mustn't if it's been wrapped with mock.patch (python 2 only)\n        if not (inspect.isfunction(obj) or inspect.isfunction(get_real_func(obj))):\n            filename, lineno = getfslineno(obj)\n            warnings.warn_explicit(\n                message=PytestCollectionWarning(\n                    \"cannot collect %r because it is not a function.\" % name\n                ),\n                category=None,\n                filename=str(filename),\n                lineno=lineno + 1,\n            )\n        elif getattr(obj, \"__test__\", True):\n            if is_generator(obj):\n                res = Function.from_parent(collector, name=name)\n                reason = \"yield tests were removed in pytest 4.0 - {name} will be ignored\".format(\n                    name=name\n                )\n                res.add_marker(MARK_GEN.xfail(run=False, reason=reason))\n                res.warn(PytestCollectionWarning(reason))\n            else:\n                res = list(collector._genfunctions(name, obj))\n            outcome.force_result(res)"}, {"id": "_pytest.python.PyobjMixin", "kind": "class", "range": [249, 0, 309, 38, 8832, 10982], "file_path": "src/_pytest/python.py", "content": "class PyobjMixin:\n    module = pyobj_property(\"Module\")\n    cls = pyobj_property(\"Class\")\n    instance = pyobj_property(\"Instance\")\n    _ALLOW_MARKERS = True\n\n    @property\n    def obj(self):\n        \"\"\"Underlying Python object.\"\"\"\n        obj = getattr(self, \"_obj\", None)\n        if obj is None:\n            self._obj = obj = self._getobj()\n            # XXX evil hack\n            # used to avoid Instance collector marker duplication\n            if self._ALLOW_MARKERS:\n                self.own_markers.extend(get_unpacked_marks(self.obj))\n        return obj\n\n    @obj.setter\n    def obj(self, value):\n        self._obj = value\n\n    def _getobj(self):\n        \"\"\"Gets the underlying Python object. May be overwritten by subclasses.\"\"\"\n        return getattr(self.parent.obj, self.name)\n\n    def getmodpath(self, stopatmodule=True, includemodule=False):\n        \"\"\" return python path relative to the containing module. \"\"\"\n        chain = self.listchain()\n        chain.reverse()\n        parts = []\n        for node in chain:\n            if isinstance(node, Instance):\n                continue\n            name = node.name\n            if isinstance(node, Module):\n                name = os.path.splitext(name)[0]\n                if stopatmodule:\n                    if includemodule:\n                        parts.append(name)\n                    break\n            parts.append(name)\n        parts.reverse()\n        return \".\".join(parts)\n\n    def reportinfo(self) -> Tuple[Union[py.path.local, str], int, str]:\n        # XXX caching?\n        obj = self.obj\n        compat_co_firstlineno = getattr(obj, \"compat_co_firstlineno\", None)\n        if isinstance(compat_co_firstlineno, int):\n            # nose compatibility\n            file_path = sys.modules[obj.__module__].__file__\n            if file_path.endswith(\".pyc\"):\n                file_path = file_path[:-1]\n            fspath = file_path  # type: Union[py.path.local, str]\n            lineno = compat_co_firstlineno\n        else:\n            fspath, lineno = getfslineno(obj)\n        modpath = self.getmodpath()\n        assert isinstance(lineno, int)\n        return fspath, lineno, modpath"}, {"id": "_pytest.python.PyobjMixin.module", "kind": "variable", "range": [250, 4, 250, 37, 8854, 8887], "file_path": "src/_pytest/python.py", "content": "module = pyobj_property(\"Module\")"}, {"id": "_pytest.python.PyobjMixin.cls", "kind": "variable", "range": [251, 4, 251, 33, 8892, 8921], "file_path": "src/_pytest/python.py", "content": "cls = pyobj_property(\"Class\")"}, {"id": "_pytest.python.PyobjMixin.instance", "kind": "variable", "range": [252, 4, 252, 41, 8926, 8963], "file_path": "src/_pytest/python.py", "content": "instance = pyobj_property(\"Instance\")"}, {"id": "_pytest.python.PyobjMixin._ALLOW_MARKERS", "kind": "variable", "range": [253, 4, 253, 25, 8968, 8989], "file_path": "src/_pytest/python.py", "content": "_ALLOW_MARKERS = True"}, {"id": "_pytest.python.PyobjMixin.obj", "kind": "function", "range": [255, 4, 265, 18, 8995, 9393], "file_path": "src/_pytest/python.py", "content": "@property\n    def obj(self):\n        \"\"\"Underlying Python object.\"\"\"\n        obj = getattr(self, \"_obj\", None)\n        if obj is None:\n            self._obj = obj = self._getobj()\n            # XXX evil hack\n            # used to avoid Instance collector marker duplication\n            if self._ALLOW_MARKERS:\n                self.own_markers.extend(get_unpacked_marks(self.obj))\n        return obj"}, {"id": "_pytest.python.PyobjMixin.obj", "kind": "function", "range": [267, 4, 269, 25, 9399, 9462], "file_path": "src/_pytest/python.py", "content": "@obj.setter\n    def obj(self, value):\n        self._obj = value"}, {"id": "_pytest.python.PyobjMixin._getobj", "kind": "function", "range": [271, 4, 273, 50, 9468, 9620], "file_path": "src/_pytest/python.py", "content": "def _getobj(self):\n        \"\"\"Gets the underlying Python object. May be overwritten by subclasses.\"\"\"\n        return getattr(self.parent.obj, self.name)"}, {"id": "_pytest.python.PyobjMixin.getmodpath", "kind": "function", "range": [275, 4, 292, 30, 9626, 10273], "file_path": "src/_pytest/python.py", "content": "def getmodpath(self, stopatmodule=True, includemodule=False):\n        \"\"\" return python path relative to the containing module. \"\"\"\n        chain = self.listchain()\n        chain.reverse()\n        parts = []\n        for node in chain:\n            if isinstance(node, Instance):\n                continue\n            name = node.name\n            if isinstance(node, Module):\n                name = os.path.splitext(name)[0]\n                if stopatmodule:\n                    if includemodule:\n                        parts.append(name)\n                    break\n            parts.append(name)\n        parts.reverse()\n        return \".\".join(parts)"}, {"id": "_pytest.python.PyobjMixin.reportinfo", "kind": "function", "range": [294, 4, 309, 38, 10279, 10982], "file_path": "src/_pytest/python.py", "content": "def reportinfo(self) -> Tuple[Union[py.path.local, str], int, str]:\n        # XXX caching?\n        obj = self.obj\n        compat_co_firstlineno = getattr(obj, \"compat_co_firstlineno\", None)\n        if isinstance(compat_co_firstlineno, int):\n            # nose compatibility\n            file_path = sys.modules[obj.__module__].__file__\n            if file_path.endswith(\".pyc\"):\n                file_path = file_path[:-1]\n            fspath = file_path  # type: Union[py.path.local, str]\n            lineno = compat_co_firstlineno\n        else:\n            fspath, lineno = getfslineno(obj)\n        modpath = self.getmodpath()\n        assert isinstance(lineno, int)\n        return fspath, lineno, modpath"}, {"id": "_pytest.python.PyCollector", "kind": "class", "range": [312, 0, 435, 17, 10985, 15840], "file_path": "src/_pytest/python.py", "content": "class PyCollector(PyobjMixin, nodes.Collector):\n    def funcnamefilter(self, name):\n        return self._matches_prefix_or_glob_option(\"python_functions\", name)\n\n    def isnosetest(self, obj):\n        \"\"\" Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True\n\n    def classnamefilter(self, name):\n        return self._matches_prefix_or_glob_option(\"python_classes\", name)\n\n    def istestfunction(self, obj, name):\n        if self.funcnamefilter(name) or self.isnosetest(obj):\n            if isinstance(obj, staticmethod):\n                # static methods need to be unwrapped\n                obj = safe_getattr(obj, \"__func__\", False)\n            return (\n                safe_getattr(obj, \"__call__\", False)\n                and fixtures.getfixturemarker(obj) is None\n            )\n        else:\n            return False\n\n    def istestclass(self, obj, name):\n        return self.classnamefilter(name) or self.isnosetest(obj)\n\n    def _matches_prefix_or_glob_option(self, option_name, name):\n        \"\"\"\n        checks if the given name matches the prefix or glob-pattern defined\n        in ini configuration.\n        \"\"\"\n        for option in self.config.getini(option_name):\n            if name.startswith(option):\n                return True\n            # check that name looks like a glob-string before calling fnmatch\n            # because this is called for every name in each collected module,\n            # and fnmatch is somewhat expensive to call\n            elif (\"*\" in option or \"?\" in option or \"[\" in option) and fnmatch.fnmatch(\n                name, option\n            ):\n                return True\n        return False\n\n    def collect(self):\n        if not getattr(self.obj, \"__test__\", True):\n            return []\n\n        # NB. we avoid random getattrs and peek in the __dict__ instead\n        # (XXX originally introduced from a PyPy need, still true?)\n        dicts = [getattr(self.obj, \"__dict__\", {})]\n        for basecls in inspect.getmro(self.obj.__class__):\n            dicts.append(basecls.__dict__)\n        seen = {}\n        values = []\n        for dic in dicts:\n            for name, obj in list(dic.items()):\n                if name in seen:\n                    continue\n                seen[name] = True\n                res = self._makeitem(name, obj)\n                if res is None:\n                    continue\n                if not isinstance(res, list):\n                    res = [res]\n                values.extend(res)\n\n        def sort_key(item):\n            fspath, lineno, _ = item.reportinfo()\n            return (str(fspath), lineno)\n\n        values.sort(key=sort_key)\n        return values\n\n    def _makeitem(self, name, obj):\n        # assert self.ihook.fspath == self.fspath, self\n        return self.ihook.pytest_pycollect_makeitem(collector=self, name=name, obj=obj)\n\n    def _genfunctions(self, name, funcobj):\n        module = self.getparent(Module).obj\n        clscol = self.getparent(Class)\n        cls = clscol and clscol.obj or None\n        fm = self.session._fixturemanager\n\n        definition = FunctionDefinition.from_parent(self, name=name, callobj=funcobj)\n        fixtureinfo = definition._fixtureinfo\n\n        metafunc = Metafunc(\n            definition, fixtureinfo, self.config, cls=cls, module=module\n        )\n        methods = []\n        if hasattr(module, \"pytest_generate_tests\"):\n            methods.append(module.pytest_generate_tests)\n        if hasattr(cls, \"pytest_generate_tests\"):\n            methods.append(cls().pytest_generate_tests)\n\n        self.ihook.pytest_generate_tests.call_extra(methods, dict(metafunc=metafunc))\n\n        if not metafunc._calls:\n            yield Function.from_parent(self, name=name, fixtureinfo=fixtureinfo)\n        else:\n            # add funcargs() as fixturedefs to fixtureinfo.arg2fixturedefs\n            fixtures.add_funcarg_pseudo_fixture_def(self, metafunc, fm)\n\n            # add_funcarg_pseudo_fixture_def may have shadowed some fixtures\n            # with direct parametrization, so make sure we update what the\n            # function really needs.\n            fixtureinfo.prune_dependency_tree()\n\n            for callspec in metafunc._calls:\n                subname = \"{}[{}]\".format(name, callspec.id)\n                yield Function.from_parent(\n                    self,\n                    name=subname,\n                    callspec=callspec,\n                    callobj=funcobj,\n                    fixtureinfo=fixtureinfo,\n                    keywords={callspec.id: True},\n                    originalname=name,\n                )"}, {"id": "_pytest.python.PyCollector.funcnamefilter", "kind": "function", "range": [313, 4, 314, 76, 11037, 11145], "file_path": "src/_pytest/python.py", "content": "def funcnamefilter(self, name):\n        return self._matches_prefix_or_glob_option(\"python_functions\", name)"}, {"id": "_pytest.python.PyCollector.isnosetest", "kind": "function", "range": [316, 4, 323, 59, 11151, 11544], "file_path": "src/_pytest/python.py", "content": "def isnosetest(self, obj):\n        \"\"\" Look for the __test__ attribute, which is applied by the\n        @nose.tools.istest decorator\n        \"\"\"\n        # We explicitly check for \"is True\" here to not mistakenly treat\n        # classes with a custom __getattr__ returning something truthy (like a\n        # function) as test classes.\n        return safe_getattr(obj, \"__test__\", False) is True"}, {"id": "_pytest.python.PyCollector.classnamefilter", "kind": "function", "range": [325, 4, 326, 74, 11550, 11657], "file_path": "src/_pytest/python.py", "content": "def classnamefilter(self, name):\n        return self._matches_prefix_or_glob_option(\"python_classes\", name)"}, {"id": "_pytest.python.PyCollector.istestfunction", "kind": "function", "range": [328, 4, 338, 24, 11663, 12106], "file_path": "src/_pytest/python.py", "content": "def istestfunction(self, obj, name):\n        if self.funcnamefilter(name) or self.isnosetest(obj):\n            if isinstance(obj, staticmethod):\n                # static methods need to be unwrapped\n                obj = safe_getattr(obj, \"__func__\", False)\n            return (\n                safe_getattr(obj, \"__call__\", False)\n                and fixtures.getfixturemarker(obj) is None\n            )\n        else:\n            return False"}, {"id": "_pytest.python.PyCollector.istestclass", "kind": "function", "range": [340, 4, 341, 65, 12112, 12211], "file_path": "src/_pytest/python.py", "content": "def istestclass(self, obj, name):\n        return self.classnamefilter(name) or self.isnosetest(obj)"}, {"id": "_pytest.python.PyCollector._matches_prefix_or_glob_option", "kind": "function", "range": [343, 4, 358, 20, 12217, 12923], "file_path": "src/_pytest/python.py", "content": "def _matches_prefix_or_glob_option(self, option_name, name):\n        \"\"\"\n        checks if the given name matches the prefix or glob-pattern defined\n        in ini configuration.\n        \"\"\"\n        for option in self.config.getini(option_name):\n            if name.startswith(option):\n                return True\n            # check that name looks like a glob-string before calling fnmatch\n            # because this is called for every name in each collected module,\n            # and fnmatch is somewhat expensive to call\n            elif (\"*\" in option or \"?\" in option or \"[\" in option) and fnmatch.fnmatch(\n                name, option\n            ):\n                return True\n        return False"}, {"id": "_pytest.python.PyCollector.collect", "kind": "function", "range": [360, 4, 388, 21, 12929, 13923], "file_path": "src/_pytest/python.py", "content": "def collect(self):\n        if not getattr(self.obj, \"__test__\", True):\n            return []\n\n        # NB. we avoid random getattrs and peek in the __dict__ instead\n        # (XXX originally introduced from a PyPy need, still true?)\n        dicts = [getattr(self.obj, \"__dict__\", {})]\n        for basecls in inspect.getmro(self.obj.__class__):\n            dicts.append(basecls.__dict__)\n        seen = {}\n        values = []\n        for dic in dicts:\n            for name, obj in list(dic.items()):\n                if name in seen:\n                    continue\n                seen[name] = True\n                res = self._makeitem(name, obj)\n                if res is None:\n                    continue\n                if not isinstance(res, list):\n                    res = [res]\n                values.extend(res)\n\n        def sort_key(item):\n            fspath, lineno, _ = item.reportinfo()\n            return (str(fspath), lineno)\n\n        values.sort(key=sort_key)\n        return values"}, {"id": "_pytest.python.PyCollector._makeitem", "kind": "function", "range": [390, 4, 392, 87, 13929, 14104], "file_path": "src/_pytest/python.py", "content": "def _makeitem(self, name, obj):\n        # assert self.ihook.fspath == self.fspath, self\n        return self.ihook.pytest_pycollect_makeitem(collector=self, name=name, obj=obj)"}, {"id": "_pytest.python.PyCollector._genfunctions", "kind": "function", "range": [394, 4, 435, 17, 14110, 15840], "file_path": "src/_pytest/python.py", "content": "def _genfunctions(self, name, funcobj):\n        module = self.getparent(Module).obj\n        clscol = self.getparent(Class)\n        cls = clscol and clscol.obj or None\n        fm = self.session._fixturemanager\n\n        definition = FunctionDefinition.from_parent(self, name=name, callobj=funcobj)\n        fixtureinfo = definition._fixtureinfo\n\n        metafunc = Metafunc(\n            definition, fixtureinfo, self.config, cls=cls, module=module\n        )\n        methods = []\n        if hasattr(module, \"pytest_generate_tests\"):\n            methods.append(module.pytest_generate_tests)\n        if hasattr(cls, \"pytest_generate_tests\"):\n            methods.append(cls().pytest_generate_tests)\n\n        self.ihook.pytest_generate_tests.call_extra(methods, dict(metafunc=metafunc))\n\n        if not metafunc._calls:\n            yield Function.from_parent(self, name=name, fixtureinfo=fixtureinfo)\n        else:\n            # add funcargs() as fixturedefs to fixtureinfo.arg2fixturedefs\n            fixtures.add_funcarg_pseudo_fixture_def(self, metafunc, fm)\n\n            # add_funcarg_pseudo_fixture_def may have shadowed some fixtures\n            # with direct parametrization, so make sure we update what the\n            # function really needs.\n            fixtureinfo.prune_dependency_tree()\n\n            for callspec in metafunc._calls:\n                subname = \"{}[{}]\".format(name, callspec.id)\n                yield Function.from_parent(\n                    self,\n                    name=subname,\n                    callspec=callspec,\n                    callobj=funcobj,\n                    fixtureinfo=fixtureinfo,\n                    keywords={callspec.id: True},\n                    originalname=name,\n                )"}, {"id": "_pytest.python.Module", "kind": "class", "range": [438, 0, 549, 18, 15843, 20710], "file_path": "src/_pytest/python.py", "content": "class Module(nodes.File, PyCollector):\n    \"\"\" Collector for test classes and functions. \"\"\"\n\n    def _getobj(self):\n        return self._importtestmodule()\n\n    def collect(self):\n        self._inject_setup_module_fixture()\n        self._inject_setup_function_fixture()\n        self.session._fixturemanager.parsefactories(self)\n        return super().collect()\n\n    def _inject_setup_module_fixture(self):\n        \"\"\"Injects a hidden autouse, module scoped fixture into the collected module object\n        that invokes setUpModule/tearDownModule if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_module = _get_first_non_fixture_func(\n            self.obj, (\"setUpModule\", \"setup_module\")\n        )\n        teardown_module = _get_first_non_fixture_func(\n            self.obj, (\"tearDownModule\", \"teardown_module\")\n        )\n\n        if setup_module is None and teardown_module is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"module\")\n        def xunit_setup_module_fixture(request):\n            if setup_module is not None:\n                _call_with_optional_argument(setup_module, request.module)\n            yield\n            if teardown_module is not None:\n                _call_with_optional_argument(teardown_module, request.module)\n\n        self.obj.__pytest_setup_module = xunit_setup_module_fixture\n\n    def _inject_setup_function_fixture(self):\n        \"\"\"Injects a hidden autouse, function scoped fixture into the collected module object\n        that invokes setup_function/teardown_function if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_function = _get_first_non_fixture_func(self.obj, (\"setup_function\",))\n        teardown_function = _get_first_non_fixture_func(\n            self.obj, (\"teardown_function\",)\n        )\n        if setup_function is None and teardown_function is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"function\")\n        def xunit_setup_function_fixture(request):\n            if request.instance is not None:\n                # in this case we are bound to an instance, so we need to let\n                # setup_method handle this\n                yield\n                return\n            if setup_function is not None:\n                _call_with_optional_argument(setup_function, request.function)\n            yield\n            if teardown_function is not None:\n                _call_with_optional_argument(teardown_function, request.function)\n\n        self.obj.__pytest_setup_function = xunit_setup_function_fixture\n\n    def _importtestmodule(self):\n        # we assume we are only called once per module\n        importmode = self.config.getoption(\"--import-mode\")\n        try:\n            mod = self.fspath.pyimport(ensuresyspath=importmode)\n        except SyntaxError:\n            raise self.CollectError(ExceptionInfo.from_current().getrepr(style=\"short\"))\n        except self.fspath.ImportMismatchError as e:\n            raise self.CollectError(\n                \"import file mismatch:\\n\"\n                \"imported module %r has this __file__ attribute:\\n\"\n                \"  %s\\n\"\n                \"which is not the same as the test file we want to collect:\\n\"\n                \"  %s\\n\"\n                \"HINT: remove __pycache__ / .pyc files and/or use a \"\n                \"unique basename for your test file modules\" % e.args\n            )\n        except ImportError:\n            exc_info = ExceptionInfo.from_current()\n            if self.config.getoption(\"verbose\") < 2:\n                exc_info.traceback = exc_info.traceback.filter(filter_traceback)\n            exc_repr = (\n                exc_info.getrepr(style=\"short\")\n                if exc_info.traceback\n                else exc_info.exconly()\n            )\n            formatted_tb = str(exc_repr)\n            raise self.CollectError(\n                \"ImportError while importing test module '{fspath}'.\\n\"\n                \"Hint: make sure your test modules/packages have valid Python names.\\n\"\n                \"Traceback:\\n\"\n                \"{traceback}\".format(fspath=self.fspath, traceback=formatted_tb)\n            )\n        except _pytest.runner.Skipped as e:\n            if e.allow_module_level:\n                raise\n            raise self.CollectError(\n                \"Using pytest.skip outside of a test is not allowed. \"\n                \"To decorate a test function, use the @pytest.mark.skip \"\n                \"or @pytest.mark.skipif decorators instead, and to skip a \"\n                \"module use `pytestmark = pytest.mark.{skip,skipif}.\"\n            )\n        self.config.pluginmanager.consider_module(mod)\n        return mod"}, {"id": "_pytest.python.Module._getobj", "kind": "function", "range": [441, 4, 442, 39, 15941, 15999], "file_path": "src/_pytest/python.py", "content": "def _getobj(self):\n        return self._importtestmodule()"}, {"id": "_pytest.python.Module.collect", "kind": "function", "range": [444, 4, 448, 32, 16005, 16204], "file_path": "src/_pytest/python.py", "content": "def collect(self):\n        self._inject_setup_module_fixture()\n        self._inject_setup_function_fixture()\n        self.session._fixturemanager.parsefactories(self)\n        return super().collect()"}, {"id": "_pytest.python.Module._inject_setup_module_fixture", "kind": "function", "range": [450, 4, 475, 67, 16210, 17313], "file_path": "src/_pytest/python.py", "content": "def _inject_setup_module_fixture(self):\n        \"\"\"Injects a hidden autouse, module scoped fixture into the collected module object\n        that invokes setUpModule/tearDownModule if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_module = _get_first_non_fixture_func(\n            self.obj, (\"setUpModule\", \"setup_module\")\n        )\n        teardown_module = _get_first_non_fixture_func(\n            self.obj, (\"tearDownModule\", \"teardown_module\")\n        )\n\n        if setup_module is None and teardown_module is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"module\")\n        def xunit_setup_module_fixture(request):\n            if setup_module is not None:\n                _call_with_optional_argument(setup_module, request.module)\n            yield\n            if teardown_module is not None:\n                _call_with_optional_argument(teardown_module, request.module)\n\n        self.obj.__pytest_setup_module = xunit_setup_module_fixture"}, {"id": "_pytest.python.Module._inject_setup_function_fixture", "kind": "function", "range": [477, 4, 504, 71, 17319, 18621], "file_path": "src/_pytest/python.py", "content": "def _inject_setup_function_fixture(self):\n        \"\"\"Injects a hidden autouse, function scoped fixture into the collected module object\n        that invokes setup_function/teardown_function if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_function = _get_first_non_fixture_func(self.obj, (\"setup_function\",))\n        teardown_function = _get_first_non_fixture_func(\n            self.obj, (\"teardown_function\",)\n        )\n        if setup_function is None and teardown_function is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"function\")\n        def xunit_setup_function_fixture(request):\n            if request.instance is not None:\n                # in this case we are bound to an instance, so we need to let\n                # setup_method handle this\n                yield\n                return\n            if setup_function is not None:\n                _call_with_optional_argument(setup_function, request.function)\n            yield\n            if teardown_function is not None:\n                _call_with_optional_argument(teardown_function, request.function)\n\n        self.obj.__pytest_setup_function = xunit_setup_function_fixture"}, {"id": "_pytest.python.Module._importtestmodule", "kind": "function", "range": [506, 4, 549, 18, 18627, 20710], "file_path": "src/_pytest/python.py", "content": "def _importtestmodule(self):\n        # we assume we are only called once per module\n        importmode = self.config.getoption(\"--import-mode\")\n        try:\n            mod = self.fspath.pyimport(ensuresyspath=importmode)\n        except SyntaxError:\n            raise self.CollectError(ExceptionInfo.from_current().getrepr(style=\"short\"))\n        except self.fspath.ImportMismatchError as e:\n            raise self.CollectError(\n                \"import file mismatch:\\n\"\n                \"imported module %r has this __file__ attribute:\\n\"\n                \"  %s\\n\"\n                \"which is not the same as the test file we want to collect:\\n\"\n                \"  %s\\n\"\n                \"HINT: remove __pycache__ / .pyc files and/or use a \"\n                \"unique basename for your test file modules\" % e.args\n            )\n        except ImportError:\n            exc_info = ExceptionInfo.from_current()\n            if self.config.getoption(\"verbose\") < 2:\n                exc_info.traceback = exc_info.traceback.filter(filter_traceback)\n            exc_repr = (\n                exc_info.getrepr(style=\"short\")\n                if exc_info.traceback\n                else exc_info.exconly()\n            )\n            formatted_tb = str(exc_repr)\n            raise self.CollectError(\n                \"ImportError while importing test module '{fspath}'.\\n\"\n                \"Hint: make sure your test modules/packages have valid Python names.\\n\"\n                \"Traceback:\\n\"\n                \"{traceback}\".format(fspath=self.fspath, traceback=formatted_tb)\n            )\n        except _pytest.runner.Skipped as e:\n            if e.allow_module_level:\n                raise\n            raise self.CollectError(\n                \"Using pytest.skip outside of a test is not allowed. \"\n                \"To decorate a test function, use the @pytest.mark.skip \"\n                \"or @pytest.mark.skipif decorators instead, and to skip a \"\n                \"module use `pytestmark = pytest.mark.{skip,skipif}.\"\n            )\n        self.config.pluginmanager.consider_module(mod)\n        return mod"}, {"id": "_pytest.python.Package", "kind": "class", "range": [552, 0, 621, 38, 20713, 23332], "file_path": "src/_pytest/python.py", "content": "class Package(Module):\n    def __init__(\n        self,\n        fspath: py.path.local,\n        parent: nodes.Collector,\n        # NOTE: following args are unused:\n        config=None,\n        session=None,\n        nodeid=None,\n    ) -> None:\n        # NOTE: could be just the following, but kept as-is for compat.\n        # nodes.FSCollector.__init__(self, fspath, parent=parent)\n        session = parent.session\n        nodes.FSCollector.__init__(\n            self, fspath, parent=parent, config=config, session=session, nodeid=nodeid\n        )\n\n        self.name = fspath.dirname\n\n    def setup(self):\n        # not using fixtures to call setup_module here because autouse fixtures\n        # from packages are not called automatically (#4085)\n        setup_module = _get_first_non_fixture_func(\n            self.obj, (\"setUpModule\", \"setup_module\")\n        )\n        if setup_module is not None:\n            _call_with_optional_argument(setup_module, self.obj)\n\n        teardown_module = _get_first_non_fixture_func(\n            self.obj, (\"tearDownModule\", \"teardown_module\")\n        )\n        if teardown_module is not None:\n            func = partial(_call_with_optional_argument, teardown_module, self.obj)\n            self.addfinalizer(func)\n\n    def gethookproxy(self, fspath: py.path.local):\n        return super()._gethookproxy(fspath)\n\n    def isinitpath(self, path):\n        return path in self.session._initialpaths\n\n    def collect(self):\n        this_path = self.fspath.dirpath()\n        init_module = this_path.join(\"__init__.py\")\n        if init_module.check(file=1) and path_matches_patterns(\n            init_module, self.config.getini(\"python_files\")\n        ):\n            yield Module.from_parent(self, fspath=init_module)\n        pkg_prefixes = set()\n        for path in this_path.visit(rec=self._recurse, bf=True, sort=True):\n            # We will visit our own __init__.py file, in which case we skip it.\n            is_file = path.isfile()\n            if is_file:\n                if path.basename == \"__init__.py\" and path.dirpath() == this_path:\n                    continue\n\n            parts_ = parts(path.strpath)\n            if any(\n                pkg_prefix in parts_ and pkg_prefix.join(\"__init__.py\") != path\n                for pkg_prefix in pkg_prefixes\n            ):\n                continue\n\n            if is_file:\n                yield from self._collectfile(path)\n            elif not path.isdir():\n                # Broken symlink or invalid/missing file.\n                continue\n            elif path.join(\"__init__.py\").check(file=1):\n                pkg_prefixes.add(path)"}, {"id": "_pytest.python.Package.__init__", "kind": "function", "range": [553, 4, 569, 34, 20740, 21293], "file_path": "src/_pytest/python.py", "content": "def __init__(\n        self,\n        fspath: py.path.local,\n        parent: nodes.Collector,\n        # NOTE: following args are unused:\n        config=None,\n        session=None,\n        nodeid=None,\n    ) -> None:\n        # NOTE: could be just the following, but kept as-is for compat.\n        # nodes.FSCollector.__init__(self, fspath, parent=parent)\n        session = parent.session\n        nodes.FSCollector.__init__(\n            self, fspath, parent=parent, config=config, session=session, nodeid=nodeid\n        )\n\n        self.name = fspath.dirname"}, {"id": "_pytest.python.Package.setup", "kind": "function", "range": [571, 4, 585, 35, 21299, 21960], "file_path": "src/_pytest/python.py", "content": "def setup(self):\n        # not using fixtures to call setup_module here because autouse fixtures\n        # from packages are not called automatically (#4085)\n        setup_module = _get_first_non_fixture_func(\n            self.obj, (\"setUpModule\", \"setup_module\")\n        )\n        if setup_module is not None:\n            _call_with_optional_argument(setup_module, self.obj)\n\n        teardown_module = _get_first_non_fixture_func(\n            self.obj, (\"tearDownModule\", \"teardown_module\")\n        )\n        if teardown_module is not None:\n            func = partial(_call_with_optional_argument, teardown_module, self.obj)\n            self.addfinalizer(func)"}, {"id": "_pytest.python.Package.gethookproxy", "kind": "function", "range": [587, 4, 588, 44, 21966, 22057], "file_path": "src/_pytest/python.py", "content": "def gethookproxy(self, fspath: py.path.local):\n        return super()._gethookproxy(fspath)"}, {"id": "_pytest.python.Package.isinitpath", "kind": "function", "range": [590, 4, 591, 49, 22063, 22140], "file_path": "src/_pytest/python.py", "content": "def isinitpath(self, path):\n        return path in self.session._initialpaths"}, {"id": "_pytest.python.Package.collect", "kind": "function", "range": [593, 4, 621, 38, 22146, 23332], "file_path": "src/_pytest/python.py", "content": "def collect(self):\n        this_path = self.fspath.dirpath()\n        init_module = this_path.join(\"__init__.py\")\n        if init_module.check(file=1) and path_matches_patterns(\n            init_module, self.config.getini(\"python_files\")\n        ):\n            yield Module.from_parent(self, fspath=init_module)\n        pkg_prefixes = set()\n        for path in this_path.visit(rec=self._recurse, bf=True, sort=True):\n            # We will visit our own __init__.py file, in which case we skip it.\n            is_file = path.isfile()\n            if is_file:\n                if path.basename == \"__init__.py\" and path.dirpath() == this_path:\n                    continue\n\n            parts_ = parts(path.strpath)\n            if any(\n                pkg_prefix in parts_ and pkg_prefix.join(\"__init__.py\") != path\n                for pkg_prefix in pkg_prefixes\n            ):\n                continue\n\n            if is_file:\n                yield from self._collectfile(path)\n            elif not path.isdir():\n                # Broken symlink or invalid/missing file.\n                continue\n            elif path.join(\"__init__.py\").check(file=1):\n                pkg_prefixes.add(path)"}, {"id": "_pytest.python._call_with_optional_argument", "kind": "function", "range": [624, 0, 633, 14, 23335, 23667], "file_path": "src/_pytest/python.py", "content": "def _call_with_optional_argument(func, arg):\n    \"\"\"Call the given function with the given argument if func accepts one argument, otherwise\n    calls func without arguments\"\"\"\n    arg_count = func.__code__.co_argcount\n    if inspect.ismethod(func):\n        arg_count -= 1\n    if arg_count:\n        func(arg)\n    else:\n        func()"}, {"id": "_pytest.python._get_first_non_fixture_func", "kind": "function", "range": [636, 0, 644, 23, 23670, 24056], "file_path": "src/_pytest/python.py", "content": "def _get_first_non_fixture_func(obj, names):\n    \"\"\"Return the attribute from the given object to be used as a setup/teardown\n    xunit-style function, but only if not marked as a fixture to\n    avoid calling it twice.\n    \"\"\"\n    for name in names:\n        meth = getattr(obj, name, None)\n        if meth is not None and fixtures.getfixturemarker(meth) is None:\n            return meth"}, {"id": "_pytest.python.Class", "kind": "class", "range": [647, 0, 731, 67, 24059, 27424], "file_path": "src/_pytest/python.py", "content": "class Class(PyCollector):\n    \"\"\" Collector for test methods. \"\"\"\n\n    @classmethod\n    def from_parent(cls, parent, *, name, obj=None):\n        \"\"\"\n        The public constructor\n        \"\"\"\n        return super().from_parent(name=name, parent=parent)\n\n    def collect(self):\n        if not safe_getattr(self.obj, \"__test__\", True):\n            return []\n        if hasinit(self.obj):\n            self.warn(\n                PytestCollectionWarning(\n                    \"cannot collect test class %r because it has a \"\n                    \"__init__ constructor (from: %s)\"\n                    % (self.obj.__name__, self.parent.nodeid)\n                )\n            )\n            return []\n        elif hasnew(self.obj):\n            self.warn(\n                PytestCollectionWarning(\n                    \"cannot collect test class %r because it has a \"\n                    \"__new__ constructor (from: %s)\"\n                    % (self.obj.__name__, self.parent.nodeid)\n                )\n            )\n            return []\n\n        self._inject_setup_class_fixture()\n        self._inject_setup_method_fixture()\n\n        return [Instance.from_parent(self, name=\"()\")]\n\n    def _inject_setup_class_fixture(self):\n        \"\"\"Injects a hidden autouse, class scoped fixture into the collected class object\n        that invokes setup_class/teardown_class if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_class = _get_first_non_fixture_func(self.obj, (\"setup_class\",))\n        teardown_class = getattr(self.obj, \"teardown_class\", None)\n        if setup_class is None and teardown_class is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"class\")\n        def xunit_setup_class_fixture(cls):\n            if setup_class is not None:\n                func = getimfunc(setup_class)\n                _call_with_optional_argument(func, self.obj)\n            yield\n            if teardown_class is not None:\n                func = getimfunc(teardown_class)\n                _call_with_optional_argument(func, self.obj)\n\n        self.obj.__pytest_setup_class = xunit_setup_class_fixture\n\n    def _inject_setup_method_fixture(self):\n        \"\"\"Injects a hidden autouse, function scoped fixture into the collected class object\n        that invokes setup_method/teardown_method if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_method = _get_first_non_fixture_func(self.obj, (\"setup_method\",))\n        teardown_method = getattr(self.obj, \"teardown_method\", None)\n        if setup_method is None and teardown_method is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"function\")\n        def xunit_setup_method_fixture(self, request):\n            method = request.function\n            if setup_method is not None:\n                func = getattr(self, \"setup_method\")\n                _call_with_optional_argument(func, method)\n            yield\n            if teardown_method is not None:\n                func = getattr(self, \"teardown_method\")\n                _call_with_optional_argument(func, method)\n\n        self.obj.__pytest_setup_method = xunit_setup_method_fixture"}, {"id": "_pytest.python.Class.from_parent", "kind": "function", "range": [650, 4, 655, 60, 24130, 24311], "file_path": "src/_pytest/python.py", "content": "@classmethod\n    def from_parent(cls, parent, *, name, obj=None):\n        \"\"\"\n        The public constructor\n        \"\"\"\n        return super().from_parent(name=name, parent=parent)"}, {"id": "_pytest.python.Class.collect", "kind": "function", "range": [657, 4, 682, 54, 24317, 25224], "file_path": "src/_pytest/python.py", "content": "def collect(self):\n        if not safe_getattr(self.obj, \"__test__\", True):\n            return []\n        if hasinit(self.obj):\n            self.warn(\n                PytestCollectionWarning(\n                    \"cannot collect test class %r because it has a \"\n                    \"__init__ constructor (from: %s)\"\n                    % (self.obj.__name__, self.parent.nodeid)\n                )\n            )\n            return []\n        elif hasnew(self.obj):\n            self.warn(\n                PytestCollectionWarning(\n                    \"cannot collect test class %r because it has a \"\n                    \"__new__ constructor (from: %s)\"\n                    % (self.obj.__name__, self.parent.nodeid)\n                )\n            )\n            return []\n\n        self._inject_setup_class_fixture()\n        self._inject_setup_method_fixture()\n\n        return [Instance.from_parent(self, name=\"()\")]"}, {"id": "_pytest.python.Class._inject_setup_class_fixture", "kind": "function", "range": [684, 4, 706, 65, 25230, 26285], "file_path": "src/_pytest/python.py", "content": "def _inject_setup_class_fixture(self):\n        \"\"\"Injects a hidden autouse, class scoped fixture into the collected class object\n        that invokes setup_class/teardown_class if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_class = _get_first_non_fixture_func(self.obj, (\"setup_class\",))\n        teardown_class = getattr(self.obj, \"teardown_class\", None)\n        if setup_class is None and teardown_class is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"class\")\n        def xunit_setup_class_fixture(cls):\n            if setup_class is not None:\n                func = getimfunc(setup_class)\n                _call_with_optional_argument(func, self.obj)\n            yield\n            if teardown_class is not None:\n                func = getimfunc(teardown_class)\n                _call_with_optional_argument(func, self.obj)\n\n        self.obj.__pytest_setup_class = xunit_setup_class_fixture"}, {"id": "_pytest.python.Class._inject_setup_method_fixture", "kind": "function", "range": [708, 4, 731, 67, 26291, 27424], "file_path": "src/_pytest/python.py", "content": "def _inject_setup_method_fixture(self):\n        \"\"\"Injects a hidden autouse, function scoped fixture into the collected class object\n        that invokes setup_method/teardown_method if either or both are available.\n\n        Using a fixture to invoke this methods ensures we play nicely and unsurprisingly with\n        other fixtures (#517).\n        \"\"\"\n        setup_method = _get_first_non_fixture_func(self.obj, (\"setup_method\",))\n        teardown_method = getattr(self.obj, \"teardown_method\", None)\n        if setup_method is None and teardown_method is None:\n            return\n\n        @fixtures.fixture(autouse=True, scope=\"function\")\n        def xunit_setup_method_fixture(self, request):\n            method = request.function\n            if setup_method is not None:\n                func = getattr(self, \"setup_method\")\n                _call_with_optional_argument(func, method)\n            yield\n            if teardown_method is not None:\n                func = getattr(self, \"teardown_method\")\n                _call_with_optional_argument(func, method)\n\n        self.obj.__pytest_setup_method = xunit_setup_method_fixture"}, {"id": "_pytest.python.Instance", "kind": "class", "range": [734, 0, 749, 23, 27427, 27940], "file_path": "src/_pytest/python.py", "content": "class Instance(PyCollector):\n    _ALLOW_MARKERS = False  # hack, destroy later\n    # instances share the object with their parents in a way\n    # that duplicates markers instances if not taken out\n    # can be removed at node structure reorganization time\n\n    def _getobj(self):\n        return self.parent.obj()\n\n    def collect(self):\n        self.session._fixturemanager.parsefactories(self)\n        return super().collect()\n\n    def newinstance(self):\n        self.obj = self._getobj()\n        return self.obj"}, {"id": "_pytest.python.Instance._ALLOW_MARKERS", "kind": "variable", "range": [735, 4, 735, 26, 27460, 27482], "file_path": "src/_pytest/python.py", "content": "_ALLOW_MARKERS = False"}, {"id": "_pytest.python.Instance._getobj", "kind": "function", "range": [740, 4, 741, 32, 27688, 27739], "file_path": "src/_pytest/python.py", "content": "def _getobj(self):\n        return self.parent.obj()"}, {"id": "_pytest.python.Instance.collect", "kind": "function", "range": [743, 4, 745, 32, 27745, 27854], "file_path": "src/_pytest/python.py", "content": "def collect(self):\n        self.session._fixturemanager.parsefactories(self)\n        return super().collect()"}, {"id": "_pytest.python.Instance.newinstance", "kind": "function", "range": [747, 4, 749, 23, 27860, 27940], "file_path": "src/_pytest/python.py", "content": "def newinstance(self):\n        self.obj = self._getobj()\n        return self.obj"}, {"id": "_pytest.python.hasinit", "kind": "function", "range": [752, 0, 755, 38, 27943, 28054], "file_path": "src/_pytest/python.py", "content": "def hasinit(obj):\n    init = getattr(obj, \"__init__\", None)\n    if init:\n        return init != object.__init__"}, {"id": "_pytest.python.hasnew", "kind": "function", "range": [758, 0, 761, 36, 28057, 28162], "file_path": "src/_pytest/python.py", "content": "def hasnew(obj):\n    new = getattr(obj, \"__new__\", None)\n    if new:\n        return new != object.__new__"}, {"id": "_pytest.python.CallSpec2", "kind": "class", "range": [764, 0, 806, 53, 28165, 29609], "file_path": "src/_pytest/python.py", "content": "class CallSpec2:\n    def __init__(self, metafunc):\n        self.metafunc = metafunc\n        self.funcargs = {}\n        self._idlist = []\n        self.params = {}\n        self._arg2scopenum = {}  # used for sorting parametrized resources\n        self.marks = []\n        self.indices = {}\n\n    def copy(self):\n        cs = CallSpec2(self.metafunc)\n        cs.funcargs.update(self.funcargs)\n        cs.params.update(self.params)\n        cs.marks.extend(self.marks)\n        cs.indices.update(self.indices)\n        cs._arg2scopenum.update(self._arg2scopenum)\n        cs._idlist = list(self._idlist)\n        return cs\n\n    def _checkargnotcontained(self, arg):\n        if arg in self.params or arg in self.funcargs:\n            raise ValueError(\"duplicate {!r}\".format(arg))\n\n    def getparam(self, name):\n        try:\n            return self.params[name]\n        except KeyError:\n            raise ValueError(name)\n\n    @property\n    def id(self):\n        return \"-\".join(map(str, self._idlist))\n\n    def setmulti2(self, valtypes, argnames, valset, id, marks, scopenum, param_index):\n        for arg, val in zip(argnames, valset):\n            self._checkargnotcontained(arg)\n            valtype_for_arg = valtypes[arg]\n            getattr(self, valtype_for_arg)[arg] = val\n            self.indices[arg] = param_index\n            self._arg2scopenum[arg] = scopenum\n        self._idlist.append(id)\n        self.marks.extend(normalize_mark_list(marks))"}, {"id": "_pytest.python.CallSpec2.__init__", "kind": "function", "range": [765, 4, 772, 25, 28186, 28451], "file_path": "src/_pytest/python.py", "content": "def __init__(self, metafunc):\n        self.metafunc = metafunc\n        self.funcargs = {}\n        self._idlist = []\n        self.params = {}\n        self._arg2scopenum = {}  # used for sorting parametrized resources\n        self.marks = []\n        self.indices = {}"}, {"id": "_pytest.python.CallSpec2.copy", "kind": "function", "range": [774, 4, 782, 17, 28457, 28776], "file_path": "src/_pytest/python.py", "content": "def copy(self):\n        cs = CallSpec2(self.metafunc)\n        cs.funcargs.update(self.funcargs)\n        cs.params.update(self.params)\n        cs.marks.extend(self.marks)\n        cs.indices.update(self.indices)\n        cs._arg2scopenum.update(self._arg2scopenum)\n        cs._idlist = list(self._idlist)\n        return cs"}, {"id": "_pytest.python.CallSpec2._checkargnotcontained", "kind": "function", "range": [784, 4, 786, 58, 28782, 28933], "file_path": "src/_pytest/python.py", "content": "def _checkargnotcontained(self, arg):\n        if arg in self.params or arg in self.funcargs:\n            raise ValueError(\"duplicate {!r}\".format(arg))"}, {"id": "_pytest.python.CallSpec2.getparam", "kind": "function", "range": [788, 4, 792, 34, 28939, 29074], "file_path": "src/_pytest/python.py", "content": "def getparam(self, name):\n        try:\n            return self.params[name]\n        except KeyError:\n            raise ValueError(name)"}, {"id": "_pytest.python.CallSpec2.id", "kind": "function", "range": [794, 4, 796, 47, 29080, 29155], "file_path": "src/_pytest/python.py", "content": "@property\n    def id(self):\n        return \"-\".join(map(str, self._idlist))"}, {"id": "_pytest.python.CallSpec2.setmulti2", "kind": "function", "range": [798, 4, 806, 53, 29161, 29609], "file_path": "src/_pytest/python.py", "content": "def setmulti2(self, valtypes, argnames, valset, id, marks, scopenum, param_index):\n        for arg, val in zip(argnames, valset):\n            self._checkargnotcontained(arg)\n            valtype_for_arg = valtypes[arg]\n            getattr(self, valtype_for_arg)[arg] = val\n            self.indices[arg] = param_index\n            self._arg2scopenum[arg] = scopenum\n        self._idlist.append(id)\n        self.marks.extend(normalize_mark_list(marks))"}, {"id": "_pytest.python.Metafunc", "kind": "class", "range": [809, 0, 1141, 40, 29612, 43579], "file_path": "src/_pytest/python.py", "content": "class Metafunc:\n    \"\"\"\n    Metafunc objects are passed to the :func:`pytest_generate_tests <_pytest.hookspec.pytest_generate_tests>` hook.\n    They help to inspect a test function and to generate tests according to\n    test configuration or values specified in the class or module where a\n    test function is defined.\n    \"\"\"\n\n    def __init__(\n        self,\n        definition: \"FunctionDefinition\",\n        fixtureinfo: fixtures.FuncFixtureInfo,\n        config: Config,\n        cls=None,\n        module=None,\n    ) -> None:\n        self.definition = definition\n\n        #: access to the :class:`_pytest.config.Config` object for the test session\n        self.config = config\n\n        #: the module object where the test function is defined in.\n        self.module = module\n\n        #: underlying python test function\n        self.function = definition.obj\n\n        #: set of fixture names required by the test function\n        self.fixturenames = fixtureinfo.names_closure\n\n        #: class object where the test function is defined in or ``None``.\n        self.cls = cls\n\n        self._calls = []  # type: List[CallSpec2]\n        self._arg2fixturedefs = fixtureinfo.name2fixturedefs\n\n    @property\n    def funcargnames(self):\n        \"\"\" alias attribute for ``fixturenames`` for pre-2.3 compatibility\"\"\"\n        warnings.warn(FUNCARGNAMES, stacklevel=2)\n        return self.fixturenames\n\n    def parametrize(\n        self,\n        argnames: Union[str, List[str], Tuple[str, ...]],\n        argvalues: Iterable[Union[ParameterSet, typing.Sequence[object], object]],\n        indirect: Union[bool, typing.Sequence[str]] = False,\n        ids: Optional[\n            Union[\n                Iterable[Union[None, str, float, int, bool]],\n                Callable[[object], Optional[object]],\n            ]\n        ] = None,\n        scope: \"Optional[str]\" = None,\n        *,\n        _param_mark: Optional[Mark] = None\n    ) -> None:\n        \"\"\" Add new invocations to the underlying test function using the list\n        of argvalues for the given argnames.  Parametrization is performed\n        during the collection phase.  If you need to setup expensive resources\n        see about setting indirect to do it rather at test setup time.\n\n        :arg argnames: a comma-separated string denoting one or more argument\n                       names, or a list/tuple of argument strings.\n\n        :arg argvalues: The list of argvalues determines how often a\n            test is invoked with different argument values.  If only one\n            argname was specified argvalues is a list of values.  If N\n            argnames were specified, argvalues must be a list of N-tuples,\n            where each tuple-element specifies a value for its respective\n            argname.\n\n        :arg indirect: The list of argnames or boolean. A list of arguments'\n            names (subset of argnames). If True the list contains all names from\n            the argnames. Each argvalue corresponding to an argname in this list will\n            be passed as request.param to its respective argname fixture\n            function so that it can perform more expensive setups during the\n            setup phase of a test rather than at collection time.\n\n        :arg ids: sequence of (or generator for) ids for ``argvalues``,\n              or a callable to return part of the id for each argvalue.\n\n            With sequences (and generators like ``itertools.count()``) the\n            returned ids should be of type ``string``, ``int``, ``float``,\n            ``bool``, or ``None``.\n            They are mapped to the corresponding index in ``argvalues``.\n            ``None`` means to use the auto-generated id.\n\n            If it is a callable it will be called for each entry in\n            ``argvalues``, and the return value is used as part of the\n            auto-generated id for the whole set (where parts are joined with\n            dashes (\"-\")).\n            This is useful to provide more specific ids for certain items, e.g.\n            dates.  Returning ``None`` will use an auto-generated id.\n\n            If no ids are provided they will be generated automatically from\n            the argvalues.\n\n        :arg scope: if specified it denotes the scope of the parameters.\n            The scope is used for grouping tests by parameter instances.\n            It will also override any fixture-function defined scope, allowing\n            to set a dynamic scope using test context or configuration.\n        \"\"\"\n        from _pytest.fixtures import scope2index\n\n        argnames, parameters = ParameterSet._for_parametrize(\n            argnames,\n            argvalues,\n            self.function,\n            self.config,\n            function_definition=self.definition,\n        )\n        del argvalues\n\n        if \"request\" in argnames:\n            fail(\n                \"'request' is a reserved name and cannot be used in @pytest.mark.parametrize\",\n                pytrace=False,\n            )\n\n        if scope is None:\n            scope = _find_parametrized_scope(argnames, self._arg2fixturedefs, indirect)\n\n        self._validate_if_using_arg_names(argnames, indirect)\n\n        arg_values_types = self._resolve_arg_value_types(argnames, indirect)\n\n        self._validate_explicit_parameters(argnames, indirect)\n\n        # Use any already (possibly) generated ids with parametrize Marks.\n        if _param_mark and _param_mark._param_ids_from:\n            generated_ids = _param_mark._param_ids_from._param_ids_generated\n            if generated_ids is not None:\n                ids = generated_ids\n\n        ids = self._resolve_arg_ids(argnames, ids, parameters, item=self.definition)\n\n        # Store used (possibly generated) ids with parametrize Marks.\n        if _param_mark and _param_mark._param_ids_from and generated_ids is None:\n            object.__setattr__(_param_mark._param_ids_from, \"_param_ids_generated\", ids)\n\n        scopenum = scope2index(\n            scope, descr=\"parametrize() call in {}\".format(self.function.__name__)\n        )\n\n        # create the new calls: if we are parametrize() multiple times (by applying the decorator\n        # more than once) then we accumulate those calls generating the cartesian product\n        # of all calls\n        newcalls = []\n        for callspec in self._calls or [CallSpec2(self)]:\n            for param_index, (param_id, param_set) in enumerate(zip(ids, parameters)):\n                newcallspec = callspec.copy()\n                newcallspec.setmulti2(\n                    arg_values_types,\n                    argnames,\n                    param_set.values,\n                    param_id,\n                    param_set.marks,\n                    scopenum,\n                    param_index,\n                )\n                newcalls.append(newcallspec)\n        self._calls = newcalls\n\n    def _resolve_arg_ids(\n        self,\n        argnames: typing.Sequence[str],\n        ids: Optional[\n            Union[\n                Iterable[Union[None, str, float, int, bool]],\n                Callable[[object], Optional[object]],\n            ]\n        ],\n        parameters: typing.Sequence[ParameterSet],\n        item,\n    ) -> List[str]:\n        \"\"\"Resolves the actual ids for the given argnames, based on the ``ids`` parameter given\n        to ``parametrize``.\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param ids: the ids parameter of the parametrized call (see docs).\n        :param List[ParameterSet] parameters: the list of parameter values, same size as ``argnames``.\n        :param Item item: the item that generated this parametrized call.\n        :rtype: List[str]\n        :return: the list of ids for each argname given\n        \"\"\"\n        if ids is None:\n            idfn = None\n            ids_ = None\n        elif callable(ids):\n            idfn = ids\n            ids_ = None\n        else:\n            idfn = None\n            ids_ = self._validate_ids(ids, parameters, self.function.__name__)\n        return idmaker(argnames, parameters, idfn, ids_, self.config, item=item)\n\n    def _validate_ids(\n        self,\n        ids: Iterable[Union[None, str, float, int, bool]],\n        parameters: typing.Sequence[ParameterSet],\n        func_name: str,\n    ) -> List[Union[None, str]]:\n        try:\n            num_ids = len(ids)  # type: ignore[arg-type] # noqa: F821\n        except TypeError:\n            try:\n                iter(ids)\n            except TypeError:\n                raise TypeError(\"ids must be a callable or an iterable\")\n            num_ids = len(parameters)\n\n        # num_ids == 0 is a special case: https://github.com/pytest-dev/pytest/issues/1849\n        if num_ids != len(parameters) and num_ids != 0:\n            msg = \"In {}: {} parameter sets specified, with different number of ids: {}\"\n            fail(msg.format(func_name, len(parameters), num_ids), pytrace=False)\n\n        new_ids = []\n        for idx, id_value in enumerate(itertools.islice(ids, num_ids)):\n            if id_value is None or isinstance(id_value, str):\n                new_ids.append(id_value)\n            elif isinstance(id_value, (float, int, bool)):\n                new_ids.append(str(id_value))\n            else:\n                msg = \"In {}: ids must be list of string/float/int/bool, found: {} (type: {!r}) at index {}\"\n                fail(\n                    msg.format(func_name, saferepr(id_value), type(id_value), idx),\n                    pytrace=False,\n                )\n        return new_ids\n\n    def _resolve_arg_value_types(\n        self,\n        argnames: typing.Sequence[str],\n        indirect: Union[bool, typing.Sequence[str]],\n    ) -> Dict[str, str]:\n        \"\"\"Resolves if each parametrized argument must be considered a parameter to a fixture or a \"funcarg\"\n        to the function, based on the ``indirect`` parameter of the parametrized() call.\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param indirect: same ``indirect`` parameter of ``parametrize()``.\n        :rtype: Dict[str, str]\n            A dict mapping each arg name to either:\n            * \"params\" if the argname should be the parameter of a fixture of the same name.\n            * \"funcargs\" if the argname should be a parameter to the parametrized test function.\n        \"\"\"\n        if isinstance(indirect, bool):\n            valtypes = dict.fromkeys(argnames, \"params\" if indirect else \"funcargs\")\n        elif isinstance(indirect, Sequence):\n            valtypes = dict.fromkeys(argnames, \"funcargs\")\n            for arg in indirect:\n                if arg not in argnames:\n                    fail(\n                        \"In {}: indirect fixture '{}' doesn't exist\".format(\n                            self.function.__name__, arg\n                        ),\n                        pytrace=False,\n                    )\n                valtypes[arg] = \"params\"\n        else:\n            fail(\n                \"In {func}: expected Sequence or boolean for indirect, got {type}\".format(\n                    type=type(indirect).__name__, func=self.function.__name__\n                ),\n                pytrace=False,\n            )\n        return valtypes\n\n    def _validate_if_using_arg_names(\n        self,\n        argnames: typing.Sequence[str],\n        indirect: Union[bool, typing.Sequence[str]],\n    ) -> None:\n        \"\"\"\n        Check if all argnames are being used, by default values, or directly/indirectly.\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param indirect: same ``indirect`` parameter of ``parametrize()``.\n        :raise ValueError: if validation fails.\n        \"\"\"\n        default_arg_names = set(get_default_arg_names(self.function))\n        func_name = self.function.__name__\n        for arg in argnames:\n            if arg not in self.fixturenames:\n                if arg in default_arg_names:\n                    fail(\n                        \"In {}: function already takes an argument '{}' with a default value\".format(\n                            func_name, arg\n                        ),\n                        pytrace=False,\n                    )\n                else:\n                    if isinstance(indirect, Sequence):\n                        name = \"fixture\" if arg in indirect else \"argument\"\n                    else:\n                        name = \"fixture\" if indirect else \"argument\"\n                    fail(\n                        \"In {}: function uses no {} '{}'\".format(func_name, name, arg),\n                        pytrace=False,\n                    )\n\n    def _validate_explicit_parameters(\n        self,\n        argnames: typing.Sequence[str],\n        indirect: Union[bool, typing.Sequence[str]],\n    ) -> None:\n        \"\"\"\n        The argnames in *parametrize* should either be declared explicitly via\n        indirect list or in the function signature\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param indirect: same ``indirect`` parameter of ``parametrize()``.\n        :raise ValueError: if validation fails\n        \"\"\"\n        if isinstance(indirect, bool):\n            parametrized_argnames = [] if indirect else argnames\n        else:\n            parametrized_argnames = [arg for arg in argnames if arg not in indirect]\n\n        if not parametrized_argnames:\n            return\n\n        funcargnames = _pytest.compat.getfuncargnames(self.function)\n        usefixtures = fixtures.get_use_fixtures_for_node(self.definition)\n\n        for arg in parametrized_argnames:\n            if arg not in funcargnames and arg not in usefixtures:\n                func_name = self.function.__name__\n                msg = (\n                    'In function \"{func_name}\":\\n'\n                    'Parameter \"{arg}\" should be declared explicitly via indirect or in function itself'\n                ).format(func_name=func_name, arg=arg)\n                fail(msg, pytrace=False)"}, {"id": "_pytest.python.Metafunc.__init__", "kind": "function", "range": [817, 4, 843, 60, 29945, 30799], "file_path": "src/_pytest/python.py", "content": "def __init__(\n        self,\n        definition: \"FunctionDefinition\",\n        fixtureinfo: fixtures.FuncFixtureInfo,\n        config: Config,\n        cls=None,\n        module=None,\n    ) -> None:\n        self.definition = definition\n\n        #: access to the :class:`_pytest.config.Config` object for the test session\n        self.config = config\n\n        #: the module object where the test function is defined in.\n        self.module = module\n\n        #: underlying python test function\n        self.function = definition.obj\n\n        #: set of fixture names required by the test function\n        self.fixturenames = fixtureinfo.names_closure\n\n        #: class object where the test function is defined in or ``None``.\n        self.cls = cls\n\n        self._calls = []  # type: List[CallSpec2]\n        self._arg2fixturedefs = fixtureinfo.name2fixturedefs"}, {"id": "_pytest.python.Metafunc.funcargnames", "kind": "function", "range": [845, 4, 849, 32, 30805, 31003], "file_path": "src/_pytest/python.py", "content": "@property\n    def funcargnames(self):\n        \"\"\" alias attribute for ``fixturenames`` for pre-2.3 compatibility\"\"\"\n        warnings.warn(FUNCARGNAMES, stacklevel=2)\n        return self.fixturenames"}, {"id": "_pytest.python.Metafunc.parametrize", "kind": "function", "range": [851, 4, 971, 30, 31009, 36442], "file_path": "src/_pytest/python.py", "content": "def parametrize(\n        self,\n        argnames: Union[str, List[str], Tuple[str, ...]],\n        argvalues: Iterable[Union[ParameterSet, typing.Sequence[object], object]],\n        indirect: Union[bool, typing.Sequence[str]] = False,\n        ids: Optional[\n            Union[\n                Iterable[Union[None, str, float, int, bool]],\n                Callable[[object], Optional[object]],\n            ]\n        ] = None,\n        scope: \"Optional[str]\" = None,\n        *,\n        _param_mark: Optional[Mark] = None\n    ) -> None:\n        \"\"\" Add new invocations to the underlying test function using the list\n        of argvalues for the given argnames.  Parametrization is performed\n        during the collection phase.  If you need to setup expensive resources\n        see about setting indirect to do it rather at test setup time.\n\n        :arg argnames: a comma-separated string denoting one or more argument\n                       names, or a list/tuple of argument strings.\n\n        :arg argvalues: The list of argvalues determines how often a\n            test is invoked with different argument values.  If only one\n            argname was specified argvalues is a list of values.  If N\n            argnames were specified, argvalues must be a list of N-tuples,\n            where each tuple-element specifies a value for its respective\n            argname.\n\n        :arg indirect: The list of argnames or boolean. A list of arguments'\n            names (subset of argnames). If True the list contains all names from\n            the argnames. Each argvalue corresponding to an argname in this list will\n            be passed as request.param to its respective argname fixture\n            function so that it can perform more expensive setups during the\n            setup phase of a test rather than at collection time.\n\n        :arg ids: sequence of (or generator for) ids for ``argvalues``,\n              or a callable to return part of the id for each argvalue.\n\n            With sequences (and generators like ``itertools.count()``) the\n            returned ids should be of type ``string``, ``int``, ``float``,\n            ``bool``, or ``None``.\n            They are mapped to the corresponding index in ``argvalues``.\n            ``None`` means to use the auto-generated id.\n\n            If it is a callable it will be called for each entry in\n            ``argvalues``, and the return value is used as part of the\n            auto-generated id for the whole set (where parts are joined with\n            dashes (\"-\")).\n            This is useful to provide more specific ids for certain items, e.g.\n            dates.  Returning ``None`` will use an auto-generated id.\n\n            If no ids are provided they will be generated automatically from\n            the argvalues.\n\n        :arg scope: if specified it denotes the scope of the parameters.\n            The scope is used for grouping tests by parameter instances.\n            It will also override any fixture-function defined scope, allowing\n            to set a dynamic scope using test context or configuration.\n        \"\"\"\n        from _pytest.fixtures import scope2index\n\n        argnames, parameters = ParameterSet._for_parametrize(\n            argnames,\n            argvalues,\n            self.function,\n            self.config,\n            function_definition=self.definition,\n        )\n        del argvalues\n\n        if \"request\" in argnames:\n            fail(\n                \"'request' is a reserved name and cannot be used in @pytest.mark.parametrize\",\n                pytrace=False,\n            )\n\n        if scope is None:\n            scope = _find_parametrized_scope(argnames, self._arg2fixturedefs, indirect)\n\n        self._validate_if_using_arg_names(argnames, indirect)\n\n        arg_values_types = self._resolve_arg_value_types(argnames, indirect)\n\n        self._validate_explicit_parameters(argnames, indirect)\n\n        # Use any already (possibly) generated ids with parametrize Marks.\n        if _param_mark and _param_mark._param_ids_from:\n            generated_ids = _param_mark._param_ids_from._param_ids_generated\n            if generated_ids is not None:\n                ids = generated_ids\n\n        ids = self._resolve_arg_ids(argnames, ids, parameters, item=self.definition)\n\n        # Store used (possibly generated) ids with parametrize Marks.\n        if _param_mark and _param_mark._param_ids_from and generated_ids is None:\n            object.__setattr__(_param_mark._param_ids_from, \"_param_ids_generated\", ids)\n\n        scopenum = scope2index(\n            scope, descr=\"parametrize() call in {}\".format(self.function.__name__)\n        )\n\n        # create the new calls: if we are parametrize() multiple times (by applying the decorator\n        # more than once) then we accumulate those calls generating the cartesian product\n        # of all calls\n        newcalls = []\n        for callspec in self._calls or [CallSpec2(self)]:\n            for param_index, (param_id, param_set) in enumerate(zip(ids, parameters)):\n                newcallspec = callspec.copy()\n                newcallspec.setmulti2(\n                    arg_values_types,\n                    argnames,\n                    param_set.values,\n                    param_id,\n                    param_set.marks,\n                    scopenum,\n                    param_index,\n                )\n                newcalls.append(newcallspec)\n        self._calls = newcalls"}, {"id": "_pytest.python.Metafunc._resolve_arg_ids", "kind": "function", "range": [973, 4, 1004, 80, 36448, 37694], "file_path": "src/_pytest/python.py", "content": "def _resolve_arg_ids(\n        self,\n        argnames: typing.Sequence[str],\n        ids: Optional[\n            Union[\n                Iterable[Union[None, str, float, int, bool]],\n                Callable[[object], Optional[object]],\n            ]\n        ],\n        parameters: typing.Sequence[ParameterSet],\n        item,\n    ) -> List[str]:\n        \"\"\"Resolves the actual ids for the given argnames, based on the ``ids`` parameter given\n        to ``parametrize``.\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param ids: the ids parameter of the parametrized call (see docs).\n        :param List[ParameterSet] parameters: the list of parameter values, same size as ``argnames``.\n        :param Item item: the item that generated this parametrized call.\n        :rtype: List[str]\n        :return: the list of ids for each argname given\n        \"\"\"\n        if ids is None:\n            idfn = None\n            ids_ = None\n        elif callable(ids):\n            idfn = ids\n            ids_ = None\n        else:\n            idfn = None\n            ids_ = self._validate_ids(ids, parameters, self.function.__name__)\n        return idmaker(argnames, parameters, idfn, ids_, self.config, item=item)"}, {"id": "_pytest.python.Metafunc._validate_ids", "kind": "function", "range": [1006, 4, 1038, 22, 37700, 39121], "file_path": "src/_pytest/python.py", "content": "def _validate_ids(\n        self,\n        ids: Iterable[Union[None, str, float, int, bool]],\n        parameters: typing.Sequence[ParameterSet],\n        func_name: str,\n    ) -> List[Union[None, str]]:\n        try:\n            num_ids = len(ids)  # type: ignore[arg-type] # noqa: F821\n        except TypeError:\n            try:\n                iter(ids)\n            except TypeError:\n                raise TypeError(\"ids must be a callable or an iterable\")\n            num_ids = len(parameters)\n\n        # num_ids == 0 is a special case: https://github.com/pytest-dev/pytest/issues/1849\n        if num_ids != len(parameters) and num_ids != 0:\n            msg = \"In {}: {} parameter sets specified, with different number of ids: {}\"\n            fail(msg.format(func_name, len(parameters), num_ids), pytrace=False)\n\n        new_ids = []\n        for idx, id_value in enumerate(itertools.islice(ids, num_ids)):\n            if id_value is None or isinstance(id_value, str):\n                new_ids.append(id_value)\n            elif isinstance(id_value, (float, int, bool)):\n                new_ids.append(str(id_value))\n            else:\n                msg = \"In {}: ids must be list of string/float/int/bool, found: {} (type: {!r}) at index {}\"\n                fail(\n                    msg.format(func_name, saferepr(id_value), type(id_value), idx),\n                    pytrace=False,\n                )\n        return new_ids"}, {"id": "_pytest.python.Metafunc._resolve_arg_value_types", "kind": "function", "range": [1040, 4, 1075, 23, 39127, 40812], "file_path": "src/_pytest/python.py", "content": "def _resolve_arg_value_types(\n        self,\n        argnames: typing.Sequence[str],\n        indirect: Union[bool, typing.Sequence[str]],\n    ) -> Dict[str, str]:\n        \"\"\"Resolves if each parametrized argument must be considered a parameter to a fixture or a \"funcarg\"\n        to the function, based on the ``indirect`` parameter of the parametrized() call.\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param indirect: same ``indirect`` parameter of ``parametrize()``.\n        :rtype: Dict[str, str]\n            A dict mapping each arg name to either:\n            * \"params\" if the argname should be the parameter of a fixture of the same name.\n            * \"funcargs\" if the argname should be a parameter to the parametrized test function.\n        \"\"\"\n        if isinstance(indirect, bool):\n            valtypes = dict.fromkeys(argnames, \"params\" if indirect else \"funcargs\")\n        elif isinstance(indirect, Sequence):\n            valtypes = dict.fromkeys(argnames, \"funcargs\")\n            for arg in indirect:\n                if arg not in argnames:\n                    fail(\n                        \"In {}: indirect fixture '{}' doesn't exist\".format(\n                            self.function.__name__, arg\n                        ),\n                        pytrace=False,\n                    )\n                valtypes[arg] = \"params\"\n        else:\n            fail(\n                \"In {func}: expected Sequence or boolean for indirect, got {type}\".format(\n                    type=type(indirect).__name__, func=self.function.__name__\n                ),\n                pytrace=False,\n            )\n        return valtypes"}, {"id": "_pytest.python.Metafunc._validate_if_using_arg_names", "kind": "function", "range": [1077, 4, 1108, 21, 40818, 42211], "file_path": "src/_pytest/python.py", "content": "def _validate_if_using_arg_names(\n        self,\n        argnames: typing.Sequence[str],\n        indirect: Union[bool, typing.Sequence[str]],\n    ) -> None:\n        \"\"\"\n        Check if all argnames are being used, by default values, or directly/indirectly.\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param indirect: same ``indirect`` parameter of ``parametrize()``.\n        :raise ValueError: if validation fails.\n        \"\"\"\n        default_arg_names = set(get_default_arg_names(self.function))\n        func_name = self.function.__name__\n        for arg in argnames:\n            if arg not in self.fixturenames:\n                if arg in default_arg_names:\n                    fail(\n                        \"In {}: function already takes an argument '{}' with a default value\".format(\n                            func_name, arg\n                        ),\n                        pytrace=False,\n                    )\n                else:\n                    if isinstance(indirect, Sequence):\n                        name = \"fixture\" if arg in indirect else \"argument\"\n                    else:\n                        name = \"fixture\" if indirect else \"argument\"\n                    fail(\n                        \"In {}: function uses no {} '{}'\".format(func_name, name, arg),\n                        pytrace=False,\n                    )"}, {"id": "_pytest.python.Metafunc._validate_explicit_parameters", "kind": "function", "range": [1110, 4, 1141, 40, 42217, 43579], "file_path": "src/_pytest/python.py", "content": "def _validate_explicit_parameters(\n        self,\n        argnames: typing.Sequence[str],\n        indirect: Union[bool, typing.Sequence[str]],\n    ) -> None:\n        \"\"\"\n        The argnames in *parametrize* should either be declared explicitly via\n        indirect list or in the function signature\n\n        :param List[str] argnames: list of argument names passed to ``parametrize()``.\n        :param indirect: same ``indirect`` parameter of ``parametrize()``.\n        :raise ValueError: if validation fails\n        \"\"\"\n        if isinstance(indirect, bool):\n            parametrized_argnames = [] if indirect else argnames\n        else:\n            parametrized_argnames = [arg for arg in argnames if arg not in indirect]\n\n        if not parametrized_argnames:\n            return\n\n        funcargnames = _pytest.compat.getfuncargnames(self.function)\n        usefixtures = fixtures.get_use_fixtures_for_node(self.definition)\n\n        for arg in parametrized_argnames:\n            if arg not in funcargnames and arg not in usefixtures:\n                func_name = self.function.__name__\n                msg = (\n                    'In function \"{func_name}\":\\n'\n                    'Parameter \"{arg}\" should be declared explicitly via indirect or in function itself'\n                ).format(func_name=func_name, arg=arg)\n                fail(msg, pytrace=False)"}, {"id": "_pytest.python._find_parametrized_scope", "kind": "function", "range": [1144, 0, 1174, 21, 43582, 44714], "file_path": "src/_pytest/python.py", "content": "def _find_parametrized_scope(argnames, arg2fixturedefs, indirect):\n    \"\"\"Find the most appropriate scope for a parametrized call based on its arguments.\n\n    When there's at least one direct argument, always use \"function\" scope.\n\n    When a test function is parametrized and all its arguments are indirect\n    (e.g. fixtures), return the most narrow scope based on the fixtures used.\n\n    Related to issue #1832, based on code posted by @Kingdread.\n    \"\"\"\n    from _pytest.fixtures import scopes\n\n    if isinstance(indirect, (list, tuple)):\n        all_arguments_are_fixtures = len(indirect) == len(argnames)\n    else:\n        all_arguments_are_fixtures = bool(indirect)\n\n    if all_arguments_are_fixtures:\n        fixturedefs = arg2fixturedefs or {}\n        used_scopes = [\n            fixturedef[0].scope\n            for name, fixturedef in fixturedefs.items()\n            if name in argnames\n        ]\n        if used_scopes:\n            # Takes the most narrow scope from used fixtures\n            for scope in reversed(scopes):\n                if scope in used_scopes:\n                    return scope\n\n    return \"function\""}, {"id": "_pytest.python._ascii_escaped_by_config", "kind": "function", "range": [1177, 0, 1187, 71, 44717, 45253], "file_path": "src/_pytest/python.py", "content": "def _ascii_escaped_by_config(val: Union[str, bytes], config: Optional[Config]) -> str:\n    if config is None:\n        escape_option = False\n    else:\n        escape_option = config.getini(\n            \"disable_test_id_escaping_and_forfeit_all_rights_to_community_support\"\n        )\n    # TODO: If escaping is turned off and the user passes bytes,\n    #       will return a bytes. For now we ignore this but the\n    #       code *probably* doesn't handle this case.\n    return val if escape_option else ascii_escaped(val)  # type: ignore"}, {"id": "_pytest.python._idval", "kind": "function", "range": [1190, 0, 1226, 34, 45256, 46531], "file_path": "src/_pytest/python.py", "content": "def _idval(\n    val: object,\n    argname: str,\n    idx: int,\n    idfn: Optional[Callable[[object], Optional[object]]],\n    item,\n    config: Optional[Config],\n) -> str:\n    if idfn:\n        try:\n            generated_id = idfn(val)\n            if generated_id is not None:\n                val = generated_id\n        except Exception as e:\n            msg = \"{}: error raised while trying to determine id of parameter '{}' at position {}\"\n            msg = msg.format(item.nodeid, argname, idx)\n            raise ValueError(msg) from e\n    elif config:\n        hook_id = config.hook.pytest_make_parametrize_id(\n            config=config, val=val, argname=argname\n        )  # type: Optional[str]\n        if hook_id:\n            return hook_id\n\n    if isinstance(val, STRING_TYPES):\n        return _ascii_escaped_by_config(val, config)\n    elif val is None or isinstance(val, (float, int, bool)):\n        return str(val)\n    elif isinstance(val, REGEX_TYPE):\n        return ascii_escaped(val.pattern)\n    elif isinstance(val, enum.Enum):\n        return str(val)\n    elif isinstance(getattr(val, \"__name__\", None), str):\n        # name of a class, function, module, etc.\n        name = getattr(val, \"__name__\")  # type: str\n        return name\n    return str(argname) + str(idx)"}, {"id": "_pytest.python._idvalset", "kind": "function", "range": [1229, 0, 1248, 51, 46534, 47177], "file_path": "src/_pytest/python.py", "content": "def _idvalset(\n    idx: int,\n    parameterset: ParameterSet,\n    argnames: Iterable[str],\n    idfn: Optional[Callable[[object], Optional[object]]],\n    ids: Optional[List[Union[None, str]]],\n    item,\n    config: Optional[Config],\n):\n    if parameterset.id is not None:\n        return parameterset.id\n    id = None if ids is None or idx >= len(ids) else ids[idx]\n    if id is None:\n        this_id = [\n            _idval(val, argname, idx, idfn, item=item, config=config)\n            for val, argname in zip(parameterset.values, argnames)\n        ]\n        return \"-\".join(this_id)\n    else:\n        return _ascii_escaped_by_config(id, config)"}, {"id": "_pytest.python.idmaker", "kind": "function", "range": [1251, 0, 1280, 23, 47180, 48270], "file_path": "src/_pytest/python.py", "content": "def idmaker(\n    argnames: Iterable[str],\n    parametersets: Iterable[ParameterSet],\n    idfn: Optional[Callable[[object], Optional[object]]] = None,\n    ids: Optional[List[Union[None, str]]] = None,\n    config: Optional[Config] = None,\n    item=None,\n) -> List[str]:\n    resolved_ids = [\n        _idvalset(valindex, parameterset, argnames, idfn, ids, config=config, item=item)\n        for valindex, parameterset in enumerate(parametersets)\n    ]\n\n    # All IDs must be unique!\n    unique_ids = set(resolved_ids)\n    if len(unique_ids) != len(resolved_ids):\n\n        # Record the number of occurrences of each test ID\n        test_id_counts = Counter(resolved_ids)\n\n        # Map the test ID to its next suffix\n        test_id_suffixes = defaultdict(int)  # type: Dict[str, int]\n\n        # Suffix non-unique IDs to make them unique\n        for index, test_id in enumerate(resolved_ids):\n            if test_id_counts[test_id] > 1:\n                resolved_ids[index] = \"{}{}\".format(test_id, test_id_suffixes[test_id])\n                test_id_suffixes[test_id] += 1\n\n    return resolved_ids"}, {"id": "_pytest.python.show_fixtures_per_test", "kind": "function", "range": [1283, 0, 1286, 56, 48273, 48408], "file_path": "src/_pytest/python.py", "content": "def show_fixtures_per_test(config):\n    from _pytest.main import wrap_session\n\n    return wrap_session(config, _show_fixtures_per_test)"}, {"id": "_pytest.python._show_fixtures_per_test", "kind": "function", "range": [1289, 0, 1338, 32, 48411, 50189], "file_path": "src/_pytest/python.py", "content": "def _show_fixtures_per_test(config, session):\n    import _pytest.config\n\n    session.perform_collect()\n    curdir = py.path.local()\n    tw = _pytest.config.create_terminal_writer(config)\n    verbose = config.getvalue(\"verbose\")\n\n    def get_best_relpath(func):\n        loc = getlocation(func, curdir)\n        return curdir.bestrelpath(loc)\n\n    def write_fixture(fixture_def):\n        argname = fixture_def.argname\n        if verbose <= 0 and argname.startswith(\"_\"):\n            return\n        if verbose > 0:\n            bestrel = get_best_relpath(fixture_def.func)\n            funcargspec = \"{} -- {}\".format(argname, bestrel)\n        else:\n            funcargspec = argname\n        tw.line(funcargspec, green=True)\n        fixture_doc = inspect.getdoc(fixture_def.func)\n        if fixture_doc:\n            write_docstring(tw, fixture_doc)\n        else:\n            tw.line(\"    no docstring available\", red=True)\n\n    def write_item(item):\n        try:\n            info = item._fixtureinfo\n        except AttributeError:\n            # doctests items have no _fixtureinfo attribute\n            return\n        if not info.name2fixturedefs:\n            # this test item does not use any fixtures\n            return\n        tw.line()\n        tw.sep(\"-\", \"fixtures used by {}\".format(item.name))\n        tw.sep(\"-\", \"({})\".format(get_best_relpath(item.function)))\n        # dict key not used in loop but needed for sorting\n        for _, fixturedefs in sorted(info.name2fixturedefs.items()):\n            assert fixturedefs is not None\n            if not fixturedefs:\n                continue\n            # last item is expected to be the one used by the test item\n            write_fixture(fixturedefs[-1])\n\n    for session_item in session.items:\n        write_item(session_item)"}, {"id": "_pytest.python.showfixtures", "kind": "function", "range": [1341, 0, 1344, 51, 50192, 50312], "file_path": "src/_pytest/python.py", "content": "def showfixtures(config):\n    from _pytest.main import wrap_session\n\n    return wrap_session(config, _showfixtures_main)"}, {"id": "_pytest.python._showfixtures_main", "kind": "function", "range": [1347, 0, 1401, 17, 50315, 52174], "file_path": "src/_pytest/python.py", "content": "def _showfixtures_main(config, session):\n    import _pytest.config\n\n    session.perform_collect()\n    curdir = py.path.local()\n    tw = _pytest.config.create_terminal_writer(config)\n    verbose = config.getvalue(\"verbose\")\n\n    fm = session._fixturemanager\n\n    available = []\n    seen = set()\n\n    for argname, fixturedefs in fm._arg2fixturedefs.items():\n        assert fixturedefs is not None\n        if not fixturedefs:\n            continue\n        for fixturedef in fixturedefs:\n            loc = getlocation(fixturedef.func, curdir)\n            if (fixturedef.argname, loc) in seen:\n                continue\n            seen.add((fixturedef.argname, loc))\n            available.append(\n                (\n                    len(fixturedef.baseid),\n                    fixturedef.func.__module__,\n                    curdir.bestrelpath(loc),\n                    fixturedef.argname,\n                    fixturedef,\n                )\n            )\n\n    available.sort()\n    currentmodule = None\n    for baseid, module, bestrel, argname, fixturedef in available:\n        if currentmodule != module:\n            if not module.startswith(\"_pytest.\"):\n                tw.line()\n                tw.sep(\"-\", \"fixtures defined from {}\".format(module))\n                currentmodule = module\n        if verbose <= 0 and argname[0] == \"_\":\n            continue\n        tw.write(argname, green=True)\n        if fixturedef.scope != \"function\":\n            tw.write(\" [%s scope]\" % fixturedef.scope, cyan=True)\n        if verbose > 0:\n            tw.write(\" -- %s\" % bestrel, yellow=True)\n        tw.write(\"\\n\")\n        loc = getlocation(fixturedef.func, curdir)\n        doc = inspect.getdoc(fixturedef.func)\n        if doc:\n            write_docstring(tw, doc)\n        else:\n            tw.line(\"    {}: no docstring available\".format(loc), red=True)\n        tw.line()"}, {"id": "_pytest.python.write_docstring", "kind": "function", "range": [1404, 0, 1406, 38, 52177, 52329], "file_path": "src/_pytest/python.py", "content": "def write_docstring(tw: TerminalWriter, doc: str, indent: str = \"    \") -> None:\n    for line in doc.split(\"\\n\"):\n        tw.write(indent + line + \"\\n\")"}, {"id": "_pytest.python.Function", "kind": "class", "range": [1409, 0, 1545, 58, 52332, 57213], "file_path": "src/_pytest/python.py", "content": "class Function(PyobjMixin, nodes.Item):\n    \"\"\" a Function Item is responsible for setting up and executing a\n    Python test function.\n    \"\"\"\n\n    # disable since functions handle it themselves\n    _ALLOW_MARKERS = False\n\n    def __init__(\n        self,\n        name,\n        parent,\n        args=None,\n        config=None,\n        callspec: Optional[CallSpec2] = None,\n        callobj=NOTSET,\n        keywords=None,\n        session=None,\n        fixtureinfo: Optional[FuncFixtureInfo] = None,\n        originalname=None,\n    ) -> None:\n        super().__init__(name, parent, config=config, session=session)\n        self._args = args\n        if callobj is not NOTSET:\n            self.obj = callobj\n\n        self.keywords.update(self.obj.__dict__)\n        self.own_markers.extend(get_unpacked_marks(self.obj))\n        if callspec:\n            self.callspec = callspec\n            # this is total hostile and a mess\n            # keywords are broken by design by now\n            # this will be redeemed later\n            for mark in callspec.marks:\n                # feel free to cry, this was broken for years before\n                # and keywords cant fix it per design\n                self.keywords[mark.name] = mark\n            self.own_markers.extend(normalize_mark_list(callspec.marks))\n        if keywords:\n            self.keywords.update(keywords)\n\n        # todo: this is a hell of a hack\n        # https://github.com/pytest-dev/pytest/issues/4569\n\n        self.keywords.update(\n            {\n                mark.name: True\n                for mark in self.iter_markers()\n                if mark.name not in self.keywords\n            }\n        )\n\n        if fixtureinfo is None:\n            fixtureinfo = self.session._fixturemanager.getfixtureinfo(\n                self, self.obj, self.cls, funcargs=True\n            )\n        self._fixtureinfo = fixtureinfo  # type: FuncFixtureInfo\n        self.fixturenames = fixtureinfo.names_closure\n        self._initrequest()\n\n        #: original function name, without any decorations (for example\n        #: parametrization adds a ``\"[...]\"`` suffix to function names).\n        #:\n        #: .. versionadded:: 3.0\n        self.originalname = originalname\n\n    @classmethod\n    def from_parent(cls, parent, **kw):  # todo: determine sound type limitations\n        \"\"\"\n        The public  constructor\n        \"\"\"\n        return super().from_parent(parent=parent, **kw)\n\n    def _initrequest(self):\n        self.funcargs = {}\n        self._request = fixtures.FixtureRequest(self)\n\n    @property\n    def function(self):\n        \"underlying python 'function' object\"\n        return getimfunc(self.obj)\n\n    def _getobj(self):\n        name = self.name\n        i = name.find(\"[\")  # parametrization\n        if i != -1:\n            name = name[:i]\n        return getattr(self.parent.obj, name)\n\n    @property\n    def _pyfuncitem(self):\n        \"(compatonly) for code expecting pytest-2.2 style request objects\"\n        return self\n\n    @property\n    def funcargnames(self):\n        \"\"\" alias attribute for ``fixturenames`` for pre-2.3 compatibility\"\"\"\n        warnings.warn(FUNCARGNAMES, stacklevel=2)\n        return self.fixturenames\n\n    def runtest(self) -> None:\n        \"\"\" execute the underlying test function. \"\"\"\n        self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n\n    def setup(self) -> None:\n        if isinstance(self.parent, Instance):\n            self.parent.newinstance()\n            self.obj = self._getobj()\n        self._request._fillfixtures()\n\n    def _prunetraceback(self, excinfo: ExceptionInfo) -> None:\n        if hasattr(self, \"_obj\") and not self.config.getoption(\"fulltrace\", False):\n            code = _pytest._code.Code(get_real_func(self.obj))\n            path, firstlineno = code.path, code.firstlineno\n            traceback = excinfo.traceback\n            ntraceback = traceback.cut(path=path, firstlineno=firstlineno)\n            if ntraceback == traceback:\n                ntraceback = ntraceback.cut(path=path)\n                if ntraceback == traceback:\n                    ntraceback = ntraceback.filter(filter_traceback)\n                    if not ntraceback:\n                        ntraceback = traceback\n\n            excinfo.traceback = ntraceback.filter()\n            # issue364: mark all but first and last frames to\n            # only show a single-line message for each frame\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"auto\":\n                if len(excinfo.traceback) > 2:\n                    for entry in excinfo.traceback[1:-1]:\n                        entry.set_repr_style(\"short\")\n\n    def repr_failure(self, excinfo, outerr=None):\n        assert outerr is None, \"XXX outerr usage is deprecated\"\n        style = self.config.getoption(\"tbstyle\", \"auto\")\n        if style == \"auto\":\n            style = \"long\"\n        return self._repr_failure_py(excinfo, style=style)"}, {"id": "_pytest.python.Function._ALLOW_MARKERS", "kind": "variable", "range": [1415, 4, 1415, 26, 52532, 52554], "file_path": "src/_pytest/python.py", "content": "_ALLOW_MARKERS = False"}, {"id": "_pytest.python.Function.__init__", "kind": "function", "range": [1417, 4, 1473, 40, 52560, 54540], "file_path": "src/_pytest/python.py", "content": "def __init__(\n        self,\n        name,\n        parent,\n        args=None,\n        config=None,\n        callspec: Optional[CallSpec2] = None,\n        callobj=NOTSET,\n        keywords=None,\n        session=None,\n        fixtureinfo: Optional[FuncFixtureInfo] = None,\n        originalname=None,\n    ) -> None:\n        super().__init__(name, parent, config=config, session=session)\n        self._args = args\n        if callobj is not NOTSET:\n            self.obj = callobj\n\n        self.keywords.update(self.obj.__dict__)\n        self.own_markers.extend(get_unpacked_marks(self.obj))\n        if callspec:\n            self.callspec = callspec\n            # this is total hostile and a mess\n            # keywords are broken by design by now\n            # this will be redeemed later\n            for mark in callspec.marks:\n                # feel free to cry, this was broken for years before\n                # and keywords cant fix it per design\n                self.keywords[mark.name] = mark\n            self.own_markers.extend(normalize_mark_list(callspec.marks))\n        if keywords:\n            self.keywords.update(keywords)\n\n        # todo: this is a hell of a hack\n        # https://github.com/pytest-dev/pytest/issues/4569\n\n        self.keywords.update(\n            {\n                mark.name: True\n                for mark in self.iter_markers()\n                if mark.name not in self.keywords\n            }\n        )\n\n        if fixtureinfo is None:\n            fixtureinfo = self.session._fixturemanager.getfixtureinfo(\n                self, self.obj, self.cls, funcargs=True\n            )\n        self._fixtureinfo = fixtureinfo  # type: FuncFixtureInfo\n        self.fixturenames = fixtureinfo.names_closure\n        self._initrequest()\n\n        #: original function name, without any decorations (for example\n        #: parametrization adds a ``\"[...]\"`` suffix to function names).\n        #:\n        #: .. versionadded:: 3.0\n        self.originalname = originalname"}, {"id": "_pytest.python.Function.from_parent", "kind": "function", "range": [1475, 4, 1480, 55, 54546, 54752], "file_path": "src/_pytest/python.py", "content": "@classmethod\n    def from_parent(cls, parent, **kw):  # todo: determine sound type limitations\n        \"\"\"\n        The public  constructor\n        \"\"\"\n        return super().from_parent(parent=parent, **kw)"}, {"id": "_pytest.python.Function._initrequest", "kind": "function", "range": [1482, 4, 1484, 53, 54758, 54862], "file_path": "src/_pytest/python.py", "content": "def _initrequest(self):\n        self.funcargs = {}\n        self._request = fixtures.FixtureRequest(self)"}, {"id": "_pytest.python.Function.function", "kind": "function", "range": [1486, 4, 1489, 34, 54868, 54982], "file_path": "src/_pytest/python.py", "content": "@property\n    def function(self):\n        \"underlying python 'function' object\"\n        return getimfunc(self.obj)"}, {"id": "_pytest.python.Function._getobj", "kind": "function", "range": [1491, 4, 1496, 45, 54988, 55171], "file_path": "src/_pytest/python.py", "content": "def _getobj(self):\n        name = self.name\n        i = name.find(\"[\")  # parametrization\n        if i != -1:\n            name = name[:i]\n        return getattr(self.parent.obj, name)"}, {"id": "_pytest.python.Function._pyfuncitem", "kind": "function", "range": [1498, 4, 1501, 19, 55177, 55308], "file_path": "src/_pytest/python.py", "content": "@property\n    def _pyfuncitem(self):\n        \"(compatonly) for code expecting pytest-2.2 style request objects\"\n        return self"}, {"id": "_pytest.python.Function.funcargnames", "kind": "function", "range": [1503, 4, 1507, 32, 55314, 55512], "file_path": "src/_pytest/python.py", "content": "@property\n    def funcargnames(self):\n        \"\"\" alias attribute for ``fixturenames`` for pre-2.3 compatibility\"\"\"\n        warnings.warn(FUNCARGNAMES, stacklevel=2)\n        return self.fixturenames"}, {"id": "_pytest.python.Function.runtest", "kind": "function", "range": [1509, 4, 1511, 54, 55518, 55653], "file_path": "src/_pytest/python.py", "content": "def runtest(self) -> None:\n        \"\"\" execute the underlying test function. \"\"\"\n        self.ihook.pytest_pyfunc_call(pyfuncitem=self)"}, {"id": "_pytest.python.Function.setup", "kind": "function", "range": [1513, 4, 1517, 37, 55659, 55843], "file_path": "src/_pytest/python.py", "content": "def setup(self) -> None:\n        if isinstance(self.parent, Instance):\n            self.parent.newinstance()\n            self.obj = self._getobj()\n        self._request._fillfixtures()"}, {"id": "_pytest.python.Function._prunetraceback", "kind": "function", "range": [1519, 4, 1538, 53, 55849, 56927], "file_path": "src/_pytest/python.py", "content": "def _prunetraceback(self, excinfo: ExceptionInfo) -> None:\n        if hasattr(self, \"_obj\") and not self.config.getoption(\"fulltrace\", False):\n            code = _pytest._code.Code(get_real_func(self.obj))\n            path, firstlineno = code.path, code.firstlineno\n            traceback = excinfo.traceback\n            ntraceback = traceback.cut(path=path, firstlineno=firstlineno)\n            if ntraceback == traceback:\n                ntraceback = ntraceback.cut(path=path)\n                if ntraceback == traceback:\n                    ntraceback = ntraceback.filter(filter_traceback)\n                    if not ntraceback:\n                        ntraceback = traceback\n\n            excinfo.traceback = ntraceback.filter()\n            # issue364: mark all but first and last frames to\n            # only show a single-line message for each frame\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"auto\":\n                if len(excinfo.traceback) > 2:\n                    for entry in excinfo.traceback[1:-1]:\n                        entry.set_repr_style(\"short\")"}, {"id": "_pytest.python.Function.repr_failure", "kind": "function", "range": [1540, 4, 1545, 58, 56933, 57213], "file_path": "src/_pytest/python.py", "content": "def repr_failure(self, excinfo, outerr=None):\n        assert outerr is None, \"XXX outerr usage is deprecated\"\n        style = self.config.getoption(\"tbstyle\", \"auto\")\n        if style == \"auto\":\n            style = \"long\"\n        return self._repr_failure_py(excinfo, style=style)"}, {"id": "_pytest.python.FunctionDefinition", "kind": "class", "range": [1548, 0, 1557, 19, 57216, 57494], "file_path": "src/_pytest/python.py", "content": "class FunctionDefinition(Function):\n    \"\"\"\n    internal hack until we get actual definition nodes instead of the\n    crappy metafunc hack\n    \"\"\"\n\n    def runtest(self) -> None:\n        raise RuntimeError(\"function definitions are not supposed to be used\")\n\n    setup = runtest"}, {"id": "_pytest.python.FunctionDefinition.runtest", "kind": "function", "range": [1554, 4, 1555, 78, 57368, 57473], "file_path": "src/_pytest/python.py", "content": "def runtest(self) -> None:\n        raise RuntimeError(\"function definitions are not supposed to be used\")"}, {"id": "_pytest.python.FunctionDefinition.setup", "kind": "variable", "range": [1557, 4, 1557, 19, 57479, 57494], "file_path": "src/_pytest/python.py", "content": "setup = runtest"}, {"id": "_pytest.reports.getslaveinfoline", "kind": "function", "range": [28, 0, 37, 16, 834, 1165], "file_path": "src/_pytest/reports.py", "content": "def getslaveinfoline(node):\n    try:\n        return node._slaveinfocache\n    except AttributeError:\n        d = node.slaveinfo\n        ver = \"%s.%s.%s\" % d[\"version_info\"][:3]\n        node._slaveinfocache = s = \"[{}] {} -- Python {} {}\".format(\n            d[\"id\"], d[\"sysplatform\"], ver, d[\"executable\"]\n        )\n        return s"}, {"id": "_pytest.reports.BaseReport", "kind": "class", "range": [40, 0, 193, 28, 1168, 5629], "file_path": "src/_pytest/reports.py", "content": "class BaseReport:\n    when = None  # type: Optional[str]\n    location = None  # type: Optional[Tuple[str, Optional[int], str]]\n    longrepr = None\n    sections = []  # type: List[Tuple[str, str]]\n    nodeid = None  # type: str\n\n    def __init__(self, **kw: Any) -> None:\n        self.__dict__.update(kw)\n\n    if TYPE_CHECKING:\n        # Can have arbitrary fields given to __init__().\n        def __getattr__(self, key: str) -> Any:\n            raise NotImplementedError()\n\n    def toterminal(self, out) -> None:\n        if hasattr(self, \"node\"):\n            out.line(getslaveinfoline(self.node))\n\n        longrepr = self.longrepr\n        if longrepr is None:\n            return\n\n        if hasattr(longrepr, \"toterminal\"):\n            longrepr.toterminal(out)\n        else:\n            try:\n                out.line(longrepr)\n            except UnicodeEncodeError:\n                out.line(\"<unprintable longrepr>\")\n\n    def get_sections(self, prefix):\n        for name, content in self.sections:\n            if name.startswith(prefix):\n                yield prefix, content\n\n    @property\n    def longreprtext(self):\n        \"\"\"\n        Read-only property that returns the full string representation\n        of ``longrepr``.\n\n        .. versionadded:: 3.0\n        \"\"\"\n        tw = TerminalWriter(stringio=True)\n        tw.hasmarkup = False\n        self.toterminal(tw)\n        exc = tw.stringio.getvalue()\n        return exc.strip()\n\n    @property\n    def caplog(self):\n        \"\"\"Return captured log lines, if log capturing is enabled\n\n        .. versionadded:: 3.5\n        \"\"\"\n        return \"\\n\".join(\n            content for (prefix, content) in self.get_sections(\"Captured log\")\n        )\n\n    @property\n    def capstdout(self):\n        \"\"\"Return captured text from stdout, if capturing is enabled\n\n        .. versionadded:: 3.0\n        \"\"\"\n        return \"\".join(\n            content for (prefix, content) in self.get_sections(\"Captured stdout\")\n        )\n\n    @property\n    def capstderr(self):\n        \"\"\"Return captured text from stderr, if capturing is enabled\n\n        .. versionadded:: 3.0\n        \"\"\"\n        return \"\".join(\n            content for (prefix, content) in self.get_sections(\"Captured stderr\")\n        )\n\n    passed = property(lambda x: x.outcome == \"passed\")\n    failed = property(lambda x: x.outcome == \"failed\")\n    skipped = property(lambda x: x.outcome == \"skipped\")\n\n    @property\n    def fspath(self) -> str:\n        return self.nodeid.split(\"::\")[0]\n\n    @property\n    def count_towards_summary(self):\n        \"\"\"\n        **Experimental**\n\n        ``True`` if this report should be counted towards the totals shown at the end of the\n        test session: \"1 passed, 1 failure, etc\".\n\n        .. note::\n\n            This function is considered **experimental**, so beware that it is subject to changes\n            even in patch releases.\n        \"\"\"\n        return True\n\n    @property\n    def head_line(self):\n        \"\"\"\n        **Experimental**\n\n        Returns the head line shown with longrepr output for this report, more commonly during\n        traceback representation during failures::\n\n            ________ Test.foo ________\n\n\n        In the example above, the head_line is \"Test.foo\".\n\n        .. note::\n\n            This function is considered **experimental**, so beware that it is subject to changes\n            even in patch releases.\n        \"\"\"\n        if self.location is not None:\n            fspath, lineno, domain = self.location\n            return domain\n\n    def _get_verbose_word(self, config):\n        _category, _short, verbose = config.hook.pytest_report_teststatus(\n            report=self, config=config\n        )\n        return verbose\n\n    def _to_json(self):\n        \"\"\"\n        This was originally the serialize_report() function from xdist (ca03269).\n\n        Returns the contents of this report as a dict of builtin entries, suitable for\n        serialization.\n\n        Experimental method.\n        \"\"\"\n        return _report_to_json(self)\n\n    @classmethod\n    def _from_json(cls, reportdict):\n        \"\"\"\n        This was originally the serialize_report() function from xdist (ca03269).\n\n        Factory method that returns either a TestReport or CollectReport, depending on the calling\n        class. It's the callers responsibility to know which class to pass here.\n\n        Experimental method.\n        \"\"\"\n        kwargs = _report_kwargs_from_json(reportdict)\n        return cls(**kwargs)"}, {"id": "_pytest.reports.BaseReport.when", "kind": "variable", "range": [41, 4, 41, 15, 1190, 1201], "file_path": "src/_pytest/reports.py", "content": "when = None"}, {"id": "_pytest.reports.BaseReport.location", "kind": "variable", "range": [42, 4, 42, 19, 1229, 1244], "file_path": "src/_pytest/reports.py", "content": "location = None"}, {"id": "_pytest.reports.BaseReport.longrepr", "kind": "variable", "range": [43, 4, 43, 19, 1299, 1314], "file_path": "src/_pytest/reports.py", "content": "longrepr = None"}, {"id": "_pytest.reports.BaseReport.sections", "kind": "variable", "range": [44, 4, 44, 17, 1319, 1332], "file_path": "src/_pytest/reports.py", "content": "sections = []"}, {"id": "_pytest.reports.BaseReport.nodeid", "kind": "variable", "range": [45, 4, 45, 17, 1368, 1381], "file_path": "src/_pytest/reports.py", "content": "nodeid = None"}, {"id": "_pytest.reports.BaseReport.__init__", "kind": "function", "range": [47, 4, 48, 32, 1400, 1471], "file_path": "src/_pytest/reports.py", "content": "def __init__(self, **kw: Any) -> None:\n        self.__dict__.update(kw)"}, {"id": "_pytest.reports.BaseReport.toterminal", "kind": "function", "range": [55, 4, 69, 50, 1645, 2083], "file_path": "src/_pytest/reports.py", "content": "def toterminal(self, out) -> None:\n        if hasattr(self, \"node\"):\n            out.line(getslaveinfoline(self.node))\n\n        longrepr = self.longrepr\n        if longrepr is None:\n            return\n\n        if hasattr(longrepr, \"toterminal\"):\n            longrepr.toterminal(out)\n        else:\n            try:\n                out.line(longrepr)\n            except UnicodeEncodeError:\n                out.line(\"<unprintable longrepr>\")"}, {"id": "_pytest.reports.BaseReport.get_sections", "kind": "function", "range": [71, 4, 74, 37, 2089, 2242], "file_path": "src/_pytest/reports.py", "content": "def get_sections(self, prefix):\n        for name, content in self.sections:\n            if name.startswith(prefix):\n                yield prefix, content"}, {"id": "_pytest.reports.BaseReport.longreprtext", "kind": "function", "range": [76, 4, 88, 26, 2248, 2600], "file_path": "src/_pytest/reports.py", "content": "@property\n    def longreprtext(self):\n        \"\"\"\n        Read-only property that returns the full string representation\n        of ``longrepr``.\n\n        .. versionadded:: 3.0\n        \"\"\"\n        tw = TerminalWriter(stringio=True)\n        tw.hasmarkup = False\n        self.toterminal(tw)\n        exc = tw.stringio.getvalue()\n        return exc.strip()"}, {"id": "_pytest.reports.BaseReport.caplog", "kind": "function", "range": [90, 4, 98, 9, 2606, 2861], "file_path": "src/_pytest/reports.py", "content": "@property\n    def caplog(self):\n        \"\"\"Return captured log lines, if log capturing is enabled\n\n        .. versionadded:: 3.5\n        \"\"\"\n        return \"\\n\".join(\n            content for (prefix, content) in self.get_sections(\"Captured log\")\n        )"}, {"id": "_pytest.reports.BaseReport.capstdout", "kind": "function", "range": [100, 4, 108, 9, 2867, 3129], "file_path": "src/_pytest/reports.py", "content": "@property\n    def capstdout(self):\n        \"\"\"Return captured text from stdout, if capturing is enabled\n\n        .. versionadded:: 3.0\n        \"\"\"\n        return \"\".join(\n            content for (prefix, content) in self.get_sections(\"Captured stdout\")\n        )"}, {"id": "_pytest.reports.BaseReport.capstderr", "kind": "function", "range": [110, 4, 118, 9, 3135, 3397], "file_path": "src/_pytest/reports.py", "content": "@property\n    def capstderr(self):\n        \"\"\"Return captured text from stderr, if capturing is enabled\n\n        .. versionadded:: 3.0\n        \"\"\"\n        return \"\".join(\n            content for (prefix, content) in self.get_sections(\"Captured stderr\")\n        )"}, {"id": "_pytest.reports.BaseReport.passed", "kind": "variable", "range": [120, 4, 120, 54, 3403, 3453], "file_path": "src/_pytest/reports.py", "content": "passed = property(lambda x: x.outcome == \"passed\")"}, {"id": "_pytest.reports.BaseReport.failed", "kind": "variable", "range": [121, 4, 121, 54, 3458, 3508], "file_path": "src/_pytest/reports.py", "content": "failed = property(lambda x: x.outcome == \"failed\")"}, {"id": "_pytest.reports.BaseReport.skipped", "kind": "variable", "range": [122, 4, 122, 56, 3513, 3565], "file_path": "src/_pytest/reports.py", "content": "skipped = property(lambda x: x.outcome == \"skipped\")"}, {"id": "_pytest.reports.BaseReport.fspath", "kind": "function", "range": [124, 4, 126, 41, 3571, 3651], "file_path": "src/_pytest/reports.py", "content": "@property\n    def fspath(self) -> str:\n        return self.nodeid.split(\"::\")[0]"}, {"id": "_pytest.reports.BaseReport.count_towards_summary", "kind": "function", "range": [128, 4, 141, 19, 3657, 4070], "file_path": "src/_pytest/reports.py", "content": "@property\n    def count_towards_summary(self):\n        \"\"\"\n        **Experimental**\n\n        ``True`` if this report should be counted towards the totals shown at the end of the\n        test session: \"1 passed, 1 failure, etc\".\n\n        .. note::\n\n            This function is considered **experimental**, so beware that it is subject to changes\n            even in patch releases.\n        \"\"\"\n        return True"}, {"id": "_pytest.reports.BaseReport.head_line", "kind": "function", "range": [143, 4, 163, 25, 4076, 4676], "file_path": "src/_pytest/reports.py", "content": "@property\n    def head_line(self):\n        \"\"\"\n        **Experimental**\n\n        Returns the head line shown with longrepr output for this report, more commonly during\n        traceback representation during failures::\n\n            ________ Test.foo ________\n\n\n        In the example above, the head_line is \"Test.foo\".\n\n        .. note::\n\n            This function is considered **experimental**, so beware that it is subject to changes\n            even in patch releases.\n        \"\"\"\n        if self.location is not None:\n            fspath, lineno, domain = self.location\n            return domain"}, {"id": "_pytest.reports.BaseReport._get_verbose_word", "kind": "function", "range": [165, 4, 169, 22, 4682, 4865], "file_path": "src/_pytest/reports.py", "content": "def _get_verbose_word(self, config):\n        _category, _short, verbose = config.hook.pytest_report_teststatus(\n            report=self, config=config\n        )\n        return verbose"}, {"id": "_pytest.reports.BaseReport._to_json", "kind": "function", "range": [171, 4, 180, 36, 4871, 5174], "file_path": "src/_pytest/reports.py", "content": "def _to_json(self):\n        \"\"\"\n        This was originally the serialize_report() function from xdist (ca03269).\n\n        Returns the contents of this report as a dict of builtin entries, suitable for\n        serialization.\n\n        Experimental method.\n        \"\"\"\n        return _report_to_json(self)"}, {"id": "_pytest.reports.BaseReport._from_json", "kind": "function", "range": [182, 4, 193, 28, 5180, 5629], "file_path": "src/_pytest/reports.py", "content": "@classmethod\n    def _from_json(cls, reportdict):\n        \"\"\"\n        This was originally the serialize_report() function from xdist (ca03269).\n\n        Factory method that returns either a TestReport or CollectReport, depending on the calling\n        class. It's the callers responsibility to know which class to pass here.\n\n        Experimental method.\n        \"\"\"\n        kwargs = _report_kwargs_from_json(reportdict)\n        return cls(**kwargs)"}, {"id": "_pytest.reports._report_unserialization_failure", "kind": "function", "range": [196, 0, 205, 41, 5632, 6151], "file_path": "src/_pytest/reports.py", "content": "def _report_unserialization_failure(type_name, report_class, reportdict):\n    url = \"https://github.com/pytest-dev/pytest/issues\"\n    stream = StringIO()\n    pprint(\"-\" * 100, stream=stream)\n    pprint(\"INTERNALERROR: Unknown entry type returned: %s\" % type_name, stream=stream)\n    pprint(\"report_name: %s\" % report_class, stream=stream)\n    pprint(reportdict, stream=stream)\n    pprint(\"Please report this bug at %s\" % url, stream=stream)\n    pprint(\"-\" * 100, stream=stream)\n    raise RuntimeError(stream.getvalue())"}, {"id": "_pytest.reports.TestReport", "kind": "class", "range": [208, 0, 310, 9, 6154, 9677], "file_path": "src/_pytest/reports.py", "content": "class TestReport(BaseReport):\n    \"\"\" Basic test report object (also used for setup and teardown calls if\n    they fail).\n    \"\"\"\n\n    __test__ = False\n\n    def __init__(\n        self,\n        nodeid,\n        location: Tuple[str, Optional[int], str],\n        keywords,\n        outcome,\n        longrepr,\n        when,\n        sections=(),\n        duration=0,\n        user_properties=None,\n        **extra\n    ) -> None:\n        #: normalized collection node id\n        self.nodeid = nodeid\n\n        #: a (filesystempath, lineno, domaininfo) tuple indicating the\n        #: actual location of a test item - it might be different from the\n        #: collected one e.g. if a method is inherited from a different module.\n        self.location = location  # type: Tuple[str, Optional[int], str]\n\n        #: a name -> value dictionary containing all keywords and\n        #: markers associated with a test invocation.\n        self.keywords = keywords\n\n        #: test outcome, always one of \"passed\", \"failed\", \"skipped\".\n        self.outcome = outcome\n\n        #: None or a failure representation.\n        self.longrepr = longrepr\n\n        #: one of 'setup', 'call', 'teardown' to indicate runtest phase.\n        self.when = when\n\n        #: user properties is a list of tuples (name, value) that holds user\n        #: defined properties of the test\n        self.user_properties = list(user_properties or [])\n\n        #: list of pairs ``(str, str)`` of extra information which needs to\n        #: marshallable. Used by pytest to add captured text\n        #: from ``stdout`` and ``stderr``, but may be used by other plugins\n        #: to add arbitrary information to reports.\n        self.sections = list(sections)\n\n        #: time it took to run just the test\n        self.duration = duration\n\n        self.__dict__.update(extra)\n\n    def __repr__(self):\n        return \"<{} {!r} when={!r} outcome={!r}>\".format(\n            self.__class__.__name__, self.nodeid, self.when, self.outcome\n        )\n\n    @classmethod\n    def from_item_and_call(cls, item, call) -> \"TestReport\":\n        \"\"\"\n        Factory method to create and fill a TestReport with standard item and call info.\n        \"\"\"\n        when = call.when\n        duration = call.duration\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome = \"passed\"\n            longrepr = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif excinfo.errisinstance(skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((\"Captured {} {}\".format(key, rwhen), content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n            duration,\n            user_properties=item.user_properties,\n        )"}, {"id": "_pytest.reports.TestReport.__test__", "kind": "variable", "range": [213, 4, 213, 20, 6289, 6305], "file_path": "src/_pytest/reports.py", "content": "__test__ = False"}, {"id": "_pytest.reports.TestReport.__init__", "kind": "function", "range": [215, 4, 262, 35, 6311, 7977], "file_path": "src/_pytest/reports.py", "content": "def __init__(\n        self,\n        nodeid,\n        location: Tuple[str, Optional[int], str],\n        keywords,\n        outcome,\n        longrepr,\n        when,\n        sections=(),\n        duration=0,\n        user_properties=None,\n        **extra\n    ) -> None:\n        #: normalized collection node id\n        self.nodeid = nodeid\n\n        #: a (filesystempath, lineno, domaininfo) tuple indicating the\n        #: actual location of a test item - it might be different from the\n        #: collected one e.g. if a method is inherited from a different module.\n        self.location = location  # type: Tuple[str, Optional[int], str]\n\n        #: a name -> value dictionary containing all keywords and\n        #: markers associated with a test invocation.\n        self.keywords = keywords\n\n        #: test outcome, always one of \"passed\", \"failed\", \"skipped\".\n        self.outcome = outcome\n\n        #: None or a failure representation.\n        self.longrepr = longrepr\n\n        #: one of 'setup', 'call', 'teardown' to indicate runtest phase.\n        self.when = when\n\n        #: user properties is a list of tuples (name, value) that holds user\n        #: defined properties of the test\n        self.user_properties = list(user_properties or [])\n\n        #: list of pairs ``(str, str)`` of extra information which needs to\n        #: marshallable. Used by pytest to add captured text\n        #: from ``stdout`` and ``stderr``, but may be used by other plugins\n        #: to add arbitrary information to reports.\n        self.sections = list(sections)\n\n        #: time it took to run just the test\n        self.duration = duration\n\n        self.__dict__.update(extra)"}, {"id": "_pytest.reports.TestReport.__repr__", "kind": "function", "range": [264, 4, 267, 9, 7983, 8144], "file_path": "src/_pytest/reports.py", "content": "def __repr__(self):\n        return \"<{} {!r} when={!r} outcome={!r}>\".format(\n            self.__class__.__name__, self.nodeid, self.when, self.outcome\n        )"}, {"id": "_pytest.reports.TestReport.from_item_and_call", "kind": "function", "range": [269, 4, 310, 9, 8150, 9677], "file_path": "src/_pytest/reports.py", "content": "@classmethod\n    def from_item_and_call(cls, item, call) -> \"TestReport\":\n        \"\"\"\n        Factory method to create and fill a TestReport with standard item and call info.\n        \"\"\"\n        when = call.when\n        duration = call.duration\n        keywords = {x: 1 for x in item.keywords}\n        excinfo = call.excinfo\n        sections = []\n        if not call.excinfo:\n            outcome = \"passed\"\n            longrepr = None\n        else:\n            if not isinstance(excinfo, ExceptionInfo):\n                outcome = \"failed\"\n                longrepr = excinfo\n            elif excinfo.errisinstance(skip.Exception):\n                outcome = \"skipped\"\n                r = excinfo._getreprcrash()\n                longrepr = (str(r.path), r.lineno, r.message)\n            else:\n                outcome = \"failed\"\n                if call.when == \"call\":\n                    longrepr = item.repr_failure(excinfo)\n                else:  # exception in setup or teardown\n                    longrepr = item._repr_failure_py(\n                        excinfo, style=item.config.getoption(\"tbstyle\", \"auto\")\n                    )\n        for rwhen, key, content in item._report_sections:\n            sections.append((\"Captured {} {}\".format(key, rwhen), content))\n        return cls(\n            item.nodeid,\n            item.location,\n            keywords,\n            outcome,\n            longrepr,\n            when,\n            sections,\n            duration,\n            user_properties=item.user_properties,\n        )"}, {"id": "_pytest.reports.CollectReport", "kind": "class", "range": [313, 0, 333, 9, 9680, 10307], "file_path": "src/_pytest/reports.py", "content": "class CollectReport(BaseReport):\n    when = \"collect\"\n\n    def __init__(\n        self, nodeid: str, outcome, longrepr, result: List[Node], sections=(), **extra\n    ) -> None:\n        self.nodeid = nodeid\n        self.outcome = outcome\n        self.longrepr = longrepr\n        self.result = result or []\n        self.sections = list(sections)\n        self.__dict__.update(extra)\n\n    @property\n    def location(self):\n        return (self.fspath, None, self.fspath)\n\n    def __repr__(self):\n        return \"<CollectReport {!r} lenresult={} outcome={!r}>\".format(\n            self.nodeid, len(self.result), self.outcome\n        )"}, {"id": "_pytest.reports.CollectReport.when", "kind": "variable", "range": [314, 4, 314, 20, 9717, 9733], "file_path": "src/_pytest/reports.py", "content": "when = \"collect\""}, {"id": "_pytest.reports.CollectReport.__init__", "kind": "function", "range": [316, 4, 324, 35, 9739, 10057], "file_path": "src/_pytest/reports.py", "content": "def __init__(\n        self, nodeid: str, outcome, longrepr, result: List[Node], sections=(), **extra\n    ) -> None:\n        self.nodeid = nodeid\n        self.outcome = outcome\n        self.longrepr = longrepr\n        self.result = result or []\n        self.sections = list(sections)\n        self.__dict__.update(extra)"}, {"id": "_pytest.reports.CollectReport.location", "kind": "function", "range": [326, 4, 328, 47, 10063, 10144], "file_path": "src/_pytest/reports.py", "content": "@property\n    def location(self):\n        return (self.fspath, None, self.fspath)"}, {"id": "_pytest.reports.CollectReport.__repr__", "kind": "function", "range": [330, 4, 333, 9, 10150, 10307], "file_path": "src/_pytest/reports.py", "content": "def __repr__(self):\n        return \"<CollectReport {!r} lenresult={} outcome={!r}>\".format(\n            self.nodeid, len(self.result), self.outcome\n        )"}, {"id": "_pytest.reports.CollectErrorRepr", "kind": "class", "range": [336, 0, 341, 41, 10310, 10486], "file_path": "src/_pytest/reports.py", "content": "class CollectErrorRepr(TerminalRepr):\n    def __init__(self, msg):\n        self.longrepr = msg\n\n    def toterminal(self, out) -> None:\n        out.line(self.longrepr, red=True)"}, {"id": "_pytest.reports.CollectErrorRepr.__init__", "kind": "function", "range": [337, 4, 338, 27, 10352, 10404], "file_path": "src/_pytest/reports.py", "content": "def __init__(self, msg):\n        self.longrepr = msg"}, {"id": "_pytest.reports.CollectErrorRepr.toterminal", "kind": "function", "range": [340, 4, 341, 41, 10410, 10486], "file_path": "src/_pytest/reports.py", "content": "def toterminal(self, out) -> None:\n        out.line(self.longrepr, red=True)"}, {"id": "_pytest.reports.pytest_report_to_serializable", "kind": "function", "range": [344, 0, 348, 19, 10489, 10697], "file_path": "src/_pytest/reports.py", "content": "def pytest_report_to_serializable(report):\n    if isinstance(report, (TestReport, CollectReport)):\n        data = report._to_json()\n        data[\"$report_type\"] = report.__class__.__name__\n        return data"}, {"id": "_pytest.reports.pytest_report_from_serializable", "kind": "function", "range": [351, 0, 359, 9, 10700, 11089], "file_path": "src/_pytest/reports.py", "content": "def pytest_report_from_serializable(data):\n    if \"$report_type\" in data:\n        if data[\"$report_type\"] == \"TestReport\":\n            return TestReport._from_json(data)\n        elif data[\"$report_type\"] == \"CollectReport\":\n            return CollectReport._from_json(data)\n        assert False, \"Unknown report_type unserialize data: {}\".format(\n            data[\"$report_type\"]\n        )"}, {"id": "_pytest.reports._report_to_json", "kind": "function", "range": [362, 0, 425, 12, 11092, 13372], "file_path": "src/_pytest/reports.py", "content": "def _report_to_json(report):\n    \"\"\"\n    This was originally the serialize_report() function from xdist (ca03269).\n\n    Returns the contents of this report as a dict of builtin entries, suitable for\n    serialization.\n    \"\"\"\n\n    def serialize_repr_entry(entry):\n        entry_data = {\"type\": type(entry).__name__, \"data\": attr.asdict(entry)}\n        for key, value in entry_data[\"data\"].items():\n            if hasattr(value, \"__dict__\"):\n                entry_data[\"data\"][key] = attr.asdict(value)\n        return entry_data\n\n    def serialize_repr_traceback(reprtraceback: ReprTraceback):\n        result = attr.asdict(reprtraceback)\n        result[\"reprentries\"] = [\n            serialize_repr_entry(x) for x in reprtraceback.reprentries\n        ]\n        return result\n\n    def serialize_repr_crash(reprcrash: Optional[ReprFileLocation]):\n        if reprcrash is not None:\n            return attr.asdict(reprcrash)\n        else:\n            return None\n\n    def serialize_longrepr(rep):\n        result = {\n            \"reprcrash\": serialize_repr_crash(rep.longrepr.reprcrash),\n            \"reprtraceback\": serialize_repr_traceback(rep.longrepr.reprtraceback),\n            \"sections\": rep.longrepr.sections,\n        }\n        if isinstance(rep.longrepr, ExceptionChainRepr):\n            result[\"chain\"] = []\n            for repr_traceback, repr_crash, description in rep.longrepr.chain:\n                result[\"chain\"].append(\n                    (\n                        serialize_repr_traceback(repr_traceback),\n                        serialize_repr_crash(repr_crash),\n                        description,\n                    )\n                )\n        else:\n            result[\"chain\"] = None\n        return result\n\n    d = report.__dict__.copy()\n    if hasattr(report.longrepr, \"toterminal\"):\n        if hasattr(report.longrepr, \"reprtraceback\") and hasattr(\n            report.longrepr, \"reprcrash\"\n        ):\n            d[\"longrepr\"] = serialize_longrepr(report)\n        else:\n            d[\"longrepr\"] = str(report.longrepr)\n    else:\n        d[\"longrepr\"] = report.longrepr\n    for name in d:\n        if isinstance(d[name], (py.path.local, Path)):\n            d[name] = str(d[name])\n        elif name == \"result\":\n            d[name] = None  # for now\n    return d"}, {"id": "_pytest.reports._report_kwargs_from_json", "kind": "function", "range": [428, 0, 506, 21, 13375, 16342], "file_path": "src/_pytest/reports.py", "content": "def _report_kwargs_from_json(reportdict):\n    \"\"\"\n    This was originally the serialize_report() function from xdist (ca03269).\n\n    Returns **kwargs that can be used to construct a TestReport or CollectReport instance.\n    \"\"\"\n\n    def deserialize_repr_entry(entry_data):\n        data = entry_data[\"data\"]\n        entry_type = entry_data[\"type\"]\n        if entry_type == \"ReprEntry\":\n            reprfuncargs = None\n            reprfileloc = None\n            reprlocals = None\n            if data[\"reprfuncargs\"]:\n                reprfuncargs = ReprFuncArgs(**data[\"reprfuncargs\"])\n            if data[\"reprfileloc\"]:\n                reprfileloc = ReprFileLocation(**data[\"reprfileloc\"])\n            if data[\"reprlocals\"]:\n                reprlocals = ReprLocals(data[\"reprlocals\"][\"lines\"])\n\n            reprentry = ReprEntry(\n                lines=data[\"lines\"],\n                reprfuncargs=reprfuncargs,\n                reprlocals=reprlocals,\n                reprfileloc=reprfileloc,\n                style=data[\"style\"],\n            )  # type: Union[ReprEntry, ReprEntryNative]\n        elif entry_type == \"ReprEntryNative\":\n            reprentry = ReprEntryNative(data[\"lines\"])\n        else:\n            _report_unserialization_failure(entry_type, TestReport, reportdict)\n        return reprentry\n\n    def deserialize_repr_traceback(repr_traceback_dict):\n        repr_traceback_dict[\"reprentries\"] = [\n            deserialize_repr_entry(x) for x in repr_traceback_dict[\"reprentries\"]\n        ]\n        return ReprTraceback(**repr_traceback_dict)\n\n    def deserialize_repr_crash(repr_crash_dict: Optional[dict]):\n        if repr_crash_dict is not None:\n            return ReprFileLocation(**repr_crash_dict)\n        else:\n            return None\n\n    if (\n        reportdict[\"longrepr\"]\n        and \"reprcrash\" in reportdict[\"longrepr\"]\n        and \"reprtraceback\" in reportdict[\"longrepr\"]\n    ):\n\n        reprtraceback = deserialize_repr_traceback(\n            reportdict[\"longrepr\"][\"reprtraceback\"]\n        )\n        reprcrash = deserialize_repr_crash(reportdict[\"longrepr\"][\"reprcrash\"])\n        if reportdict[\"longrepr\"][\"chain\"]:\n            chain = []\n            for repr_traceback_data, repr_crash_data, description in reportdict[\n                \"longrepr\"\n            ][\"chain\"]:\n                chain.append(\n                    (\n                        deserialize_repr_traceback(repr_traceback_data),\n                        deserialize_repr_crash(repr_crash_data),\n                        description,\n                    )\n                )\n            exception_info = ExceptionChainRepr(\n                chain\n            )  # type: Union[ExceptionChainRepr,ReprExceptionInfo]\n        else:\n            exception_info = ReprExceptionInfo(reprtraceback, reprcrash)\n\n        for section in reportdict[\"longrepr\"][\"sections\"]:\n            exception_info.addsection(*section)\n        reportdict[\"longrepr\"] = exception_info\n\n    return reportdict"}, {"id": "_pytest.doctest.DOCTEST_REPORT_CHOICE_NONE", "kind": "variable", "range": [34, 0, 34, 35, 898, 933], "file_path": "src/_pytest/doctest.py", "content": "DOCTEST_REPORT_CHOICE_NONE = \"none\""}, {"id": "_pytest.doctest.DOCTEST_REPORT_CHOICE_CDIFF", "kind": "variable", "range": [35, 0, 35, 37, 934, 971], "file_path": "src/_pytest/doctest.py", "content": "DOCTEST_REPORT_CHOICE_CDIFF = \"cdiff\""}, {"id": "_pytest.doctest.DOCTEST_REPORT_CHOICE_NDIFF", "kind": "variable", "range": [36, 0, 36, 37, 972, 1009], "file_path": "src/_pytest/doctest.py", "content": "DOCTEST_REPORT_CHOICE_NDIFF = \"ndiff\""}, {"id": "_pytest.doctest.DOCTEST_REPORT_CHOICE_UDIFF", "kind": "variable", "range": [37, 0, 37, 37, 1010, 1047], "file_path": "src/_pytest/doctest.py", "content": "DOCTEST_REPORT_CHOICE_UDIFF = \"udiff\""}, {"id": "_pytest.doctest.DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE", "kind": "variable", "range": [38, 0, 38, 63, 1048, 1111], "file_path": "src/_pytest/doctest.py", "content": "DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE = \"only_first_failure\""}, {"id": "_pytest.doctest.DOCTEST_REPORT_CHOICES", "kind": "variable", "range": [40, 0, 46, 1, 1113, 1318], "file_path": "src/_pytest/doctest.py", "content": "DOCTEST_REPORT_CHOICES = (\n    DOCTEST_REPORT_CHOICE_NONE,\n    DOCTEST_REPORT_CHOICE_CDIFF,\n    DOCTEST_REPORT_CHOICE_NDIFF,\n    DOCTEST_REPORT_CHOICE_UDIFF,\n    DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE,\n)"}, {"id": "_pytest.doctest.RUNNER_CLASS", "kind": "variable", "range": [49, 0, 49, 19, 1354, 1373], "file_path": "src/_pytest/doctest.py", "content": "RUNNER_CLASS = None"}, {"id": "_pytest.doctest.CHECKER_CLASS", "kind": "variable", "range": [51, 0, 51, 20, 1416, 1436], "file_path": "src/_pytest/doctest.py", "content": "CHECKER_CLASS = None"}, {"id": "_pytest.doctest.pytest_addoption", "kind": "function", "range": [54, 0, 101, 5, 1486, 2904], "file_path": "src/_pytest/doctest.py", "content": "def pytest_addoption(parser):\n    parser.addini(\n        \"doctest_optionflags\",\n        \"option flags for doctests\",\n        type=\"args\",\n        default=[\"ELLIPSIS\"],\n    )\n    parser.addini(\n        \"doctest_encoding\", \"encoding used for doctest files\", default=\"utf-8\"\n    )\n    group = parser.getgroup(\"collect\")\n    group.addoption(\n        \"--doctest-modules\",\n        action=\"store_true\",\n        default=False,\n        help=\"run doctests in all .py modules\",\n        dest=\"doctestmodules\",\n    )\n    group.addoption(\n        \"--doctest-report\",\n        type=str.lower,\n        default=\"udiff\",\n        help=\"choose another output format for diffs on doctest failure\",\n        choices=DOCTEST_REPORT_CHOICES,\n        dest=\"doctestreport\",\n    )\n    group.addoption(\n        \"--doctest-glob\",\n        action=\"append\",\n        default=[],\n        metavar=\"pat\",\n        help=\"doctests file matching pattern, default: test*.txt\",\n        dest=\"doctestglob\",\n    )\n    group.addoption(\n        \"--doctest-ignore-import-errors\",\n        action=\"store_true\",\n        default=False,\n        help=\"ignore doctest ImportErrors\",\n        dest=\"doctest_ignore_import_errors\",\n    )\n    group.addoption(\n        \"--doctest-continue-on-failure\",\n        action=\"store_true\",\n        default=False,\n        help=\"for a given doctest, continue to run after the first failure\",\n        dest=\"doctest_continue_on_failure\",\n    )"}, {"id": "_pytest.doctest.pytest_unconfigure", "kind": "function", "range": [104, 0, 107, 23, 2907, 2981], "file_path": "src/_pytest/doctest.py", "content": "def pytest_unconfigure():\n    global RUNNER_CLASS\n\n    RUNNER_CLASS = None"}, {"id": "_pytest.doctest.pytest_collect_file", "kind": "function", "range": [110, 0, 116, 63, 2984, 3333], "file_path": "src/_pytest/doctest.py", "content": "def pytest_collect_file(path, parent):\n    config = parent.config\n    if path.ext == \".py\":\n        if config.option.doctestmodules and not _is_setup_py(config, path, parent):\n            return DoctestModule.from_parent(parent, fspath=path)\n    elif _is_doctest(config, path, parent):\n        return DoctestTextfile.from_parent(parent, fspath=path)"}, {"id": "_pytest.doctest._is_setup_py", "kind": "function", "range": [119, 0, 123, 62, 3336, 3522], "file_path": "src/_pytest/doctest.py", "content": "def _is_setup_py(config, path, parent):\n    if path.basename != \"setup.py\":\n        return False\n    contents = path.read()\n    return \"setuptools\" in contents or \"distutils\" in contents"}, {"id": "_pytest.doctest._is_doctest", "kind": "function", "range": [126, 0, 133, 16, 3525, 3818], "file_path": "src/_pytest/doctest.py", "content": "def _is_doctest(config, path, parent):\n    if path.ext in (\".txt\", \".rst\") and parent.session.isinitpath(path):\n        return True\n    globs = config.getoption(\"doctestglob\") or [\"test*.txt\"]\n    for glob in globs:\n        if path.check(fnmatch=glob):\n            return True\n    return False"}, {"id": "_pytest.doctest.ReprFailDoctest", "kind": "class", "range": [136, 0, 146, 39, 3821, 4234], "file_path": "src/_pytest/doctest.py", "content": "class ReprFailDoctest(TerminalRepr):\n    def __init__(\n        self, reprlocation_lines: Sequence[Tuple[ReprFileLocation, Sequence[str]]]\n    ):\n        self.reprlocation_lines = reprlocation_lines\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        for reprlocation, lines in self.reprlocation_lines:\n            for line in lines:\n                tw.line(line)\n            reprlocation.toterminal(tw)"}, {"id": "_pytest.doctest.ReprFailDoctest.__init__", "kind": "function", "range": [137, 4, 140, 52, 3862, 4018], "file_path": "src/_pytest/doctest.py", "content": "def __init__(\n        self, reprlocation_lines: Sequence[Tuple[ReprFileLocation, Sequence[str]]]\n    ):\n        self.reprlocation_lines = reprlocation_lines"}, {"id": "_pytest.doctest.ReprFailDoctest.toterminal", "kind": "function", "range": [142, 4, 146, 39, 4024, 4234], "file_path": "src/_pytest/doctest.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        for reprlocation, lines in self.reprlocation_lines:\n            for line in lines:\n                tw.line(line)\n            reprlocation.toterminal(tw)"}, {"id": "_pytest.doctest.MultipleDoctestFailures", "kind": "class", "range": [149, 0, 152, 32, 4237, 4372], "file_path": "src/_pytest/doctest.py", "content": "class MultipleDoctestFailures(Exception):\n    def __init__(self, failures):\n        super().__init__()\n        self.failures = failures"}, {"id": "_pytest.doctest.MultipleDoctestFailures.__init__", "kind": "function", "range": [150, 4, 152, 32, 4283, 4372], "file_path": "src/_pytest/doctest.py", "content": "def __init__(self, failures):\n        super().__init__()\n        self.failures = failures"}, {"id": "_pytest.doctest._init_runner_class", "kind": "function", "range": [155, 0, 190, 30, 4375, 5727], "file_path": "src/_pytest/doctest.py", "content": "def _init_runner_class() -> \"Type[doctest.DocTestRunner]\":\n    import doctest\n\n    class PytestDoctestRunner(doctest.DebugRunner):\n        \"\"\"\n        Runner to collect failures.  Note that the out variable in this case is\n        a list instead of a stdout-like object\n        \"\"\"\n\n        def __init__(\n            self, checker=None, verbose=None, optionflags=0, continue_on_failure=True\n        ):\n            doctest.DebugRunner.__init__(\n                self, checker=checker, verbose=verbose, optionflags=optionflags\n            )\n            self.continue_on_failure = continue_on_failure\n\n        def report_failure(self, out, test, example, got):\n            failure = doctest.DocTestFailure(test, example, got)\n            if self.continue_on_failure:\n                out.append(failure)\n            else:\n                raise failure\n\n        def report_unexpected_exception(self, out, test, example, exc_info):\n            if isinstance(exc_info[1], OutcomeException):\n                raise exc_info[1]\n            if isinstance(exc_info[1], bdb.BdbQuit):\n                outcomes.exit(\"Quitting debugger\")\n            failure = doctest.UnexpectedException(test, example, exc_info)\n            if self.continue_on_failure:\n                out.append(failure)\n            else:\n                raise failure\n\n    return PytestDoctestRunner"}, {"id": "_pytest.doctest._get_runner", "kind": "function", "range": [193, 0, 210, 5, 5730, 6424], "file_path": "src/_pytest/doctest.py", "content": "def _get_runner(\n    checker: Optional[\"doctest.OutputChecker\"] = None,\n    verbose: Optional[bool] = None,\n    optionflags: int = 0,\n    continue_on_failure: bool = True,\n) -> \"doctest.DocTestRunner\":\n    # We need this in order to do a lazy import on doctest\n    global RUNNER_CLASS\n    if RUNNER_CLASS is None:\n        RUNNER_CLASS = _init_runner_class()\n    # Type ignored because the continue_on_failure argument is only defined on\n    # PytestDoctestRunner, which is lazily defined so can't be used as a type.\n    return RUNNER_CLASS(  # type: ignore\n        checker=checker,\n        verbose=verbose,\n        optionflags=optionflags,\n        continue_on_failure=continue_on_failure,\n    )"}, {"id": "_pytest.doctest.DoctestItem", "kind": "class", "range": [213, 0, 325, 73, 6427, 11176], "file_path": "src/_pytest/doctest.py", "content": "class DoctestItem(pytest.Item):\n    def __init__(self, name, parent, runner=None, dtest=None):\n        super().__init__(name, parent)\n        self.runner = runner\n        self.dtest = dtest\n        self.obj = None\n        self.fixture_request = None\n\n    @classmethod\n    def from_parent(  # type: ignore\n        cls, parent: \"Union[DoctestTextfile, DoctestModule]\", *, name, runner, dtest\n    ):\n        # incompatible signature due to to imposed limits on sublcass\n        \"\"\"\n        the public named constructor\n        \"\"\"\n        return super().from_parent(name=name, parent=parent, runner=runner, dtest=dtest)\n\n    def setup(self):\n        if self.dtest is not None:\n            self.fixture_request = _setup_fixtures(self)\n            globs = dict(getfixture=self.fixture_request.getfixturevalue)\n            for name, value in self.fixture_request.getfixturevalue(\n                \"doctest_namespace\"\n            ).items():\n                globs[name] = value\n            self.dtest.globs.update(globs)\n\n    def runtest(self) -> None:\n        _check_all_skipped(self.dtest)\n        self._disable_output_capturing_for_darwin()\n        failures = []  # type: List[doctest.DocTestFailure]\n        self.runner.run(self.dtest, out=failures)\n        if failures:\n            raise MultipleDoctestFailures(failures)\n\n    def _disable_output_capturing_for_darwin(self):\n        \"\"\"\n        Disable output capturing. Otherwise, stdout is lost to doctest (#985)\n        \"\"\"\n        if platform.system() != \"Darwin\":\n            return\n        capman = self.config.pluginmanager.getplugin(\"capturemanager\")\n        if capman:\n            capman.suspend_global_capture(in_=True)\n            out, err = capman.read_global_capture()\n            sys.stdout.write(out)\n            sys.stderr.write(err)\n\n    def repr_failure(self, excinfo):\n        import doctest\n\n        failures = (\n            None\n        )  # type: Optional[List[Union[doctest.DocTestFailure, doctest.UnexpectedException]]]\n        if excinfo.errisinstance((doctest.DocTestFailure, doctest.UnexpectedException)):\n            failures = [excinfo.value]\n        elif excinfo.errisinstance(MultipleDoctestFailures):\n            failures = excinfo.value.failures\n\n        if failures is not None:\n            reprlocation_lines = []\n            for failure in failures:\n                example = failure.example\n                test = failure.test\n                filename = test.filename\n                if test.lineno is None:\n                    lineno = None\n                else:\n                    lineno = test.lineno + example.lineno + 1\n                message = type(failure).__name__\n                reprlocation = ReprFileLocation(filename, lineno, message)\n                checker = _get_checker()\n                report_choice = _get_report_choice(\n                    self.config.getoption(\"doctestreport\")\n                )\n                if lineno is not None:\n                    assert failure.test.docstring is not None\n                    lines = failure.test.docstring.splitlines(False)\n                    # add line numbers to the left of the error message\n                    assert test.lineno is not None\n                    lines = [\n                        \"%03d %s\" % (i + test.lineno + 1, x)\n                        for (i, x) in enumerate(lines)\n                    ]\n                    # trim docstring error lines to 10\n                    lines = lines[max(example.lineno - 9, 0) : example.lineno + 1]\n                else:\n                    lines = [\n                        \"EXAMPLE LOCATION UNKNOWN, not showing all tests of that example\"\n                    ]\n                    indent = \">>>\"\n                    for line in example.source.splitlines():\n                        lines.append(\"??? {} {}\".format(indent, line))\n                        indent = \"...\"\n                if isinstance(failure, doctest.DocTestFailure):\n                    lines += checker.output_difference(\n                        example, failure.got, report_choice\n                    ).split(\"\\n\")\n                else:\n                    inner_excinfo = ExceptionInfo(failure.exc_info)\n                    lines += [\"UNEXPECTED EXCEPTION: %s\" % repr(inner_excinfo.value)]\n                    lines += [\n                        x.strip(\"\\n\")\n                        for x in traceback.format_exception(*failure.exc_info)\n                    ]\n                reprlocation_lines.append((reprlocation, lines))\n            return ReprFailDoctest(reprlocation_lines)\n        else:\n            return super().repr_failure(excinfo)\n\n    def reportinfo(self) -> Tuple[py.path.local, int, str]:\n        return self.fspath, self.dtest.lineno, \"[doctest] %s\" % self.name"}, {"id": "_pytest.doctest.DoctestItem.__init__", "kind": "function", "range": [214, 4, 219, 35, 6463, 6676], "file_path": "src/_pytest/doctest.py", "content": "def __init__(self, name, parent, runner=None, dtest=None):\n        super().__init__(name, parent)\n        self.runner = runner\n        self.dtest = dtest\n        self.obj = None\n        self.fixture_request = None"}, {"id": "_pytest.doctest.DoctestItem.from_parent", "kind": "function", "range": [221, 4, 229, 88, 6682, 7043], "file_path": "src/_pytest/doctest.py", "content": "@classmethod\n    def from_parent(  # type: ignore\n        cls, parent: \"Union[DoctestTextfile, DoctestModule]\", *, name, runner, dtest\n    ):\n        # incompatible signature due to to imposed limits on sublcass\n        \"\"\"\n        the public named constructor\n        \"\"\"\n        return super().from_parent(name=name, parent=parent, runner=runner, dtest=dtest)"}, {"id": "_pytest.doctest.DoctestItem.setup", "kind": "function", "range": [231, 4, 239, 42, 7049, 7438], "file_path": "src/_pytest/doctest.py", "content": "def setup(self):\n        if self.dtest is not None:\n            self.fixture_request = _setup_fixtures(self)\n            globs = dict(getfixture=self.fixture_request.getfixturevalue)\n            for name, value in self.fixture_request.getfixturevalue(\n                \"doctest_namespace\"\n            ).items():\n                globs[name] = value\n            self.dtest.globs.update(globs)"}, {"id": "_pytest.doctest.DoctestItem.runtest", "kind": "function", "range": [241, 4, 247, 51, 7444, 7744], "file_path": "src/_pytest/doctest.py", "content": "def runtest(self) -> None:\n        _check_all_skipped(self.dtest)\n        self._disable_output_capturing_for_darwin()\n        failures = []  # type: List[doctest.DocTestFailure]\n        self.runner.run(self.dtest, out=failures)\n        if failures:\n            raise MultipleDoctestFailures(failures)"}, {"id": "_pytest.doctest.DoctestItem._disable_output_capturing_for_darwin", "kind": "function", "range": [249, 4, 260, 33, 7750, 8222], "file_path": "src/_pytest/doctest.py", "content": "def _disable_output_capturing_for_darwin(self):\n        \"\"\"\n        Disable output capturing. Otherwise, stdout is lost to doctest (#985)\n        \"\"\"\n        if platform.system() != \"Darwin\":\n            return\n        capman = self.config.pluginmanager.getplugin(\"capturemanager\")\n        if capman:\n            capman.suspend_global_capture(in_=True)\n            out, err = capman.read_global_capture()\n            sys.stdout.write(out)\n            sys.stderr.write(err)"}, {"id": "_pytest.doctest.DoctestItem.repr_failure", "kind": "function", "range": [262, 4, 322, 48, 8228, 11041], "file_path": "src/_pytest/doctest.py", "content": "def repr_failure(self, excinfo):\n        import doctest\n\n        failures = (\n            None\n        )  # type: Optional[List[Union[doctest.DocTestFailure, doctest.UnexpectedException]]]\n        if excinfo.errisinstance((doctest.DocTestFailure, doctest.UnexpectedException)):\n            failures = [excinfo.value]\n        elif excinfo.errisinstance(MultipleDoctestFailures):\n            failures = excinfo.value.failures\n\n        if failures is not None:\n            reprlocation_lines = []\n            for failure in failures:\n                example = failure.example\n                test = failure.test\n                filename = test.filename\n                if test.lineno is None:\n                    lineno = None\n                else:\n                    lineno = test.lineno + example.lineno + 1\n                message = type(failure).__name__\n                reprlocation = ReprFileLocation(filename, lineno, message)\n                checker = _get_checker()\n                report_choice = _get_report_choice(\n                    self.config.getoption(\"doctestreport\")\n                )\n                if lineno is not None:\n                    assert failure.test.docstring is not None\n                    lines = failure.test.docstring.splitlines(False)\n                    # add line numbers to the left of the error message\n                    assert test.lineno is not None\n                    lines = [\n                        \"%03d %s\" % (i + test.lineno + 1, x)\n                        for (i, x) in enumerate(lines)\n                    ]\n                    # trim docstring error lines to 10\n                    lines = lines[max(example.lineno - 9, 0) : example.lineno + 1]\n                else:\n                    lines = [\n                        \"EXAMPLE LOCATION UNKNOWN, not showing all tests of that example\"\n                    ]\n                    indent = \">>>\"\n                    for line in example.source.splitlines():\n                        lines.append(\"??? {} {}\".format(indent, line))\n                        indent = \"...\"\n                if isinstance(failure, doctest.DocTestFailure):\n                    lines += checker.output_difference(\n                        example, failure.got, report_choice\n                    ).split(\"\\n\")\n                else:\n                    inner_excinfo = ExceptionInfo(failure.exc_info)\n                    lines += [\"UNEXPECTED EXCEPTION: %s\" % repr(inner_excinfo.value)]\n                    lines += [\n                        x.strip(\"\\n\")\n                        for x in traceback.format_exception(*failure.exc_info)\n                    ]\n                reprlocation_lines.append((reprlocation, lines))\n            return ReprFailDoctest(reprlocation_lines)\n        else:\n            return super().repr_failure(excinfo)"}, {"id": "_pytest.doctest.DoctestItem.reportinfo", "kind": "function", "range": [324, 4, 325, 73, 11047, 11176], "file_path": "src/_pytest/doctest.py", "content": "def reportinfo(self) -> Tuple[py.path.local, int, str]:\n        return self.fspath, self.dtest.lineno, \"[doctest] %s\" % self.name"}, {"id": "_pytest.doctest._get_flag_lookup", "kind": "function", "range": [328, 0, 341, 5, 11179, 11726], "file_path": "src/_pytest/doctest.py", "content": "def _get_flag_lookup() -> Dict[str, int]:\n    import doctest\n\n    return dict(\n        DONT_ACCEPT_TRUE_FOR_1=doctest.DONT_ACCEPT_TRUE_FOR_1,\n        DONT_ACCEPT_BLANKLINE=doctest.DONT_ACCEPT_BLANKLINE,\n        NORMALIZE_WHITESPACE=doctest.NORMALIZE_WHITESPACE,\n        ELLIPSIS=doctest.ELLIPSIS,\n        IGNORE_EXCEPTION_DETAIL=doctest.IGNORE_EXCEPTION_DETAIL,\n        COMPARISON_FLAGS=doctest.COMPARISON_FLAGS,\n        ALLOW_UNICODE=_get_allow_unicode_flag(),\n        ALLOW_BYTES=_get_allow_bytes_flag(),\n        NUMBER=_get_number_flag(),\n    )"}, {"id": "_pytest.doctest.get_optionflags", "kind": "function", "range": [344, 0, 350, 19, 11729, 11980], "file_path": "src/_pytest/doctest.py", "content": "def get_optionflags(parent):\n    optionflags_str = parent.config.getini(\"doctest_optionflags\")\n    flag_lookup_table = _get_flag_lookup()\n    flag_acc = 0\n    for flag in optionflags_str:\n        flag_acc |= flag_lookup_table[flag]\n    return flag_acc"}, {"id": "_pytest.doctest._get_continue_on_failure", "kind": "function", "range": [353, 0, 360, 30, 11983, 12331], "file_path": "src/_pytest/doctest.py", "content": "def _get_continue_on_failure(config):\n    continue_on_failure = config.getvalue(\"doctest_continue_on_failure\")\n    if continue_on_failure:\n        # We need to turn off this if we use pdb since we should stop at\n        # the first failure\n        if config.getvalue(\"usepdb\"):\n            continue_on_failure = False\n    return continue_on_failure"}, {"id": "_pytest.doctest.DoctestTextfile", "kind": "class", "range": [363, 0, 391, 13, 12334, 13296], "file_path": "src/_pytest/doctest.py", "content": "class DoctestTextfile(pytest.Module):\n    obj = None\n\n    def collect(self):\n        import doctest\n\n        # inspired by doctest.testfile; ideally we would use it directly,\n        # but it doesn't support passing a custom checker\n        encoding = self.config.getini(\"doctest_encoding\")\n        text = self.fspath.read_text(encoding)\n        filename = str(self.fspath)\n        name = self.fspath.basename\n        globs = {\"__name__\": \"__main__\"}\n\n        optionflags = get_optionflags(self)\n\n        runner = _get_runner(\n            verbose=False,\n            optionflags=optionflags,\n            checker=_get_checker(),\n            continue_on_failure=_get_continue_on_failure(self.config),\n        )\n\n        parser = doctest.DocTestParser()\n        test = parser.get_doctest(text, globs, name, filename, 0)\n        if test.examples:\n            yield DoctestItem.from_parent(\n                self, name=test.name, runner=runner, dtest=test\n            )"}, {"id": "_pytest.doctest.DoctestTextfile.obj", "kind": "variable", "range": [364, 4, 364, 14, 12376, 12386], "file_path": "src/_pytest/doctest.py", "content": "obj = None"}, {"id": "_pytest.doctest.DoctestTextfile.collect", "kind": "function", "range": [366, 4, 391, 13, 12392, 13296], "file_path": "src/_pytest/doctest.py", "content": "def collect(self):\n        import doctest\n\n        # inspired by doctest.testfile; ideally we would use it directly,\n        # but it doesn't support passing a custom checker\n        encoding = self.config.getini(\"doctest_encoding\")\n        text = self.fspath.read_text(encoding)\n        filename = str(self.fspath)\n        name = self.fspath.basename\n        globs = {\"__name__\": \"__main__\"}\n\n        optionflags = get_optionflags(self)\n\n        runner = _get_runner(\n            verbose=False,\n            optionflags=optionflags,\n            checker=_get_checker(),\n            continue_on_failure=_get_continue_on_failure(self.config),\n        )\n\n        parser = doctest.DocTestParser()\n        test = parser.get_doctest(text, globs, name, filename, 0)\n        if test.examples:\n            yield DoctestItem.from_parent(\n                self, name=test.name, runner=runner, dtest=test\n            )"}, {"id": "_pytest.doctest._check_all_skipped", "kind": "function", "range": [394, 0, 402, 56, 13299, 13609], "file_path": "src/_pytest/doctest.py", "content": "def _check_all_skipped(test):\n    \"\"\"raises pytest.skip() if all examples in the given DocTest have the SKIP\n    option set.\n    \"\"\"\n    import doctest\n\n    all_skipped = all(x.options.get(doctest.SKIP, False) for x in test.examples)\n    if all_skipped:\n        pytest.skip(\"all tests skipped by +SKIP option\")"}, {"id": "_pytest.doctest._is_mocked", "kind": "function", "range": [405, 0, 412, 5, 13612, 13881], "file_path": "src/_pytest/doctest.py", "content": "def _is_mocked(obj):\n    \"\"\"\n    returns if a object is possibly a mock object by checking the existence of a highly improbable attribute\n    \"\"\"\n    return (\n        safe_getattr(obj, \"pytest_mock_example_attribute_that_shouldnt_exist\", None)\n        is not None\n    )"}, {"id": "_pytest.doctest._patch_unwrap_mock_aware", "kind": "function", "range": [415, 0, 441, 36, 13884, 14814], "file_path": "src/_pytest/doctest.py", "content": "@contextmanager\ndef _patch_unwrap_mock_aware():\n    \"\"\"\n    contextmanager which replaces ``inspect.unwrap`` with a version\n    that's aware of mock objects and doesn't recurse on them\n    \"\"\"\n    real_unwrap = inspect.unwrap\n\n    def _mock_aware_unwrap(obj, stop=None):\n        try:\n            if stop is None or stop is _is_mocked:\n                return real_unwrap(obj, stop=_is_mocked)\n            return real_unwrap(obj, stop=lambda obj: _is_mocked(obj) or stop(obj))\n        except Exception as e:\n            warnings.warn(\n                \"Got %r when unwrapping %r.  This is usually caused \"\n                \"by a violation of Python's object protocol; see e.g. \"\n                \"https://github.com/pytest-dev/pytest/issues/5080\" % (e, obj),\n                PytestWarning,\n            )\n            raise\n\n    inspect.unwrap = _mock_aware_unwrap\n    try:\n        yield\n    finally:\n        inspect.unwrap = real_unwrap"}, {"id": "_pytest.doctest.DoctestModule", "kind": "class", "range": [444, 0, 502, 17, 14817, 17129], "file_path": "src/_pytest/doctest.py", "content": "class DoctestModule(pytest.Module):\n    def collect(self):\n        import doctest\n\n        class MockAwareDocTestFinder(doctest.DocTestFinder):\n            \"\"\"\n            a hackish doctest finder that overrides stdlib internals to fix a stdlib bug\n\n            https://github.com/pytest-dev/pytest/issues/3456\n            https://bugs.python.org/issue25532\n            \"\"\"\n\n            def _find_lineno(self, obj, source_lines):\n                \"\"\"\n                Doctest code does not take into account `@property`, this is a hackish way to fix it.\n\n                https://bugs.python.org/issue17446\n                \"\"\"\n                if isinstance(obj, property):\n                    obj = getattr(obj, \"fget\", obj)\n                return doctest.DocTestFinder._find_lineno(self, obj, source_lines)\n\n            def _find(\n                self, tests, obj, name, module, source_lines, globs, seen\n            ) -> None:\n                if _is_mocked(obj):\n                    return\n                with _patch_unwrap_mock_aware():\n\n                    # Type ignored because this is a private function.\n                    doctest.DocTestFinder._find(  # type: ignore\n                        self, tests, obj, name, module, source_lines, globs, seen\n                    )\n\n        if self.fspath.basename == \"conftest.py\":\n            module = self.config.pluginmanager._importconftest(self.fspath)\n        else:\n            try:\n                module = self.fspath.pyimport()\n            except ImportError:\n                if self.config.getvalue(\"doctest_ignore_import_errors\"):\n                    pytest.skip(\"unable to import module %r\" % self.fspath)\n                else:\n                    raise\n        # uses internal doctest module parsing mechanism\n        finder = MockAwareDocTestFinder()\n        optionflags = get_optionflags(self)\n        runner = _get_runner(\n            verbose=False,\n            optionflags=optionflags,\n            checker=_get_checker(),\n            continue_on_failure=_get_continue_on_failure(self.config),\n        )\n\n        for test in finder.find(module, module.__name__):\n            if test.examples:  # skip empty doctests\n                yield DoctestItem.from_parent(\n                    self, name=test.name, runner=runner, dtest=test\n                )"}, {"id": "_pytest.doctest.DoctestModule.collect", "kind": "function", "range": [445, 4, 502, 17, 14857, 17129], "file_path": "src/_pytest/doctest.py", "content": "def collect(self):\n        import doctest\n\n        class MockAwareDocTestFinder(doctest.DocTestFinder):\n            \"\"\"\n            a hackish doctest finder that overrides stdlib internals to fix a stdlib bug\n\n            https://github.com/pytest-dev/pytest/issues/3456\n            https://bugs.python.org/issue25532\n            \"\"\"\n\n            def _find_lineno(self, obj, source_lines):\n                \"\"\"\n                Doctest code does not take into account `@property`, this is a hackish way to fix it.\n\n                https://bugs.python.org/issue17446\n                \"\"\"\n                if isinstance(obj, property):\n                    obj = getattr(obj, \"fget\", obj)\n                return doctest.DocTestFinder._find_lineno(self, obj, source_lines)\n\n            def _find(\n                self, tests, obj, name, module, source_lines, globs, seen\n            ) -> None:\n                if _is_mocked(obj):\n                    return\n                with _patch_unwrap_mock_aware():\n\n                    # Type ignored because this is a private function.\n                    doctest.DocTestFinder._find(  # type: ignore\n                        self, tests, obj, name, module, source_lines, globs, seen\n                    )\n\n        if self.fspath.basename == \"conftest.py\":\n            module = self.config.pluginmanager._importconftest(self.fspath)\n        else:\n            try:\n                module = self.fspath.pyimport()\n            except ImportError:\n                if self.config.getvalue(\"doctest_ignore_import_errors\"):\n                    pytest.skip(\"unable to import module %r\" % self.fspath)\n                else:\n                    raise\n        # uses internal doctest module parsing mechanism\n        finder = MockAwareDocTestFinder()\n        optionflags = get_optionflags(self)\n        runner = _get_runner(\n            verbose=False,\n            optionflags=optionflags,\n            checker=_get_checker(),\n            continue_on_failure=_get_continue_on_failure(self.config),\n        )\n\n        for test in finder.find(module, module.__name__):\n            if test.examples:  # skip empty doctests\n                yield DoctestItem.from_parent(\n                    self, name=test.name, runner=runner, dtest=test\n                )"}, {"id": "_pytest.doctest._setup_fixtures", "kind": "function", "range": [505, 0, 520, 26, 17132, 17598], "file_path": "src/_pytest/doctest.py", "content": "def _setup_fixtures(doctest_item):\n    \"\"\"\n    Used by DoctestTextfile and DoctestItem to setup fixture information.\n    \"\"\"\n\n    def func():\n        pass\n\n    doctest_item.funcargs = {}\n    fm = doctest_item.session._fixturemanager\n    doctest_item._fixtureinfo = fm.getfixtureinfo(\n        node=doctest_item, func=func, cls=None, funcargs=False\n    )\n    fixture_request = FixtureRequest(doctest_item)\n    fixture_request._fillfixtures()\n    return fixture_request"}, {"id": "_pytest.doctest._init_checker_class", "kind": "function", "range": [523, 0, 613, 32, 17601, 21044], "file_path": "src/_pytest/doctest.py", "content": "def _init_checker_class() -> \"Type[doctest.OutputChecker]\":\n    import doctest\n    import re\n\n    class LiteralsOutputChecker(doctest.OutputChecker):\n        \"\"\"\n        Based on doctest_nose_plugin.py from the nltk project\n        (https://github.com/nltk/nltk) and on the \"numtest\" doctest extension\n        by Sebastien Boisgerault (https://github.com/boisgera/numtest).\n        \"\"\"\n\n        _unicode_literal_re = re.compile(r\"(\\W|^)[uU]([rR]?[\\'\\\"])\", re.UNICODE)\n        _bytes_literal_re = re.compile(r\"(\\W|^)[bB]([rR]?[\\'\\\"])\", re.UNICODE)\n        _number_re = re.compile(\n            r\"\"\"\n            (?P<number>\n              (?P<mantissa>\n                (?P<integer1> [+-]?\\d*)\\.(?P<fraction>\\d+)\n                |\n                (?P<integer2> [+-]?\\d+)\\.\n              )\n              (?:\n                [Ee]\n                (?P<exponent1> [+-]?\\d+)\n              )?\n              |\n              (?P<integer3> [+-]?\\d+)\n              (?:\n                [Ee]\n                (?P<exponent2> [+-]?\\d+)\n              )\n            )\n            \"\"\",\n            re.VERBOSE,\n        )\n\n        def check_output(self, want, got, optionflags):\n            if doctest.OutputChecker.check_output(self, want, got, optionflags):\n                return True\n\n            allow_unicode = optionflags & _get_allow_unicode_flag()\n            allow_bytes = optionflags & _get_allow_bytes_flag()\n            allow_number = optionflags & _get_number_flag()\n\n            if not allow_unicode and not allow_bytes and not allow_number:\n                return False\n\n            def remove_prefixes(regex, txt):\n                return re.sub(regex, r\"\\1\\2\", txt)\n\n            if allow_unicode:\n                want = remove_prefixes(self._unicode_literal_re, want)\n                got = remove_prefixes(self._unicode_literal_re, got)\n\n            if allow_bytes:\n                want = remove_prefixes(self._bytes_literal_re, want)\n                got = remove_prefixes(self._bytes_literal_re, got)\n\n            if allow_number:\n                got = self._remove_unwanted_precision(want, got)\n\n            return doctest.OutputChecker.check_output(self, want, got, optionflags)\n\n        def _remove_unwanted_precision(self, want, got):\n            wants = list(self._number_re.finditer(want))\n            gots = list(self._number_re.finditer(got))\n            if len(wants) != len(gots):\n                return got\n            offset = 0\n            for w, g in zip(wants, gots):\n                fraction = w.group(\"fraction\")\n                exponent = w.group(\"exponent1\")\n                if exponent is None:\n                    exponent = w.group(\"exponent2\")\n                if fraction is None:\n                    precision = 0\n                else:\n                    precision = len(fraction)\n                if exponent is not None:\n                    precision -= int(exponent)\n                if float(w.group()) == approx(float(g.group()), abs=10 ** -precision):\n                    # They're close enough. Replace the text we actually\n                    # got with the text we want, so that it will match when we\n                    # check the string literally.\n                    got = (\n                        got[: g.start() + offset] + w.group() + got[g.end() + offset :]\n                    )\n                    offset += w.end() - w.start() - (g.end() - g.start())\n            return got\n\n    return LiteralsOutputChecker"}, {"id": "_pytest.doctest._get_checker", "kind": "function", "range": [616, 0, 634, 26, 21047, 21718], "file_path": "src/_pytest/doctest.py", "content": "def _get_checker() -> \"doctest.OutputChecker\":\n    \"\"\"\n    Returns a doctest.OutputChecker subclass that supports some\n    additional options:\n\n    * ALLOW_UNICODE and ALLOW_BYTES options to ignore u'' and b''\n      prefixes (respectively) in string literals. Useful when the same\n      doctest should run in Python 2 and Python 3.\n\n    * NUMBER to ignore floating-point differences smaller than the\n      precision of the literal number in the doctest.\n\n    An inner class is used to avoid importing \"doctest\" at the module\n    level.\n    \"\"\"\n    global CHECKER_CLASS\n    if CHECKER_CLASS is None:\n        CHECKER_CLASS = _init_checker_class()\n    return CHECKER_CLASS()"}, {"id": "_pytest.doctest._get_allow_unicode_flag", "kind": "function", "range": [637, 0, 643, 55, 21721, 21900], "file_path": "src/_pytest/doctest.py", "content": "def _get_allow_unicode_flag() -> int:\n    \"\"\"\n    Registers and returns the ALLOW_UNICODE flag.\n    \"\"\"\n    import doctest\n\n    return doctest.register_optionflag(\"ALLOW_UNICODE\")"}, {"id": "_pytest.doctest._get_allow_bytes_flag", "kind": "function", "range": [646, 0, 652, 53, 21903, 22076], "file_path": "src/_pytest/doctest.py", "content": "def _get_allow_bytes_flag() -> int:\n    \"\"\"\n    Registers and returns the ALLOW_BYTES flag.\n    \"\"\"\n    import doctest\n\n    return doctest.register_optionflag(\"ALLOW_BYTES\")"}, {"id": "_pytest.doctest._get_number_flag", "kind": "function", "range": [655, 0, 661, 48, 22079, 22237], "file_path": "src/_pytest/doctest.py", "content": "def _get_number_flag() -> int:\n    \"\"\"\n    Registers and returns the NUMBER flag.\n    \"\"\"\n    import doctest\n\n    return doctest.register_optionflag(\"NUMBER\")"}, {"id": "_pytest.doctest._get_report_choice", "kind": "function", "range": [664, 0, 677, 10, 22240, 22862], "file_path": "src/_pytest/doctest.py", "content": "def _get_report_choice(key: str) -> int:\n    \"\"\"\n    This function returns the actual `doctest` module flag value, we want to do it as late as possible to avoid\n    importing `doctest` and all its dependencies when parsing options, as it adds overhead and breaks tests.\n    \"\"\"\n    import doctest\n\n    return {\n        DOCTEST_REPORT_CHOICE_UDIFF: doctest.REPORT_UDIFF,\n        DOCTEST_REPORT_CHOICE_CDIFF: doctest.REPORT_CDIFF,\n        DOCTEST_REPORT_CHOICE_NDIFF: doctest.REPORT_NDIFF,\n        DOCTEST_REPORT_CHOICE_ONLY_FIRST_FAILURE: doctest.REPORT_ONLY_FIRST_FAILURE,\n        DOCTEST_REPORT_CHOICE_NONE: 0,\n    }[key]"}, {"id": "_pytest.doctest.doctest_namespace", "kind": "function", "range": [680, 0, 685, 17, 22865, 23054], "file_path": "src/_pytest/doctest.py", "content": "@pytest.fixture(scope=\"session\")\ndef doctest_namespace():\n    \"\"\"\n    Fixture that returns a :py:class:`dict` that will be injected into the namespace of doctests.\n    \"\"\"\n    return dict()"}, {"id": "_pytest.setuponly.pytest_addoption", "kind": "function", "range": [3, 0, 16, 5, 16, 415], "file_path": "src/_pytest/setuponly.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"debugconfig\")\n    group.addoption(\n        \"--setuponly\",\n        \"--setup-only\",\n        action=\"store_true\",\n        help=\"only setup fixtures, do not execute tests.\",\n    )\n    group.addoption(\n        \"--setupshow\",\n        \"--setup-show\",\n        action=\"store_true\",\n        help=\"show setup of fixtures while executing tests.\",\n    )"}, {"id": "_pytest.setuponly.pytest_fixture_setup", "kind": "function", "range": [19, 0, 33, 49, 418, 1108], "file_path": "src/_pytest/setuponly.py", "content": "@pytest.hookimpl(hookwrapper=True)\ndef pytest_fixture_setup(fixturedef, request):\n    yield\n    if request.config.option.setupshow:\n        if hasattr(request, \"param\"):\n            # Save the fixture parameter so ._show_fixture_action() can\n            # display it now and during the teardown (in .finish()).\n            if fixturedef.ids:\n                if callable(fixturedef.ids):\n                    fixturedef.cached_param = fixturedef.ids(request.param)\n                else:\n                    fixturedef.cached_param = fixturedef.ids[request.param_index]\n            else:\n                fixturedef.cached_param = request.param\n        _show_fixture_action(fixturedef, \"SETUP\")"}, {"id": "_pytest.setuponly.pytest_fixture_post_finalizer", "kind": "function", "range": [36, 0, 42, 43, 1111, 1450], "file_path": "src/_pytest/setuponly.py", "content": "def pytest_fixture_post_finalizer(fixturedef) -> None:\n    if fixturedef.cached_result is not None:\n        config = fixturedef._fixturemanager.config\n        if config.option.setupshow:\n            _show_fixture_action(fixturedef, \"TEARDOWN\")\n            if hasattr(fixturedef, \"cached_param\"):\n                del fixturedef.cached_param"}, {"id": "_pytest.setuponly._show_fixture_action", "kind": "function", "range": [45, 0, 71, 38, 1453, 2324], "file_path": "src/_pytest/setuponly.py", "content": "def _show_fixture_action(fixturedef, msg):\n    config = fixturedef._fixturemanager.config\n    capman = config.pluginmanager.getplugin(\"capturemanager\")\n    if capman:\n        capman.suspend_global_capture()\n\n    tw = config.get_terminal_writer()\n    tw.line()\n    tw.write(\" \" * 2 * fixturedef.scopenum)\n    tw.write(\n        \"{step} {scope} {fixture}\".format(\n            step=msg.ljust(8),  # align the output to TEARDOWN\n            scope=fixturedef.scope[0].upper(),\n            fixture=fixturedef.argname,\n        )\n    )\n\n    if msg == \"SETUP\":\n        deps = sorted(arg for arg in fixturedef.argnames if arg != \"request\")\n        if deps:\n            tw.write(\" (fixtures used: {})\".format(\", \".join(deps)))\n\n    if hasattr(fixturedef, \"cached_param\"):\n        tw.write(\"[{}]\".format(fixturedef.cached_param))\n\n    if capman:\n        capman.resume_global_capture()"}, {"id": "_pytest.setuponly.pytest_cmdline_main", "kind": "function", "range": [74, 0, 77, 38, 2327, 2462], "file_path": "src/_pytest/setuponly.py", "content": "@pytest.hookimpl(tryfirst=True)\ndef pytest_cmdline_main(config):\n    if config.option.setuponly:\n        config.option.setupshow = True"}, {"id": "_pytest.nose.pytest_runtest_setup", "kind": "function", "range": [6, 0, 13, 82, 136, 548], "file_path": "src/_pytest/nose.py", "content": "@hookimpl(trylast=True)\ndef pytest_runtest_setup(item):\n    if is_potential_nosetest(item):\n        if not call_optional(item.obj, \"setup\"):\n            # call module level setup if there is no object level one\n            call_optional(item.parent.obj, \"setup\")\n        # XXX this implies we only call teardown when setup worked\n        item.session._setupstate.addfinalizer((lambda: teardown_nose(item)), item)"}, {"id": "_pytest.nose.teardown_nose", "kind": "function", "range": [16, 0, 19, 54, 551, 718], "file_path": "src/_pytest/nose.py", "content": "def teardown_nose(item):\n    if is_potential_nosetest(item):\n        if not call_optional(item.obj, \"teardown\"):\n            call_optional(item.parent.obj, \"teardown\")"}, {"id": "_pytest.nose.is_potential_nosetest", "kind": "function", "range": [22, 0, 27, 5, 721, 973], "file_path": "src/_pytest/nose.py", "content": "def is_potential_nosetest(item):\n    # extra check needed since we do not do nose style setup/teardown\n    # on direct unittest style classes\n    return isinstance(item, python.Function) and not isinstance(\n        item, unittest.TestCaseFunction\n    )"}, {"id": "_pytest.nose.call_optional", "kind": "function", "range": [30, 0, 37, 19, 976, 1312], "file_path": "src/_pytest/nose.py", "content": "def call_optional(obj, name):\n    method = getattr(obj, name, None)\n    isfixture = hasattr(method, \"_pytestfixturefunction\")\n    if method is not None and not isfixture and callable(method):\n        # If there's any problems allow the exception to raise rather than\n        # silently ignoring them\n        method()\n        return True"}, {"id": "_pytest.nodes.SEP", "kind": "variable", "range": [37, 0, 37, 9, 1166, 1175], "file_path": "src/_pytest/nodes.py", "content": "SEP = \"/\""}, {"id": "_pytest.nodes.tracebackcutdir", "kind": "variable", "range": [39, 0, 39, 59, 1177, 1236], "file_path": "src/_pytest/nodes.py", "content": "tracebackcutdir = py.path.local(_pytest.__file__).dirpath()"}, {"id": "_pytest.nodes._splitnode", "kind": "function", "range": [42, 0, 65, 23, 1239, 2139], "file_path": "src/_pytest/nodes.py", "content": "@lru_cache(maxsize=None)\ndef _splitnode(nodeid):\n    \"\"\"Split a nodeid into constituent 'parts'.\n\n    Node IDs are strings, and can be things like:\n        ''\n        'testing/code'\n        'testing/code/test_excinfo.py'\n        'testing/code/test_excinfo.py::TestFormattedExcinfo'\n\n    Return values are lists e.g.\n        []\n        ['testing', 'code']\n        ['testing', 'code', 'test_excinfo.py']\n        ['testing', 'code', 'test_excinfo.py', 'TestFormattedExcinfo']\n    \"\"\"\n    if nodeid == \"\":\n        # If there is no root node at all, return an empty list so the caller's logic can remain sane\n        return ()\n    parts = nodeid.split(SEP)\n    # Replace single last element 'test_foo.py::Bar' with multiple elements 'test_foo.py', 'Bar'\n    parts[-1:] = parts[-1].split(\"::\")\n    # Convert parts into a tuple to avoid possible errors with caching of a mutable type\n    return tuple(parts)"}, {"id": "_pytest.nodes.ischildnode", "kind": "function", "range": [68, 0, 77, 54, 2142, 2535], "file_path": "src/_pytest/nodes.py", "content": "def ischildnode(baseid, nodeid):\n    \"\"\"Return True if the nodeid is a child node of the baseid.\n\n    E.g. 'foo/bar::Baz' is a child of 'foo', 'foo/bar' and 'foo/bar::Baz', but not of 'foo/blorp'\n    \"\"\"\n    base_parts = _splitnode(baseid)\n    node_parts = _splitnode(nodeid)\n    if len(node_parts) < len(base_parts):\n        return False\n    return node_parts[: len(base_parts)] == base_parts"}, {"id": "_pytest.nodes.NodeMeta", "kind": "class", "range": [80, 0, 86, 41, 2538, 2796], "file_path": "src/_pytest/nodes.py", "content": "class NodeMeta(type):\n    def __call__(self, *k, **kw):\n        warnings.warn(NODE_USE_FROM_PARENT.format(name=self.__name__), stacklevel=2)\n        return super().__call__(*k, **kw)\n\n    def _create(self, *k, **kw):\n        return super().__call__(*k, **kw)"}, {"id": "_pytest.nodes.NodeMeta.__call__", "kind": "function", "range": [81, 4, 83, 41, 2564, 2720], "file_path": "src/_pytest/nodes.py", "content": "def __call__(self, *k, **kw):\n        warnings.warn(NODE_USE_FROM_PARENT.format(name=self.__name__), stacklevel=2)\n        return super().__call__(*k, **kw)"}, {"id": "_pytest.nodes.NodeMeta._create", "kind": "function", "range": [85, 4, 86, 41, 2726, 2796], "file_path": "src/_pytest/nodes.py", "content": "def _create(self, *k, **kw):\n        return super().__call__(*k, **kw)"}, {"id": "_pytest.nodes.Node", "kind": "class", "range": [89, 0, 371, 52, 2799, 12490], "file_path": "src/_pytest/nodes.py", "content": "class Node(metaclass=NodeMeta):\n    \"\"\" base class for Collector and Item the test collection tree.\n    Collector subclasses have children, Items are terminal nodes.\"\"\"\n\n    def __init__(\n        self,\n        name: str,\n        parent: Optional[\"Node\"] = None,\n        config: Optional[Config] = None,\n        session: Optional[\"Session\"] = None,\n        fspath: Optional[py.path.local] = None,\n        nodeid: Optional[str] = None,\n    ) -> None:\n        #: a unique name within the scope of the parent node\n        self.name = name\n\n        #: the parent collector node.\n        self.parent = parent\n\n        #: the pytest config object\n        if config:\n            self.config = config\n        else:\n            if not parent:\n                raise TypeError(\"config or parent must be provided\")\n            self.config = parent.config\n\n        #: the session this node is part of\n        if session:\n            self.session = session\n        else:\n            if not parent:\n                raise TypeError(\"session or parent must be provided\")\n            self.session = parent.session\n\n        #: filesystem path where this node was collected from (can be None)\n        self.fspath = fspath or getattr(parent, \"fspath\", None)\n\n        #: keywords/markers collected from all scopes\n        self.keywords = NodeKeywords(self)\n\n        #: the marker objects belonging to this node\n        self.own_markers = []  # type: List[Mark]\n\n        #: allow adding of extra keywords to use for matching\n        self.extra_keyword_matches = set()  # type: Set[str]\n\n        # used for storing artificial fixturedefs for direct parametrization\n        self._name2pseudofixturedef = {}  # type: Dict[str, FixtureDef]\n\n        if nodeid is not None:\n            assert \"::()\" not in nodeid\n            self._nodeid = nodeid\n        else:\n            if not self.parent:\n                raise TypeError(\"nodeid or parent must be provided\")\n            self._nodeid = self.parent.nodeid\n            if self.name != \"()\":\n                self._nodeid += \"::\" + self.name\n\n        # A place where plugins can store information on the node for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()\n\n    @classmethod\n    def from_parent(cls, parent: \"Node\", **kw):\n        \"\"\"\n        Public Constructor for Nodes\n\n        This indirection got introduced in order to enable removing\n        the fragile logic from the node constructors.\n\n        Subclasses can use ``super().from_parent(...)`` when overriding the construction\n\n        :param parent: the parent node of this test Node\n        \"\"\"\n        if \"config\" in kw:\n            raise TypeError(\"config is not a valid argument for from_parent\")\n        if \"session\" in kw:\n            raise TypeError(\"session is not a valid argument for from_parent\")\n        return cls._create(parent=parent, **kw)\n\n    @property\n    def ihook(self):\n        \"\"\" fspath sensitive hook proxy used to call pytest hooks\"\"\"\n        return self.session.gethookproxy(self.fspath)\n\n    def __repr__(self):\n        return \"<{} {}>\".format(self.__class__.__name__, getattr(self, \"name\", None))\n\n    def warn(self, warning):\n        \"\"\"Issue a warning for this item.\n\n        Warnings will be displayed after the test session, unless explicitly suppressed\n\n        :param Warning warning: the warning instance to issue. Must be a subclass of PytestWarning.\n\n        :raise ValueError: if ``warning`` instance is not a subclass of PytestWarning.\n\n        Example usage:\n\n        .. code-block:: python\n\n            node.warn(PytestWarning(\"some message\"))\n\n        \"\"\"\n        from _pytest.warning_types import PytestWarning\n\n        if not isinstance(warning, PytestWarning):\n            raise ValueError(\n                \"warning must be an instance of PytestWarning or subclass, got {!r}\".format(\n                    warning\n                )\n            )\n        path, lineno = get_fslocation_from_item(self)\n        warnings.warn_explicit(\n            warning,\n            category=None,\n            filename=str(path),\n            lineno=lineno + 1 if lineno is not None else None,\n        )\n\n    # methods for ordering nodes\n    @property\n    def nodeid(self):\n        \"\"\" a ::-separated string denoting its collection tree address. \"\"\"\n        return self._nodeid\n\n    def __hash__(self):\n        return hash(self.nodeid)\n\n    def setup(self):\n        pass\n\n    def teardown(self):\n        pass\n\n    def listchain(self):\n        \"\"\" return list of all parent collectors up to self,\n            starting from root of collection tree. \"\"\"\n        chain = []\n        item = self  # type: Optional[Node]\n        while item is not None:\n            chain.append(item)\n            item = item.parent\n        chain.reverse()\n        return chain\n\n    def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)\n\n    def iter_markers(self, name=None):\n        \"\"\"\n        :param name: if given, filter the results by the name attribute\n\n        iterate over all markers of the node\n        \"\"\"\n        return (x[1] for x in self.iter_markers_with_node(name=name))\n\n    def iter_markers_with_node(self, name=None):\n        \"\"\"\n        :param name: if given, filter the results by the name attribute\n\n        iterate over all markers of the node\n        returns sequence of tuples (node, mark)\n        \"\"\"\n        for node in reversed(self.listchain()):\n            for mark in node.own_markers:\n                if name is None or getattr(mark, \"name\", None) == name:\n                    yield node, mark\n\n    def get_closest_marker(self, name, default=None):\n        \"\"\"return the first marker matching the name, from closest (for example function) to farther level (for example\n        module level).\n\n        :param default: fallback return value of no marker was found\n        :param name: name to filter by\n        \"\"\"\n        return next(self.iter_markers(name=name), default)\n\n    def listextrakeywords(self):\n        \"\"\" Return a set of all extra keywords in self and any parents.\"\"\"\n        extra_keywords = set()  # type: Set[str]\n        for item in self.listchain():\n            extra_keywords.update(item.extra_keyword_matches)\n        return extra_keywords\n\n    def listnames(self):\n        return [x.name for x in self.listchain()]\n\n    def addfinalizer(self, fin):\n        \"\"\" register a function to be called when this node is finalized.\n\n        This method can only be called when this node is active\n        in a setup chain, for example during self.setup().\n        \"\"\"\n        self.session._setupstate.addfinalizer(fin, self)\n\n    def getparent(self, cls):\n        \"\"\" get the next parent node (including ourself)\n        which is an instance of the given class\"\"\"\n        current = self  # type: Optional[Node]\n        while current and not isinstance(current, cls):\n            current = current.parent\n        return current\n\n    def _prunetraceback(self, excinfo):\n        pass\n\n    def _repr_failure_py(\n        self, excinfo: ExceptionInfo[Union[Failed, FixtureLookupError]], style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                return str(excinfo.value)\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n        else:\n            tb = _pytest._code.Traceback([excinfo.traceback[-1]])\n            self._prunetraceback(excinfo)\n            if len(excinfo.traceback) == 0:\n                excinfo.traceback = tb\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.getoption(\"verbose\", 0) > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        try:\n            os.getcwd()\n            abspath = False\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=False,  # pruned already, or in --fulltrace mode.\n            truncate_locals=truncate_locals,\n        )\n\n    def repr_failure(\n        self, excinfo, style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        \"\"\"\n        Return a representation of a collection or test failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        return self._repr_failure_py(excinfo, style)"}, {"id": "_pytest.nodes.Node.__init__", "kind": "function", "range": [93, 4, 151, 29, 2973, 5032], "file_path": "src/_pytest/nodes.py", "content": "def __init__(\n        self,\n        name: str,\n        parent: Optional[\"Node\"] = None,\n        config: Optional[Config] = None,\n        session: Optional[\"Session\"] = None,\n        fspath: Optional[py.path.local] = None,\n        nodeid: Optional[str] = None,\n    ) -> None:\n        #: a unique name within the scope of the parent node\n        self.name = name\n\n        #: the parent collector node.\n        self.parent = parent\n\n        #: the pytest config object\n        if config:\n            self.config = config\n        else:\n            if not parent:\n                raise TypeError(\"config or parent must be provided\")\n            self.config = parent.config\n\n        #: the session this node is part of\n        if session:\n            self.session = session\n        else:\n            if not parent:\n                raise TypeError(\"session or parent must be provided\")\n            self.session = parent.session\n\n        #: filesystem path where this node was collected from (can be None)\n        self.fspath = fspath or getattr(parent, \"fspath\", None)\n\n        #: keywords/markers collected from all scopes\n        self.keywords = NodeKeywords(self)\n\n        #: the marker objects belonging to this node\n        self.own_markers = []  # type: List[Mark]\n\n        #: allow adding of extra keywords to use for matching\n        self.extra_keyword_matches = set()  # type: Set[str]\n\n        # used for storing artificial fixturedefs for direct parametrization\n        self._name2pseudofixturedef = {}  # type: Dict[str, FixtureDef]\n\n        if nodeid is not None:\n            assert \"::()\" not in nodeid\n            self._nodeid = nodeid\n        else:\n            if not self.parent:\n                raise TypeError(\"nodeid or parent must be provided\")\n            self._nodeid = self.parent.nodeid\n            if self.name != \"()\":\n                self._nodeid += \"::\" + self.name\n\n        # A place where plugins can store information on the node for their\n        # own use. Currently only intended for internal plugins.\n        self._store = Store()"}, {"id": "_pytest.nodes.Node.from_parent", "kind": "function", "range": [153, 4, 169, 47, 5038, 5690], "file_path": "src/_pytest/nodes.py", "content": "@classmethod\n    def from_parent(cls, parent: \"Node\", **kw):\n        \"\"\"\n        Public Constructor for Nodes\n\n        This indirection got introduced in order to enable removing\n        the fragile logic from the node constructors.\n\n        Subclasses can use ``super().from_parent(...)`` when overriding the construction\n\n        :param parent: the parent node of this test Node\n        \"\"\"\n        if \"config\" in kw:\n            raise TypeError(\"config is not a valid argument for from_parent\")\n        if \"session\" in kw:\n            raise TypeError(\"session is not a valid argument for from_parent\")\n        return cls._create(parent=parent, **kw)"}, {"id": "_pytest.nodes.Node.ihook", "kind": "function", "range": [171, 4, 174, 53, 5696, 5849], "file_path": "src/_pytest/nodes.py", "content": "@property\n    def ihook(self):\n        \"\"\" fspath sensitive hook proxy used to call pytest hooks\"\"\"\n        return self.session.gethookproxy(self.fspath)"}, {"id": "_pytest.nodes.Node.__repr__", "kind": "function", "range": [176, 4, 177, 85, 5855, 5960], "file_path": "src/_pytest/nodes.py", "content": "def __repr__(self):\n        return \"<{} {}>\".format(self.__class__.__name__, getattr(self, \"name\", None))"}, {"id": "_pytest.nodes.Node.warn", "kind": "function", "range": [179, 4, 209, 9, 5966, 6963], "file_path": "src/_pytest/nodes.py", "content": "def warn(self, warning):\n        \"\"\"Issue a warning for this item.\n\n        Warnings will be displayed after the test session, unless explicitly suppressed\n\n        :param Warning warning: the warning instance to issue. Must be a subclass of PytestWarning.\n\n        :raise ValueError: if ``warning`` instance is not a subclass of PytestWarning.\n\n        Example usage:\n\n        .. code-block:: python\n\n            node.warn(PytestWarning(\"some message\"))\n\n        \"\"\"\n        from _pytest.warning_types import PytestWarning\n\n        if not isinstance(warning, PytestWarning):\n            raise ValueError(\n                \"warning must be an instance of PytestWarning or subclass, got {!r}\".format(\n                    warning\n                )\n            )\n        path, lineno = get_fslocation_from_item(self)\n        warnings.warn_explicit(\n            warning,\n            category=None,\n            filename=str(path),\n            lineno=lineno + 1 if lineno is not None else None,\n        )"}, {"id": "_pytest.nodes.Node.nodeid", "kind": "function", "range": [212, 4, 215, 27, 7002, 7137], "file_path": "src/_pytest/nodes.py", "content": "@property\n    def nodeid(self):\n        \"\"\" a ::-separated string denoting its collection tree address. \"\"\"\n        return self._nodeid"}, {"id": "_pytest.nodes.Node.__hash__", "kind": "function", "range": [217, 4, 218, 32, 7143, 7195], "file_path": "src/_pytest/nodes.py", "content": "def __hash__(self):\n        return hash(self.nodeid)"}, {"id": "_pytest.nodes.Node.setup", "kind": "function", "range": [220, 4, 221, 12, 7201, 7230], "file_path": "src/_pytest/nodes.py", "content": "def setup(self):\n        pass"}, {"id": "_pytest.nodes.Node.teardown", "kind": "function", "range": [223, 4, 224, 12, 7236, 7268], "file_path": "src/_pytest/nodes.py", "content": "def teardown(self):\n        pass"}, {"id": "_pytest.nodes.Node.listchain", "kind": "function", "range": [226, 4, 235, 20, 7274, 7612], "file_path": "src/_pytest/nodes.py", "content": "def listchain(self):\n        \"\"\" return list of all parent collectors up to self,\n            starting from root of collection tree. \"\"\"\n        chain = []\n        item = self  # type: Optional[Node]\n        while item is not None:\n            chain.append(item)\n            item = item.parent\n        chain.reverse()\n        return chain"}, {"id": "_pytest.nodes.Node.add_marker", "kind": "function", "range": [237, 4, 259, 52, 7618, 8448], "file_path": "src/_pytest/nodes.py", "content": "def add_marker(\n        self, marker: Union[str, MarkDecorator], append: bool = True\n    ) -> None:\n        \"\"\"dynamically add a marker object to the node.\n\n        :type marker: ``str`` or ``pytest.mark.*``  object\n        :param marker:\n            ``append=True`` whether to append the marker,\n            if ``False`` insert at position ``0``.\n        \"\"\"\n        from _pytest.mark import MARK_GEN\n\n        if isinstance(marker, MarkDecorator):\n            marker_ = marker\n        elif isinstance(marker, str):\n            marker_ = getattr(MARK_GEN, marker)\n        else:\n            raise ValueError(\"is not a string or pytest.mark.* Marker\")\n        self.keywords[marker_.name] = marker\n        if append:\n            self.own_markers.append(marker_.mark)\n        else:\n            self.own_markers.insert(0, marker_.mark)"}, {"id": "_pytest.nodes.Node.iter_markers", "kind": "function", "range": [261, 4, 267, 69, 8454, 8700], "file_path": "src/_pytest/nodes.py", "content": "def iter_markers(self, name=None):\n        \"\"\"\n        :param name: if given, filter the results by the name attribute\n\n        iterate over all markers of the node\n        \"\"\"\n        return (x[1] for x in self.iter_markers_with_node(name=name))"}, {"id": "_pytest.nodes.Node.iter_markers_with_node", "kind": "function", "range": [269, 4, 279, 36, 8706, 9139], "file_path": "src/_pytest/nodes.py", "content": "def iter_markers_with_node(self, name=None):\n        \"\"\"\n        :param name: if given, filter the results by the name attribute\n\n        iterate over all markers of the node\n        returns sequence of tuples (node, mark)\n        \"\"\"\n        for node in reversed(self.listchain()):\n            for mark in node.own_markers:\n                if name is None or getattr(mark, \"name\", None) == name:\n                    yield node, mark"}, {"id": "_pytest.nodes.Node.get_closest_marker", "kind": "function", "range": [281, 4, 288, 58, 9145, 9517], "file_path": "src/_pytest/nodes.py", "content": "def get_closest_marker(self, name, default=None):\n        \"\"\"return the first marker matching the name, from closest (for example function) to farther level (for example\n        module level).\n\n        :param default: fallback return value of no marker was found\n        :param name: name to filter by\n        \"\"\"\n        return next(self.iter_markers(name=name), default)"}, {"id": "_pytest.nodes.Node.listextrakeywords", "kind": "function", "range": [290, 4, 295, 29, 9523, 9805], "file_path": "src/_pytest/nodes.py", "content": "def listextrakeywords(self):\n        \"\"\" Return a set of all extra keywords in self and any parents.\"\"\"\n        extra_keywords = set()  # type: Set[str]\n        for item in self.listchain():\n            extra_keywords.update(item.extra_keyword_matches)\n        return extra_keywords"}, {"id": "_pytest.nodes.Node.listnames", "kind": "function", "range": [297, 4, 298, 49, 9811, 9881], "file_path": "src/_pytest/nodes.py", "content": "def listnames(self):\n        return [x.name for x in self.listchain()]"}, {"id": "_pytest.nodes.Node.addfinalizer", "kind": "function", "range": [300, 4, 306, 56, 9887, 10182], "file_path": "src/_pytest/nodes.py", "content": "def addfinalizer(self, fin):\n        \"\"\" register a function to be called when this node is finalized.\n\n        This method can only be called when this node is active\n        in a setup chain, for example during self.setup().\n        \"\"\"\n        self.session._setupstate.addfinalizer(fin, self)"}, {"id": "_pytest.nodes.Node.getparent", "kind": "function", "range": [308, 4, 314, 22, 10188, 10484], "file_path": "src/_pytest/nodes.py", "content": "def getparent(self, cls):\n        \"\"\" get the next parent node (including ourself)\n        which is an instance of the given class\"\"\"\n        current = self  # type: Optional[Node]\n        while current and not isinstance(current, cls):\n            current = current.parent\n        return current"}, {"id": "_pytest.nodes.Node._prunetraceback", "kind": "function", "range": [316, 4, 317, 12, 10490, 10538], "file_path": "src/_pytest/nodes.py", "content": "def _prunetraceback(self, excinfo):\n        pass"}, {"id": "_pytest.nodes.Node._repr_failure_py", "kind": "function", "range": [319, 4, 361, 9, 10544, 12143], "file_path": "src/_pytest/nodes.py", "content": "def _repr_failure_py(\n        self, excinfo: ExceptionInfo[Union[Failed, FixtureLookupError]], style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        if isinstance(excinfo.value, fail.Exception):\n            if not excinfo.value.pytrace:\n                return str(excinfo.value)\n        if isinstance(excinfo.value, FixtureLookupError):\n            return excinfo.value.formatrepr()\n        if self.config.getoption(\"fulltrace\", False):\n            style = \"long\"\n        else:\n            tb = _pytest._code.Traceback([excinfo.traceback[-1]])\n            self._prunetraceback(excinfo)\n            if len(excinfo.traceback) == 0:\n                excinfo.traceback = tb\n            if style == \"auto\":\n                style = \"long\"\n        # XXX should excinfo.getrepr record all data and toterminal() process it?\n        if style is None:\n            if self.config.getoption(\"tbstyle\", \"auto\") == \"short\":\n                style = \"short\"\n            else:\n                style = \"long\"\n\n        if self.config.getoption(\"verbose\", 0) > 1:\n            truncate_locals = False\n        else:\n            truncate_locals = True\n\n        try:\n            os.getcwd()\n            abspath = False\n        except OSError:\n            abspath = True\n\n        return excinfo.getrepr(\n            funcargs=True,\n            abspath=abspath,\n            showlocals=self.config.getoption(\"showlocals\", False),\n            style=style,\n            tbfilter=False,  # pruned already, or in --fulltrace mode.\n            truncate_locals=truncate_locals,\n        )"}, {"id": "_pytest.nodes.Node.repr_failure", "kind": "function", "range": [363, 4, 371, 52, 12149, 12490], "file_path": "src/_pytest/nodes.py", "content": "def repr_failure(\n        self, excinfo, style=None\n    ) -> Union[str, ReprExceptionInfo, ExceptionChainRepr, FixtureLookupErrorRepr]:\n        \"\"\"\n        Return a representation of a collection or test failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        return self._repr_failure_py(excinfo, style)"}, {"id": "_pytest.nodes.get_fslocation_from_item", "kind": "function", "range": [374, 0, 392, 58, 12493, 13126], "file_path": "src/_pytest/nodes.py", "content": "def get_fslocation_from_item(\n    item: \"Item\",\n) -> Tuple[Union[str, py.path.local], Optional[int]]:\n    \"\"\"Tries to extract the actual location from an item, depending on available attributes:\n\n    * \"fslocation\": a pair (path, lineno)\n    * \"obj\": a Python object that the item wraps.\n    * \"fspath\": just a path\n\n    :rtype: a tuple of (str|LocalPath, int) with filename and line number.\n    \"\"\"\n    try:\n        return item.location[:2]\n    except AttributeError:\n        pass\n    obj = getattr(item, \"obj\", None)\n    if obj is not None:\n        return getfslineno(obj)\n    return getattr(item, \"fspath\", \"unknown location\"), -1"}, {"id": "_pytest.nodes.Collector", "kind": "class", "range": [395, 0, 435, 51, 13129, 14591], "file_path": "src/_pytest/nodes.py", "content": "class Collector(Node):\n    \"\"\" Collector instances create children through collect()\n        and thus iteratively build a tree.\n    \"\"\"\n\n    class CollectError(Exception):\n        \"\"\" an error during collection, contains a custom message. \"\"\"\n\n    def collect(self):\n        \"\"\" returns a list of children (items and collectors)\n            for this collection node.\n        \"\"\"\n        raise NotImplementedError(\"abstract\")\n\n    def repr_failure(self, excinfo):\n        \"\"\"\n        Return a representation of a collection failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        if excinfo.errisinstance(self.CollectError) and not self.config.getoption(\n            \"fulltrace\", False\n        ):\n            exc = excinfo.value\n            return str(exc.args[0])\n\n        # Respect explicit tbstyle option, but default to \"short\"\n        # (_repr_failure_py uses \"long\" with \"fulltrace\" option always).\n        tbstyle = self.config.getoption(\"tbstyle\", \"auto\")\n        if tbstyle == \"auto\":\n            tbstyle = \"short\"\n\n        return self._repr_failure_py(excinfo, style=tbstyle)\n\n    def _prunetraceback(self, excinfo):\n        if hasattr(self, \"fspath\"):\n            traceback = excinfo.traceback\n            ntraceback = traceback.cut(path=self.fspath)\n            if ntraceback == traceback:\n                ntraceback = ntraceback.cut(excludepath=tracebackcutdir)\n            excinfo.traceback = ntraceback.filter()"}, {"id": "_pytest.nodes.Collector.CollectError", "kind": "class", "range": [400, 4, 401, 70, 13270, 13371], "file_path": "src/_pytest/nodes.py", "content": "class CollectError(Exception):\n        \"\"\" an error during collection, contains a custom message. \"\"\""}, {"id": "_pytest.nodes.Collector.collect", "kind": "function", "range": [403, 4, 407, 45, 13377, 13553], "file_path": "src/_pytest/nodes.py", "content": "def collect(self):\n        \"\"\" returns a list of children (items and collectors)\n            for this collection node.\n        \"\"\"\n        raise NotImplementedError(\"abstract\")"}, {"id": "_pytest.nodes.Collector.repr_failure", "kind": "function", "range": [409, 4, 427, 60, 13559, 14250], "file_path": "src/_pytest/nodes.py", "content": "def repr_failure(self, excinfo):\n        \"\"\"\n        Return a representation of a collection failure.\n\n        :param excinfo: Exception information for the failure.\n        \"\"\"\n        if excinfo.errisinstance(self.CollectError) and not self.config.getoption(\n            \"fulltrace\", False\n        ):\n            exc = excinfo.value\n            return str(exc.args[0])\n\n        # Respect explicit tbstyle option, but default to \"short\"\n        # (_repr_failure_py uses \"long\" with \"fulltrace\" option always).\n        tbstyle = self.config.getoption(\"tbstyle\", \"auto\")\n        if tbstyle == \"auto\":\n            tbstyle = \"short\"\n\n        return self._repr_failure_py(excinfo, style=tbstyle)"}, {"id": "_pytest.nodes.Collector._prunetraceback", "kind": "function", "range": [429, 4, 435, 51, 14256, 14591], "file_path": "src/_pytest/nodes.py", "content": "def _prunetraceback(self, excinfo):\n        if hasattr(self, \"fspath\"):\n            traceback = excinfo.traceback\n            ntraceback = traceback.cut(path=self.fspath)\n            if ntraceback == traceback:\n                ntraceback = ntraceback.cut(excludepath=tracebackcutdir)\n            excinfo.traceback = ntraceback.filter()"}, {"id": "_pytest.nodes._check_initialpaths_for_relpath", "kind": "function", "range": [438, 0, 441, 45, 14594, 14796], "file_path": "src/_pytest/nodes.py", "content": "def _check_initialpaths_for_relpath(session, fspath):\n    for initial_path in session._initialpaths:\n        if fspath.common(initial_path) == initial_path:\n            return fspath.relto(initial_path)"}, {"id": "_pytest.nodes.FSHookProxy", "kind": "class", "range": [444, 0, 455, 16, 14799, 15179], "file_path": "src/_pytest/nodes.py", "content": "class FSHookProxy:\n    def __init__(\n        self, fspath: py.path.local, pm: PytestPluginManager, remove_mods\n    ) -> None:\n        self.fspath = fspath\n        self.pm = pm\n        self.remove_mods = remove_mods\n\n    def __getattr__(self, name: str):\n        x = self.pm.subset_hook_caller(name, remove_plugins=self.remove_mods)\n        self.__dict__[name] = x\n        return x"}, {"id": "_pytest.nodes.FSHookProxy.__init__", "kind": "function", "range": [445, 4, 450, 38, 14822, 15013], "file_path": "src/_pytest/nodes.py", "content": "def __init__(\n        self, fspath: py.path.local, pm: PytestPluginManager, remove_mods\n    ) -> None:\n        self.fspath = fspath\n        self.pm = pm\n        self.remove_mods = remove_mods"}, {"id": "_pytest.nodes.FSHookProxy.__getattr__", "kind": "function", "range": [452, 4, 455, 16, 15019, 15179], "file_path": "src/_pytest/nodes.py", "content": "def __getattr__(self, name: str):\n        x = self.pm.subset_hook_caller(name, remove_plugins=self.remove_mods)\n        self.__dict__[name] = x\n        return x"}, {"id": "_pytest.nodes.FSCollector", "kind": "class", "range": [458, 0, 538, 64, 15182, 18209], "file_path": "src/_pytest/nodes.py", "content": "class FSCollector(Collector):\n    def __init__(\n        self, fspath: py.path.local, parent=None, config=None, session=None, nodeid=None\n    ) -> None:\n        name = fspath.basename\n        if parent is not None:\n            rel = fspath.relto(parent.fspath)\n            if rel:\n                name = rel\n            name = name.replace(os.sep, SEP)\n        self.fspath = fspath\n\n        session = session or parent.session\n\n        if nodeid is None:\n            nodeid = self.fspath.relto(session.config.rootdir)\n\n            if not nodeid:\n                nodeid = _check_initialpaths_for_relpath(session, fspath)\n            if nodeid and os.sep != SEP:\n                nodeid = nodeid.replace(os.sep, SEP)\n\n        super().__init__(name, parent, config, session, nodeid=nodeid, fspath=fspath)\n\n        self._norecursepatterns = self.config.getini(\"norecursedirs\")\n\n    @classmethod\n    def from_parent(cls, parent, *, fspath, **kw):\n        \"\"\"\n        The public constructor\n        \"\"\"\n        return super().from_parent(parent=parent, fspath=fspath, **kw)\n\n    def _gethookproxy(self, fspath: py.path.local):\n        # check if we have the common case of running\n        # hooks with all conftest.py files\n        pm = self.config.pluginmanager\n        my_conftestmodules = pm._getconftestmodules(fspath)\n        remove_mods = pm._conftest_plugins.difference(my_conftestmodules)\n        if remove_mods:\n            # one or more conftests are not in use at this fspath\n            proxy = FSHookProxy(fspath, pm, remove_mods)\n        else:\n            # all plugins are active for this fspath\n            proxy = self.config.hook\n        return proxy\n\n    def _recurse(self, dirpath: py.path.local) -> bool:\n        if dirpath.basename == \"__pycache__\":\n            return False\n        ihook = self._gethookproxy(dirpath.dirpath())\n        if ihook.pytest_ignore_collect(path=dirpath, config=self.config):\n            return False\n        for pat in self._norecursepatterns:\n            if dirpath.check(fnmatch=pat):\n                return False\n        ihook = self._gethookproxy(dirpath)\n        ihook.pytest_collect_directory(path=dirpath, parent=self)\n        return True\n\n    def _collectfile(self, path, handle_dupes=True):\n        assert (\n            path.isfile()\n        ), \"{!r} is not a file (isdir={!r}, exists={!r}, islink={!r})\".format(\n            path, path.isdir(), path.exists(), path.islink()\n        )\n        ihook = self.gethookproxy(path)\n        if not self.isinitpath(path):\n            if ihook.pytest_ignore_collect(path=path, config=self.config):\n                return ()\n\n        if handle_dupes:\n            keepduplicates = self.config.getoption(\"keepduplicates\")\n            if not keepduplicates:\n                duplicate_paths = self.config.pluginmanager._duplicatepaths\n                if path in duplicate_paths:\n                    return ()\n                else:\n                    duplicate_paths.add(path)\n\n        return ihook.pytest_collect_file(path=path, parent=self)"}, {"id": "_pytest.nodes.FSCollector.__init__", "kind": "function", "range": [459, 4, 482, 69, 15216, 16052], "file_path": "src/_pytest/nodes.py", "content": "def __init__(\n        self, fspath: py.path.local, parent=None, config=None, session=None, nodeid=None\n    ) -> None:\n        name = fspath.basename\n        if parent is not None:\n            rel = fspath.relto(parent.fspath)\n            if rel:\n                name = rel\n            name = name.replace(os.sep, SEP)\n        self.fspath = fspath\n\n        session = session or parent.session\n\n        if nodeid is None:\n            nodeid = self.fspath.relto(session.config.rootdir)\n\n            if not nodeid:\n                nodeid = _check_initialpaths_for_relpath(session, fspath)\n            if nodeid and os.sep != SEP:\n                nodeid = nodeid.replace(os.sep, SEP)\n\n        super().__init__(name, parent, config, session, nodeid=nodeid, fspath=fspath)\n\n        self._norecursepatterns = self.config.getini(\"norecursedirs\")"}, {"id": "_pytest.nodes.FSCollector.from_parent", "kind": "function", "range": [484, 4, 489, 70, 16058, 16247], "file_path": "src/_pytest/nodes.py", "content": "@classmethod\n    def from_parent(cls, parent, *, fspath, **kw):\n        \"\"\"\n        The public constructor\n        \"\"\"\n        return super().from_parent(parent=parent, fspath=fspath, **kw)"}, {"id": "_pytest.nodes.FSCollector._gethookproxy", "kind": "function", "range": [491, 4, 503, 20, 16253, 16842], "file_path": "src/_pytest/nodes.py", "content": "def _gethookproxy(self, fspath: py.path.local):\n        # check if we have the common case of running\n        # hooks with all conftest.py files\n        pm = self.config.pluginmanager\n        my_conftestmodules = pm._getconftestmodules(fspath)\n        remove_mods = pm._conftest_plugins.difference(my_conftestmodules)\n        if remove_mods:\n            # one or more conftests are not in use at this fspath\n            proxy = FSHookProxy(fspath, pm, remove_mods)\n        else:\n            # all plugins are active for this fspath\n            proxy = self.config.hook\n        return proxy"}, {"id": "_pytest.nodes.FSCollector._recurse", "kind": "function", "range": [505, 4, 516, 19, 16848, 17369], "file_path": "src/_pytest/nodes.py", "content": "def _recurse(self, dirpath: py.path.local) -> bool:\n        if dirpath.basename == \"__pycache__\":\n            return False\n        ihook = self._gethookproxy(dirpath.dirpath())\n        if ihook.pytest_ignore_collect(path=dirpath, config=self.config):\n            return False\n        for pat in self._norecursepatterns:\n            if dirpath.check(fnmatch=pat):\n                return False\n        ihook = self._gethookproxy(dirpath)\n        ihook.pytest_collect_directory(path=dirpath, parent=self)\n        return True"}, {"id": "_pytest.nodes.FSCollector._collectfile", "kind": "function", "range": [518, 4, 538, 64, 17375, 18209], "file_path": "src/_pytest/nodes.py", "content": "def _collectfile(self, path, handle_dupes=True):\n        assert (\n            path.isfile()\n        ), \"{!r} is not a file (isdir={!r}, exists={!r}, islink={!r})\".format(\n            path, path.isdir(), path.exists(), path.islink()\n        )\n        ihook = self.gethookproxy(path)\n        if not self.isinitpath(path):\n            if ihook.pytest_ignore_collect(path=path, config=self.config):\n                return ()\n\n        if handle_dupes:\n            keepduplicates = self.config.getoption(\"keepduplicates\")\n            if not keepduplicates:\n                duplicate_paths = self.config.pluginmanager._duplicatepaths\n                if path in duplicate_paths:\n                    return ()\n                else:\n                    duplicate_paths.add(path)\n\n        return ihook.pytest_collect_file(path=path, parent=self)"}, {"id": "_pytest.nodes.File", "kind": "class", "range": [541, 0, 542, 56, 18212, 18293], "file_path": "src/_pytest/nodes.py", "content": "class File(FSCollector):\n    \"\"\" base class for collecting tests from a file. \"\"\""}, {"id": "_pytest.nodes.Item", "kind": "class", "range": [545, 0, 594, 52, 18296, 20258], "file_path": "src/_pytest/nodes.py", "content": "class Item(Node):\n    \"\"\" a basic test invocation item. Note that for a single function\n    there might be multiple test invocation items.\n    \"\"\"\n\n    nextitem = None\n\n    def __init__(self, name, parent=None, config=None, session=None, nodeid=None):\n        super().__init__(name, parent, config, session, nodeid=nodeid)\n        self._report_sections = []  # type: List[Tuple[str, str, str]]\n\n        #: user properties is a list of tuples (name, value) that holds user\n        #: defined properties for this test.\n        self.user_properties = []  # type: List[Tuple[str, Any]]\n\n    def runtest(self) -> None:\n        raise NotImplementedError(\"runtest must be implemented by Item subclass\")\n\n    def add_report_section(self, when: str, key: str, content: str) -> None:\n        \"\"\"\n        Adds a new report section, similar to what's done internally to add stdout and\n        stderr captured output::\n\n            item.add_report_section(\"call\", \"stdout\", \"report section contents\")\n\n        :param str when:\n            One of the possible capture states, ``\"setup\"``, ``\"call\"``, ``\"teardown\"``.\n        :param str key:\n            Name of the section, can be customized at will. Pytest uses ``\"stdout\"`` and\n            ``\"stderr\"`` internally.\n\n        :param str content:\n            The full contents as a string.\n        \"\"\"\n        if content:\n            self._report_sections.append((when, key, content))\n\n    def reportinfo(self) -> Tuple[Union[py.path.local, str], Optional[int], str]:\n        return self.fspath, None, \"\"\n\n    @cached_property\n    def location(self) -> Tuple[str, Optional[int], str]:\n        location = self.reportinfo()\n        if isinstance(location[0], py.path.local):\n            fspath = location[0]\n        else:\n            fspath = py.path.local(location[0])\n        relfspath = self.session._node_location_to_relpath(fspath)\n        assert type(location[2]) is str\n        return (relfspath, location[1], location[2])"}, {"id": "_pytest.nodes.Item.nextitem", "kind": "variable", "range": [550, 4, 550, 19, 18448, 18463], "file_path": "src/_pytest/nodes.py", "content": "nextitem = None"}, {"id": "_pytest.nodes.Item.__init__", "kind": "function", "range": [552, 4, 558, 64, 18469, 18877], "file_path": "src/_pytest/nodes.py", "content": "def __init__(self, name, parent=None, config=None, session=None, nodeid=None):\n        super().__init__(name, parent, config, session, nodeid=nodeid)\n        self._report_sections = []  # type: List[Tuple[str, str, str]]\n\n        #: user properties is a list of tuples (name, value) that holds user\n        #: defined properties for this test.\n        self.user_properties = []  # type: List[Tuple[str, Any]]"}, {"id": "_pytest.nodes.Item.runtest", "kind": "function", "range": [560, 4, 561, 81, 18883, 18991], "file_path": "src/_pytest/nodes.py", "content": "def runtest(self) -> None:\n        raise NotImplementedError(\"runtest must be implemented by Item subclass\")"}, {"id": "_pytest.nodes.Item.add_report_section", "kind": "function", "range": [563, 4, 580, 62, 18997, 19715], "file_path": "src/_pytest/nodes.py", "content": "def add_report_section(self, when: str, key: str, content: str) -> None:\n        \"\"\"\n        Adds a new report section, similar to what's done internally to add stdout and\n        stderr captured output::\n\n            item.add_report_section(\"call\", \"stdout\", \"report section contents\")\n\n        :param str when:\n            One of the possible capture states, ``\"setup\"``, ``\"call\"``, ``\"teardown\"``.\n        :param str key:\n            Name of the section, can be customized at will. Pytest uses ``\"stdout\"`` and\n            ``\"stderr\"`` internally.\n\n        :param str content:\n            The full contents as a string.\n        \"\"\"\n        if content:\n            self._report_sections.append((when, key, content))"}, {"id": "_pytest.nodes.Item.reportinfo", "kind": "function", "range": [582, 4, 583, 36, 19721, 19835], "file_path": "src/_pytest/nodes.py", "content": "def reportinfo(self) -> Tuple[Union[py.path.local, str], Optional[int], str]:\n        return self.fspath, None, \"\""}, {"id": "_pytest.nodes.Item.location", "kind": "function", "range": [585, 4, 594, 52, 19841, 20258], "file_path": "src/_pytest/nodes.py", "content": "@cached_property\n    def location(self) -> Tuple[str, Optional[int], str]:\n        location = self.reportinfo()\n        if isinstance(location[0], py.path.local):\n            fspath = location[0]\n        else:\n            fspath = py.path.local(location[0])\n        relfspath = self.session._node_location_to_relpath(fspath)\n        assert type(location[2]) is str\n        return (relfspath, location[1], location[2])"}, {"id": "_pytest.main.pytest_addoption", "kind": "function", "range": [40, 0, 174, 5, 989, 5037], "file_path": "src/_pytest/main.py", "content": "def pytest_addoption(parser):\n    parser.addini(\n        \"norecursedirs\",\n        \"directory patterns to avoid for recursion\",\n        type=\"args\",\n        default=[\".*\", \"build\", \"dist\", \"CVS\", \"_darcs\", \"{arch}\", \"*.egg\", \"venv\"],\n    )\n    parser.addini(\n        \"testpaths\",\n        \"directories to search for tests when no files or directories are given in the \"\n        \"command line.\",\n        type=\"args\",\n        default=[],\n    )\n    group = parser.getgroup(\"general\", \"running and selection options\")\n    group._addoption(\n        \"-x\",\n        \"--exitfirst\",\n        action=\"store_const\",\n        dest=\"maxfail\",\n        const=1,\n        help=\"exit instantly on first error or failed test.\",\n    )\n    group._addoption(\n        \"--maxfail\",\n        metavar=\"num\",\n        action=\"store\",\n        type=int,\n        dest=\"maxfail\",\n        default=0,\n        help=\"exit after first num failures or errors.\",\n    )\n    group._addoption(\n        \"--strict-markers\",\n        \"--strict\",\n        action=\"store_true\",\n        help=\"markers not registered in the `markers` section of the configuration file raise errors.\",\n    )\n    group._addoption(\n        \"-c\",\n        metavar=\"file\",\n        type=str,\n        dest=\"inifilename\",\n        help=\"load configuration from `file` instead of trying to locate one of the implicit \"\n        \"configuration files.\",\n    )\n    group._addoption(\n        \"--continue-on-collection-errors\",\n        action=\"store_true\",\n        default=False,\n        dest=\"continue_on_collection_errors\",\n        help=\"Force test execution even if collection errors occur.\",\n    )\n    group._addoption(\n        \"--rootdir\",\n        action=\"store\",\n        dest=\"rootdir\",\n        help=\"Define root directory for tests. Can be relative path: 'root_dir', './root_dir', \"\n        \"'root_dir/another_dir/'; absolute path: '/home/user/root_dir'; path with variables: \"\n        \"'$HOME/root_dir'.\",\n    )\n\n    group = parser.getgroup(\"collect\", \"collection\")\n    group.addoption(\n        \"--collectonly\",\n        \"--collect-only\",\n        \"--co\",\n        action=\"store_true\",\n        help=\"only collect tests, don't execute them.\",\n    )\n    group.addoption(\n        \"--pyargs\",\n        action=\"store_true\",\n        help=\"try to interpret all arguments as python packages.\",\n    )\n    group.addoption(\n        \"--ignore\",\n        action=\"append\",\n        metavar=\"path\",\n        help=\"ignore path during collection (multi-allowed).\",\n    )\n    group.addoption(\n        \"--ignore-glob\",\n        action=\"append\",\n        metavar=\"path\",\n        help=\"ignore path pattern during collection (multi-allowed).\",\n    )\n    group.addoption(\n        \"--deselect\",\n        action=\"append\",\n        metavar=\"nodeid_prefix\",\n        help=\"deselect item (via node id prefix) during collection (multi-allowed).\",\n    )\n    group.addoption(\n        \"--confcutdir\",\n        dest=\"confcutdir\",\n        default=None,\n        metavar=\"dir\",\n        type=functools.partial(directory_arg, optname=\"--confcutdir\"),\n        help=\"only load conftest.py's relative to specified dir.\",\n    )\n    group.addoption(\n        \"--noconftest\",\n        action=\"store_true\",\n        dest=\"noconftest\",\n        default=False,\n        help=\"Don't load any conftest.py files.\",\n    )\n    group.addoption(\n        \"--keepduplicates\",\n        \"--keep-duplicates\",\n        action=\"store_true\",\n        dest=\"keepduplicates\",\n        default=False,\n        help=\"Keep duplicate tests.\",\n    )\n    group.addoption(\n        \"--collect-in-virtualenv\",\n        action=\"store_true\",\n        dest=\"collect_in_virtualenv\",\n        default=False,\n        help=\"Don't ignore tests in a local virtualenv directory\",\n    )\n\n    group = parser.getgroup(\"debugconfig\", \"test session debugging and configuration\")\n    group.addoption(\n        \"--basetemp\",\n        dest=\"basetemp\",\n        default=None,\n        metavar=\"dir\",\n        help=(\n            \"base temporary directory for this test run.\"\n            \"(warning: this directory is removed if it exists)\"\n        ),\n    )"}, {"id": "_pytest.main.wrap_session", "kind": "function", "range": [177, 0, 235, 29, 5040, 7567], "file_path": "src/_pytest/main.py", "content": "def wrap_session(\n    config: Config, doit: Callable[[Config, \"Session\"], Optional[Union[int, ExitCode]]]\n) -> Union[int, ExitCode]:\n    \"\"\"Skeleton command line program\"\"\"\n    session = Session.from_config(config)\n    session.exitstatus = ExitCode.OK\n    initstate = 0\n    try:\n        try:\n            config._do_configure()\n            initstate = 1\n            config.hook.pytest_sessionstart(session=session)\n            initstate = 2\n            session.exitstatus = doit(config, session) or 0\n        except UsageError:\n            session.exitstatus = ExitCode.USAGE_ERROR\n            raise\n        except Failed:\n            session.exitstatus = ExitCode.TESTS_FAILED\n        except (KeyboardInterrupt, exit.Exception):\n            excinfo = _pytest._code.ExceptionInfo.from_current()\n            exitstatus = ExitCode.INTERRUPTED  # type: Union[int, ExitCode]\n            if isinstance(excinfo.value, exit.Exception):\n                if excinfo.value.returncode is not None:\n                    exitstatus = excinfo.value.returncode\n                if initstate < 2:\n                    sys.stderr.write(\n                        \"{}: {}\\n\".format(excinfo.typename, excinfo.value.msg)\n                    )\n            config.hook.pytest_keyboard_interrupt(excinfo=excinfo)\n            session.exitstatus = exitstatus\n        except:  # noqa\n            session.exitstatus = ExitCode.INTERNAL_ERROR\n            excinfo = _pytest._code.ExceptionInfo.from_current()\n            try:\n                config.notify_exception(excinfo, config.option)\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(\"{}: {}\\n\".format(type(exc).__name__, exc))\n            else:\n                if excinfo.errisinstance(SystemExit):\n                    sys.stderr.write(\"mainloop: caught unexpected SystemExit!\\n\")\n\n    finally:\n        # Explicitly break reference cycle.\n        excinfo = None  # type: ignore\n        session.startdir.chdir()\n        if initstate >= 2:\n            try:\n                config.hook.pytest_sessionfinish(\n                    session=session, exitstatus=session.exitstatus\n                )\n            except exit.Exception as exc:\n                if exc.returncode is not None:\n                    session.exitstatus = exc.returncode\n                sys.stderr.write(\"{}: {}\\n\".format(type(exc).__name__, exc))\n        config._ensure_unconfigure()\n    return session.exitstatus"}, {"id": "_pytest.main.pytest_cmdline_main", "kind": "function", "range": [238, 0, 239, 38, 7570, 7641], "file_path": "src/_pytest/main.py", "content": "def pytest_cmdline_main(config):\n    return wrap_session(config, _main)"}, {"id": "_pytest.main._main", "kind": "function", "range": [242, 0, 252, 15, 7644, 8094], "file_path": "src/_pytest/main.py", "content": "def _main(config: Config, session: \"Session\") -> Optional[Union[int, ExitCode]]:\n    \"\"\" default command line protocol for initialization, session,\n    running tests and reporting. \"\"\"\n    config.hook.pytest_collection(session=session)\n    config.hook.pytest_runtestloop(session=session)\n\n    if session.testsfailed:\n        return ExitCode.TESTS_FAILED\n    elif session.testscollected == 0:\n        return ExitCode.NO_TESTS_COLLECTED\n    return None"}, {"id": "_pytest.main.pytest_collection", "kind": "function", "range": [255, 0, 256, 36, 8097, 8165], "file_path": "src/_pytest/main.py", "content": "def pytest_collection(session):\n    return session.perform_collect()"}, {"id": "_pytest.main.pytest_runtestloop", "kind": "function", "range": [259, 0, 276, 15, 8168, 8910], "file_path": "src/_pytest/main.py", "content": "def pytest_runtestloop(session):\n    if session.testsfailed and not session.config.option.continue_on_collection_errors:\n        raise session.Interrupted(\n            \"%d error%s during collection\"\n            % (session.testsfailed, \"s\" if session.testsfailed != 1 else \"\")\n        )\n\n    if session.config.option.collectonly:\n        return True\n\n    for i, item in enumerate(session.items):\n        nextitem = session.items[i + 1] if i + 1 < len(session.items) else None\n        item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n        if session.shouldfail:\n            raise session.Failed(session.shouldfail)\n        if session.shouldstop:\n            raise session.Interrupted(session.shouldstop)\n    return True"}, {"id": "_pytest.main._in_venv", "kind": "function", "range": [279, 0, 293, 75, 8913, 9443], "file_path": "src/_pytest/main.py", "content": "def _in_venv(path):\n    \"\"\"Attempts to detect if ``path`` is the root of a Virtual Environment by\n    checking for the existence of the appropriate activate script\"\"\"\n    bindir = path.join(\"Scripts\" if sys.platform.startswith(\"win\") else \"bin\")\n    if not bindir.isdir():\n        return False\n    activates = (\n        \"activate\",\n        \"activate.csh\",\n        \"activate.fish\",\n        \"Activate\",\n        \"Activate.bat\",\n        \"Activate.ps1\",\n    )\n    return any([fname.basename in activates for fname in bindir.listdir()])"}, {"id": "_pytest.main.pytest_ignore_collect", "kind": "function", "range": [296, 0, 322, 15, 9446, 10399], "file_path": "src/_pytest/main.py", "content": "def pytest_ignore_collect(\n    path: py.path.local, config: Config\n) -> \"Optional[Literal[True]]\":\n    ignore_paths = config._getconftest_pathlist(\"collect_ignore\", path=path.dirpath())\n    ignore_paths = ignore_paths or []\n    excludeopt = config.getoption(\"ignore\")\n    if excludeopt:\n        ignore_paths.extend([py.path.local(x) for x in excludeopt])\n\n    if py.path.local(path) in ignore_paths:\n        return True\n\n    ignore_globs = config._getconftest_pathlist(\n        \"collect_ignore_glob\", path=path.dirpath()\n    )\n    ignore_globs = ignore_globs or []\n    excludeglobopt = config.getoption(\"ignore_glob\")\n    if excludeglobopt:\n        ignore_globs.extend([py.path.local(x) for x in excludeglobopt])\n\n    if any(fnmatch.fnmatch(str(path), str(glob)) for glob in ignore_globs):\n        return True\n\n    allow_in_venv = config.getoption(\"collect_in_virtualenv\")\n    if not allow_in_venv and _in_venv(path):\n        return True\n    return None"}, {"id": "_pytest.main.pytest_collection_modifyitems", "kind": "function", "range": [325, 0, 340, 28, 10402, 10881], "file_path": "src/_pytest/main.py", "content": "def pytest_collection_modifyitems(items, config):\n    deselect_prefixes = tuple(config.getoption(\"deselect\") or [])\n    if not deselect_prefixes:\n        return\n\n    remaining = []\n    deselected = []\n    for colitem in items:\n        if colitem.nodeid.startswith(deselect_prefixes):\n            deselected.append(colitem)\n        else:\n            remaining.append(colitem)\n\n    if deselected:\n        config.hook.pytest_deselected(items=deselected)\n        items[:] = remaining"}, {"id": "_pytest.main.NoMatch", "kind": "class", "range": [343, 0, 344, 62, 10884, 10972], "file_path": "src/_pytest/main.py", "content": "class NoMatch(Exception):\n    \"\"\" raised if matching cannot locate a matching names. \"\"\""}, {"id": "_pytest.main.Interrupted", "kind": "class", "range": [347, 0, 350, 38, 10975, 11097], "file_path": "src/_pytest/main.py", "content": "class Interrupted(KeyboardInterrupt):\n    \"\"\" signals an interrupted test run. \"\"\"\n\n    __module__ = \"builtins\"  # for py3"}, {"id": "_pytest.main.Interrupted.__module__", "kind": "variable", "range": [350, 4, 350, 27, 11063, 11086], "file_path": "src/_pytest/main.py", "content": "__module__ = \"builtins\""}, {"id": "_pytest.main.Failed", "kind": "class", "range": [353, 0, 354, 46, 11100, 11171], "file_path": "src/_pytest/main.py", "content": "class Failed(Exception):\n    \"\"\" signals a stop as failed test run. \"\"\""}, {"id": "_pytest.main._bestrelpath_cache", "kind": "class", "range": [357, 0, 364, 16, 11174, 11401], "file_path": "src/_pytest/main.py", "content": "@attr.s\nclass _bestrelpath_cache(dict):\n    path = attr.ib(type=py.path.local)\n\n    def __missing__(self, path: py.path.local) -> str:\n        r = self.path.bestrelpath(path)  # type: str\n        self[path] = r\n        return r"}, {"id": "_pytest.main._bestrelpath_cache.path", "kind": "variable", "range": [359, 4, 359, 38, 11218, 11252], "file_path": "src/_pytest/main.py", "content": "path = attr.ib(type=py.path.local)"}, {"id": "_pytest.main._bestrelpath_cache.__missing__", "kind": "function", "range": [361, 4, 364, 16, 11258, 11401], "file_path": "src/_pytest/main.py", "content": "def __missing__(self, path: py.path.local) -> str:\n        r = self.path.bestrelpath(path)  # type: str\n        self[path] = r\n        return r"}, {"id": "_pytest.main.Session", "kind": "class", "range": [367, 0, 684, 55, 11404, 24571], "file_path": "src/_pytest/main.py", "content": "class Session(nodes.FSCollector):\n    Interrupted = Interrupted\n    Failed = Failed\n    # Set on the session by runner.pytest_sessionstart.\n    _setupstate = None  # type: SetupState\n    # Set on the session by fixtures.pytest_sessionstart.\n    _fixturemanager = None  # type: FixtureManager\n    exitstatus = None  # type: Union[int, ExitCode]\n\n    def __init__(self, config: Config) -> None:\n        nodes.FSCollector.__init__(\n            self, config.rootdir, parent=None, config=config, session=self, nodeid=\"\"\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self.shouldstop = False\n        self.shouldfail = False\n        self.trace = config.trace.root.get(\"collection\")\n        self.startdir = config.invocation_dir\n        self._initialpaths = frozenset()  # type: FrozenSet[py.path.local]\n\n        # Keep track of any collected nodes in here, so we don't duplicate fixtures\n        self._collection_node_cache1 = (\n            {}\n        )  # type: Dict[py.path.local, Sequence[nodes.Collector]]\n        self._collection_node_cache2 = (\n            {}\n        )  # type: Dict[Tuple[Type[nodes.Collector], py.path.local], nodes.Collector]\n        self._collection_node_cache3 = (\n            {}\n        )  # type: Dict[Tuple[Type[nodes.Collector], str], CollectReport]\n\n        # Dirnames of pkgs with dunder-init files.\n        self._collection_pkg_roots = {}  # type: Dict[py.path.local, Package]\n\n        self._bestrelpathcache = _bestrelpath_cache(\n            config.rootdir\n        )  # type: Dict[py.path.local, str]\n\n        self.config.pluginmanager.register(self, name=\"session\")\n\n    @classmethod\n    def from_config(cls, config):\n        return cls._create(config)\n\n    def __repr__(self):\n        return \"<%s %s exitstatus=%r testsfailed=%d testscollected=%d>\" % (\n            self.__class__.__name__,\n            self.name,\n            getattr(self, \"exitstatus\", \"<UNSET>\"),\n            self.testsfailed,\n            self.testscollected,\n        )\n\n    def _node_location_to_relpath(self, node_path: py.path.local) -> str:\n        # bestrelpath is a quite slow function\n        return self._bestrelpathcache[node_path]\n\n    @hookimpl(tryfirst=True)\n    def pytest_collectstart(self):\n        if self.shouldfail:\n            raise self.Failed(self.shouldfail)\n        if self.shouldstop:\n            raise self.Interrupted(self.shouldstop)\n\n    @hookimpl(tryfirst=True)\n    def pytest_runtest_logreport(self, report):\n        if report.failed and not hasattr(report, \"wasxfail\"):\n            self.testsfailed += 1\n            maxfail = self.config.getvalue(\"maxfail\")\n            if maxfail and self.testsfailed >= maxfail:\n                self.shouldfail = \"stopping after %d failures\" % (self.testsfailed)\n\n    pytest_collectreport = pytest_runtest_logreport\n\n    def isinitpath(self, path):\n        return path in self._initialpaths\n\n    def gethookproxy(self, fspath: py.path.local):\n        return super()._gethookproxy(fspath)\n\n    def perform_collect(self, args=None, genitems=True):\n        hook = self.config.hook\n        try:\n            items = self._perform_collect(args, genitems)\n            self.config.pluginmanager.check_pending()\n            hook.pytest_collection_modifyitems(\n                session=self, config=self.config, items=items\n            )\n        finally:\n            hook.pytest_collection_finish(session=self)\n        self.testscollected = len(items)\n        return items\n\n    def _perform_collect(self, args, genitems):\n        if args is None:\n            args = self.config.args\n        self.trace(\"perform_collect\", self, args)\n        self.trace.root.indent += 1\n        self._notfound = []\n        initialpaths = []  # type: List[py.path.local]\n        self._initial_parts = []  # type: List[Tuple[py.path.local, List[str]]]\n        self.items = items = []\n        for arg in args:\n            fspath, parts = self._parsearg(arg)\n            self._initial_parts.append((fspath, parts))\n            initialpaths.append(fspath)\n        self._initialpaths = frozenset(initialpaths)\n        rep = collect_one_node(self)\n        self.ihook.pytest_collectreport(report=rep)\n        self.trace.root.indent -= 1\n        if self._notfound:\n            errors = []\n            for arg, exc in self._notfound:\n                line = \"(no name {!r} in any of {!r})\".format(arg, exc.args[0])\n                errors.append(\"not found: {}\\n{}\".format(arg, line))\n            raise UsageError(*errors)\n        if not genitems:\n            return rep.result\n        else:\n            if rep.passed:\n                for node in rep.result:\n                    self.items.extend(self.genitems(node))\n            return items\n\n    def collect(self):\n        for fspath, parts in self._initial_parts:\n            self.trace(\"processing argument\", (fspath, parts))\n            self.trace.root.indent += 1\n            try:\n                yield from self._collect(fspath, parts)\n            except NoMatch as exc:\n                report_arg = \"::\".join((str(fspath), *parts))\n                # we are inside a make_report hook so\n                # we cannot directly pass through the exception\n                self._notfound.append((report_arg, exc))\n\n            self.trace.root.indent -= 1\n        self._collection_node_cache1.clear()\n        self._collection_node_cache2.clear()\n        self._collection_node_cache3.clear()\n        self._collection_pkg_roots.clear()\n\n    def _collect(self, argpath, names):\n        from _pytest.python import Package\n\n        # Start with a Session root, and delve to argpath item (dir or file)\n        # and stack all Packages found on the way.\n        # No point in finding packages when collecting doctests\n        if not self.config.getoption(\"doctestmodules\", False):\n            pm = self.config.pluginmanager\n            for parent in reversed(argpath.parts()):\n                if pm._confcutdir and pm._confcutdir.relto(parent):\n                    break\n\n                if parent.isdir():\n                    pkginit = parent.join(\"__init__.py\")\n                    if pkginit.isfile():\n                        if pkginit not in self._collection_node_cache1:\n                            col = self._collectfile(pkginit, handle_dupes=False)\n                            if col:\n                                if isinstance(col[0], Package):\n                                    self._collection_pkg_roots[parent] = col[0]\n                                # always store a list in the cache, matchnodes expects it\n                                self._collection_node_cache1[col[0].fspath] = [col[0]]\n\n        # If it's a directory argument, recurse and look for any Subpackages.\n        # Let the Package collector deal with subnodes, don't collect here.\n        if argpath.check(dir=1):\n            assert not names, \"invalid arg {!r}\".format((argpath, names))\n\n            seen_dirs = set()\n            for path in argpath.visit(\n                fil=self._visit_filter, rec=self._recurse, bf=True, sort=True\n            ):\n                dirpath = path.dirpath()\n                if dirpath not in seen_dirs:\n                    # Collect packages first.\n                    seen_dirs.add(dirpath)\n                    pkginit = dirpath.join(\"__init__.py\")\n                    if pkginit.exists():\n                        for x in self._collectfile(pkginit):\n                            yield x\n                            if isinstance(x, Package):\n                                self._collection_pkg_roots[dirpath] = x\n                if dirpath in self._collection_pkg_roots:\n                    # Do not collect packages here.\n                    continue\n\n                for x in self._collectfile(path):\n                    key = (type(x), x.fspath)\n                    if key in self._collection_node_cache2:\n                        yield self._collection_node_cache2[key]\n                    else:\n                        self._collection_node_cache2[key] = x\n                        yield x\n        else:\n            assert argpath.check(file=1)\n\n            if argpath in self._collection_node_cache1:\n                col = self._collection_node_cache1[argpath]\n            else:\n                collect_root = self._collection_pkg_roots.get(argpath.dirname, self)\n                col = collect_root._collectfile(argpath, handle_dupes=False)\n                if col:\n                    self._collection_node_cache1[argpath] = col\n            m = self.matchnodes(col, names)\n            # If __init__.py was the only file requested, then the matched node will be\n            # the corresponding Package, and the first yielded item will be the __init__\n            # Module itself, so just use that. If this special case isn't taken, then all\n            # the files in the package will be yielded.\n            if argpath.basename == \"__init__.py\":\n                try:\n                    yield next(m[0].collect())\n                except StopIteration:\n                    # The package collects nothing with only an __init__.py\n                    # file in it, which gets ignored by the default\n                    # \"python_files\" option.\n                    pass\n                return\n            yield from m\n\n    @staticmethod\n    def _visit_filter(f):\n        return f.check(file=1)\n\n    def _tryconvertpyarg(self, x):\n        \"\"\"Convert a dotted module name to path.\"\"\"\n        try:\n            spec = importlib.util.find_spec(x)\n        # AttributeError: looks like package module, but actually filename\n        # ImportError: module does not exist\n        # ValueError: not a module name\n        except (AttributeError, ImportError, ValueError):\n            return x\n        if spec is None or spec.origin in {None, \"namespace\"}:\n            return x\n        elif spec.submodule_search_locations:\n            return os.path.dirname(spec.origin)\n        else:\n            return spec.origin\n\n    def _parsearg(self, arg):\n        \"\"\" return (fspath, names) tuple after checking the file exists. \"\"\"\n        strpath, *parts = str(arg).split(\"::\")\n        if self.config.option.pyargs:\n            strpath = self._tryconvertpyarg(strpath)\n        relpath = strpath.replace(\"/\", os.sep)\n        fspath = self.config.invocation_dir.join(relpath, abs=True)\n        if not fspath.check():\n            if self.config.option.pyargs:\n                raise UsageError(\n                    \"file or package not found: \" + arg + \" (missing __init__.py?)\"\n                )\n            raise UsageError(\"file not found: \" + arg)\n        fspath = fspath.realpath()\n        return (fspath, parts)\n\n    def matchnodes(self, matching, names):\n        self.trace(\"matchnodes\", matching, names)\n        self.trace.root.indent += 1\n        nodes = self._matchnodes(matching, names)\n        num = len(nodes)\n        self.trace(\"matchnodes finished -> \", num, \"nodes\")\n        self.trace.root.indent -= 1\n        if num == 0:\n            raise NoMatch(matching, names[:1])\n        return nodes\n\n    def _matchnodes(self, matching, names):\n        if not matching or not names:\n            return matching\n        name = names[0]\n        assert name\n        nextnames = names[1:]\n        resultnodes = []\n        for node in matching:\n            if isinstance(node, nodes.Item):\n                if not names:\n                    resultnodes.append(node)\n                continue\n            assert isinstance(node, nodes.Collector)\n            key = (type(node), node.nodeid)\n            if key in self._collection_node_cache3:\n                rep = self._collection_node_cache3[key]\n            else:\n                rep = collect_one_node(node)\n                self._collection_node_cache3[key] = rep\n            if rep.passed:\n                has_matched = False\n                for x in rep.result:\n                    # TODO: remove parametrized workaround once collection structure contains parametrization\n                    if x.name == name or x.name.split(\"[\")[0] == name:\n                        resultnodes.extend(self.matchnodes([x], nextnames))\n                        has_matched = True\n                # XXX accept IDs that don't have \"()\" for class instances\n                if not has_matched and len(rep.result) == 1 and x.name == \"()\":\n                    nextnames.insert(0, name)\n                    resultnodes.extend(self.matchnodes([x], nextnames))\n            else:\n                # report collection failures here to avoid failing to run some test\n                # specified in the command line because the module could not be\n                # imported (#134)\n                node.ihook.pytest_collectreport(report=rep)\n        return resultnodes\n\n    def genitems(self, node):\n        self.trace(\"genitems\", node)\n        if isinstance(node, nodes.Item):\n            node.ihook.pytest_itemcollected(item=node)\n            yield node\n        else:\n            assert isinstance(node, nodes.Collector)\n            rep = collect_one_node(node)\n            if rep.passed:\n                for subnode in rep.result:\n                    yield from self.genitems(subnode)\n            node.ihook.pytest_collectreport(report=rep)"}, {"id": "_pytest.main.Session.Interrupted", "kind": "variable", "range": [368, 4, 368, 29, 11442, 11467], "file_path": "src/_pytest/main.py", "content": "Interrupted = Interrupted"}, {"id": "_pytest.main.Session.Failed", "kind": "variable", "range": [369, 4, 369, 19, 11472, 11487], "file_path": "src/_pytest/main.py", "content": "Failed = Failed"}, {"id": "_pytest.main.Session._setupstate", "kind": "variable", "range": [371, 4, 371, 22, 11548, 11566], "file_path": "src/_pytest/main.py", "content": "_setupstate = None"}, {"id": "_pytest.main.Session._fixturemanager", "kind": "variable", "range": [373, 4, 373, 26, 11649, 11671], "file_path": "src/_pytest/main.py", "content": "_fixturemanager = None"}, {"id": "_pytest.main.Session.exitstatus", "kind": "variable", "range": [374, 4, 374, 21, 11700, 11717], "file_path": "src/_pytest/main.py", "content": "exitstatus = None"}, {"id": "_pytest.main.Session.__init__", "kind": "function", "range": [376, 4, 406, 64, 11753, 13031], "file_path": "src/_pytest/main.py", "content": "def __init__(self, config: Config) -> None:\n        nodes.FSCollector.__init__(\n            self, config.rootdir, parent=None, config=config, session=self, nodeid=\"\"\n        )\n        self.testsfailed = 0\n        self.testscollected = 0\n        self.shouldstop = False\n        self.shouldfail = False\n        self.trace = config.trace.root.get(\"collection\")\n        self.startdir = config.invocation_dir\n        self._initialpaths = frozenset()  # type: FrozenSet[py.path.local]\n\n        # Keep track of any collected nodes in here, so we don't duplicate fixtures\n        self._collection_node_cache1 = (\n            {}\n        )  # type: Dict[py.path.local, Sequence[nodes.Collector]]\n        self._collection_node_cache2 = (\n            {}\n        )  # type: Dict[Tuple[Type[nodes.Collector], py.path.local], nodes.Collector]\n        self._collection_node_cache3 = (\n            {}\n        )  # type: Dict[Tuple[Type[nodes.Collector], str], CollectReport]\n\n        # Dirnames of pkgs with dunder-init files.\n        self._collection_pkg_roots = {}  # type: Dict[py.path.local, Package]\n\n        self._bestrelpathcache = _bestrelpath_cache(\n            config.rootdir\n        )  # type: Dict[py.path.local, str]\n\n        self.config.pluginmanager.register(self, name=\"session\")"}, {"id": "_pytest.main.Session.from_config", "kind": "function", "range": [408, 4, 410, 34, 13037, 13118], "file_path": "src/_pytest/main.py", "content": "@classmethod\n    def from_config(cls, config):\n        return cls._create(config)"}, {"id": "_pytest.main.Session.__repr__", "kind": "function", "range": [412, 4, 419, 9, 13124, 13404], "file_path": "src/_pytest/main.py", "content": "def __repr__(self):\n        return \"<%s %s exitstatus=%r testsfailed=%d testscollected=%d>\" % (\n            self.__class__.__name__,\n            self.name,\n            getattr(self, \"exitstatus\", \"<UNSET>\"),\n            self.testsfailed,\n            self.testscollected,\n        )"}, {"id": "_pytest.main.Session._node_location_to_relpath", "kind": "function", "range": [421, 4, 423, 48, 13410, 13575], "file_path": "src/_pytest/main.py", "content": "def _node_location_to_relpath(self, node_path: py.path.local) -> str:\n        # bestrelpath is a quite slow function\n        return self._bestrelpathcache[node_path]"}, {"id": "_pytest.main.Session.pytest_collectstart", "kind": "function", "range": [425, 4, 430, 51, 13581, 13795], "file_path": "src/_pytest/main.py", "content": "@hookimpl(tryfirst=True)\n    def pytest_collectstart(self):\n        if self.shouldfail:\n            raise self.Failed(self.shouldfail)\n        if self.shouldstop:\n            raise self.Interrupted(self.shouldstop)"}, {"id": "_pytest.main.Session.pytest_runtest_logreport", "kind": "function", "range": [432, 4, 438, 83, 13801, 14163], "file_path": "src/_pytest/main.py", "content": "@hookimpl(tryfirst=True)\n    def pytest_runtest_logreport(self, report):\n        if report.failed and not hasattr(report, \"wasxfail\"):\n            self.testsfailed += 1\n            maxfail = self.config.getvalue(\"maxfail\")\n            if maxfail and self.testsfailed >= maxfail:\n                self.shouldfail = \"stopping after %d failures\" % (self.testsfailed)"}, {"id": "_pytest.main.Session.pytest_collectreport", "kind": "variable", "range": [440, 4, 440, 51, 14169, 14216], "file_path": "src/_pytest/main.py", "content": "pytest_collectreport = pytest_runtest_logreport"}, {"id": "_pytest.main.Session.isinitpath", "kind": "function", "range": [442, 4, 443, 41, 14222, 14291], "file_path": "src/_pytest/main.py", "content": "def isinitpath(self, path):\n        return path in self._initialpaths"}, {"id": "_pytest.main.Session.gethookproxy", "kind": "function", "range": [445, 4, 446, 44, 14297, 14388], "file_path": "src/_pytest/main.py", "content": "def gethookproxy(self, fspath: py.path.local):\n        return super()._gethookproxy(fspath)"}, {"id": "_pytest.main.Session.perform_collect", "kind": "function", "range": [448, 4, 459, 20, 14394, 14862], "file_path": "src/_pytest/main.py", "content": "def perform_collect(self, args=None, genitems=True):\n        hook = self.config.hook\n        try:\n            items = self._perform_collect(args, genitems)\n            self.config.pluginmanager.check_pending()\n            hook.pytest_collection_modifyitems(\n                session=self, config=self.config, items=items\n            )\n        finally:\n            hook.pytest_collection_finish(session=self)\n        self.testscollected = len(items)\n        return items"}, {"id": "_pytest.main.Session._perform_collect", "kind": "function", "range": [461, 4, 490, 24, 14868, 16102], "file_path": "src/_pytest/main.py", "content": "def _perform_collect(self, args, genitems):\n        if args is None:\n            args = self.config.args\n        self.trace(\"perform_collect\", self, args)\n        self.trace.root.indent += 1\n        self._notfound = []\n        initialpaths = []  # type: List[py.path.local]\n        self._initial_parts = []  # type: List[Tuple[py.path.local, List[str]]]\n        self.items = items = []\n        for arg in args:\n            fspath, parts = self._parsearg(arg)\n            self._initial_parts.append((fspath, parts))\n            initialpaths.append(fspath)\n        self._initialpaths = frozenset(initialpaths)\n        rep = collect_one_node(self)\n        self.ihook.pytest_collectreport(report=rep)\n        self.trace.root.indent -= 1\n        if self._notfound:\n            errors = []\n            for arg, exc in self._notfound:\n                line = \"(no name {!r} in any of {!r})\".format(arg, exc.args[0])\n                errors.append(\"not found: {}\\n{}\".format(arg, line))\n            raise UsageError(*errors)\n        if not genitems:\n            return rep.result\n        else:\n            if rep.passed:\n                for node in rep.result:\n                    self.items.extend(self.genitems(node))\n            return items"}, {"id": "_pytest.main.Session.collect", "kind": "function", "range": [492, 4, 508, 42, 16108, 16843], "file_path": "src/_pytest/main.py", "content": "def collect(self):\n        for fspath, parts in self._initial_parts:\n            self.trace(\"processing argument\", (fspath, parts))\n            self.trace.root.indent += 1\n            try:\n                yield from self._collect(fspath, parts)\n            except NoMatch as exc:\n                report_arg = \"::\".join((str(fspath), *parts))\n                # we are inside a make_report hook so\n                # we cannot directly pass through the exception\n                self._notfound.append((report_arg, exc))\n\n            self.trace.root.indent -= 1\n        self._collection_node_cache1.clear()\n        self._collection_node_cache2.clear()\n        self._collection_node_cache3.clear()\n        self._collection_pkg_roots.clear()"}, {"id": "_pytest.main.Session._collect", "kind": "function", "range": [510, 4, 587, 24, 16849, 20645], "file_path": "src/_pytest/main.py", "content": "def _collect(self, argpath, names):\n        from _pytest.python import Package\n\n        # Start with a Session root, and delve to argpath item (dir or file)\n        # and stack all Packages found on the way.\n        # No point in finding packages when collecting doctests\n        if not self.config.getoption(\"doctestmodules\", False):\n            pm = self.config.pluginmanager\n            for parent in reversed(argpath.parts()):\n                if pm._confcutdir and pm._confcutdir.relto(parent):\n                    break\n\n                if parent.isdir():\n                    pkginit = parent.join(\"__init__.py\")\n                    if pkginit.isfile():\n                        if pkginit not in self._collection_node_cache1:\n                            col = self._collectfile(pkginit, handle_dupes=False)\n                            if col:\n                                if isinstance(col[0], Package):\n                                    self._collection_pkg_roots[parent] = col[0]\n                                # always store a list in the cache, matchnodes expects it\n                                self._collection_node_cache1[col[0].fspath] = [col[0]]\n\n        # If it's a directory argument, recurse and look for any Subpackages.\n        # Let the Package collector deal with subnodes, don't collect here.\n        if argpath.check(dir=1):\n            assert not names, \"invalid arg {!r}\".format((argpath, names))\n\n            seen_dirs = set()\n            for path in argpath.visit(\n                fil=self._visit_filter, rec=self._recurse, bf=True, sort=True\n            ):\n                dirpath = path.dirpath()\n                if dirpath not in seen_dirs:\n                    # Collect packages first.\n                    seen_dirs.add(dirpath)\n                    pkginit = dirpath.join(\"__init__.py\")\n                    if pkginit.exists():\n                        for x in self._collectfile(pkginit):\n                            yield x\n                            if isinstance(x, Package):\n                                self._collection_pkg_roots[dirpath] = x\n                if dirpath in self._collection_pkg_roots:\n                    # Do not collect packages here.\n                    continue\n\n                for x in self._collectfile(path):\n                    key = (type(x), x.fspath)\n                    if key in self._collection_node_cache2:\n                        yield self._collection_node_cache2[key]\n                    else:\n                        self._collection_node_cache2[key] = x\n                        yield x\n        else:\n            assert argpath.check(file=1)\n\n            if argpath in self._collection_node_cache1:\n                col = self._collection_node_cache1[argpath]\n            else:\n                collect_root = self._collection_pkg_roots.get(argpath.dirname, self)\n                col = collect_root._collectfile(argpath, handle_dupes=False)\n                if col:\n                    self._collection_node_cache1[argpath] = col\n            m = self.matchnodes(col, names)\n            # If __init__.py was the only file requested, then the matched node will be\n            # the corresponding Package, and the first yielded item will be the __init__\n            # Module itself, so just use that. If this special case isn't taken, then all\n            # the files in the package will be yielded.\n            if argpath.basename == \"__init__.py\":\n                try:\n                    yield next(m[0].collect())\n                except StopIteration:\n                    # The package collects nothing with only an __init__.py\n                    # file in it, which gets ignored by the default\n                    # \"python_files\" option.\n                    pass\n                return\n            yield from m"}, {"id": "_pytest.main.Session._visit_filter", "kind": "function", "range": [589, 4, 591, 30, 20651, 20721], "file_path": "src/_pytest/main.py", "content": "@staticmethod\n    def _visit_filter(f):\n        return f.check(file=1)"}, {"id": "_pytest.main.Session._tryconvertpyarg", "kind": "function", "range": [593, 4, 607, 30, 20727, 21331], "file_path": "src/_pytest/main.py", "content": "def _tryconvertpyarg(self, x):\n        \"\"\"Convert a dotted module name to path.\"\"\"\n        try:\n            spec = importlib.util.find_spec(x)\n        # AttributeError: looks like package module, but actually filename\n        # ImportError: module does not exist\n        # ValueError: not a module name\n        except (AttributeError, ImportError, ValueError):\n            return x\n        if spec is None or spec.origin in {None, \"namespace\"}:\n            return x\n        elif spec.submodule_search_locations:\n            return os.path.dirname(spec.origin)\n        else:\n            return spec.origin"}, {"id": "_pytest.main.Session._parsearg", "kind": "function", "range": [609, 4, 623, 30, 21337, 22022], "file_path": "src/_pytest/main.py", "content": "def _parsearg(self, arg):\n        \"\"\" return (fspath, names) tuple after checking the file exists. \"\"\"\n        strpath, *parts = str(arg).split(\"::\")\n        if self.config.option.pyargs:\n            strpath = self._tryconvertpyarg(strpath)\n        relpath = strpath.replace(\"/\", os.sep)\n        fspath = self.config.invocation_dir.join(relpath, abs=True)\n        if not fspath.check():\n            if self.config.option.pyargs:\n                raise UsageError(\n                    \"file or package not found: \" + arg + \" (missing __init__.py?)\"\n                )\n            raise UsageError(\"file not found: \" + arg)\n        fspath = fspath.realpath()\n        return (fspath, parts)"}, {"id": "_pytest.main.Session.matchnodes", "kind": "function", "range": [625, 4, 634, 20, 22028, 22412], "file_path": "src/_pytest/main.py", "content": "def matchnodes(self, matching, names):\n        self.trace(\"matchnodes\", matching, names)\n        self.trace.root.indent += 1\n        nodes = self._matchnodes(matching, names)\n        num = len(nodes)\n        self.trace(\"matchnodes finished -> \", num, \"nodes\")\n        self.trace.root.indent -= 1\n        if num == 0:\n            raise NoMatch(matching, names[:1])\n        return nodes"}, {"id": "_pytest.main.Session._matchnodes", "kind": "function", "range": [636, 4, 671, 26, 22418, 24096], "file_path": "src/_pytest/main.py", "content": "def _matchnodes(self, matching, names):\n        if not matching or not names:\n            return matching\n        name = names[0]\n        assert name\n        nextnames = names[1:]\n        resultnodes = []\n        for node in matching:\n            if isinstance(node, nodes.Item):\n                if not names:\n                    resultnodes.append(node)\n                continue\n            assert isinstance(node, nodes.Collector)\n            key = (type(node), node.nodeid)\n            if key in self._collection_node_cache3:\n                rep = self._collection_node_cache3[key]\n            else:\n                rep = collect_one_node(node)\n                self._collection_node_cache3[key] = rep\n            if rep.passed:\n                has_matched = False\n                for x in rep.result:\n                    # TODO: remove parametrized workaround once collection structure contains parametrization\n                    if x.name == name or x.name.split(\"[\")[0] == name:\n                        resultnodes.extend(self.matchnodes([x], nextnames))\n                        has_matched = True\n                # XXX accept IDs that don't have \"()\" for class instances\n                if not has_matched and len(rep.result) == 1 and x.name == \"()\":\n                    nextnames.insert(0, name)\n                    resultnodes.extend(self.matchnodes([x], nextnames))\n            else:\n                # report collection failures here to avoid failing to run some test\n                # specified in the command line because the module could not be\n                # imported (#134)\n                node.ihook.pytest_collectreport(report=rep)\n        return resultnodes"}, {"id": "_pytest.main.Session.genitems", "kind": "function", "range": [673, 4, 684, 55, 24102, 24571], "file_path": "src/_pytest/main.py", "content": "def genitems(self, node):\n        self.trace(\"genitems\", node)\n        if isinstance(node, nodes.Item):\n            node.ihook.pytest_itemcollected(item=node)\n            yield node\n        else:\n            assert isinstance(node, nodes.Collector)\n            rep = collect_one_node(node)\n            if rep.passed:\n                for subnode in rep.result:\n                    yield from self.genitems(subnode)\n            node.ihook.pytest_collectreport(report=rep)"}, {"id": "_pytest.monkeypatch.RE_IMPORT_ERROR_NAME", "kind": "variable", "range": [12, 0, 12, 60, 251, 311], "file_path": "src/_pytest/monkeypatch.py", "content": "RE_IMPORT_ERROR_NAME = re.compile(r\"^No module named (.*)$\")"}, {"id": "_pytest.monkeypatch.monkeypatch", "kind": "function", "range": [15, 0, 36, 17, 314, 1169], "file_path": "src/_pytest/monkeypatch.py", "content": "@fixture\ndef monkeypatch():\n    \"\"\"The returned ``monkeypatch`` fixture provides these\n    helper methods to modify objects, dictionaries or os.environ::\n\n        monkeypatch.setattr(obj, name, value, raising=True)\n        monkeypatch.delattr(obj, name, raising=True)\n        monkeypatch.setitem(mapping, name, value)\n        monkeypatch.delitem(obj, name, raising=True)\n        monkeypatch.setenv(name, value, prepend=False)\n        monkeypatch.delenv(name, raising=True)\n        monkeypatch.syspath_prepend(path)\n        monkeypatch.chdir(path)\n\n    All modifications will be undone after the requesting\n    test function or fixture has finished. The ``raising``\n    parameter determines if a KeyError or AttributeError\n    will be raised if the set/deletion operation has no target.\n    \"\"\"\n    mpatch = MonkeyPatch()\n    yield mpatch\n    mpatch.undo()"}, {"id": "_pytest.monkeypatch.resolve", "kind": "function", "range": [39, 0, 65, 16, 1172, 1994], "file_path": "src/_pytest/monkeypatch.py", "content": "def resolve(name):\n    # simplified from zope.dottedname\n    parts = name.split(\".\")\n\n    used = parts.pop(0)\n    found = __import__(used)\n    for part in parts:\n        used += \".\" + part\n        try:\n            found = getattr(found, part)\n        except AttributeError:\n            pass\n        else:\n            continue\n        # we use explicit un-nesting of the handling block in order\n        # to avoid nested exceptions on python 3\n        try:\n            __import__(used)\n        except ImportError as ex:\n            # str is used for py2 vs py3\n            expected = str(ex).split()[-1]\n            if expected == used:\n                raise\n            else:\n                raise ImportError(\"import error in {}: {}\".format(used, ex))\n        found = annotated_getattr(found, part, used)\n    return found"}, {"id": "_pytest.monkeypatch.annotated_getattr", "kind": "function", "range": [68, 0, 77, 14, 1997, 2281], "file_path": "src/_pytest/monkeypatch.py", "content": "def annotated_getattr(obj, name, ann):\n    try:\n        obj = getattr(obj, name)\n    except AttributeError:\n        raise AttributeError(\n            \"{!r} object at {} has no attribute {!r}\".format(\n                type(obj).__name__, ann, name\n            )\n        )\n    return obj"}, {"id": "_pytest.monkeypatch.derive_importpath", "kind": "function", "range": [80, 0, 89, 23, 2284, 2677], "file_path": "src/_pytest/monkeypatch.py", "content": "def derive_importpath(import_path, raising):\n    if not isinstance(import_path, str) or \".\" not in import_path:\n        raise TypeError(\n            \"must be absolute import path string, not {!r}\".format(import_path)\n        )\n    module, attr = import_path.rsplit(\".\", 1)\n    target = resolve(module)\n    if raising:\n        annotated_getattr(target, attr, ann=module)\n    return attr, target"}, {"id": "_pytest.monkeypatch.Notset", "kind": "class", "range": [92, 0, 94, 25, 2680, 2743], "file_path": "src/_pytest/monkeypatch.py", "content": "class Notset:\n    def __repr__(self):\n        return \"<notset>\""}, {"id": "_pytest.monkeypatch.Notset.__repr__", "kind": "function", "range": [93, 4, 94, 25, 2698, 2743], "file_path": "src/_pytest/monkeypatch.py", "content": "def __repr__(self):\n        return \"<notset>\""}, {"id": "_pytest.monkeypatch.notset", "kind": "variable", "range": [97, 0, 97, 17, 2746, 2763], "file_path": "src/_pytest/monkeypatch.py", "content": "notset = Notset()"}, {"id": "_pytest.monkeypatch.MonkeyPatch", "kind": "class", "range": [100, 0, 323, 28, 2766, 11401], "file_path": "src/_pytest/monkeypatch.py", "content": "class MonkeyPatch:\n    \"\"\" Object returned by the ``monkeypatch`` fixture keeping a record of setattr/item/env/syspath changes.\n    \"\"\"\n\n    def __init__(self):\n        self._setattr = []\n        self._setitem = []\n        self._cwd = None\n        self._savesyspath = None\n\n    @contextmanager\n    def context(self) -> Generator[\"MonkeyPatch\", None, None]:\n        \"\"\"\n        Context manager that returns a new :class:`MonkeyPatch` object which\n        undoes any patching done inside the ``with`` block upon exit:\n\n        .. code-block:: python\n\n            import functools\n\n\n            def test_partial(monkeypatch):\n                with monkeypatch.context() as m:\n                    m.setattr(functools, \"partial\", 3)\n\n        Useful in situations where it is desired to undo some patches before the test ends,\n        such as mocking ``stdlib`` functions that might break pytest itself if mocked (for examples\n        of this see `#3290 <https://github.com/pytest-dev/pytest/issues/3290>`_.\n        \"\"\"\n        m = MonkeyPatch()\n        try:\n            yield m\n        finally:\n            m.undo()\n\n    def setattr(self, target, name, value=notset, raising=True):\n        \"\"\" Set attribute value on target, memorizing the old value.\n        By default raise AttributeError if the attribute did not exist.\n\n        For convenience you can specify a string as ``target`` which\n        will be interpreted as a dotted import path, with the last part\n        being the attribute name.  Example:\n        ``monkeypatch.setattr(\"os.getcwd\", lambda: \"/\")``\n        would set the ``getcwd`` function of the ``os`` module.\n\n        The ``raising`` value determines if the setattr should fail\n        if the attribute is not already present (defaults to True\n        which means it will raise).\n        \"\"\"\n        __tracebackhide__ = True\n        import inspect\n\n        if value is notset:\n            if not isinstance(target, str):\n                raise TypeError(\n                    \"use setattr(target, name, value) or \"\n                    \"setattr(target, value) with target being a dotted \"\n                    \"import string\"\n                )\n            value = name\n            name, target = derive_importpath(target, raising)\n\n        oldval = getattr(target, name, notset)\n        if raising and oldval is notset:\n            raise AttributeError(\"{!r} has no attribute {!r}\".format(target, name))\n\n        # avoid class descriptors like staticmethod/classmethod\n        if inspect.isclass(target):\n            oldval = target.__dict__.get(name, notset)\n        self._setattr.append((target, name, oldval))\n        setattr(target, name, value)\n\n    def delattr(self, target, name=notset, raising=True):\n        \"\"\" Delete attribute ``name`` from ``target``, by default raise\n        AttributeError it the attribute did not previously exist.\n\n        If no ``name`` is specified and ``target`` is a string\n        it will be interpreted as a dotted import path with the\n        last part being the attribute name.\n\n        If ``raising`` is set to False, no exception will be raised if the\n        attribute is missing.\n        \"\"\"\n        __tracebackhide__ = True\n        import inspect\n\n        if name is notset:\n            if not isinstance(target, str):\n                raise TypeError(\n                    \"use delattr(target, name) or \"\n                    \"delattr(target) with target being a dotted \"\n                    \"import string\"\n                )\n            name, target = derive_importpath(target, raising)\n\n        if not hasattr(target, name):\n            if raising:\n                raise AttributeError(name)\n        else:\n            oldval = getattr(target, name, notset)\n            # Avoid class descriptors like staticmethod/classmethod.\n            if inspect.isclass(target):\n                oldval = target.__dict__.get(name, notset)\n            self._setattr.append((target, name, oldval))\n            delattr(target, name)\n\n    def setitem(self, dic, name, value):\n        \"\"\" Set dictionary entry ``name`` to value. \"\"\"\n        self._setitem.append((dic, name, dic.get(name, notset)))\n        dic[name] = value\n\n    def delitem(self, dic, name, raising=True):\n        \"\"\" Delete ``name`` from dict. Raise KeyError if it doesn't exist.\n\n        If ``raising`` is set to False, no exception will be raised if the\n        key is missing.\n        \"\"\"\n        if name not in dic:\n            if raising:\n                raise KeyError(name)\n        else:\n            self._setitem.append((dic, name, dic.get(name, notset)))\n            del dic[name]\n\n    def setenv(self, name, value, prepend=None):\n        \"\"\" Set environment variable ``name`` to ``value``.  If ``prepend``\n        is a character, read the current environment variable value\n        and prepend the ``value`` adjoined with the ``prepend`` character.\"\"\"\n        if not isinstance(value, str):\n            warnings.warn(\n                pytest.PytestWarning(\n                    \"Value of environment variable {name} type should be str, but got \"\n                    \"{value!r} (type: {type}); converted to str implicitly\".format(\n                        name=name, value=value, type=type(value).__name__\n                    )\n                ),\n                stacklevel=2,\n            )\n            value = str(value)\n        if prepend and name in os.environ:\n            value = value + prepend + os.environ[name]\n        self.setitem(os.environ, name, value)\n\n    def delenv(self, name, raising=True):\n        \"\"\" Delete ``name`` from the environment. Raise KeyError if it does\n        not exist.\n\n        If ``raising`` is set to False, no exception will be raised if the\n        environment variable is missing.\n        \"\"\"\n        self.delitem(os.environ, name, raising=raising)\n\n    def syspath_prepend(self, path):\n        \"\"\" Prepend ``path`` to ``sys.path`` list of import locations. \"\"\"\n        from pkg_resources import fixup_namespace_packages\n\n        if self._savesyspath is None:\n            self._savesyspath = sys.path[:]\n        sys.path.insert(0, str(path))\n\n        # https://github.com/pypa/setuptools/blob/d8b901bc/docs/pkg_resources.txt#L162-L171\n        fixup_namespace_packages(str(path))\n\n        # A call to syspathinsert() usually means that the caller wants to\n        # import some dynamically created files, thus with python3 we\n        # invalidate its import caches.\n        # This is especially important when any namespace package is in use,\n        # since then the mtime based FileFinder cache (that gets created in\n        # this case already) gets not invalidated when writing the new files\n        # quickly afterwards.\n        from importlib import invalidate_caches\n\n        invalidate_caches()\n\n    def chdir(self, path):\n        \"\"\" Change the current working directory to the specified path.\n        Path can be a string or a py.path.local object.\n        \"\"\"\n        if self._cwd is None:\n            self._cwd = os.getcwd()\n        if hasattr(path, \"chdir\"):\n            path.chdir()\n        elif isinstance(path, Path):\n            # modern python uses the fspath protocol here LEGACY\n            os.chdir(str(path))\n        else:\n            os.chdir(path)\n\n    def undo(self):\n        \"\"\" Undo previous changes.  This call consumes the\n        undo stack. Calling it a second time has no effect unless\n        you do more monkeypatching after the undo call.\n\n        There is generally no need to call `undo()`, since it is\n        called automatically during tear-down.\n\n        Note that the same `monkeypatch` fixture is used across a\n        single test function invocation. If `monkeypatch` is used both by\n        the test function itself and one of the test fixtures,\n        calling `undo()` will undo all of the changes made in\n        both functions.\n        \"\"\"\n        for obj, name, value in reversed(self._setattr):\n            if value is not notset:\n                setattr(obj, name, value)\n            else:\n                delattr(obj, name)\n        self._setattr[:] = []\n        for dictionary, name, value in reversed(self._setitem):\n            if value is notset:\n                try:\n                    del dictionary[name]\n                except KeyError:\n                    pass  # was already deleted, so we have the desired state\n            else:\n                dictionary[name] = value\n        self._setitem[:] = []\n        if self._savesyspath is not None:\n            sys.path[:] = self._savesyspath\n            self._savesyspath = None\n\n        if self._cwd is not None:\n            os.chdir(self._cwd)\n            self._cwd = None"}, {"id": "_pytest.monkeypatch.MonkeyPatch.__init__", "kind": "function", "range": [104, 4, 108, 32, 2907, 3038], "file_path": "src/_pytest/monkeypatch.py", "content": "def __init__(self):\n        self._setattr = []\n        self._setitem = []\n        self._cwd = None\n        self._savesyspath = None"}, {"id": "_pytest.monkeypatch.MonkeyPatch.context", "kind": "function", "range": [110, 4, 133, 20, 3044, 3875], "file_path": "src/_pytest/monkeypatch.py", "content": "@contextmanager\n    def context(self) -> Generator[\"MonkeyPatch\", None, None]:\n        \"\"\"\n        Context manager that returns a new :class:`MonkeyPatch` object which\n        undoes any patching done inside the ``with`` block upon exit:\n\n        .. code-block:: python\n\n            import functools\n\n\n            def test_partial(monkeypatch):\n                with monkeypatch.context() as m:\n                    m.setattr(functools, \"partial\", 3)\n\n        Useful in situations where it is desired to undo some patches before the test ends,\n        such as mocking ``stdlib`` functions that might break pytest itself if mocked (for examples\n        of this see `#3290 <https://github.com/pytest-dev/pytest/issues/3290>`_.\n        \"\"\"\n        m = MonkeyPatch()\n        try:\n            yield m\n        finally:\n            m.undo()"}, {"id": "_pytest.monkeypatch.MonkeyPatch.setattr", "kind": "function", "range": [135, 4, 170, 36, 3881, 5427], "file_path": "src/_pytest/monkeypatch.py", "content": "def setattr(self, target, name, value=notset, raising=True):\n        \"\"\" Set attribute value on target, memorizing the old value.\n        By default raise AttributeError if the attribute did not exist.\n\n        For convenience you can specify a string as ``target`` which\n        will be interpreted as a dotted import path, with the last part\n        being the attribute name.  Example:\n        ``monkeypatch.setattr(\"os.getcwd\", lambda: \"/\")``\n        would set the ``getcwd`` function of the ``os`` module.\n\n        The ``raising`` value determines if the setattr should fail\n        if the attribute is not already present (defaults to True\n        which means it will raise).\n        \"\"\"\n        __tracebackhide__ = True\n        import inspect\n\n        if value is notset:\n            if not isinstance(target, str):\n                raise TypeError(\n                    \"use setattr(target, name, value) or \"\n                    \"setattr(target, value) with target being a dotted \"\n                    \"import string\"\n                )\n            value = name\n            name, target = derive_importpath(target, raising)\n\n        oldval = getattr(target, name, notset)\n        if raising and oldval is notset:\n            raise AttributeError(\"{!r} has no attribute {!r}\".format(target, name))\n\n        # avoid class descriptors like staticmethod/classmethod\n        if inspect.isclass(target):\n            oldval = target.__dict__.get(name, notset)\n        self._setattr.append((target, name, oldval))\n        setattr(target, name, value)"}, {"id": "_pytest.monkeypatch.MonkeyPatch.delattr", "kind": "function", "range": [172, 4, 204, 33, 5433, 6739], "file_path": "src/_pytest/monkeypatch.py", "content": "def delattr(self, target, name=notset, raising=True):\n        \"\"\" Delete attribute ``name`` from ``target``, by default raise\n        AttributeError it the attribute did not previously exist.\n\n        If no ``name`` is specified and ``target`` is a string\n        it will be interpreted as a dotted import path with the\n        last part being the attribute name.\n\n        If ``raising`` is set to False, no exception will be raised if the\n        attribute is missing.\n        \"\"\"\n        __tracebackhide__ = True\n        import inspect\n\n        if name is notset:\n            if not isinstance(target, str):\n                raise TypeError(\n                    \"use delattr(target, name) or \"\n                    \"delattr(target) with target being a dotted \"\n                    \"import string\"\n                )\n            name, target = derive_importpath(target, raising)\n\n        if not hasattr(target, name):\n            if raising:\n                raise AttributeError(name)\n        else:\n            oldval = getattr(target, name, notset)\n            # Avoid class descriptors like staticmethod/classmethod.\n            if inspect.isclass(target):\n                oldval = target.__dict__.get(name, notset)\n            self._setattr.append((target, name, oldval))\n            delattr(target, name)"}, {"id": "_pytest.monkeypatch.MonkeyPatch.setitem", "kind": "function", "range": [206, 4, 209, 25, 6745, 6928], "file_path": "src/_pytest/monkeypatch.py", "content": "def setitem(self, dic, name, value):\n        \"\"\" Set dictionary entry ``name`` to value. \"\"\"\n        self._setitem.append((dic, name, dic.get(name, notset)))\n        dic[name] = value"}, {"id": "_pytest.monkeypatch.MonkeyPatch.delitem", "kind": "function", "range": [211, 4, 222, 25, 6934, 7362], "file_path": "src/_pytest/monkeypatch.py", "content": "def delitem(self, dic, name, raising=True):\n        \"\"\" Delete ``name`` from dict. Raise KeyError if it doesn't exist.\n\n        If ``raising`` is set to False, no exception will be raised if the\n        key is missing.\n        \"\"\"\n        if name not in dic:\n            if raising:\n                raise KeyError(name)\n        else:\n            self._setitem.append((dic, name, dic.get(name, notset)))\n            del dic[name]"}, {"id": "_pytest.monkeypatch.MonkeyPatch.setenv", "kind": "function", "range": [224, 4, 241, 45, 7368, 8244], "file_path": "src/_pytest/monkeypatch.py", "content": "def setenv(self, name, value, prepend=None):\n        \"\"\" Set environment variable ``name`` to ``value``.  If ``prepend``\n        is a character, read the current environment variable value\n        and prepend the ``value`` adjoined with the ``prepend`` character.\"\"\"\n        if not isinstance(value, str):\n            warnings.warn(\n                pytest.PytestWarning(\n                    \"Value of environment variable {name} type should be str, but got \"\n                    \"{value!r} (type: {type}); converted to str implicitly\".format(\n                        name=name, value=value, type=type(value).__name__\n                    )\n                ),\n                stacklevel=2,\n            )\n            value = str(value)\n        if prepend and name in os.environ:\n            value = value + prepend + os.environ[name]\n        self.setitem(os.environ, name, value)"}, {"id": "_pytest.monkeypatch.MonkeyPatch.delenv", "kind": "function", "range": [243, 4, 250, 55, 8250, 8567], "file_path": "src/_pytest/monkeypatch.py", "content": "def delenv(self, name, raising=True):\n        \"\"\" Delete ``name`` from the environment. Raise KeyError if it does\n        not exist.\n\n        If ``raising`` is set to False, no exception will be raised if the\n        environment variable is missing.\n        \"\"\"\n        self.delitem(os.environ, name, raising=raising)"}, {"id": "_pytest.monkeypatch.MonkeyPatch.syspath_prepend", "kind": "function", "range": [252, 4, 272, 27, 8573, 9520], "file_path": "src/_pytest/monkeypatch.py", "content": "def syspath_prepend(self, path):\n        \"\"\" Prepend ``path`` to ``sys.path`` list of import locations. \"\"\"\n        from pkg_resources import fixup_namespace_packages\n\n        if self._savesyspath is None:\n            self._savesyspath = sys.path[:]\n        sys.path.insert(0, str(path))\n\n        # https://github.com/pypa/setuptools/blob/d8b901bc/docs/pkg_resources.txt#L162-L171\n        fixup_namespace_packages(str(path))\n\n        # A call to syspathinsert() usually means that the caller wants to\n        # import some dynamically created files, thus with python3 we\n        # invalidate its import caches.\n        # This is especially important when any namespace package is in use,\n        # since then the mtime based FileFinder cache (that gets created in\n        # this case already) gets not invalidated when writing the new files\n        # quickly afterwards.\n        from importlib import invalidate_caches\n\n        invalidate_caches()"}, {"id": "_pytest.monkeypatch.MonkeyPatch.chdir", "kind": "function", "range": [274, 4, 286, 26, 9526, 9989], "file_path": "src/_pytest/monkeypatch.py", "content": "def chdir(self, path):\n        \"\"\" Change the current working directory to the specified path.\n        Path can be a string or a py.path.local object.\n        \"\"\"\n        if self._cwd is None:\n            self._cwd = os.getcwd()\n        if hasattr(path, \"chdir\"):\n            path.chdir()\n        elif isinstance(path, Path):\n            # modern python uses the fspath protocol here LEGACY\n            os.chdir(str(path))\n        else:\n            os.chdir(path)"}, {"id": "_pytest.monkeypatch.MonkeyPatch.undo", "kind": "function", "range": [288, 4, 323, 28, 9995, 11401], "file_path": "src/_pytest/monkeypatch.py", "content": "def undo(self):\n        \"\"\" Undo previous changes.  This call consumes the\n        undo stack. Calling it a second time has no effect unless\n        you do more monkeypatching after the undo call.\n\n        There is generally no need to call `undo()`, since it is\n        called automatically during tear-down.\n\n        Note that the same `monkeypatch` fixture is used across a\n        single test function invocation. If `monkeypatch` is used both by\n        the test function itself and one of the test fixtures,\n        calling `undo()` will undo all of the changes made in\n        both functions.\n        \"\"\"\n        for obj, name, value in reversed(self._setattr):\n            if value is not notset:\n                setattr(obj, name, value)\n            else:\n                delattr(obj, name)\n        self._setattr[:] = []\n        for dictionary, name, value in reversed(self._setitem):\n            if value is notset:\n                try:\n                    del dictionary[name]\n                except KeyError:\n                    pass  # was already deleted, so we have the desired state\n            else:\n                dictionary[name] = value\n        self._setitem[:] = []\n        if self._savesyspath is not None:\n            sys.path[:] = self._savesyspath\n            self._savesyspath = None\n\n        if self._cwd is not None:\n            os.chdir(self._cwd)\n            self._cwd = None"}, {"id": "_pytest.setupplan.pytest_addoption", "kind": "function", "range": [3, 0, 11, 5, 16, 293], "file_path": "src/_pytest/setupplan.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"debugconfig\")\n    group.addoption(\n        \"--setupplan\",\n        \"--setup-plan\",\n        action=\"store_true\",\n        help=\"show what fixtures and tests would be executed but \"\n        \"don't execute anything.\",\n    )"}, {"id": "_pytest.setupplan.pytest_fixture_setup", "kind": "function", "range": [14, 0, 20, 39, 296, 640], "file_path": "src/_pytest/setupplan.py", "content": "@pytest.hookimpl(tryfirst=True)\ndef pytest_fixture_setup(fixturedef, request):\n    # Will return a dummy fixture if the setuponly option is provided.\n    if request.config.option.setupplan:\n        my_cache_key = fixturedef.cache_key(request)\n        fixturedef.cached_result = (None, my_cache_key, None)\n        return fixturedef.cached_result"}, {"id": "_pytest.setupplan.pytest_cmdline_main", "kind": "function", "range": [23, 0, 27, 38, 643, 817], "file_path": "src/_pytest/setupplan.py", "content": "@pytest.hookimpl(tryfirst=True)\ndef pytest_cmdline_main(config):\n    if config.option.setupplan:\n        config.option.setuponly = True\n        config.option.setupshow = True"}, {"id": "_pytest.pathlib.__all__", "kind": "variable", "range": [27, 0, 27, 30, 592, 622], "file_path": "src/_pytest/pathlib.py", "content": "__all__ = [\"Path\", \"PurePath\"]"}, {"id": "_pytest.pathlib.LOCK_TIMEOUT", "kind": "variable", "range": [30, 0, 30, 26, 625, 651], "file_path": "src/_pytest/pathlib.py", "content": "LOCK_TIMEOUT = 60 * 60 * 3"}, {"id": "_pytest.pathlib._AnyPurePath", "kind": "variable", "range": [33, 0, 33, 54, 654, 708], "file_path": "src/_pytest/pathlib.py", "content": "_AnyPurePath = TypeVar(\"_AnyPurePath\", bound=PurePath)"}, {"id": "_pytest.pathlib.get_lock_path", "kind": "function", "range": [36, 0, 37, 33, 711, 799], "file_path": "src/_pytest/pathlib.py", "content": "def get_lock_path(path: _AnyPurePath) -> _AnyPurePath:\n    return path.joinpath(\".lock\")"}, {"id": "_pytest.pathlib.ensure_reset_dir", "kind": "function", "range": [40, 0, 46, 16, 802, 967], "file_path": "src/_pytest/pathlib.py", "content": "def ensure_reset_dir(path: Path) -> None:\n    \"\"\"\n    ensures the given path is an empty directory\n    \"\"\"\n    if path.exists():\n        rm_rf(path)\n    path.mkdir()"}, {"id": "_pytest.pathlib.on_rm_rf_error", "kind": "function", "range": [49, 0, 99, 15, 970, 2594], "file_path": "src/_pytest/pathlib.py", "content": "def on_rm_rf_error(func, path: str, exc, *, start_path: Path) -> bool:\n    \"\"\"Handles known read-only errors during rmtree.\n\n    The returned value is used only by our own tests.\n    \"\"\"\n    exctype, excvalue = exc[:2]\n\n    # another process removed the file in the middle of the \"rm_rf\" (xdist for example)\n    # more context: https://github.com/pytest-dev/pytest/issues/5974#issuecomment-543799018\n    if isinstance(excvalue, FileNotFoundError):\n        return False\n\n    if not isinstance(excvalue, PermissionError):\n        warnings.warn(\n            PytestWarning(\n                \"(rm_rf) error removing {}\\n{}: {}\".format(path, exctype, excvalue)\n            )\n        )\n        return False\n\n    if func not in (os.rmdir, os.remove, os.unlink):\n        if func not in (os.open,):\n            warnings.warn(\n                PytestWarning(\n                    \"(rm_rf) unknown function {} when removing {}:\\n{}: {}\".format(\n                        func, path, exctype, excvalue\n                    )\n                )\n            )\n        return False\n\n    # Chmod + retry.\n    import stat\n\n    def chmod_rw(p: str) -> None:\n        mode = os.stat(p).st_mode\n        os.chmod(p, mode | stat.S_IRUSR | stat.S_IWUSR)\n\n    # For files, we need to recursively go upwards in the directories to\n    # ensure they all are also writable.\n    p = Path(path)\n    if p.is_file():\n        for parent in p.parents:\n            chmod_rw(str(parent))\n            # stop when we reach the original path passed to rm_rf\n            if parent == start_path:\n                break\n    chmod_rw(str(path))\n\n    func(path)\n    return True"}, {"id": "_pytest.pathlib.rm_rf", "kind": "function", "range": [102, 0, 107, 45, 2597, 2822], "file_path": "src/_pytest/pathlib.py", "content": "def rm_rf(path: Path) -> None:\n    \"\"\"Remove the path contents recursively, even if some elements\n    are read-only.\n    \"\"\"\n    onerror = partial(on_rm_rf_error, start_path=path)\n    shutil.rmtree(str(path), onerror=onerror)"}, {"id": "_pytest.pathlib.find_prefixed", "kind": "function", "range": [110, 0, 115, 19, 2825, 3095], "file_path": "src/_pytest/pathlib.py", "content": "def find_prefixed(root: Path, prefix: str) -> Iterator[Path]:\n    \"\"\"finds all elements in root that begin with the prefix, case insensitive\"\"\"\n    l_prefix = prefix.lower()\n    for x in root.iterdir():\n        if x.name.lower().startswith(l_prefix):\n            yield x"}, {"id": "_pytest.pathlib.extract_suffixes", "kind": "function", "range": [118, 0, 126, 28, 3098, 3416], "file_path": "src/_pytest/pathlib.py", "content": "def extract_suffixes(iter: Iterable[PurePath], prefix: str) -> Iterator[str]:\n    \"\"\"\n    :param iter: iterator over path names\n    :param prefix: expected prefix of the path names\n    :returns: the parts of the paths following the prefix\n    \"\"\"\n    p_len = len(prefix)\n    for p in iter:\n        yield p.name[p_len:]"}, {"id": "_pytest.pathlib.find_suffixes", "kind": "function", "range": [129, 0, 132, 64, 3419, 3603], "file_path": "src/_pytest/pathlib.py", "content": "def find_suffixes(root: Path, prefix: str) -> Iterator[str]:\n    \"\"\"combines find_prefixes and extract_suffixes\n    \"\"\"\n    return extract_suffixes(find_prefixed(root, prefix), prefix)"}, {"id": "_pytest.pathlib.parse_num", "kind": "function", "range": [135, 0, 140, 17, 3606, 3777], "file_path": "src/_pytest/pathlib.py", "content": "def parse_num(maybe_num) -> int:\n    \"\"\"parses number path suffixes, returns -1 on error\"\"\"\n    try:\n        return int(maybe_num)\n    except ValueError:\n        return -1"}, {"id": "_pytest.pathlib._force_symlink", "kind": "function", "range": [143, 0, 162, 12, 3780, 4379], "file_path": "src/_pytest/pathlib.py", "content": "def _force_symlink(\n    root: Path, target: Union[str, PurePath], link_to: Union[str, Path]\n) -> None:\n    \"\"\"helper to create the current symlink\n\n    it's full of race conditions that are reasonably ok to ignore\n    for the context of best effort linking to the latest test run\n\n    the presumption being that in case of much parallelism\n    the inaccuracy is going to be acceptable\n    \"\"\"\n    current_symlink = root.joinpath(target)\n    try:\n        current_symlink.unlink()\n    except OSError:\n        pass\n    try:\n        current_symlink.symlink_to(link_to)\n    except Exception:\n        pass"}, {"id": "_pytest.pathlib.make_numbered_dir", "kind": "function", "range": [165, 0, 183, 9, 4382, 5157], "file_path": "src/_pytest/pathlib.py", "content": "def make_numbered_dir(root: Path, prefix: str) -> Path:\n    \"\"\"create a directory with an increased number as suffix for the given prefix\"\"\"\n    for i in range(10):\n        # try up to 10 times to create the folder\n        max_existing = max(map(parse_num, find_suffixes(root, prefix)), default=-1)\n        new_number = max_existing + 1\n        new_path = root.joinpath(\"{}{}\".format(prefix, new_number))\n        try:\n            new_path.mkdir()\n        except Exception:\n            pass\n        else:\n            _force_symlink(root, prefix + \"current\", new_path)\n            return new_path\n    else:\n        raise OSError(\n            \"could not create numbered dir with prefix \"\n            \"{prefix} in {root} after 10 tries\".format(prefix=prefix, root=root)\n        )"}, {"id": "_pytest.pathlib.create_cleanup_lock", "kind": "function", "range": [186, 0, 200, 24, 5160, 5753], "file_path": "src/_pytest/pathlib.py", "content": "def create_cleanup_lock(p: Path) -> Path:\n    \"\"\"crates a lock to prevent premature folder cleanup\"\"\"\n    lock_path = get_lock_path(p)\n    try:\n        fd = os.open(str(lock_path), os.O_WRONLY | os.O_CREAT | os.O_EXCL, 0o644)\n    except FileExistsError as e:\n        raise OSError(\"cannot create lockfile in {path}\".format(path=p)) from e\n    else:\n        pid = os.getpid()\n        spid = str(pid).encode()\n        os.write(fd, spid)\n        os.close(fd)\n        if not lock_path.is_file():\n            raise OSError(\"lock path got renamed after successful creation\")\n        return lock_path"}, {"id": "_pytest.pathlib.register_cleanup_lock_removal", "kind": "function", "range": [203, 0, 217, 36, 5756, 6259], "file_path": "src/_pytest/pathlib.py", "content": "def register_cleanup_lock_removal(lock_path: Path, register=atexit.register):\n    \"\"\"registers a cleanup function for removing a lock, by default on atexit\"\"\"\n    pid = os.getpid()\n\n    def cleanup_on_exit(lock_path: Path = lock_path, original_pid: int = pid) -> None:\n        current_pid = os.getpid()\n        if current_pid != original_pid:\n            # fork\n            return\n        try:\n            lock_path.unlink()\n        except OSError:\n            pass\n\n    return register(cleanup_on_exit)"}, {"id": "_pytest.pathlib.maybe_delete_a_numbered_dir", "kind": "function", "range": [220, 0, 243, 20, 6262, 7100], "file_path": "src/_pytest/pathlib.py", "content": "def maybe_delete_a_numbered_dir(path: Path) -> None:\n    \"\"\"removes a numbered directory if its lock can be obtained and it does not seem to be in use\"\"\"\n    lock_path = None\n    try:\n        lock_path = create_cleanup_lock(path)\n        parent = path.parent\n\n        garbage = parent.joinpath(\"garbage-{}\".format(uuid.uuid4()))\n        path.rename(garbage)\n        rm_rf(garbage)\n    except OSError:\n        #  known races:\n        #  * other process did a cleanup at the same time\n        #  * deletable folder was found\n        #  * process cwd (Windows)\n        return\n    finally:\n        # if we created the lock, ensure we remove it even if we failed\n        # to properly remove the numbered dir\n        if lock_path is not None:\n            try:\n                lock_path.unlink()\n            except OSError:\n                pass"}, {"id": "_pytest.pathlib.ensure_deletable", "kind": "function", "range": [246, 0, 262, 24, 7103, 7637], "file_path": "src/_pytest/pathlib.py", "content": "def ensure_deletable(path: Path, consider_lock_dead_if_created_before: float) -> bool:\n    \"\"\"checks if a lock exists and breaks it if its considered dead\"\"\"\n    if path.is_symlink():\n        return False\n    lock = get_lock_path(path)\n    if not lock.exists():\n        return True\n    try:\n        lock_time = lock.stat().st_mtime\n    except Exception:\n        return False\n    else:\n        if lock_time < consider_lock_dead_if_created_before:\n            lock.unlink()\n            return True\n        else:\n            return False"}, {"id": "_pytest.pathlib.try_cleanup", "kind": "function", "range": [265, 0, 268, 41, 7640, 7900], "file_path": "src/_pytest/pathlib.py", "content": "def try_cleanup(path: Path, consider_lock_dead_if_created_before: float) -> None:\n    \"\"\"tries to cleanup a folder if we can ensure it's deletable\"\"\"\n    if ensure_deletable(path, consider_lock_dead_if_created_before):\n        maybe_delete_a_numbered_dir(path)"}, {"id": "_pytest.pathlib.cleanup_candidates", "kind": "function", "range": [271, 0, 280, 22, 7903, 8426], "file_path": "src/_pytest/pathlib.py", "content": "def cleanup_candidates(root: Path, prefix: str, keep: int) -> Iterator[Path]:\n    \"\"\"lists candidates for numbered directories to be removed - follows py.path\"\"\"\n    max_existing = max(map(parse_num, find_suffixes(root, prefix)), default=-1)\n    max_delete = max_existing - keep\n    paths = find_prefixed(root, prefix)\n    paths, paths2 = itertools.tee(paths)\n    numbers = map(parse_num, extract_suffixes(paths2, prefix))\n    for path, number in zip(paths, numbers):\n        if number <= max_delete:\n            yield path"}, {"id": "_pytest.pathlib.cleanup_numbered_dir", "kind": "function", "range": [283, 0, 290, 63, 8429, 8828], "file_path": "src/_pytest/pathlib.py", "content": "def cleanup_numbered_dir(\n    root: Path, prefix: str, keep: int, consider_lock_dead_if_created_before: float\n) -> None:\n    \"\"\"cleanup for lock driven numbered directories\"\"\"\n    for path in cleanup_candidates(root, prefix, keep):\n        try_cleanup(path, consider_lock_dead_if_created_before)\n    for path in root.glob(\"garbage-*\"):\n        try_cleanup(path, consider_lock_dead_if_created_before)"}, {"id": "_pytest.pathlib.make_numbered_dir_with_cleanup", "kind": "function", "range": [293, 0, 315, 11, 8831, 9642], "file_path": "src/_pytest/pathlib.py", "content": "def make_numbered_dir_with_cleanup(\n    root: Path, prefix: str, keep: int, lock_timeout: float\n) -> Path:\n    \"\"\"creates a numbered dir with a cleanup lock and removes old ones\"\"\"\n    e = None\n    for i in range(10):\n        try:\n            p = make_numbered_dir(root, prefix)\n            lock_path = create_cleanup_lock(p)\n            register_cleanup_lock_removal(lock_path)\n        except Exception as exc:\n            e = exc\n        else:\n            consider_lock_dead_if_created_before = p.stat().st_mtime - lock_timeout\n            cleanup_numbered_dir(\n                root=root,\n                prefix=prefix,\n                keep=keep,\n                consider_lock_dead_if_created_before=consider_lock_dead_if_created_before,\n            )\n            return p\n    assert e is not None\n    raise e"}, {"id": "_pytest.pathlib.resolve_from_str", "kind": "function", "range": [318, 0, 326, 35, 9645, 9916], "file_path": "src/_pytest/pathlib.py", "content": "def resolve_from_str(input, root):\n    assert not isinstance(input, Path), \"would break on py2\"\n    root = Path(root)\n    input = expanduser(input)\n    input = expandvars(input)\n    if isabs(input):\n        return Path(input)\n    else:\n        return root.joinpath(input)"}, {"id": "_pytest.pathlib.fnmatch_ex", "kind": "function", "range": [329, 0, 361, 41, 9919, 11286], "file_path": "src/_pytest/pathlib.py", "content": "def fnmatch_ex(pattern: str, path) -> bool:\n    \"\"\"FNMatcher port from py.path.common which works with PurePath() instances.\n\n    The difference between this algorithm and PurePath.match() is that the latter matches \"**\" glob expressions\n    for each part of the path, while this algorithm uses the whole path instead.\n\n    For example:\n        \"tests/foo/bar/doc/test_foo.py\" matches pattern \"tests/**/doc/test*.py\" with this algorithm, but not with\n        PurePath.match().\n\n    This algorithm was ported to keep backward-compatibility with existing settings which assume paths match according\n    this logic.\n\n    References:\n    * https://bugs.python.org/issue29249\n    * https://bugs.python.org/issue34731\n    \"\"\"\n    path = PurePath(path)\n    iswin32 = sys.platform.startswith(\"win\")\n\n    if iswin32 and sep not in pattern and posix_sep in pattern:\n        # Running on Windows, the pattern has no Windows path separators,\n        # and the pattern has one or more Posix path separators. Replace\n        # the Posix path separators with the Windows path separator.\n        pattern = pattern.replace(posix_sep, sep)\n\n    if sep not in pattern:\n        name = path.name\n    else:\n        name = str(path)\n        if path.is_absolute() and not os.path.isabs(pattern):\n            pattern = \"*{}{}\".format(os.sep, pattern)\n    return fnmatch.fnmatch(name, pattern)"}, {"id": "_pytest.pathlib.parts", "kind": "function", "range": [364, 0, 366, 71, 11289, 11416], "file_path": "src/_pytest/pathlib.py", "content": "def parts(s: str) -> Set[str]:\n    parts = s.split(sep)\n    return {sep.join(parts[: i + 1]) or sep for i in range(len(parts))}"}, {"id": "_pytest.freeze_support.freeze_includes", "kind": "function", "range": [6, 0, 16, 17, 93, 363], "file_path": "src/_pytest/freeze_support.py", "content": "def freeze_includes():\n    \"\"\"\n    Returns a list of module names used by pytest that should be\n    included by cx_freeze.\n    \"\"\"\n    import py\n    import _pytest\n\n    result = list(_iter_all_modules(py))\n    result += list(_iter_all_modules(_pytest))\n    return result"}, {"id": "_pytest.freeze_support._iter_all_modules", "kind": "function", "range": [19, 0, 40, 31, 366, 1072], "file_path": "src/_pytest/freeze_support.py", "content": "def _iter_all_modules(package, prefix=\"\"):\n    \"\"\"\n    Iterates over the names of all modules that can be found in the given\n    package, recursively.\n\n        >>> import _pytest\n        >>> list(_iter_all_modules(_pytest))\n        ['_pytest._argcomplete', '_pytest._code.code', ...]\n    \"\"\"\n    import os\n    import pkgutil\n\n    if type(package) is not str:\n        path, prefix = package.__path__[0], package.__name__ + \".\"\n    else:\n        path = package\n    for _, name, is_package in pkgutil.iter_modules([path]):\n        if is_package:\n            for m in _iter_all_modules(os.path.join(path, name), prefix=name + \".\"):\n                yield prefix + m\n        else:\n            yield prefix + name"}, {"id": "_pytest.fixtures.PseudoFixtureDef", "kind": "class", "range": [44, 0, 47, 21, 1268, 1364], "file_path": "src/_pytest/fixtures.py", "content": "@attr.s(frozen=True)\nclass PseudoFixtureDef:\n    cached_result = attr.ib()\n    scope = attr.ib()"}, {"id": "_pytest.fixtures.PseudoFixtureDef.cached_result", "kind": "variable", "range": [46, 4, 46, 29, 1317, 1342], "file_path": "src/_pytest/fixtures.py", "content": "cached_result = attr.ib()"}, {"id": "_pytest.fixtures.PseudoFixtureDef.scope", "kind": "variable", "range": [47, 4, 47, 21, 1347, 1364], "file_path": "src/_pytest/fixtures.py", "content": "scope = attr.ib()"}, {"id": "_pytest.fixtures.pytest_sessionstart", "kind": "function", "range": [50, 0, 63, 53, 1367, 1795], "file_path": "src/_pytest/fixtures.py", "content": "def pytest_sessionstart(session: \"Session\"):\n    import _pytest.python\n    import _pytest.nodes\n\n    scopename2class.update(\n        {\n            \"package\": _pytest.python.Package,\n            \"class\": _pytest.python.Class,\n            \"module\": _pytest.python.Module,\n            \"function\": _pytest.nodes.Item,\n            \"session\": _pytest.main.Session,\n        }\n    )\n    session._fixturemanager = FixtureManager(session)"}, {"id": "_pytest.fixtures.scopename2class", "kind": "variable", "range": [66, 0, 66, 20, 1798, 1818], "file_path": "src/_pytest/fixtures.py", "content": "scopename2class = {}"}, {"id": "_pytest.fixtures.scope2props", "kind": "variable", "range": [68, 0, 68, 30, 1857, 1887], "file_path": "src/_pytest/fixtures.py", "content": "scope2props = dict(session=())"}, {"id": "_pytest.fixtures.scopeproperty", "kind": "function", "range": [76, 0, 89, 24, 2204, 2653], "file_path": "src/_pytest/fixtures.py", "content": "def scopeproperty(name=None, doc=None):\n    def decoratescope(func):\n        scopename = name or func.__name__\n\n        def provide(self):\n            if func.__name__ in scope2props[self.scope]:\n                return func(self)\n            raise AttributeError(\n                \"{} not available in {}-scoped context\".format(scopename, self.scope)\n            )\n\n        return property(provide, None, None, func.__doc__)\n\n    return decoratescope"}, {"id": "_pytest.fixtures.get_scope_package", "kind": "function", "range": [92, 0, 104, 18, 2656, 3045], "file_path": "src/_pytest/fixtures.py", "content": "def get_scope_package(node, fixturedef):\n    import pytest\n\n    cls = pytest.Package\n    current = node\n    fixture_package_name = \"{}/{}\".format(fixturedef.baseid, \"__init__.py\")\n    while current and (\n        type(current) is not cls or fixture_package_name != current.nodeid\n    ):\n        current = current.parent\n    if current is None:\n        return node.session\n    return current"}, {"id": "_pytest.fixtures.get_scope_node", "kind": "function", "range": [107, 0, 111, 30, 3048, 3210], "file_path": "src/_pytest/fixtures.py", "content": "def get_scope_node(node, scope):\n    cls = scopename2class.get(scope)\n    if cls is None:\n        raise ValueError(\"unknown scope\")\n    return node.getparent(cls)"}, {"id": "_pytest.fixtures.add_funcarg_pseudo_fixture_def", "kind": "function", "range": [114, 0, 169, 65, 3213, 5917], "file_path": "src/_pytest/fixtures.py", "content": "def add_funcarg_pseudo_fixture_def(collector, metafunc, fixturemanager):\n    # this function will transform all collected calls to a functions\n    # if they use direct funcargs (i.e. direct parametrization)\n    # because we want later test execution to be able to rely on\n    # an existing FixtureDef structure for all arguments.\n    # XXX we can probably avoid this algorithm  if we modify CallSpec2\n    # to directly care for creating the fixturedefs within its methods.\n    if not metafunc._calls[0].funcargs:\n        return  # this function call does not have direct parametrization\n    # collect funcargs of all callspecs into a list of values\n    arg2params = {}\n    arg2scope = {}\n    for callspec in metafunc._calls:\n        for argname, argvalue in callspec.funcargs.items():\n            assert argname not in callspec.params\n            callspec.params[argname] = argvalue\n            arg2params_list = arg2params.setdefault(argname, [])\n            callspec.indices[argname] = len(arg2params_list)\n            arg2params_list.append(argvalue)\n            if argname not in arg2scope:\n                scopenum = callspec._arg2scopenum.get(argname, scopenum_function)\n                arg2scope[argname] = scopes[scopenum]\n        callspec.funcargs.clear()\n\n    # register artificial FixtureDef's so that later at test execution\n    # time we can rely on a proper FixtureDef to exist for fixture setup.\n    arg2fixturedefs = metafunc._arg2fixturedefs\n    for argname, valuelist in arg2params.items():\n        # if we have a scope that is higher than function we need\n        # to make sure we only ever create an according fixturedef on\n        # a per-scope basis. We thus store and cache the fixturedef on the\n        # node related to the scope.\n        scope = arg2scope[argname]\n        node = None\n        if scope != \"function\":\n            node = get_scope_node(collector, scope)\n            if node is None:\n                assert scope == \"class\" and isinstance(collector, _pytest.python.Module)\n                # use module-level collector for class-scope (for now)\n                node = collector\n        if node and argname in node._name2pseudofixturedef:\n            arg2fixturedefs[argname] = [node._name2pseudofixturedef[argname]]\n        else:\n            fixturedef = FixtureDef(\n                fixturemanager,\n                \"\",\n                argname,\n                get_direct_param_fixture_func,\n                arg2scope[argname],\n                valuelist,\n                False,\n                False,\n            )\n            arg2fixturedefs[argname] = [fixturedef]\n            if node is not None:\n                node._name2pseudofixturedef[argname] = fixturedef"}, {"id": "_pytest.fixtures.getfixturemarker", "kind": "function", "range": [172, 0, 180, 19, 5920, 6278], "file_path": "src/_pytest/fixtures.py", "content": "def getfixturemarker(obj):\n    \"\"\" return fixturemarker or None if it doesn't exist or raised\n    exceptions.\"\"\"\n    try:\n        return getattr(obj, \"_pytestfixturefunction\", None)\n    except TEST_OUTCOME:\n        # some objects raise errors like request (from flask import request)\n        # we don't expect them to be fixture functions\n        return None"}, {"id": "_pytest.fixtures.get_parametrized_fixture_keys", "kind": "function", "range": [183, 0, 206, 21, 6281, 7317], "file_path": "src/_pytest/fixtures.py", "content": "def get_parametrized_fixture_keys(item, scopenum):\n    \"\"\" return list of keys for all parametrized arguments which match\n    the specified scope. \"\"\"\n    assert scopenum < scopenum_function  # function\n    try:\n        cs = item.callspec\n    except AttributeError:\n        pass\n    else:\n        # cs.indices.items() is random order of argnames.  Need to\n        # sort this so that different calls to\n        # get_parametrized_fixture_keys will be deterministic.\n        for argname, param_index in sorted(cs.indices.items()):\n            if cs._arg2scopenum[argname] != scopenum:\n                continue\n            if scopenum == 0:  # session\n                key = (argname, param_index)\n            elif scopenum == 1:  # package\n                key = (argname, param_index, item.fspath.dirpath())\n            elif scopenum == 2:  # module\n                key = (argname, param_index, item.fspath)\n            elif scopenum == 3:  # class\n                key = (argname, param_index, item.fspath, item.cls)\n            yield key"}, {"id": "_pytest.fixtures.reorder_items", "kind": "function", "range": [215, 0, 228, 80, 7550, 8142], "file_path": "src/_pytest/fixtures.py", "content": "def reorder_items(items):\n    argkeys_cache = {}\n    items_by_argkey = {}\n    for scopenum in range(0, scopenum_function):\n        argkeys_cache[scopenum] = d = {}\n        items_by_argkey[scopenum] = item_d = defaultdict(deque)\n        for item in items:\n            keys = OrderedDict.fromkeys(get_parametrized_fixture_keys(item, scopenum))\n            if keys:\n                d[item] = keys\n                for key in keys:\n                    item_d[key].append(item)\n    items = OrderedDict.fromkeys(items)\n    return list(reorder_items_atscope(items, argkeys_cache, items_by_argkey, 0))"}, {"id": "_pytest.fixtures.fix_cache_order", "kind": "function", "range": [231, 0, 234, 59, 8145, 8370], "file_path": "src/_pytest/fixtures.py", "content": "def fix_cache_order(item, argkeys_cache, items_by_argkey):\n    for scopenum in range(0, scopenum_function):\n        for key in argkeys_cache[scopenum].get(item, []):\n            items_by_argkey[scopenum][key].appendleft(item)"}, {"id": "_pytest.fixtures.reorder_items_atscope", "kind": "function", "range": [237, 0, 274, 21, 8373, 9995], "file_path": "src/_pytest/fixtures.py", "content": "def reorder_items_atscope(items, argkeys_cache, items_by_argkey, scopenum):\n    if scopenum >= scopenum_function or len(items) < 3:\n        return items\n    ignore = set()\n    items_deque = deque(items)\n    items_done = OrderedDict()\n    scoped_items_by_argkey = items_by_argkey[scopenum]\n    scoped_argkeys_cache = argkeys_cache[scopenum]\n    while items_deque:\n        no_argkey_group = OrderedDict()\n        slicing_argkey = None\n        while items_deque:\n            item = items_deque.popleft()\n            if item in items_done or item in no_argkey_group:\n                continue\n            argkeys = OrderedDict.fromkeys(\n                k for k in scoped_argkeys_cache.get(item, []) if k not in ignore\n            )\n            if not argkeys:\n                no_argkey_group[item] = None\n            else:\n                slicing_argkey, _ = argkeys.popitem()\n                # we don't have to remove relevant items from later in the deque because they'll just be ignored\n                matching_items = [\n                    i for i in scoped_items_by_argkey[slicing_argkey] if i in items\n                ]\n                for i in reversed(matching_items):\n                    fix_cache_order(i, argkeys_cache, items_by_argkey)\n                    items_deque.appendleft(i)\n                break\n        if no_argkey_group:\n            no_argkey_group = reorder_items_atscope(\n                no_argkey_group, argkeys_cache, items_by_argkey, scopenum + 1\n            )\n            for item in no_argkey_group:\n                items_done[item] = None\n        ignore.add(slicing_argkey)\n    return items_done"}, {"id": "_pytest.fixtures.fillfixtures", "kind": "function", "range": [277, 0, 297, 31, 9998, 10866], "file_path": "src/_pytest/fixtures.py", "content": "def fillfixtures(function):\n    \"\"\" fill missing funcargs for a test function. \"\"\"\n    warnings.warn(FILLFUNCARGS, stacklevel=2)\n    try:\n        request = function._request\n    except AttributeError:\n        # XXX this special code path is only expected to execute\n        # with the oejskit plugin.  It uses classes with funcargs\n        # and we thus have to work a bit to allow this.\n        fm = function.session._fixturemanager\n        fi = fm.getfixtureinfo(function.parent, function.obj, None)\n        function._fixtureinfo = fi\n        request = function._request = FixtureRequest(function)\n        request._fillfixtures()\n        # prune out funcargs for jstests\n        newfuncargs = {}\n        for name in fi.argnames:\n            newfuncargs[name] = function.funcargs[name]\n        function.funcargs = newfuncargs\n    else:\n        request._fillfixtures()"}, {"id": "_pytest.fixtures.get_direct_param_fixture_func", "kind": "function", "range": [300, 0, 301, 24, 10869, 10937], "file_path": "src/_pytest/fixtures.py", "content": "def get_direct_param_fixture_func(request):\n    return request.param"}, {"id": "_pytest.fixtures.FuncFixtureInfo", "kind": "class", "range": [304, 0, 340, 77, 10940, 12748], "file_path": "src/_pytest/fixtures.py", "content": "@attr.s(slots=True)\nclass FuncFixtureInfo:\n    # original function argument names\n    argnames = attr.ib(type=tuple)\n    # argnames that function immediately requires. These include argnames +\n    # fixture names specified via usefixtures and via autouse=True in fixture\n    # definitions.\n    initialnames = attr.ib(type=tuple)\n    names_closure = attr.ib()  # List[str]\n    name2fixturedefs = attr.ib()  # List[str, List[FixtureDef]]\n\n    def prune_dependency_tree(self):\n        \"\"\"Recompute names_closure from initialnames and name2fixturedefs\n\n        Can only reduce names_closure, which means that the new closure will\n        always be a subset of the old one. The order is preserved.\n\n        This method is needed because direct parametrization may shadow some\n        of the fixtures that were included in the originally built dependency\n        tree. In this way the dependency tree can get pruned, and the closure\n        of argnames may get reduced.\n        \"\"\"\n        closure = set()\n        working_set = set(self.initialnames)\n        while working_set:\n            argname = working_set.pop()\n            # argname may be smth not included in the original names_closure,\n            # in which case we ignore it. This currently happens with pseudo\n            # FixtureDefs which wrap 'get_direct_param_fixture_func(request)'.\n            # So they introduce the new dependency 'request' which might have\n            # been missing in the original tree (closure).\n            if argname not in closure and argname in self.names_closure:\n                closure.add(argname)\n                if argname in self.name2fixturedefs:\n                    working_set.update(self.name2fixturedefs[argname][-1].argnames)\n\n        self.names_closure[:] = sorted(closure, key=self.names_closure.index)"}, {"id": "_pytest.fixtures.FuncFixtureInfo.argnames", "kind": "variable", "range": [307, 4, 307, 34, 11026, 11056], "file_path": "src/_pytest/fixtures.py", "content": "argnames = attr.ib(type=tuple)"}, {"id": "_pytest.fixtures.FuncFixtureInfo.initialnames", "kind": "variable", "range": [311, 4, 311, 38, 11234, 11268], "file_path": "src/_pytest/fixtures.py", "content": "initialnames = attr.ib(type=tuple)"}, {"id": "_pytest.fixtures.FuncFixtureInfo.names_closure", "kind": "variable", "range": [312, 4, 312, 29, 11273, 11298], "file_path": "src/_pytest/fixtures.py", "content": "names_closure = attr.ib()"}, {"id": "_pytest.fixtures.FuncFixtureInfo.name2fixturedefs", "kind": "variable", "range": [313, 4, 313, 32, 11316, 11344], "file_path": "src/_pytest/fixtures.py", "content": "name2fixturedefs = attr.ib()"}, {"id": "_pytest.fixtures.FuncFixtureInfo.prune_dependency_tree", "kind": "function", "range": [315, 4, 340, 77, 11381, 12748], "file_path": "src/_pytest/fixtures.py", "content": "def prune_dependency_tree(self):\n        \"\"\"Recompute names_closure from initialnames and name2fixturedefs\n\n        Can only reduce names_closure, which means that the new closure will\n        always be a subset of the old one. The order is preserved.\n\n        This method is needed because direct parametrization may shadow some\n        of the fixtures that were included in the originally built dependency\n        tree. In this way the dependency tree can get pruned, and the closure\n        of argnames may get reduced.\n        \"\"\"\n        closure = set()\n        working_set = set(self.initialnames)\n        while working_set:\n            argname = working_set.pop()\n            # argname may be smth not included in the original names_closure,\n            # in which case we ignore it. This currently happens with pseudo\n            # FixtureDefs which wrap 'get_direct_param_fixture_func(request)'.\n            # So they introduce the new dependency 'request' which might have\n            # been missing in the original tree (closure).\n            if argname not in closure and argname in self.names_closure:\n                closure.add(argname)\n                if argname in self.name2fixturedefs:\n                    working_set.update(self.name2fixturedefs[argname][-1].argnames)\n\n        self.names_closure[:] = sorted(closure, key=self.names_closure.index)"}, {"id": "_pytest.fixtures.FixtureRequest", "kind": "class", "range": [343, 0, 638, 54, 12751, 24793], "file_path": "src/_pytest/fixtures.py", "content": "class FixtureRequest:\n    \"\"\" A request for a fixture from a test or fixture function.\n\n    A request object gives access to the requesting test context\n    and has an optional ``param`` attribute in case\n    the fixture is parametrized indirectly.\n    \"\"\"\n\n    def __init__(self, pyfuncitem):\n        self._pyfuncitem = pyfuncitem\n        #: fixture for which this request is being performed\n        self.fixturename = None\n        #: Scope string, one of \"function\", \"class\", \"module\", \"session\"\n        self.scope = \"function\"\n        self._fixture_defs = {}  # type: Dict[str, FixtureDef]\n        fixtureinfo = pyfuncitem._fixtureinfo\n        self._arg2fixturedefs = fixtureinfo.name2fixturedefs.copy()\n        self._arg2index = {}\n        self._fixturemanager = pyfuncitem.session._fixturemanager\n\n    @property\n    def fixturenames(self):\n        \"\"\"names of all active fixtures in this request\"\"\"\n        result = list(self._pyfuncitem._fixtureinfo.names_closure)\n        result.extend(set(self._fixture_defs).difference(result))\n        return result\n\n    @property\n    def funcargnames(self):\n        \"\"\" alias attribute for ``fixturenames`` for pre-2.3 compatibility\"\"\"\n        warnings.warn(FUNCARGNAMES, stacklevel=2)\n        return self.fixturenames\n\n    @property\n    def node(self):\n        \"\"\" underlying collection node (depends on current request scope)\"\"\"\n        return self._getscopeitem(self.scope)\n\n    def _getnextfixturedef(self, argname):\n        fixturedefs = self._arg2fixturedefs.get(argname, None)\n        if fixturedefs is None:\n            # we arrive here because of a dynamic call to\n            # getfixturevalue(argname) usage which was naturally\n            # not known at parsing/collection time\n            parentid = self._pyfuncitem.parent.nodeid\n            fixturedefs = self._fixturemanager.getfixturedefs(argname, parentid)\n            self._arg2fixturedefs[argname] = fixturedefs\n        # fixturedefs list is immutable so we maintain a decreasing index\n        index = self._arg2index.get(argname, 0) - 1\n        if fixturedefs is None or (-index > len(fixturedefs)):\n            raise FixtureLookupError(argname, self)\n        self._arg2index[argname] = index\n        return fixturedefs[index]\n\n    @property\n    def config(self):\n        \"\"\" the pytest config object associated with this request. \"\"\"\n        return self._pyfuncitem.config\n\n    @scopeproperty()\n    def function(self):\n        \"\"\" test function object if the request has a per-function scope. \"\"\"\n        return self._pyfuncitem.obj\n\n    @scopeproperty(\"class\")\n    def cls(self):\n        \"\"\" class (can be None) where the test function was collected. \"\"\"\n        clscol = self._pyfuncitem.getparent(_pytest.python.Class)\n        if clscol:\n            return clscol.obj\n\n    @property\n    def instance(self):\n        \"\"\" instance (can be None) on which test function was collected. \"\"\"\n        # unittest support hack, see _pytest.unittest.TestCaseFunction\n        try:\n            return self._pyfuncitem._testcase\n        except AttributeError:\n            function = getattr(self, \"function\", None)\n            return getattr(function, \"__self__\", None)\n\n    @scopeproperty()\n    def module(self):\n        \"\"\" python module object where the test function was collected. \"\"\"\n        return self._pyfuncitem.getparent(_pytest.python.Module).obj\n\n    @scopeproperty()\n    def fspath(self) -> py.path.local:\n        \"\"\" the file system path of the test module which collected this test. \"\"\"\n        # TODO: Remove ignore once _pyfuncitem is properly typed.\n        return self._pyfuncitem.fspath  # type: ignore\n\n    @property\n    def keywords(self):\n        \"\"\" keywords/markers dictionary for the underlying node. \"\"\"\n        return self.node.keywords\n\n    @property\n    def session(self):\n        \"\"\" pytest session object. \"\"\"\n        return self._pyfuncitem.session\n\n    def addfinalizer(self, finalizer):\n        \"\"\" add finalizer/teardown function to be called after the\n        last test within the requesting test context finished\n        execution. \"\"\"\n        # XXX usually this method is shadowed by fixturedef specific ones\n        self._addfinalizer(finalizer, scope=self.scope)\n\n    def _addfinalizer(self, finalizer, scope):\n        colitem = self._getscopeitem(scope)\n        self._pyfuncitem.session._setupstate.addfinalizer(\n            finalizer=finalizer, colitem=colitem\n        )\n\n    def applymarker(self, marker):\n        \"\"\" Apply a marker to a single test function invocation.\n        This method is useful if you don't want to have a keyword/marker\n        on all function invocations.\n\n        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object\n            created by a call to ``pytest.mark.NAME(...)``.\n        \"\"\"\n        self.node.add_marker(marker)\n\n    def raiseerror(self, msg):\n        \"\"\" raise a FixtureLookupError with the given message. \"\"\"\n        raise self._fixturemanager.FixtureLookupError(None, self, msg)\n\n    def _fillfixtures(self):\n        item = self._pyfuncitem\n        fixturenames = getattr(item, \"fixturenames\", self.fixturenames)\n        for argname in fixturenames:\n            if argname not in item.funcargs:\n                item.funcargs[argname] = self.getfixturevalue(argname)\n\n    def getfixturevalue(self, argname):\n        \"\"\" Dynamically run a named fixture function.\n\n        Declaring fixtures via function argument is recommended where possible.\n        But if you can only decide whether to use another fixture at test\n        setup time, you may use this function to retrieve it inside a fixture\n        or test function body.\n\n        :raise pytest.FixtureLookupError:\n            If the given fixture could not be found.\n        \"\"\"\n        return self._get_active_fixturedef(argname).cached_result[0]\n\n    def _get_active_fixturedef(self, argname):\n        try:\n            return self._fixture_defs[argname]\n        except KeyError:\n            try:\n                fixturedef = self._getnextfixturedef(argname)\n            except FixtureLookupError:\n                if argname == \"request\":\n                    cached_result = (self, [0], None)\n                    scope = \"function\"\n                    return PseudoFixtureDef(cached_result, scope)\n                raise\n        # remove indent to prevent the python3 exception\n        # from leaking into the call\n        self._compute_fixture_value(fixturedef)\n        self._fixture_defs[argname] = fixturedef\n        return fixturedef\n\n    def _get_fixturestack(self):\n        current = self\n        values = []\n        while 1:\n            fixturedef = getattr(current, \"_fixturedef\", None)\n            if fixturedef is None:\n                values.reverse()\n                return values\n            values.append(fixturedef)\n            current = current._parent_request\n\n    def _compute_fixture_value(self, fixturedef: \"FixtureDef\") -> None:\n        \"\"\"\n        Creates a SubRequest based on \"self\" and calls the execute method of the given fixturedef object. This will\n        force the FixtureDef object to throw away any previous results and compute a new fixture value, which\n        will be stored into the FixtureDef object itself.\n        \"\"\"\n        # prepare a subrequest object before calling fixture function\n        # (latter managed by fixturedef)\n        argname = fixturedef.argname\n        funcitem = self._pyfuncitem\n        scope = fixturedef.scope\n        try:\n            param = funcitem.callspec.getparam(argname)\n        except (AttributeError, ValueError):\n            param = NOTSET\n            param_index = 0\n            has_params = fixturedef.params is not None\n            fixtures_not_supported = getattr(funcitem, \"nofuncargs\", False)\n            if has_params and fixtures_not_supported:\n                msg = (\n                    \"{name} does not support fixtures, maybe unittest.TestCase subclass?\\n\"\n                    \"Node id: {nodeid}\\n\"\n                    \"Function type: {typename}\"\n                ).format(\n                    name=funcitem.name,\n                    nodeid=funcitem.nodeid,\n                    typename=type(funcitem).__name__,\n                )\n                fail(msg, pytrace=False)\n            if has_params:\n                frame = inspect.stack()[3]\n                frameinfo = inspect.getframeinfo(frame[0])\n                source_path = py.path.local(frameinfo.filename)\n                source_lineno = frameinfo.lineno\n                rel_source_path = source_path.relto(funcitem.config.rootdir)\n                if rel_source_path:\n                    source_path_str = rel_source_path\n                else:\n                    source_path_str = str(source_path)\n                msg = (\n                    \"The requested fixture has no parameter defined for test:\\n\"\n                    \"    {}\\n\\n\"\n                    \"Requested fixture '{}' defined in:\\n{}\"\n                    \"\\n\\nRequested here:\\n{}:{}\".format(\n                        funcitem.nodeid,\n                        fixturedef.argname,\n                        getlocation(fixturedef.func, funcitem.config.rootdir),\n                        source_path_str,\n                        source_lineno,\n                    )\n                )\n                fail(msg, pytrace=False)\n        else:\n            param_index = funcitem.callspec.indices[argname]\n            # if a parametrize invocation set a scope it will override\n            # the static scope defined with the fixture function\n            paramscopenum = funcitem.callspec._arg2scopenum.get(argname)\n            if paramscopenum is not None:\n                scope = scopes[paramscopenum]\n\n        subrequest = SubRequest(self, scope, param, param_index, fixturedef)\n\n        # check if a higher-level scoped fixture accesses a lower level one\n        subrequest._check_scope(argname, self.scope, scope)\n        try:\n            # call the fixture function\n            fixturedef.execute(request=subrequest)\n        finally:\n            self._schedule_finalizers(fixturedef, subrequest)\n\n    def _schedule_finalizers(self, fixturedef, subrequest):\n        # if fixture function failed it might have registered finalizers\n        self.session._setupstate.addfinalizer(\n            functools.partial(fixturedef.finish, request=subrequest), subrequest.node\n        )\n\n    def _check_scope(self, argname, invoking_scope, requested_scope):\n        if argname == \"request\":\n            return\n        if scopemismatch(invoking_scope, requested_scope):\n            # try to report something helpful\n            lines = self._factorytraceback()\n            fail(\n                \"ScopeMismatch: You tried to access the %r scoped \"\n                \"fixture %r with a %r scoped request object, \"\n                \"involved factories\\n%s\"\n                % ((requested_scope, argname, invoking_scope, \"\\n\".join(lines))),\n                pytrace=False,\n            )\n\n    def _factorytraceback(self):\n        lines = []\n        for fixturedef in self._get_fixturestack():\n            factory = fixturedef.func\n            fs, lineno = getfslineno(factory)\n            p = self._pyfuncitem.session.fspath.bestrelpath(fs)\n            args = _format_args(factory)\n            lines.append(\"%s:%d:  def %s%s\" % (p, lineno + 1, factory.__name__, args))\n        return lines\n\n    def _getscopeitem(self, scope):\n        if scope == \"function\":\n            # this might also be a non-function Item despite its attribute name\n            return self._pyfuncitem\n        if scope == \"package\":\n            node = get_scope_package(self._pyfuncitem, self._fixturedef)\n        else:\n            node = get_scope_node(self._pyfuncitem, scope)\n        if node is None and scope == \"class\":\n            # fallback to function item itself\n            node = self._pyfuncitem\n        assert node, 'Could not obtain a node for scope \"{}\" for function {!r}'.format(\n            scope, self._pyfuncitem\n        )\n        return node\n\n    def __repr__(self):\n        return \"<FixtureRequest for %r>\" % (self.node)"}, {"id": "_pytest.fixtures.FixtureRequest.__init__", "kind": "function", "range": [351, 4, 361, 65, 13013, 13552], "file_path": "src/_pytest/fixtures.py", "content": "def __init__(self, pyfuncitem):\n        self._pyfuncitem = pyfuncitem\n        #: fixture for which this request is being performed\n        self.fixturename = None\n        #: Scope string, one of \"function\", \"class\", \"module\", \"session\"\n        self.scope = \"function\"\n        self._fixture_defs = {}  # type: Dict[str, FixtureDef]\n        fixtureinfo = pyfuncitem._fixtureinfo\n        self._arg2fixturedefs = fixtureinfo.name2fixturedefs.copy()\n        self._arg2index = {}\n        self._fixturemanager = pyfuncitem.session._fixturemanager"}, {"id": "_pytest.fixtures.FixtureRequest.fixturenames", "kind": "function", "range": [363, 4, 368, 21, 13558, 13809], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def fixturenames(self):\n        \"\"\"names of all active fixtures in this request\"\"\"\n        result = list(self._pyfuncitem._fixtureinfo.names_closure)\n        result.extend(set(self._fixture_defs).difference(result))\n        return result"}, {"id": "_pytest.fixtures.FixtureRequest.funcargnames", "kind": "function", "range": [370, 4, 374, 32, 13815, 14013], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def funcargnames(self):\n        \"\"\" alias attribute for ``fixturenames`` for pre-2.3 compatibility\"\"\"\n        warnings.warn(FUNCARGNAMES, stacklevel=2)\n        return self.fixturenames"}, {"id": "_pytest.fixtures.FixtureRequest.node", "kind": "function", "range": [376, 4, 379, 45, 14019, 14171], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def node(self):\n        \"\"\" underlying collection node (depends on current request scope)\"\"\"\n        return self._getscopeitem(self.scope)"}, {"id": "_pytest.fixtures.FixtureRequest._getnextfixturedef", "kind": "function", "range": [381, 4, 395, 33, 14177, 14992], "file_path": "src/_pytest/fixtures.py", "content": "def _getnextfixturedef(self, argname):\n        fixturedefs = self._arg2fixturedefs.get(argname, None)\n        if fixturedefs is None:\n            # we arrive here because of a dynamic call to\n            # getfixturevalue(argname) usage which was naturally\n            # not known at parsing/collection time\n            parentid = self._pyfuncitem.parent.nodeid\n            fixturedefs = self._fixturemanager.getfixturedefs(argname, parentid)\n            self._arg2fixturedefs[argname] = fixturedefs\n        # fixturedefs list is immutable so we maintain a decreasing index\n        index = self._arg2index.get(argname, 0) - 1\n        if fixturedefs is None or (-index > len(fixturedefs)):\n            raise FixtureLookupError(argname, self)\n        self._arg2index[argname] = index\n        return fixturedefs[index]"}, {"id": "_pytest.fixtures.FixtureRequest.config", "kind": "function", "range": [397, 4, 400, 38, 14998, 15139], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def config(self):\n        \"\"\" the pytest config object associated with this request. \"\"\"\n        return self._pyfuncitem.config"}, {"id": "_pytest.fixtures.FixtureRequest.function", "kind": "function", "range": [402, 4, 405, 35, 15145, 15299], "file_path": "src/_pytest/fixtures.py", "content": "@scopeproperty()\n    def function(self):\n        \"\"\" test function object if the request has a per-function scope. \"\"\"\n        return self._pyfuncitem.obj"}, {"id": "_pytest.fixtures.FixtureRequest.cls", "kind": "function", "range": [407, 4, 412, 29, 15305, 15537], "file_path": "src/_pytest/fixtures.py", "content": "@scopeproperty(\"class\")\n    def cls(self):\n        \"\"\" class (can be None) where the test function was collected. \"\"\"\n        clscol = self._pyfuncitem.getparent(_pytest.python.Class)\n        if clscol:\n            return clscol.obj"}, {"id": "_pytest.fixtures.FixtureRequest.instance", "kind": "function", "range": [414, 4, 422, 54, 15543, 15924], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def instance(self):\n        \"\"\" instance (can be None) on which test function was collected. \"\"\"\n        # unittest support hack, see _pytest.unittest.TestCaseFunction\n        try:\n            return self._pyfuncitem._testcase\n        except AttributeError:\n            function = getattr(self, \"function\", None)\n            return getattr(function, \"__self__\", None)"}, {"id": "_pytest.fixtures.FixtureRequest.module", "kind": "function", "range": [424, 4, 427, 68, 15930, 16113], "file_path": "src/_pytest/fixtures.py", "content": "@scopeproperty()\n    def module(self):\n        \"\"\" python module object where the test function was collected. \"\"\"\n        return self._pyfuncitem.getparent(_pytest.python.Module).obj"}, {"id": "_pytest.fixtures.FixtureRequest.fspath", "kind": "function", "range": [429, 4, 433, 54, 16119, 16378], "file_path": "src/_pytest/fixtures.py", "content": "@scopeproperty()\n    def fspath(self) -> py.path.local:\n        \"\"\" the file system path of the test module which collected this test. \"\"\"\n        # TODO: Remove ignore once _pyfuncitem is properly typed.\n        return self._pyfuncitem.fspath  # type: ignore"}, {"id": "_pytest.fixtures.FixtureRequest.keywords", "kind": "function", "range": [435, 4, 438, 33, 16384, 16520], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def keywords(self):\n        \"\"\" keywords/markers dictionary for the underlying node. \"\"\"\n        return self.node.keywords"}, {"id": "_pytest.fixtures.FixtureRequest.session", "kind": "function", "range": [440, 4, 443, 39, 16526, 16637], "file_path": "src/_pytest/fixtures.py", "content": "@property\n    def session(self):\n        \"\"\" pytest session object. \"\"\"\n        return self._pyfuncitem.session"}, {"id": "_pytest.fixtures.FixtureRequest.addfinalizer", "kind": "function", "range": [445, 4, 450, 55, 16643, 16959], "file_path": "src/_pytest/fixtures.py", "content": "def addfinalizer(self, finalizer):\n        \"\"\" add finalizer/teardown function to be called after the\n        last test within the requesting test context finished\n        execution. \"\"\"\n        # XXX usually this method is shadowed by fixturedef specific ones\n        self._addfinalizer(finalizer, scope=self.scope)"}, {"id": "_pytest.fixtures.FixtureRequest._addfinalizer", "kind": "function", "range": [452, 4, 456, 9, 16965, 17169], "file_path": "src/_pytest/fixtures.py", "content": "def _addfinalizer(self, finalizer, scope):\n        colitem = self._getscopeitem(scope)\n        self._pyfuncitem.session._setupstate.addfinalizer(\n            finalizer=finalizer, colitem=colitem\n        )"}, {"id": "_pytest.fixtures.FixtureRequest.applymarker", "kind": "function", "range": [458, 4, 466, 36, 17175, 17559], "file_path": "src/_pytest/fixtures.py", "content": "def applymarker(self, marker):\n        \"\"\" Apply a marker to a single test function invocation.\n        This method is useful if you don't want to have a keyword/marker\n        on all function invocations.\n\n        :arg marker: a :py:class:`_pytest.mark.MarkDecorator` object\n            created by a call to ``pytest.mark.NAME(...)``.\n        \"\"\"\n        self.node.add_marker(marker)"}, {"id": "_pytest.fixtures.FixtureRequest.raiseerror", "kind": "function", "range": [468, 4, 470, 70, 17565, 17729], "file_path": "src/_pytest/fixtures.py", "content": "def raiseerror(self, msg):\n        \"\"\" raise a FixtureLookupError with the given message. \"\"\"\n        raise self._fixturemanager.FixtureLookupError(None, self, msg)"}, {"id": "_pytest.fixtures.FixtureRequest._fillfixtures", "kind": "function", "range": [472, 4, 477, 70, 17735, 18016], "file_path": "src/_pytest/fixtures.py", "content": "def _fillfixtures(self):\n        item = self._pyfuncitem\n        fixturenames = getattr(item, \"fixturenames\", self.fixturenames)\n        for argname in fixturenames:\n            if argname not in item.funcargs:\n                item.funcargs[argname] = self.getfixturevalue(argname)"}, {"id": "_pytest.fixtures.FixtureRequest.getfixturevalue", "kind": "function", "range": [479, 4, 490, 68, 18022, 18552], "file_path": "src/_pytest/fixtures.py", "content": "def getfixturevalue(self, argname):\n        \"\"\" Dynamically run a named fixture function.\n\n        Declaring fixtures via function argument is recommended where possible.\n        But if you can only decide whether to use another fixture at test\n        setup time, you may use this function to retrieve it inside a fixture\n        or test function body.\n\n        :raise pytest.FixtureLookupError:\n            If the given fixture could not be found.\n        \"\"\"\n        return self._get_active_fixturedef(argname).cached_result[0]"}, {"id": "_pytest.fixtures.FixtureRequest._get_active_fixturedef", "kind": "function", "range": [492, 4, 508, 25, 18558, 19242], "file_path": "src/_pytest/fixtures.py", "content": "def _get_active_fixturedef(self, argname):\n        try:\n            return self._fixture_defs[argname]\n        except KeyError:\n            try:\n                fixturedef = self._getnextfixturedef(argname)\n            except FixtureLookupError:\n                if argname == \"request\":\n                    cached_result = (self, [0], None)\n                    scope = \"function\"\n                    return PseudoFixtureDef(cached_result, scope)\n                raise\n        # remove indent to prevent the python3 exception\n        # from leaking into the call\n        self._compute_fixture_value(fixturedef)\n        self._fixture_defs[argname] = fixturedef\n        return fixturedef"}, {"id": "_pytest.fixtures.FixtureRequest._get_fixturestack", "kind": "function", "range": [510, 4, 519, 45, 19248, 19581], "file_path": "src/_pytest/fixtures.py", "content": "def _get_fixturestack(self):\n        current = self\n        values = []\n        while 1:\n            fixturedef = getattr(current, \"_fixturedef\", None)\n            if fixturedef is None:\n                values.reverse()\n                return values\n            values.append(fixturedef)\n            current = current._parent_request"}, {"id": "_pytest.fixtures.FixtureRequest._compute_fixture_value", "kind": "function", "range": [521, 4, 589, 61, 19587, 22799], "file_path": "src/_pytest/fixtures.py", "content": "def _compute_fixture_value(self, fixturedef: \"FixtureDef\") -> None:\n        \"\"\"\n        Creates a SubRequest based on \"self\" and calls the execute method of the given fixturedef object. This will\n        force the FixtureDef object to throw away any previous results and compute a new fixture value, which\n        will be stored into the FixtureDef object itself.\n        \"\"\"\n        # prepare a subrequest object before calling fixture function\n        # (latter managed by fixturedef)\n        argname = fixturedef.argname\n        funcitem = self._pyfuncitem\n        scope = fixturedef.scope\n        try:\n            param = funcitem.callspec.getparam(argname)\n        except (AttributeError, ValueError):\n            param = NOTSET\n            param_index = 0\n            has_params = fixturedef.params is not None\n            fixtures_not_supported = getattr(funcitem, \"nofuncargs\", False)\n            if has_params and fixtures_not_supported:\n                msg = (\n                    \"{name} does not support fixtures, maybe unittest.TestCase subclass?\\n\"\n                    \"Node id: {nodeid}\\n\"\n                    \"Function type: {typename}\"\n                ).format(\n                    name=funcitem.name,\n                    nodeid=funcitem.nodeid,\n                    typename=type(funcitem).__name__,\n                )\n                fail(msg, pytrace=False)\n            if has_params:\n                frame = inspect.stack()[3]\n                frameinfo = inspect.getframeinfo(frame[0])\n                source_path = py.path.local(frameinfo.filename)\n                source_lineno = frameinfo.lineno\n                rel_source_path = source_path.relto(funcitem.config.rootdir)\n                if rel_source_path:\n                    source_path_str = rel_source_path\n                else:\n                    source_path_str = str(source_path)\n                msg = (\n                    \"The requested fixture has no parameter defined for test:\\n\"\n                    \"    {}\\n\\n\"\n                    \"Requested fixture '{}' defined in:\\n{}\"\n                    \"\\n\\nRequested here:\\n{}:{}\".format(\n                        funcitem.nodeid,\n                        fixturedef.argname,\n                        getlocation(fixturedef.func, funcitem.config.rootdir),\n                        source_path_str,\n                        source_lineno,\n                    )\n                )\n                fail(msg, pytrace=False)\n        else:\n            param_index = funcitem.callspec.indices[argname]\n            # if a parametrize invocation set a scope it will override\n            # the static scope defined with the fixture function\n            paramscopenum = funcitem.callspec._arg2scopenum.get(argname)\n            if paramscopenum is not None:\n                scope = scopes[paramscopenum]\n\n        subrequest = SubRequest(self, scope, param, param_index, fixturedef)\n\n        # check if a higher-level scoped fixture accesses a lower level one\n        subrequest._check_scope(argname, self.scope, scope)\n        try:\n            # call the fixture function\n            fixturedef.execute(request=subrequest)\n        finally:\n            self._schedule_finalizers(fixturedef, subrequest)"}, {"id": "_pytest.fixtures.FixtureRequest._schedule_finalizers", "kind": "function", "range": [591, 4, 595, 9, 22805, 23076], "file_path": "src/_pytest/fixtures.py", "content": "def _schedule_finalizers(self, fixturedef, subrequest):\n        # if fixture function failed it might have registered finalizers\n        self.session._setupstate.addfinalizer(\n            functools.partial(fixturedef.finish, request=subrequest), subrequest.node\n        )"}, {"id": "_pytest.fixtures.FixtureRequest._check_scope", "kind": "function", "range": [597, 4, 609, 13, 23082, 23666], "file_path": "src/_pytest/fixtures.py", "content": "def _check_scope(self, argname, invoking_scope, requested_scope):\n        if argname == \"request\":\n            return\n        if scopemismatch(invoking_scope, requested_scope):\n            # try to report something helpful\n            lines = self._factorytraceback()\n            fail(\n                \"ScopeMismatch: You tried to access the %r scoped \"\n                \"fixture %r with a %r scoped request object, \"\n                \"involved factories\\n%s\"\n                % ((requested_scope, argname, invoking_scope, \"\\n\".join(lines))),\n                pytrace=False,\n            )"}, {"id": "_pytest.fixtures.FixtureRequest._factorytraceback", "kind": "function", "range": [611, 4, 619, 20, 23672, 24068], "file_path": "src/_pytest/fixtures.py", "content": "def _factorytraceback(self):\n        lines = []\n        for fixturedef in self._get_fixturestack():\n            factory = fixturedef.func\n            fs, lineno = getfslineno(factory)\n            p = self._pyfuncitem.session.fspath.bestrelpath(fs)\n            args = _format_args(factory)\n            lines.append(\"%s:%d:  def %s%s\" % (p, lineno + 1, factory.__name__, args))\n        return lines"}, {"id": "_pytest.fixtures.FixtureRequest._getscopeitem", "kind": "function", "range": [621, 4, 635, 19, 24074, 24713], "file_path": "src/_pytest/fixtures.py", "content": "def _getscopeitem(self, scope):\n        if scope == \"function\":\n            # this might also be a non-function Item despite its attribute name\n            return self._pyfuncitem\n        if scope == \"package\":\n            node = get_scope_package(self._pyfuncitem, self._fixturedef)\n        else:\n            node = get_scope_node(self._pyfuncitem, scope)\n        if node is None and scope == \"class\":\n            # fallback to function item itself\n            node = self._pyfuncitem\n        assert node, 'Could not obtain a node for scope \"{}\" for function {!r}'.format(\n            scope, self._pyfuncitem\n        )\n        return node"}, {"id": "_pytest.fixtures.FixtureRequest.__repr__", "kind": "function", "range": [637, 4, 638, 54, 24719, 24793], "file_path": "src/_pytest/fixtures.py", "content": "def __repr__(self):\n        return \"<FixtureRequest for %r>\" % (self.node)"}, {"id": "_pytest.fixtures.SubRequest", "kind": "class", "range": [641, 0, 673, 60, 24796, 26209], "file_path": "src/_pytest/fixtures.py", "content": "class SubRequest(FixtureRequest):\n    \"\"\" a sub request for handling getting a fixture from a\n    test function/fixture. \"\"\"\n\n    def __init__(self, request, scope, param, param_index, fixturedef):\n        self._parent_request = request\n        self.fixturename = fixturedef.argname\n        if param is not NOTSET:\n            self.param = param\n        self.param_index = param_index\n        self.scope = scope\n        self._fixturedef = fixturedef\n        self._pyfuncitem = request._pyfuncitem\n        self._fixture_defs = request._fixture_defs\n        self._arg2fixturedefs = request._arg2fixturedefs\n        self._arg2index = request._arg2index\n        self._fixturemanager = request._fixturemanager\n\n    def __repr__(self):\n        return \"<SubRequest {!r} for {!r}>\".format(self.fixturename, self._pyfuncitem)\n\n    def addfinalizer(self, finalizer):\n        self._fixturedef.addfinalizer(finalizer)\n\n    def _schedule_finalizers(self, fixturedef, subrequest):\n        # if the executing fixturedef was not explicitly requested in the argument list (via\n        # getfixturevalue inside the fixture call) then ensure this fixture def will be finished\n        # first\n        if fixturedef.argname not in self.fixturenames:\n            fixturedef.addfinalizer(\n                functools.partial(self._fixturedef.finish, request=self)\n            )\n        super()._schedule_finalizers(fixturedef, subrequest)"}, {"id": "_pytest.fixtures.SubRequest.__init__", "kind": "function", "range": [645, 4, 657, 54, 24926, 25500], "file_path": "src/_pytest/fixtures.py", "content": "def __init__(self, request, scope, param, param_index, fixturedef):\n        self._parent_request = request\n        self.fixturename = fixturedef.argname\n        if param is not NOTSET:\n            self.param = param\n        self.param_index = param_index\n        self.scope = scope\n        self._fixturedef = fixturedef\n        self._pyfuncitem = request._pyfuncitem\n        self._fixture_defs = request._fixture_defs\n        self._arg2fixturedefs = request._arg2fixturedefs\n        self._arg2index = request._arg2index\n        self._fixturemanager = request._fixturemanager"}, {"id": "_pytest.fixtures.SubRequest.__repr__", "kind": "function", "range": [659, 4, 660, 86, 25506, 25612], "file_path": "src/_pytest/fixtures.py", "content": "def __repr__(self):\n        return \"<SubRequest {!r} for {!r}>\".format(self.fixturename, self._pyfuncitem)"}, {"id": "_pytest.fixtures.SubRequest.addfinalizer", "kind": "function", "range": [662, 4, 663, 48, 25618, 25701], "file_path": "src/_pytest/fixtures.py", "content": "def addfinalizer(self, finalizer):\n        self._fixturedef.addfinalizer(finalizer)"}, {"id": "_pytest.fixtures.SubRequest._schedule_finalizers", "kind": "function", "range": [665, 4, 673, 60, 25707, 26209], "file_path": "src/_pytest/fixtures.py", "content": "def _schedule_finalizers(self, fixturedef, subrequest):\n        # if the executing fixturedef was not explicitly requested in the argument list (via\n        # getfixturevalue inside the fixture call) then ensure this fixture def will be finished\n        # first\n        if fixturedef.argname not in self.fixturenames:\n            fixturedef.addfinalizer(\n                functools.partial(self._fixturedef.finish, request=self)\n            )\n        super()._schedule_finalizers(fixturedef, subrequest)"}, {"id": "_pytest.fixtures.scopes", "kind": "variable", "range": [676, 0, 676, 56, 26212, 26268], "file_path": "src/_pytest/fixtures.py", "content": "scopes = \"session package module class function\".split()"}, {"id": "_pytest.fixtures.scopenum_function", "kind": "variable", "range": [677, 0, 677, 44, 26269, 26313], "file_path": "src/_pytest/fixtures.py", "content": "scopenum_function = scopes.index(\"function\")"}, {"id": "_pytest.fixtures.scopemismatch", "kind": "function", "range": [680, 0, 681, 62, 26316, 26421], "file_path": "src/_pytest/fixtures.py", "content": "def scopemismatch(currentscope, newscope):\n    return scopes.index(newscope) > scopes.index(currentscope)"}, {"id": "_pytest.fixtures.scope2index", "kind": "function", "range": [684, 0, 696, 9, 26424, 26835], "file_path": "src/_pytest/fixtures.py", "content": "def scope2index(scope, descr, where=None):\n    \"\"\"Look up the index of ``scope`` and raise a descriptive value error\n    if not defined.\n    \"\"\"\n    try:\n        return scopes.index(scope)\n    except ValueError:\n        fail(\n            \"{} {}got an unexpected scope value '{}'\".format(\n                descr, \"from {} \".format(where) if where else \"\", scope\n            ),\n            pytrace=False,\n        )"}, {"id": "_pytest.fixtures.FixtureLookupError", "kind": "class", "range": [699, 0, 750, 81, 26838, 29107], "file_path": "src/_pytest/fixtures.py", "content": "class FixtureLookupError(LookupError):\n    \"\"\" could not return a requested Fixture (missing or invalid). \"\"\"\n\n    def __init__(self, argname, request, msg=None):\n        self.argname = argname\n        self.request = request\n        self.fixturestack = request._get_fixturestack()\n        self.msg = msg\n\n    def formatrepr(self) -> \"FixtureLookupErrorRepr\":\n        tblines = []  # type: List[str]\n        addline = tblines.append\n        stack = [self.request._pyfuncitem.obj]\n        stack.extend(map(lambda x: x.func, self.fixturestack))\n        msg = self.msg\n        if msg is not None:\n            # the last fixture raise an error, let's present\n            # it at the requesting side\n            stack = stack[:-1]\n        for function in stack:\n            fspath, lineno = getfslineno(function)\n            try:\n                lines, _ = inspect.getsourcelines(get_real_func(function))\n            except (OSError, IndexError, TypeError):\n                error_msg = \"file %s, line %s: source code not available\"\n                addline(error_msg % (fspath, lineno + 1))\n            else:\n                addline(\"file {}, line {}\".format(fspath, lineno + 1))\n                for i, line in enumerate(lines):\n                    line = line.rstrip()\n                    addline(\"  \" + line)\n                    if line.lstrip().startswith(\"def\"):\n                        break\n\n        if msg is None:\n            fm = self.request._fixturemanager\n            available = set()\n            parentid = self.request._pyfuncitem.parent.nodeid\n            for name, fixturedefs in fm._arg2fixturedefs.items():\n                faclist = list(fm._matchfactories(fixturedefs, parentid))\n                if faclist:\n                    available.add(name)\n            if self.argname in available:\n                msg = \" recursive dependency involving fixture '{}' detected\".format(\n                    self.argname\n                )\n            else:\n                msg = \"fixture '{}' not found\".format(self.argname)\n            msg += \"\\n available fixtures: {}\".format(\", \".join(sorted(available)))\n            msg += \"\\n use 'pytest --fixtures [testpath]' for help on them.\"\n\n        return FixtureLookupErrorRepr(fspath, lineno, tblines, msg, self.argname)"}, {"id": "_pytest.fixtures.FixtureLookupError.__init__", "kind": "function", "range": [702, 4, 706, 22, 26953, 27141], "file_path": "src/_pytest/fixtures.py", "content": "def __init__(self, argname, request, msg=None):\n        self.argname = argname\n        self.request = request\n        self.fixturestack = request._get_fixturestack()\n        self.msg = msg"}, {"id": "_pytest.fixtures.FixtureLookupError.formatrepr", "kind": "function", "range": [708, 4, 750, 81, 27147, 29107], "file_path": "src/_pytest/fixtures.py", "content": "def formatrepr(self) -> \"FixtureLookupErrorRepr\":\n        tblines = []  # type: List[str]\n        addline = tblines.append\n        stack = [self.request._pyfuncitem.obj]\n        stack.extend(map(lambda x: x.func, self.fixturestack))\n        msg = self.msg\n        if msg is not None:\n            # the last fixture raise an error, let's present\n            # it at the requesting side\n            stack = stack[:-1]\n        for function in stack:\n            fspath, lineno = getfslineno(function)\n            try:\n                lines, _ = inspect.getsourcelines(get_real_func(function))\n            except (OSError, IndexError, TypeError):\n                error_msg = \"file %s, line %s: source code not available\"\n                addline(error_msg % (fspath, lineno + 1))\n            else:\n                addline(\"file {}, line {}\".format(fspath, lineno + 1))\n                for i, line in enumerate(lines):\n                    line = line.rstrip()\n                    addline(\"  \" + line)\n                    if line.lstrip().startswith(\"def\"):\n                        break\n\n        if msg is None:\n            fm = self.request._fixturemanager\n            available = set()\n            parentid = self.request._pyfuncitem.parent.nodeid\n            for name, fixturedefs in fm._arg2fixturedefs.items():\n                faclist = list(fm._matchfactories(fixturedefs, parentid))\n                if faclist:\n                    available.add(name)\n            if self.argname in available:\n                msg = \" recursive dependency involving fixture '{}' detected\".format(\n                    self.argname\n                )\n            else:\n                msg = \"fixture '{}' not found\".format(self.argname)\n            msg += \"\\n available fixtures: {}\".format(\", \".join(sorted(available)))\n            msg += \"\\n use 'pytest --fixtures [testpath]' for help on them.\"\n\n        return FixtureLookupErrorRepr(fspath, lineno, tblines, msg, self.argname)"}, {"id": "_pytest.fixtures.FixtureLookupErrorRepr", "kind": "class", "range": [753, 0, 777, 64, 29110, 30089], "file_path": "src/_pytest/fixtures.py", "content": "class FixtureLookupErrorRepr(TerminalRepr):\n    def __init__(self, filename, firstlineno, tblines, errorstring, argname):\n        self.tblines = tblines\n        self.errorstring = errorstring\n        self.filename = filename\n        self.firstlineno = firstlineno\n        self.argname = argname\n\n    def toterminal(self, tw: TerminalWriter) -> None:\n        # tw.line(\"FixtureLookupError: %s\" %(self.argname), red=True)\n        for tbline in self.tblines:\n            tw.line(tbline.rstrip())\n        lines = self.errorstring.split(\"\\n\")\n        if lines:\n            tw.line(\n                \"{}       {}\".format(FormattedExcinfo.fail_marker, lines[0].strip()),\n                red=True,\n            )\n            for line in lines[1:]:\n                tw.line(\n                    \"{}       {}\".format(FormattedExcinfo.flow_marker, line.strip()),\n                    red=True,\n                )\n        tw.line()\n        tw.line(\"%s:%d\" % (self.filename, self.firstlineno + 1))"}, {"id": "_pytest.fixtures.FixtureLookupErrorRepr.__init__", "kind": "function", "range": [754, 4, 759, 30, 29158, 29404], "file_path": "src/_pytest/fixtures.py", "content": "def __init__(self, filename, firstlineno, tblines, errorstring, argname):\n        self.tblines = tblines\n        self.errorstring = errorstring\n        self.filename = filename\n        self.firstlineno = firstlineno\n        self.argname = argname"}, {"id": "_pytest.fixtures.FixtureLookupErrorRepr.toterminal", "kind": "function", "range": [761, 4, 777, 64, 29410, 30089], "file_path": "src/_pytest/fixtures.py", "content": "def toterminal(self, tw: TerminalWriter) -> None:\n        # tw.line(\"FixtureLookupError: %s\" %(self.argname), red=True)\n        for tbline in self.tblines:\n            tw.line(tbline.rstrip())\n        lines = self.errorstring.split(\"\\n\")\n        if lines:\n            tw.line(\n                \"{}       {}\".format(FormattedExcinfo.fail_marker, lines[0].strip()),\n                red=True,\n            )\n            for line in lines[1:]:\n                tw.line(\n                    \"{}       {}\".format(FormattedExcinfo.flow_marker, line.strip()),\n                    red=True,\n                )\n        tw.line()\n        tw.line(\"%s:%d\" % (self.filename, self.firstlineno + 1))"}, {"id": "_pytest.fixtures.fail_fixturefunc", "kind": "function", "range": [780, 0, 784, 79, 30092, 30346], "file_path": "src/_pytest/fixtures.py", "content": "def fail_fixturefunc(fixturefunc, msg):\n    fs, lineno = getfslineno(fixturefunc)\n    location = \"{}:{}\".format(fs, lineno + 1)\n    source = _pytest._code.Source(fixturefunc)\n    fail(msg + \":\\n\\n\" + str(source.indent()) + \"\\n\" + location, pytrace=False)"}, {"id": "_pytest.fixtures.call_fixture_func", "kind": "function", "range": [787, 0, 801, 25, 30349, 30924], "file_path": "src/_pytest/fixtures.py", "content": "def call_fixture_func(fixturefunc, request, kwargs):\n    yieldctx = is_generator(fixturefunc)\n    if yieldctx:\n        generator = fixturefunc(**kwargs)\n        try:\n            fixture_result = next(generator)\n        except StopIteration:\n            raise ValueError(\n                \"{} did not yield a value\".format(request.fixturename)\n            ) from None\n        finalizer = functools.partial(_teardown_yield_fixture, fixturefunc, generator)\n        request.addfinalizer(finalizer)\n    else:\n        fixture_result = fixturefunc(**kwargs)\n    return fixture_result"}, {"id": "_pytest.fixtures._teardown_yield_fixture", "kind": "function", "range": [804, 0, 814, 9, 30927, 31352], "file_path": "src/_pytest/fixtures.py", "content": "def _teardown_yield_fixture(fixturefunc, it):\n    \"\"\"Executes the teardown of a fixture function by advancing the iterator after the\n    yield and ensure the iteration ends (if not it means there is more than one yield in the function)\"\"\"\n    try:\n        next(it)\n    except StopIteration:\n        pass\n    else:\n        fail_fixturefunc(\n            fixturefunc, \"yield_fixture function has more than one 'yield'\"\n        )"}, {"id": "_pytest.fixtures._eval_scope_callable", "kind": "function", "range": [817, 0, 833, 17, 31355, 32031], "file_path": "src/_pytest/fixtures.py", "content": "def _eval_scope_callable(scope_callable, fixture_name, config):\n    try:\n        result = scope_callable(fixture_name=fixture_name, config=config)\n    except Exception:\n        raise TypeError(\n            \"Error evaluating {} while defining fixture '{}'.\\n\"\n            \"Expected a function with the signature (*, fixture_name, config)\".format(\n                scope_callable, fixture_name\n            )\n        )\n    if not isinstance(result, str):\n        fail(\n            \"Expected {} to return a 'str' while defining fixture '{}', but it returned:\\n\"\n            \"{!r}\".format(scope_callable, fixture_name, result),\n            pytrace=False,\n        )\n    return result"}, {"id": "_pytest.fixtures.FixtureDef", "kind": "class", "range": [836, 0, 930, 9, 32034, 35525], "file_path": "src/_pytest/fixtures.py", "content": "class FixtureDef:\n    \"\"\" A container for a factory definition. \"\"\"\n\n    def __init__(\n        self,\n        fixturemanager,\n        baseid,\n        argname,\n        func,\n        scope,\n        params,\n        unittest=False,\n        ids=None,\n    ):\n        self._fixturemanager = fixturemanager\n        self.baseid = baseid or \"\"\n        self.has_location = baseid is not None\n        self.func = func\n        self.argname = argname\n        if callable(scope):\n            scope = _eval_scope_callable(scope, argname, fixturemanager.config)\n        self.scope = scope\n        self.scopenum = scope2index(\n            scope or \"function\",\n            descr=\"Fixture '{}'\".format(func.__name__),\n            where=baseid,\n        )\n        self.params = params\n        self.argnames = getfuncargnames(func, name=argname, is_method=unittest)\n        self.unittest = unittest\n        self.ids = ids\n        self.cached_result = None\n        self._finalizers = []\n\n    def addfinalizer(self, finalizer):\n        self._finalizers.append(finalizer)\n\n    def finish(self, request):\n        exc = None\n        try:\n            while self._finalizers:\n                try:\n                    func = self._finalizers.pop()\n                    func()\n                except BaseException as e:\n                    # XXX Only first exception will be seen by user,\n                    #     ideally all should be reported.\n                    if exc is None:\n                        exc = e\n            if exc:\n                raise exc\n        finally:\n            hook = self._fixturemanager.session.gethookproxy(request.node.fspath)\n            hook.pytest_fixture_post_finalizer(fixturedef=self, request=request)\n            # even if finalization fails, we invalidate\n            # the cached fixture value and remove\n            # all finalizers because they may be bound methods which will\n            # keep instances alive\n            self.cached_result = None\n            self._finalizers = []\n\n    def execute(self, request):\n        # get required arguments and register our own finish()\n        # with their finalization\n        for argname in self.argnames:\n            fixturedef = request._get_active_fixturedef(argname)\n            if argname != \"request\":\n                fixturedef.addfinalizer(functools.partial(self.finish, request=request))\n\n        my_cache_key = self.cache_key(request)\n        if self.cached_result is not None:\n            result, cache_key, err = self.cached_result\n            # note: comparison with `==` can fail (or be expensive) for e.g.\n            # numpy arrays (#6497)\n            if my_cache_key is cache_key:\n                if err is not None:\n                    _, val, tb = err\n                    raise val.with_traceback(tb)\n                else:\n                    return result\n            # we have a previous but differently parametrized fixture instance\n            # so we need to tear it down before creating a new one\n            self.finish(request)\n            assert self.cached_result is None\n\n        hook = self._fixturemanager.session.gethookproxy(request.node.fspath)\n        return hook.pytest_fixture_setup(fixturedef=self, request=request)\n\n    def cache_key(self, request):\n        return request.param_index if not hasattr(request, \"param\") else request.param\n\n    def __repr__(self):\n        return \"<FixtureDef argname={!r} scope={!r} baseid={!r}>\".format(\n            self.argname, self.scope, self.baseid\n        )"}, {"id": "_pytest.fixtures.FixtureDef.__init__", "kind": "function", "range": [839, 4, 868, 29, 32107, 32995], "file_path": "src/_pytest/fixtures.py", "content": "def __init__(\n        self,\n        fixturemanager,\n        baseid,\n        argname,\n        func,\n        scope,\n        params,\n        unittest=False,\n        ids=None,\n    ):\n        self._fixturemanager = fixturemanager\n        self.baseid = baseid or \"\"\n        self.has_location = baseid is not None\n        self.func = func\n        self.argname = argname\n        if callable(scope):\n            scope = _eval_scope_callable(scope, argname, fixturemanager.config)\n        self.scope = scope\n        self.scopenum = scope2index(\n            scope or \"function\",\n            descr=\"Fixture '{}'\".format(func.__name__),\n            where=baseid,\n        )\n        self.params = params\n        self.argnames = getfuncargnames(func, name=argname, is_method=unittest)\n        self.unittest = unittest\n        self.ids = ids\n        self.cached_result = None\n        self._finalizers = []"}, {"id": "_pytest.fixtures.FixtureDef.addfinalizer", "kind": "function", "range": [870, 4, 871, 42, 33001, 33078], "file_path": "src/_pytest/fixtures.py", "content": "def addfinalizer(self, finalizer):\n        self._finalizers.append(finalizer)"}, {"id": "_pytest.fixtures.FixtureDef.finish", "kind": "function", "range": [873, 4, 895, 33, 33084, 34027], "file_path": "src/_pytest/fixtures.py", "content": "def finish(self, request):\n        exc = None\n        try:\n            while self._finalizers:\n                try:\n                    func = self._finalizers.pop()\n                    func()\n                except BaseException as e:\n                    # XXX Only first exception will be seen by user,\n                    #     ideally all should be reported.\n                    if exc is None:\n                        exc = e\n            if exc:\n                raise exc\n        finally:\n            hook = self._fixturemanager.session.gethookproxy(request.node.fspath)\n            hook.pytest_fixture_post_finalizer(fixturedef=self, request=request)\n            # even if finalization fails, we invalidate\n            # the cached fixture value and remove\n            # all finalizers because they may be bound methods which will\n            # keep instances alive\n            self.cached_result = None\n            self._finalizers = []"}, {"id": "_pytest.fixtures.FixtureDef.execute", "kind": "function", "range": [897, 4, 922, 74, 34033, 35244], "file_path": "src/_pytest/fixtures.py", "content": "def execute(self, request):\n        # get required arguments and register our own finish()\n        # with their finalization\n        for argname in self.argnames:\n            fixturedef = request._get_active_fixturedef(argname)\n            if argname != \"request\":\n                fixturedef.addfinalizer(functools.partial(self.finish, request=request))\n\n        my_cache_key = self.cache_key(request)\n        if self.cached_result is not None:\n            result, cache_key, err = self.cached_result\n            # note: comparison with `==` can fail (or be expensive) for e.g.\n            # numpy arrays (#6497)\n            if my_cache_key is cache_key:\n                if err is not None:\n                    _, val, tb = err\n                    raise val.with_traceback(tb)\n                else:\n                    return result\n            # we have a previous but differently parametrized fixture instance\n            # so we need to tear it down before creating a new one\n            self.finish(request)\n            assert self.cached_result is None\n\n        hook = self._fixturemanager.session.gethookproxy(request.node.fspath)\n        return hook.pytest_fixture_setup(fixturedef=self, request=request)"}, {"id": "_pytest.fixtures.FixtureDef.cache_key", "kind": "function", "range": [924, 4, 925, 86, 35250, 35366], "file_path": "src/_pytest/fixtures.py", "content": "def cache_key(self, request):\n        return request.param_index if not hasattr(request, \"param\") else request.param"}, {"id": "_pytest.fixtures.FixtureDef.__repr__", "kind": "function", "range": [927, 4, 930, 9, 35372, 35525], "file_path": "src/_pytest/fixtures.py", "content": "def __repr__(self):\n        return \"<FixtureDef argname={!r} scope={!r} baseid={!r}>\".format(\n            self.argname, self.scope, self.baseid\n        )"}, {"id": "_pytest.fixtures.resolve_fixture_function", "kind": "function", "range": [933, 0, 956, 22, 35528, 36715], "file_path": "src/_pytest/fixtures.py", "content": "def resolve_fixture_function(fixturedef, request):\n    \"\"\"Gets the actual callable that can be called to obtain the fixture value, dealing with unittest-specific\n    instances and bound methods.\n    \"\"\"\n    fixturefunc = fixturedef.func\n    if fixturedef.unittest:\n        if request.instance is not None:\n            # bind the unbound method to the TestCase instance\n            fixturefunc = fixturedef.func.__get__(request.instance)\n    else:\n        # the fixture function needs to be bound to the actual\n        # request.instance so that code working with \"fixturedef\" behaves\n        # as expected.\n        if request.instance is not None:\n            # handle the case where fixture is defined not in a test class, but some other class\n            # (for example a plugin class with a fixture), see #2270\n            if hasattr(fixturefunc, \"__self__\") and not isinstance(\n                request.instance, fixturefunc.__self__.__class__\n            ):\n                return fixturefunc\n            fixturefunc = getimfunc(fixturedef.func)\n            if fixturefunc != fixturedef.func:\n                fixturefunc = fixturefunc.__get__(request.instance)\n    return fixturefunc"}, {"id": "_pytest.fixtures.pytest_fixture_setup", "kind": "function", "range": [959, 0, 977, 17, 36718, 37500], "file_path": "src/_pytest/fixtures.py", "content": "def pytest_fixture_setup(fixturedef, request):\n    \"\"\" Execution of fixture setup. \"\"\"\n    kwargs = {}\n    for argname in fixturedef.argnames:\n        fixdef = request._get_active_fixturedef(argname)\n        assert fixdef.cached_result is not None\n        result, arg_cache_key, exc = fixdef.cached_result\n        request._check_scope(argname, request.scope, fixdef.scope)\n        kwargs[argname] = result\n\n    fixturefunc = resolve_fixture_function(fixturedef, request)\n    my_cache_key = fixturedef.cache_key(request)\n    try:\n        result = call_fixture_func(fixturefunc, request, kwargs)\n    except TEST_OUTCOME:\n        fixturedef.cached_result = (None, my_cache_key, sys.exc_info())\n        raise\n    fixturedef.cached_result = (result, my_cache_key, None)\n    return result"}, {"id": "_pytest.fixtures._ensure_immutable_ids", "kind": "function", "range": [980, 0, 985, 21, 37503, 37632], "file_path": "src/_pytest/fixtures.py", "content": "def _ensure_immutable_ids(ids):\n    if ids is None:\n        return\n    if callable(ids):\n        return ids\n    return tuple(ids)"}, {"id": "_pytest.fixtures.wrap_function_to_error_out_if_called_directly", "kind": "function", "range": [988, 0, 1007, 17, 37635, 38704], "file_path": "src/_pytest/fixtures.py", "content": "def wrap_function_to_error_out_if_called_directly(function, fixture_marker):\n    \"\"\"Wrap the given fixture function so we can raise an error about it being called directly,\n    instead of used as an argument in a test function.\n    \"\"\"\n    message = (\n        'Fixture \"{name}\" called directly. Fixtures are not meant to be called directly,\\n'\n        \"but are created automatically when test functions request them as parameters.\\n\"\n        \"See https://docs.pytest.org/en/latest/fixture.html for more information about fixtures, and\\n\"\n        \"https://docs.pytest.org/en/latest/deprecations.html#calling-fixtures-directly about how to update your code.\"\n    ).format(name=fixture_marker.name or function.__name__)\n\n    @functools.wraps(function)\n    def result(*args, **kwargs):\n        fail(message, pytrace=False)\n\n    # keep reference to the original function in our own custom attribute so we don't unwrap\n    # further than this point and lose useful wrappings like @mock.patch (#3774)\n    result.__pytest_wrapped__ = _PytestWrapper(function)\n\n    return result"}, {"id": "_pytest.fixtures.FixtureFunctionMarker", "kind": "class", "range": [1010, 0, 1040, 23, 38707, 39888], "file_path": "src/_pytest/fixtures.py", "content": "@attr.s(frozen=True)\nclass FixtureFunctionMarker:\n    scope = attr.ib()\n    params = attr.ib(converter=attr.converters.optional(tuple))\n    autouse = attr.ib(default=False)\n    # Ignore type because of https://github.com/python/mypy/issues/6172.\n    ids = attr.ib(default=None, converter=_ensure_immutable_ids)  # type: ignore\n    name = attr.ib(default=None)\n\n    def __call__(self, function):\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if getattr(function, \"_pytestfixturefunction\", False):\n            raise ValueError(\n                \"fixture is being applied more than once to the same function\"\n            )\n\n        function = wrap_function_to_error_out_if_called_directly(function, self)\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                \"'request' is a reserved word for fixtures, use another name:\\n  {}\".format(\n                    location\n                ),\n                pytrace=False,\n            )\n        function._pytestfixturefunction = self\n        return function"}, {"id": "_pytest.fixtures.FixtureFunctionMarker.scope", "kind": "variable", "range": [1012, 4, 1012, 21, 38761, 38778], "file_path": "src/_pytest/fixtures.py", "content": "scope = attr.ib()"}, {"id": "_pytest.fixtures.FixtureFunctionMarker.params", "kind": "variable", "range": [1013, 4, 1013, 63, 38783, 38842], "file_path": "src/_pytest/fixtures.py", "content": "params = attr.ib(converter=attr.converters.optional(tuple))"}, {"id": "_pytest.fixtures.FixtureFunctionMarker.autouse", "kind": "variable", "range": [1014, 4, 1014, 36, 38847, 38879], "file_path": "src/_pytest/fixtures.py", "content": "autouse = attr.ib(default=False)"}, {"id": "_pytest.fixtures.FixtureFunctionMarker.ids", "kind": "variable", "range": [1016, 4, 1016, 64, 38957, 39017], "file_path": "src/_pytest/fixtures.py", "content": "ids = attr.ib(default=None, converter=_ensure_immutable_ids)"}, {"id": "_pytest.fixtures.FixtureFunctionMarker.name", "kind": "variable", "range": [1017, 4, 1017, 32, 39038, 39066], "file_path": "src/_pytest/fixtures.py", "content": "name = attr.ib(default=None)"}, {"id": "_pytest.fixtures.FixtureFunctionMarker.__call__", "kind": "function", "range": [1019, 4, 1040, 23, 39072, 39888], "file_path": "src/_pytest/fixtures.py", "content": "def __call__(self, function):\n        if inspect.isclass(function):\n            raise ValueError(\"class fixtures not supported (maybe in the future)\")\n\n        if getattr(function, \"_pytestfixturefunction\", False):\n            raise ValueError(\n                \"fixture is being applied more than once to the same function\"\n            )\n\n        function = wrap_function_to_error_out_if_called_directly(function, self)\n\n        name = self.name or function.__name__\n        if name == \"request\":\n            location = getlocation(function)\n            fail(\n                \"'request' is a reserved word for fixtures, use another name:\\n  {}\".format(\n                    location\n                ),\n                pytrace=False,\n            )\n        function._pytestfixturefunction = self\n        return function"}, {"id": "_pytest.fixtures.FIXTURE_ARGS_ORDER", "kind": "variable", "range": [1043, 0, 1043, 66, 39891, 39957], "file_path": "src/_pytest/fixtures.py", "content": "FIXTURE_ARGS_ORDER = (\"scope\", \"params\", \"autouse\", \"ids\", \"name\")"}, {"id": "_pytest.fixtures._parse_fixture_args", "kind": "function", "range": [1046, 0, 1082, 38, 39960, 41104], "file_path": "src/_pytest/fixtures.py", "content": "def _parse_fixture_args(callable_or_scope, *args, **kwargs):\n    arguments = {\n        \"scope\": \"function\",\n        \"params\": None,\n        \"autouse\": False,\n        \"ids\": None,\n        \"name\": None,\n    }\n    kwargs = {\n        key: value for key, value in kwargs.items() if arguments.get(key) != value\n    }\n\n    fixture_function = None\n    if isinstance(callable_or_scope, str):\n        args = list(args)\n        args.insert(0, callable_or_scope)\n    else:\n        fixture_function = callable_or_scope\n\n    positionals = set()\n    for positional, argument_name in zip(args, FIXTURE_ARGS_ORDER):\n        arguments[argument_name] = positional\n        positionals.add(argument_name)\n\n    duplicated_kwargs = {kwarg for kwarg in kwargs.keys() if kwarg in positionals}\n    if duplicated_kwargs:\n        raise TypeError(\n            \"The fixture arguments are defined as positional and keyword: {}. \"\n            \"Use only keyword arguments.\".format(\", \".join(duplicated_kwargs))\n        )\n\n    if positionals:\n        warnings.warn(FIXTURE_POSITIONAL_ARGUMENTS, stacklevel=2)\n\n    arguments.update(kwargs)\n\n    return fixture_function, arguments"}, {"id": "_pytest.fixtures.fixture", "kind": "function", "range": [1085, 0, 1167, 76, 41107, 44454], "file_path": "src/_pytest/fixtures.py", "content": "def fixture(\n    callable_or_scope=None,\n    *args,\n    scope=\"function\",\n    params=None,\n    autouse=False,\n    ids=None,\n    name=None\n):\n    \"\"\"Decorator to mark a fixture factory function.\n\n    This decorator can be used, with or without parameters, to define a\n    fixture function.\n\n    The name of the fixture function can later be referenced to cause its\n    invocation ahead of running tests: test\n    modules or classes can use the ``pytest.mark.usefixtures(fixturename)``\n    marker.\n\n    Test functions can directly use fixture names as input\n    arguments in which case the fixture instance returned from the fixture\n    function will be injected.\n\n    Fixtures can provide their values to test functions using ``return`` or ``yield``\n    statements. When using ``yield`` the code block after the ``yield`` statement is executed\n    as teardown code regardless of the test outcome, and must yield exactly once.\n\n    :arg scope: the scope for which this fixture is shared, one of\n                ``\"function\"`` (default), ``\"class\"``, ``\"module\"``,\n                ``\"package\"`` or ``\"session\"`` (``\"package\"`` is considered **experimental**\n                at this time).\n\n                This parameter may also be a callable which receives ``(fixture_name, config)``\n                as parameters, and must return a ``str`` with one of the values mentioned above.\n\n                See :ref:`dynamic scope` in the docs for more information.\n\n    :arg params: an optional list of parameters which will cause multiple\n                invocations of the fixture function and all of the tests\n                using it.\n                The current parameter is available in ``request.param``.\n\n    :arg autouse: if True, the fixture func is activated for all tests that\n                can see it.  If False (the default) then an explicit\n                reference is needed to activate the fixture.\n\n    :arg ids: list of string ids each corresponding to the params\n                so that they are part of the test id. If no ids are provided\n                they will be generated automatically from the params.\n\n    :arg name: the name of the fixture. This defaults to the name of the\n                decorated function. If a fixture is used in the same module in\n                which it is defined, the function name of the fixture will be\n                shadowed by the function arg that requests the fixture; one way\n                to resolve this is to name the decorated function\n                ``fixture_<fixturename>`` and then use\n                ``@pytest.fixture(name='<fixturename>')``.\n    \"\"\"\n    if params is not None:\n        params = list(params)\n\n    fixture_function, arguments = _parse_fixture_args(\n        callable_or_scope,\n        *args,\n        scope=scope,\n        params=params,\n        autouse=autouse,\n        ids=ids,\n        name=name,\n    )\n    scope = arguments.get(\"scope\")\n    params = arguments.get(\"params\")\n    autouse = arguments.get(\"autouse\")\n    ids = arguments.get(\"ids\")\n    name = arguments.get(\"name\")\n\n    if fixture_function and params is None and autouse is False:\n        # direct decoration\n        return FixtureFunctionMarker(scope, params, autouse, name=name)(\n            fixture_function\n        )\n\n    return FixtureFunctionMarker(scope, params, autouse, ids=ids, name=name)"}, {"id": "_pytest.fixtures.yield_fixture", "kind": "function", "range": [1170, 0, 1192, 5, 44457, 44936], "file_path": "src/_pytest/fixtures.py", "content": "def yield_fixture(\n    callable_or_scope=None,\n    *args,\n    scope=\"function\",\n    params=None,\n    autouse=False,\n    ids=None,\n    name=None\n):\n    \"\"\" (return a) decorator to mark a yield-fixture factory function.\n\n    .. deprecated:: 3.0\n        Use :py:func:`pytest.fixture` directly instead.\n    \"\"\"\n    return fixture(\n        callable_or_scope,\n        *args,\n        scope=scope,\n        params=params,\n        autouse=autouse,\n        ids=ids,\n        name=name,\n    )"}, {"id": "_pytest.fixtures.pytestconfig", "kind": "function", "range": [1195, 0, 1206, 25, 44939, 45238], "file_path": "src/_pytest/fixtures.py", "content": "@fixture(scope=\"session\")\ndef pytestconfig(request):\n    \"\"\"Session-scoped fixture that returns the :class:`_pytest.config.Config` object.\n\n    Example::\n\n        def test_foo(pytestconfig):\n            if pytestconfig.getoption(\"verbose\") > 0:\n                ...\n\n    \"\"\"\n    return request.config"}, {"id": "_pytest.fixtures.pytest_addoption", "kind": "function", "range": [1209, 0, 1215, 5, 45241, 45429], "file_path": "src/_pytest/fixtures.py", "content": "def pytest_addoption(parser):\n    parser.addini(\n        \"usefixtures\",\n        type=\"args\",\n        default=[],\n        help=\"list of default fixtures to be used with this project\",\n    )"}, {"id": "_pytest.fixtures.FixtureManager", "kind": "class", "range": [1218, 0, 1483, 32, 45432, 56142], "file_path": "src/_pytest/fixtures.py", "content": "class FixtureManager:\n    \"\"\"\n    pytest fixtures definitions and information is stored and managed\n    from this class.\n\n    During collection fm.parsefactories() is called multiple times to parse\n    fixture function definitions into FixtureDef objects and internal\n    data structures.\n\n    During collection of test functions, metafunc-mechanics instantiate\n    a FuncFixtureInfo object which is cached per node/func-name.\n    This FuncFixtureInfo object is later retrieved by Function nodes\n    which themselves offer a fixturenames attribute.\n\n    The FuncFixtureInfo object holds information about fixtures and FixtureDefs\n    relevant for a particular function.  An initial list of fixtures is\n    assembled like this:\n\n    - ini-defined usefixtures\n    - autouse-marked fixtures along the collection chain up from the function\n    - usefixtures markers at module/class/function level\n    - test function funcargs\n\n    Subsequently the funcfixtureinfo.fixturenames attribute is computed\n    as the closure of the fixtures needed to setup the initial fixtures,\n    i. e. fixtures needed by fixture functions themselves are appended\n    to the fixturenames list.\n\n    Upon the test-setup phases all fixturenames are instantiated, retrieved\n    by a lookup of their FuncFixtureInfo.\n    \"\"\"\n\n    FixtureLookupError = FixtureLookupError\n    FixtureLookupErrorRepr = FixtureLookupErrorRepr\n\n    def __init__(self, session):\n        self.session = session\n        self.config = session.config\n        self._arg2fixturedefs = {}\n        self._holderobjseen = set()\n        self._nodeid_and_autousenames = [(\"\", self.config.getini(\"usefixtures\"))]\n        session.config.pluginmanager.register(self, \"funcmanage\")\n\n    def _get_direct_parametrize_args(self, node):\n        \"\"\"This function returns all the direct parametrization\n        arguments of a node, so we don't mistake them for fixtures\n\n        Check https://github.com/pytest-dev/pytest/issues/5036\n\n        This things are done later as well when dealing with parametrization\n        so this could be improved\n        \"\"\"\n        parametrize_argnames = []\n        for marker in node.iter_markers(name=\"parametrize\"):\n            if not marker.kwargs.get(\"indirect\", False):\n                p_argnames, _ = ParameterSet._parse_parametrize_args(\n                    *marker.args, **marker.kwargs\n                )\n                parametrize_argnames.extend(p_argnames)\n\n        return parametrize_argnames\n\n    def getfixtureinfo(self, node, func, cls, funcargs=True):\n        if funcargs and not getattr(node, \"nofuncargs\", False):\n            argnames = getfuncargnames(func, name=node.name, cls=cls)\n        else:\n            argnames = ()\n\n        usefixtures = get_use_fixtures_for_node(node)\n        initialnames = usefixtures + argnames\n        fm = node.session._fixturemanager\n        initialnames, names_closure, arg2fixturedefs = fm.getfixtureclosure(\n            initialnames, node, ignore_args=self._get_direct_parametrize_args(node)\n        )\n        return FuncFixtureInfo(argnames, initialnames, names_closure, arg2fixturedefs)\n\n    def pytest_plugin_registered(self, plugin):\n        nodeid = None\n        try:\n            p = py.path.local(plugin.__file__).realpath()\n        except AttributeError:\n            pass\n        else:\n            from _pytest import nodes\n\n            # construct the base nodeid which is later used to check\n            # what fixtures are visible for particular tests (as denoted\n            # by their test id)\n            if p.basename.startswith(\"conftest.py\"):\n                nodeid = p.dirpath().relto(self.config.rootdir)\n                if p.sep != nodes.SEP:\n                    nodeid = nodeid.replace(p.sep, nodes.SEP)\n\n        self.parsefactories(plugin, nodeid)\n\n    def _getautousenames(self, nodeid):\n        \"\"\" return a tuple of fixture names to be used. \"\"\"\n        autousenames = []\n        for baseid, basenames in self._nodeid_and_autousenames:\n            if nodeid.startswith(baseid):\n                if baseid:\n                    i = len(baseid)\n                    nextchar = nodeid[i : i + 1]\n                    if nextchar and nextchar not in \":/\":\n                        continue\n                autousenames.extend(basenames)\n        return autousenames\n\n    def getfixtureclosure(self, fixturenames, parentnode, ignore_args=()):\n        # collect the closure of all fixtures , starting with the given\n        # fixturenames as the initial set.  As we have to visit all\n        # factory definitions anyway, we also return an arg2fixturedefs\n        # mapping so that the caller can reuse it and does not have\n        # to re-discover fixturedefs again for each fixturename\n        # (discovering matching fixtures for a given name/node is expensive)\n\n        parentid = parentnode.nodeid\n        fixturenames_closure = self._getautousenames(parentid)\n\n        def merge(otherlist):\n            for arg in otherlist:\n                if arg not in fixturenames_closure:\n                    fixturenames_closure.append(arg)\n\n        merge(fixturenames)\n\n        # at this point, fixturenames_closure contains what we call \"initialnames\",\n        # which is a set of fixturenames the function immediately requests. We\n        # need to return it as well, so save this.\n        initialnames = tuple(fixturenames_closure)\n\n        arg2fixturedefs = {}\n        lastlen = -1\n        while lastlen != len(fixturenames_closure):\n            lastlen = len(fixturenames_closure)\n            for argname in fixturenames_closure:\n                if argname in ignore_args:\n                    continue\n                if argname in arg2fixturedefs:\n                    continue\n                fixturedefs = self.getfixturedefs(argname, parentid)\n                if fixturedefs:\n                    arg2fixturedefs[argname] = fixturedefs\n                    merge(fixturedefs[-1].argnames)\n\n        def sort_by_scope(arg_name):\n            try:\n                fixturedefs = arg2fixturedefs[arg_name]\n            except KeyError:\n                return scopes.index(\"function\")\n            else:\n                return fixturedefs[-1].scopenum\n\n        fixturenames_closure.sort(key=sort_by_scope)\n        return initialnames, fixturenames_closure, arg2fixturedefs\n\n    def pytest_generate_tests(self, metafunc):\n        for argname in metafunc.fixturenames:\n            faclist = metafunc._arg2fixturedefs.get(argname)\n            if faclist:\n                fixturedef = faclist[-1]\n                if fixturedef.params is not None:\n                    markers = list(metafunc.definition.iter_markers(\"parametrize\"))\n                    for parametrize_mark in markers:\n                        if \"argnames\" in parametrize_mark.kwargs:\n                            argnames = parametrize_mark.kwargs[\"argnames\"]\n                        else:\n                            argnames = parametrize_mark.args[0]\n\n                        if not isinstance(argnames, (tuple, list)):\n                            argnames = [\n                                x.strip() for x in argnames.split(\",\") if x.strip()\n                            ]\n                        if argname in argnames:\n                            break\n                    else:\n                        metafunc.parametrize(\n                            argname,\n                            fixturedef.params,\n                            indirect=True,\n                            scope=fixturedef.scope,\n                            ids=fixturedef.ids,\n                        )\n            else:\n                continue  # will raise FixtureLookupError at setup time\n\n    def pytest_collection_modifyitems(self, items):\n        # separate parametrized setups\n        items[:] = reorder_items(items)\n\n    def parsefactories(self, node_or_obj, nodeid=NOTSET, unittest=False):\n        if nodeid is not NOTSET:\n            holderobj = node_or_obj\n        else:\n            holderobj = node_or_obj.obj\n            nodeid = node_or_obj.nodeid\n        if holderobj in self._holderobjseen:\n            return\n\n        self._holderobjseen.add(holderobj)\n        autousenames = []\n        for name in dir(holderobj):\n            # The attribute can be an arbitrary descriptor, so the attribute\n            # access below can raise. safe_getatt() ignores such exceptions.\n            obj = safe_getattr(holderobj, name, None)\n            marker = getfixturemarker(obj)\n            if not isinstance(marker, FixtureFunctionMarker):\n                # magic globals  with __getattr__ might have got us a wrong\n                # fixture attribute\n                continue\n\n            if marker.name:\n                name = marker.name\n\n            # during fixture definition we wrap the original fixture function\n            # to issue a warning if called directly, so here we unwrap it in order to not emit the warning\n            # when pytest itself calls the fixture function\n            obj = get_real_method(obj, holderobj)\n\n            fixture_def = FixtureDef(\n                self,\n                nodeid,\n                name,\n                obj,\n                marker.scope,\n                marker.params,\n                unittest=unittest,\n                ids=marker.ids,\n            )\n\n            faclist = self._arg2fixturedefs.setdefault(name, [])\n            if fixture_def.has_location:\n                faclist.append(fixture_def)\n            else:\n                # fixturedefs with no location are at the front\n                # so this inserts the current fixturedef after the\n                # existing fixturedefs from external plugins but\n                # before the fixturedefs provided in conftests.\n                i = len([f for f in faclist if not f.has_location])\n                faclist.insert(i, fixture_def)\n            if marker.autouse:\n                autousenames.append(name)\n\n        if autousenames:\n            self._nodeid_and_autousenames.append((nodeid or \"\", autousenames))\n\n    def getfixturedefs(self, argname, nodeid):\n        \"\"\"\n        Gets a list of fixtures which are applicable to the given node id.\n\n        :param str argname: name of the fixture to search for\n        :param str nodeid: full node id of the requesting test.\n        :return: list[FixtureDef]\n        \"\"\"\n        try:\n            fixturedefs = self._arg2fixturedefs[argname]\n        except KeyError:\n            return None\n        return tuple(self._matchfactories(fixturedefs, nodeid))\n\n    def _matchfactories(self, fixturedefs, nodeid):\n        from _pytest import nodes\n\n        for fixturedef in fixturedefs:\n            if nodes.ischildnode(fixturedef.baseid, nodeid):\n                yield fixturedef"}, {"id": "_pytest.fixtures.FixtureManager.FixtureLookupError", "kind": "variable", "range": [1250, 4, 1250, 43, 46733, 46772], "file_path": "src/_pytest/fixtures.py", "content": "FixtureLookupError = FixtureLookupError"}, {"id": "_pytest.fixtures.FixtureManager.FixtureLookupErrorRepr", "kind": "variable", "range": [1251, 4, 1251, 51, 46777, 46824], "file_path": "src/_pytest/fixtures.py", "content": "FixtureLookupErrorRepr = FixtureLookupErrorRepr"}, {"id": "_pytest.fixtures.FixtureManager.__init__", "kind": "function", "range": [1253, 4, 1259, 65, 46830, 47145], "file_path": "src/_pytest/fixtures.py", "content": "def __init__(self, session):\n        self.session = session\n        self.config = session.config\n        self._arg2fixturedefs = {}\n        self._holderobjseen = set()\n        self._nodeid_and_autousenames = [(\"\", self.config.getini(\"usefixtures\"))]\n        session.config.pluginmanager.register(self, \"funcmanage\")"}, {"id": "_pytest.fixtures.FixtureManager._get_direct_parametrize_args", "kind": "function", "range": [1261, 4, 1278, 35, 47151, 47898], "file_path": "src/_pytest/fixtures.py", "content": "def _get_direct_parametrize_args(self, node):\n        \"\"\"This function returns all the direct parametrization\n        arguments of a node, so we don't mistake them for fixtures\n\n        Check https://github.com/pytest-dev/pytest/issues/5036\n\n        This things are done later as well when dealing with parametrization\n        so this could be improved\n        \"\"\"\n        parametrize_argnames = []\n        for marker in node.iter_markers(name=\"parametrize\"):\n            if not marker.kwargs.get(\"indirect\", False):\n                p_argnames, _ = ParameterSet._parse_parametrize_args(\n                    *marker.args, **marker.kwargs\n                )\n                parametrize_argnames.extend(p_argnames)\n\n        return parametrize_argnames"}, {"id": "_pytest.fixtures.FixtureManager.getfixtureinfo", "kind": "function", "range": [1280, 4, 1292, 86, 47904, 48536], "file_path": "src/_pytest/fixtures.py", "content": "def getfixtureinfo(self, node, func, cls, funcargs=True):\n        if funcargs and not getattr(node, \"nofuncargs\", False):\n            argnames = getfuncargnames(func, name=node.name, cls=cls)\n        else:\n            argnames = ()\n\n        usefixtures = get_use_fixtures_for_node(node)\n        initialnames = usefixtures + argnames\n        fm = node.session._fixturemanager\n        initialnames, names_closure, arg2fixturedefs = fm.getfixtureclosure(\n            initialnames, node, ignore_args=self._get_direct_parametrize_args(node)\n        )\n        return FuncFixtureInfo(argnames, initialnames, names_closure, arg2fixturedefs)"}, {"id": "_pytest.fixtures.FixtureManager.pytest_plugin_registered", "kind": "function", "range": [1294, 4, 1311, 43, 48542, 49216], "file_path": "src/_pytest/fixtures.py", "content": "def pytest_plugin_registered(self, plugin):\n        nodeid = None\n        try:\n            p = py.path.local(plugin.__file__).realpath()\n        except AttributeError:\n            pass\n        else:\n            from _pytest import nodes\n\n            # construct the base nodeid which is later used to check\n            # what fixtures are visible for particular tests (as denoted\n            # by their test id)\n            if p.basename.startswith(\"conftest.py\"):\n                nodeid = p.dirpath().relto(self.config.rootdir)\n                if p.sep != nodes.SEP:\n                    nodeid = nodeid.replace(p.sep, nodes.SEP)\n\n        self.parsefactories(plugin, nodeid)"}, {"id": "_pytest.fixtures.FixtureManager._getautousenames", "kind": "function", "range": [1313, 4, 1324, 27, 49222, 49727], "file_path": "src/_pytest/fixtures.py", "content": "def _getautousenames(self, nodeid):\n        \"\"\" return a tuple of fixture names to be used. \"\"\"\n        autousenames = []\n        for baseid, basenames in self._nodeid_and_autousenames:\n            if nodeid.startswith(baseid):\n                if baseid:\n                    i = len(baseid)\n                    nextchar = nodeid[i : i + 1]\n                    if nextchar and nextchar not in \":/\":\n                        continue\n                autousenames.extend(basenames)\n        return autousenames"}, {"id": "_pytest.fixtures.FixtureManager.getfixtureclosure", "kind": "function", "range": [1326, 4, 1372, 66, 49733, 51725], "file_path": "src/_pytest/fixtures.py", "content": "def getfixtureclosure(self, fixturenames, parentnode, ignore_args=()):\n        # collect the closure of all fixtures , starting with the given\n        # fixturenames as the initial set.  As we have to visit all\n        # factory definitions anyway, we also return an arg2fixturedefs\n        # mapping so that the caller can reuse it and does not have\n        # to re-discover fixturedefs again for each fixturename\n        # (discovering matching fixtures for a given name/node is expensive)\n\n        parentid = parentnode.nodeid\n        fixturenames_closure = self._getautousenames(parentid)\n\n        def merge(otherlist):\n            for arg in otherlist:\n                if arg not in fixturenames_closure:\n                    fixturenames_closure.append(arg)\n\n        merge(fixturenames)\n\n        # at this point, fixturenames_closure contains what we call \"initialnames\",\n        # which is a set of fixturenames the function immediately requests. We\n        # need to return it as well, so save this.\n        initialnames = tuple(fixturenames_closure)\n\n        arg2fixturedefs = {}\n        lastlen = -1\n        while lastlen != len(fixturenames_closure):\n            lastlen = len(fixturenames_closure)\n            for argname in fixturenames_closure:\n                if argname in ignore_args:\n                    continue\n                if argname in arg2fixturedefs:\n                    continue\n                fixturedefs = self.getfixturedefs(argname, parentid)\n                if fixturedefs:\n                    arg2fixturedefs[argname] = fixturedefs\n                    merge(fixturedefs[-1].argnames)\n\n        def sort_by_scope(arg_name):\n            try:\n                fixturedefs = arg2fixturedefs[arg_name]\n            except KeyError:\n                return scopes.index(\"function\")\n            else:\n                return fixturedefs[-1].scopenum\n\n        fixturenames_closure.sort(key=sort_by_scope)\n        return initialnames, fixturenames_closure, arg2fixturedefs"}, {"id": "_pytest.fixtures.FixtureManager.pytest_generate_tests", "kind": "function", "range": [1374, 4, 1402, 71, 51731, 53088], "file_path": "src/_pytest/fixtures.py", "content": "def pytest_generate_tests(self, metafunc):\n        for argname in metafunc.fixturenames:\n            faclist = metafunc._arg2fixturedefs.get(argname)\n            if faclist:\n                fixturedef = faclist[-1]\n                if fixturedef.params is not None:\n                    markers = list(metafunc.definition.iter_markers(\"parametrize\"))\n                    for parametrize_mark in markers:\n                        if \"argnames\" in parametrize_mark.kwargs:\n                            argnames = parametrize_mark.kwargs[\"argnames\"]\n                        else:\n                            argnames = parametrize_mark.args[0]\n\n                        if not isinstance(argnames, (tuple, list)):\n                            argnames = [\n                                x.strip() for x in argnames.split(\",\") if x.strip()\n                            ]\n                        if argname in argnames:\n                            break\n                    else:\n                        metafunc.parametrize(\n                            argname,\n                            fixturedef.params,\n                            indirect=True,\n                            scope=fixturedef.scope,\n                            ids=fixturedef.ids,\n                        )\n            else:\n                continue  # will raise FixtureLookupError at setup time"}, {"id": "_pytest.fixtures.FixtureManager.pytest_collection_modifyitems", "kind": "function", "range": [1404, 4, 1406, 39, 53094, 53220], "file_path": "src/_pytest/fixtures.py", "content": "def pytest_collection_modifyitems(self, items):\n        # separate parametrized setups\n        items[:] = reorder_items(items)"}, {"id": "_pytest.fixtures.FixtureManager.parsefactories", "kind": "function", "range": [1408, 4, 1462, 78, 53226, 55430], "file_path": "src/_pytest/fixtures.py", "content": "def parsefactories(self, node_or_obj, nodeid=NOTSET, unittest=False):\n        if nodeid is not NOTSET:\n            holderobj = node_or_obj\n        else:\n            holderobj = node_or_obj.obj\n            nodeid = node_or_obj.nodeid\n        if holderobj in self._holderobjseen:\n            return\n\n        self._holderobjseen.add(holderobj)\n        autousenames = []\n        for name in dir(holderobj):\n            # The attribute can be an arbitrary descriptor, so the attribute\n            # access below can raise. safe_getatt() ignores such exceptions.\n            obj = safe_getattr(holderobj, name, None)\n            marker = getfixturemarker(obj)\n            if not isinstance(marker, FixtureFunctionMarker):\n                # magic globals  with __getattr__ might have got us a wrong\n                # fixture attribute\n                continue\n\n            if marker.name:\n                name = marker.name\n\n            # during fixture definition we wrap the original fixture function\n            # to issue a warning if called directly, so here we unwrap it in order to not emit the warning\n            # when pytest itself calls the fixture function\n            obj = get_real_method(obj, holderobj)\n\n            fixture_def = FixtureDef(\n                self,\n                nodeid,\n                name,\n                obj,\n                marker.scope,\n                marker.params,\n                unittest=unittest,\n                ids=marker.ids,\n            )\n\n            faclist = self._arg2fixturedefs.setdefault(name, [])\n            if fixture_def.has_location:\n                faclist.append(fixture_def)\n            else:\n                # fixturedefs with no location are at the front\n                # so this inserts the current fixturedef after the\n                # existing fixturedefs from external plugins but\n                # before the fixturedefs provided in conftests.\n                i = len([f for f in faclist if not f.has_location])\n                faclist.insert(i, fixture_def)\n            if marker.autouse:\n                autousenames.append(name)\n\n        if autousenames:\n            self._nodeid_and_autousenames.append((nodeid or \"\", autousenames))"}, {"id": "_pytest.fixtures.FixtureManager.getfixturedefs", "kind": "function", "range": [1464, 4, 1476, 63, 55436, 55921], "file_path": "src/_pytest/fixtures.py", "content": "def getfixturedefs(self, argname, nodeid):\n        \"\"\"\n        Gets a list of fixtures which are applicable to the given node id.\n\n        :param str argname: name of the fixture to search for\n        :param str nodeid: full node id of the requesting test.\n        :return: list[FixtureDef]\n        \"\"\"\n        try:\n            fixturedefs = self._arg2fixturedefs[argname]\n        except KeyError:\n            return None\n        return tuple(self._matchfactories(fixturedefs, nodeid))"}, {"id": "_pytest.fixtures.FixtureManager._matchfactories", "kind": "function", "range": [1478, 4, 1483, 32, 55927, 56142], "file_path": "src/_pytest/fixtures.py", "content": "def _matchfactories(self, fixturedefs, nodeid):\n        from _pytest import nodes\n\n        for fixturedef in fixturedefs:\n            if nodes.ischildnode(fixturedef.baseid, nodeid):\n                yield fixturedef"}, {"id": "_pytest.fixtures.get_use_fixtures_for_node", "kind": "function", "range": [1486, 0, 1492, 5, 56145, 56407], "file_path": "src/_pytest/fixtures.py", "content": "def get_use_fixtures_for_node(node) -> Tuple[str, ...]:\n    \"\"\"Returns the names of all the usefixtures() marks on the given node\"\"\"\n    return tuple(\n        str(name)\n        for mark in node.iter_markers(name=\"usefixtures\")\n        for name in mark.args\n    )"}, {"id": "_pytest.cacheprovider.README_CONTENT", "kind": "variable", "range": [29, 0, 38, 3, 665, 985], "file_path": "src/_pytest/cacheprovider.py", "content": "README_CONTENT = \"\"\"\\\n# pytest cache directory #\n\nThis directory contains data from the pytest's cache plugin,\nwhich provides the `--lf` and `--ff` options, as well as the `cache` fixture.\n\n**Do not** commit this to version control.\n\nSee [the docs](https://docs.pytest.org/en/latest/cache.html) for more information.\n\"\"\""}, {"id": "_pytest.cacheprovider.CACHEDIR_TAG_CONTENT", "kind": "variable", "range": [40, 0, 45, 3, 987, 1213], "file_path": "src/_pytest/cacheprovider.py", "content": "CACHEDIR_TAG_CONTENT = b\"\"\"\\\nSignature: 8a477f597d28d172789f06886806bc55\n# This file is a cache directory tag created by pytest.\n# For information about cache directory tags, see:\n#\thttp://www.bford.info/cachedir/spec.html\n\"\"\""}, {"id": "_pytest.cacheprovider.Cache", "kind": "class", "range": [48, 0, 166, 59, 1216, 5664], "file_path": "src/_pytest/cacheprovider.py", "content": "@attr.s\nclass Cache:\n    _cachedir = attr.ib(repr=False)\n    _config = attr.ib(repr=False)\n\n    # sub-directory under cache-dir for directories created by \"makedir\"\n    _CACHE_PREFIX_DIRS = \"d\"\n\n    # sub-directory under cache-dir for values created by \"set\"\n    _CACHE_PREFIX_VALUES = \"v\"\n\n    @classmethod\n    def for_config(cls, config):\n        cachedir = cls.cache_dir_from_config(config)\n        if config.getoption(\"cacheclear\") and cachedir.is_dir():\n            cls.clear_cache(cachedir)\n        return cls(cachedir, config)\n\n    @classmethod\n    def clear_cache(cls, cachedir: Path):\n        \"\"\"Clears the sub-directories used to hold cached directories and values.\"\"\"\n        for prefix in (cls._CACHE_PREFIX_DIRS, cls._CACHE_PREFIX_VALUES):\n            d = cachedir / prefix\n            if d.is_dir():\n                rm_rf(d)\n\n    @staticmethod\n    def cache_dir_from_config(config):\n        return resolve_from_str(config.getini(\"cache_dir\"), config.rootdir)\n\n    def warn(self, fmt, **args):\n        import warnings\n        from _pytest.warning_types import PytestCacheWarning\n\n        warnings.warn(\n            PytestCacheWarning(fmt.format(**args) if args else fmt),\n            self._config.hook,\n            stacklevel=3,\n        )\n\n    def makedir(self, name):\n        \"\"\" return a directory path object with the given name.  If the\n        directory does not yet exist, it will be created.  You can use it\n        to manage files likes e. g. store/retrieve database\n        dumps across test sessions.\n\n        :param name: must be a string not containing a ``/`` separator.\n             Make sure the name contains your plugin or application\n             identifiers to prevent clashes with other cache users.\n        \"\"\"\n        name = Path(name)\n        if len(name.parts) > 1:\n            raise ValueError(\"name is not allowed to contain path separators\")\n        res = self._cachedir.joinpath(self._CACHE_PREFIX_DIRS, name)\n        res.mkdir(exist_ok=True, parents=True)\n        return py.path.local(res)\n\n    def _getvaluepath(self, key):\n        return self._cachedir.joinpath(self._CACHE_PREFIX_VALUES, Path(key))\n\n    def get(self, key, default):\n        \"\"\" return cached value for the given key.  If no value\n        was yet cached or the value cannot be read, the specified\n        default is returned.\n\n        :param key: must be a ``/`` separated value. Usually the first\n             name is the name of your plugin or your application.\n        :param default: must be provided in case of a cache-miss or\n             invalid cache values.\n\n        \"\"\"\n        path = self._getvaluepath(key)\n        try:\n            with path.open(\"r\") as f:\n                return json.load(f)\n        except (ValueError, OSError):\n            return default\n\n    def set(self, key, value):\n        \"\"\" save value for the given key.\n\n        :param key: must be a ``/`` separated value. Usually the first\n             name is the name of your plugin or your application.\n        :param value: must be of any combination of basic\n               python types, including nested types\n               like e. g. lists of dictionaries.\n        \"\"\"\n        path = self._getvaluepath(key)\n        try:\n            if path.parent.is_dir():\n                cache_dir_exists_already = True\n            else:\n                cache_dir_exists_already = self._cachedir.exists()\n                path.parent.mkdir(exist_ok=True, parents=True)\n        except OSError:\n            self.warn(\"could not create cache path {path}\", path=path)\n            return\n        if not cache_dir_exists_already:\n            self._ensure_supporting_files()\n        data = json.dumps(value, indent=2, sort_keys=True)\n        try:\n            f = path.open(\"w\")\n        except OSError:\n            self.warn(\"cache could not write path {path}\", path=path)\n        else:\n            with f:\n                f.write(data)\n\n    def _ensure_supporting_files(self):\n        \"\"\"Create supporting files in the cache dir that are not really part of the cache.\"\"\"\n        readme_path = self._cachedir / \"README.md\"\n        readme_path.write_text(README_CONTENT)\n\n        gitignore_path = self._cachedir.joinpath(\".gitignore\")\n        msg = \"# Created by pytest automatically.\\n*\\n\"\n        gitignore_path.write_text(msg, encoding=\"UTF-8\")\n\n        cachedir_tag_path = self._cachedir.joinpath(\"CACHEDIR.TAG\")\n        cachedir_tag_path.write_bytes(CACHEDIR_TAG_CONTENT)"}, {"id": "_pytest.cacheprovider.Cache._cachedir", "kind": "variable", "range": [50, 4, 50, 35, 1241, 1272], "file_path": "src/_pytest/cacheprovider.py", "content": "_cachedir = attr.ib(repr=False)"}, {"id": "_pytest.cacheprovider.Cache._config", "kind": "variable", "range": [51, 4, 51, 33, 1277, 1306], "file_path": "src/_pytest/cacheprovider.py", "content": "_config = attr.ib(repr=False)"}, {"id": "_pytest.cacheprovider.Cache._CACHE_PREFIX_DIRS", "kind": "variable", "range": [54, 4, 54, 28, 1385, 1409], "file_path": "src/_pytest/cacheprovider.py", "content": "_CACHE_PREFIX_DIRS = \"d\""}, {"id": "_pytest.cacheprovider.Cache._CACHE_PREFIX_VALUES", "kind": "variable", "range": [57, 4, 57, 30, 1479, 1505], "file_path": "src/_pytest/cacheprovider.py", "content": "_CACHE_PREFIX_VALUES = \"v\""}, {"id": "_pytest.cacheprovider.Cache.for_config", "kind": "function", "range": [59, 4, 64, 36, 1511, 1749], "file_path": "src/_pytest/cacheprovider.py", "content": "@classmethod\n    def for_config(cls, config):\n        cachedir = cls.cache_dir_from_config(config)\n        if config.getoption(\"cacheclear\") and cachedir.is_dir():\n            cls.clear_cache(cachedir)\n        return cls(cachedir, config)"}, {"id": "_pytest.cacheprovider.Cache.clear_cache", "kind": "function", "range": [66, 4, 72, 24, 1755, 2054], "file_path": "src/_pytest/cacheprovider.py", "content": "@classmethod\n    def clear_cache(cls, cachedir: Path):\n        \"\"\"Clears the sub-directories used to hold cached directories and values.\"\"\"\n        for prefix in (cls._CACHE_PREFIX_DIRS, cls._CACHE_PREFIX_VALUES):\n            d = cachedir / prefix\n            if d.is_dir():\n                rm_rf(d)"}, {"id": "_pytest.cacheprovider.Cache.cache_dir_from_config", "kind": "function", "range": [74, 4, 76, 75, 2060, 2188], "file_path": "src/_pytest/cacheprovider.py", "content": "@staticmethod\n    def cache_dir_from_config(config):\n        return resolve_from_str(config.getini(\"cache_dir\"), config.rootdir)"}, {"id": "_pytest.cacheprovider.Cache.warn", "kind": "function", "range": [78, 4, 86, 9, 2194, 2467], "file_path": "src/_pytest/cacheprovider.py", "content": "def warn(self, fmt, **args):\n        import warnings\n        from _pytest.warning_types import PytestCacheWarning\n\n        warnings.warn(\n            PytestCacheWarning(fmt.format(**args) if args else fmt),\n            self._config.hook,\n            stacklevel=3,\n        )"}, {"id": "_pytest.cacheprovider.Cache.makedir", "kind": "function", "range": [88, 4, 103, 33, 2473, 3247], "file_path": "src/_pytest/cacheprovider.py", "content": "def makedir(self, name):\n        \"\"\" return a directory path object with the given name.  If the\n        directory does not yet exist, it will be created.  You can use it\n        to manage files likes e. g. store/retrieve database\n        dumps across test sessions.\n\n        :param name: must be a string not containing a ``/`` separator.\n             Make sure the name contains your plugin or application\n             identifiers to prevent clashes with other cache users.\n        \"\"\"\n        name = Path(name)\n        if len(name.parts) > 1:\n            raise ValueError(\"name is not allowed to contain path separators\")\n        res = self._cachedir.joinpath(self._CACHE_PREFIX_DIRS, name)\n        res.mkdir(exist_ok=True, parents=True)\n        return py.path.local(res)"}, {"id": "_pytest.cacheprovider.Cache._getvaluepath", "kind": "function", "range": [105, 4, 106, 76, 3253, 3359], "file_path": "src/_pytest/cacheprovider.py", "content": "def _getvaluepath(self, key):\n        return self._cachedir.joinpath(self._CACHE_PREFIX_VALUES, Path(key))"}, {"id": "_pytest.cacheprovider.Cache.get", "kind": "function", "range": [108, 4, 124, 26, 3365, 3997], "file_path": "src/_pytest/cacheprovider.py", "content": "def get(self, key, default):\n        \"\"\" return cached value for the given key.  If no value\n        was yet cached or the value cannot be read, the specified\n        default is returned.\n\n        :param key: must be a ``/`` separated value. Usually the first\n             name is the name of your plugin or your application.\n        :param default: must be provided in case of a cache-miss or\n             invalid cache values.\n\n        \"\"\"\n        path = self._getvaluepath(key)\n        try:\n            with path.open(\"r\") as f:\n                return json.load(f)\n        except (ValueError, OSError):\n            return default"}, {"id": "_pytest.cacheprovider.Cache.set", "kind": "function", "range": [126, 4, 154, 29, 4003, 5125], "file_path": "src/_pytest/cacheprovider.py", "content": "def set(self, key, value):\n        \"\"\" save value for the given key.\n\n        :param key: must be a ``/`` separated value. Usually the first\n             name is the name of your plugin or your application.\n        :param value: must be of any combination of basic\n               python types, including nested types\n               like e. g. lists of dictionaries.\n        \"\"\"\n        path = self._getvaluepath(key)\n        try:\n            if path.parent.is_dir():\n                cache_dir_exists_already = True\n            else:\n                cache_dir_exists_already = self._cachedir.exists()\n                path.parent.mkdir(exist_ok=True, parents=True)\n        except OSError:\n            self.warn(\"could not create cache path {path}\", path=path)\n            return\n        if not cache_dir_exists_already:\n            self._ensure_supporting_files()\n        data = json.dumps(value, indent=2, sort_keys=True)\n        try:\n            f = path.open(\"w\")\n        except OSError:\n            self.warn(\"cache could not write path {path}\", path=path)\n        else:\n            with f:\n                f.write(data)"}, {"id": "_pytest.cacheprovider.Cache._ensure_supporting_files", "kind": "function", "range": [156, 4, 166, 59, 5131, 5664], "file_path": "src/_pytest/cacheprovider.py", "content": "def _ensure_supporting_files(self):\n        \"\"\"Create supporting files in the cache dir that are not really part of the cache.\"\"\"\n        readme_path = self._cachedir / \"README.md\"\n        readme_path.write_text(README_CONTENT)\n\n        gitignore_path = self._cachedir.joinpath(\".gitignore\")\n        msg = \"# Created by pytest automatically.\\n*\\n\"\n        gitignore_path.write_text(msg, encoding=\"UTF-8\")\n\n        cachedir_tag_path = self._cachedir.joinpath(\"CACHEDIR.TAG\")\n        cachedir_tag_path.write_bytes(CACHEDIR_TAG_CONTENT)"}, {"id": "_pytest.cacheprovider.LFPluginCollWrapper", "kind": "class", "range": [169, 0, 206, 13, 5667, 7162], "file_path": "src/_pytest/cacheprovider.py", "content": "class LFPluginCollWrapper:\n    def __init__(self, lfplugin: \"LFPlugin\"):\n        self.lfplugin = lfplugin\n        self._collected_at_least_one_failure = False\n\n    @pytest.hookimpl(hookwrapper=True)\n    def pytest_make_collect_report(self, collector) -> Generator:\n        if isinstance(collector, Session):\n            out = yield\n            res = out.get_result()  # type: CollectReport\n\n            # Sort any lf-paths to the beginning.\n            lf_paths = self.lfplugin._last_failed_paths\n            res.result = sorted(\n                res.result, key=lambda x: 0 if Path(str(x.fspath)) in lf_paths else 1,\n            )\n            out.force_result(res)\n            return\n\n        elif isinstance(collector, Module):\n            if Path(str(collector.fspath)) in self.lfplugin._last_failed_paths:\n                out = yield\n                res = out.get_result()\n\n                filtered_result = [\n                    x for x in res.result if x.nodeid in self.lfplugin.lastfailed\n                ]\n                if filtered_result:\n                    res.result = filtered_result\n                    out.force_result(res)\n\n                    if not self._collected_at_least_one_failure:\n                        self.lfplugin.config.pluginmanager.register(\n                            LFPluginCollSkipfiles(self.lfplugin), \"lfplugin-collskip\"\n                        )\n                        self._collected_at_least_one_failure = True\n                return res\n        yield"}, {"id": "_pytest.cacheprovider.LFPluginCollWrapper.__init__", "kind": "function", "range": [170, 4, 172, 52, 5698, 5825], "file_path": "src/_pytest/cacheprovider.py", "content": "def __init__(self, lfplugin: \"LFPlugin\"):\n        self.lfplugin = lfplugin\n        self._collected_at_least_one_failure = False"}, {"id": "_pytest.cacheprovider.LFPluginCollWrapper.pytest_make_collect_report", "kind": "function", "range": [174, 4, 206, 13, 5831, 7162], "file_path": "src/_pytest/cacheprovider.py", "content": "@pytest.hookimpl(hookwrapper=True)\n    def pytest_make_collect_report(self, collector) -> Generator:\n        if isinstance(collector, Session):\n            out = yield\n            res = out.get_result()  # type: CollectReport\n\n            # Sort any lf-paths to the beginning.\n            lf_paths = self.lfplugin._last_failed_paths\n            res.result = sorted(\n                res.result, key=lambda x: 0 if Path(str(x.fspath)) in lf_paths else 1,\n            )\n            out.force_result(res)\n            return\n\n        elif isinstance(collector, Module):\n            if Path(str(collector.fspath)) in self.lfplugin._last_failed_paths:\n                out = yield\n                res = out.get_result()\n\n                filtered_result = [\n                    x for x in res.result if x.nodeid in self.lfplugin.lastfailed\n                ]\n                if filtered_result:\n                    res.result = filtered_result\n                    out.force_result(res)\n\n                    if not self._collected_at_least_one_failure:\n                        self.lfplugin.config.pluginmanager.register(\n                            LFPluginCollSkipfiles(self.lfplugin), \"lfplugin-collskip\"\n                        )\n                        self._collected_at_least_one_failure = True\n                return res\n        yield"}, {"id": "_pytest.cacheprovider.LFPluginCollSkipfiles", "kind": "class", "range": [209, 0, 222, 19, 7165, 7700], "file_path": "src/_pytest/cacheprovider.py", "content": "class LFPluginCollSkipfiles:\n    def __init__(self, lfplugin: \"LFPlugin\"):\n        self.lfplugin = lfplugin\n\n    @pytest.hookimpl\n    def pytest_make_collect_report(self, collector) -> Optional[CollectReport]:\n        if isinstance(collector, Module):\n            if Path(str(collector.fspath)) not in self.lfplugin._last_failed_paths:\n                self.lfplugin._skipped_files += 1\n\n                return CollectReport(\n                    collector.nodeid, \"passed\", longrepr=None, result=[]\n                )\n        return None"}, {"id": "_pytest.cacheprovider.LFPluginCollSkipfiles.__init__", "kind": "function", "range": [210, 4, 211, 32, 7198, 7272], "file_path": "src/_pytest/cacheprovider.py", "content": "def __init__(self, lfplugin: \"LFPlugin\"):\n        self.lfplugin = lfplugin"}, {"id": "_pytest.cacheprovider.LFPluginCollSkipfiles.pytest_make_collect_report", "kind": "function", "range": [213, 4, 222, 19, 7278, 7700], "file_path": "src/_pytest/cacheprovider.py", "content": "@pytest.hookimpl\n    def pytest_make_collect_report(self, collector) -> Optional[CollectReport]:\n        if isinstance(collector, Module):\n            if Path(str(collector.fspath)) not in self.lfplugin._last_failed_paths:\n                self.lfplugin._skipped_files += 1\n\n                return CollectReport(\n                    collector.nodeid, \"passed\", longrepr=None, result=[]\n                )\n        return None"}, {"id": "_pytest.cacheprovider.LFPlugin", "kind": "class", "range": [225, 0, 325, 65, 7703, 12091], "file_path": "src/_pytest/cacheprovider.py", "content": "class LFPlugin:\n    \"\"\" Plugin which implements the --lf (run last-failing) option \"\"\"\n\n    def __init__(self, config: Config) -> None:\n        self.config = config\n        active_keys = \"lf\", \"failedfirst\"\n        self.active = any(config.getoption(key) for key in active_keys)\n        assert config.cache\n        self.lastfailed = config.cache.get(\n            \"cache/lastfailed\", {}\n        )  # type: Dict[str, bool]\n        self._previously_failed_count = None\n        self._report_status = None\n        self._skipped_files = 0  # count skipped files during collection due to --lf\n\n        if config.getoption(\"lf\"):\n            self._last_failed_paths = self.get_last_failed_paths()\n            config.pluginmanager.register(\n                LFPluginCollWrapper(self), \"lfplugin-collwrapper\"\n            )\n\n    def get_last_failed_paths(self) -> Set[Path]:\n        \"\"\"Returns a set with all Paths()s of the previously failed nodeids.\"\"\"\n        rootpath = Path(str(self.config.rootdir))\n        result = {rootpath / nodeid.split(\"::\")[0] for nodeid in self.lastfailed}\n        return {x for x in result if x.exists()}\n\n    def pytest_report_collectionfinish(self):\n        if self.active and self.config.getoption(\"verbose\") >= 0:\n            return \"run-last-failure: %s\" % self._report_status\n\n    def pytest_runtest_logreport(self, report):\n        if (report.when == \"call\" and report.passed) or report.skipped:\n            self.lastfailed.pop(report.nodeid, None)\n        elif report.failed:\n            self.lastfailed[report.nodeid] = True\n\n    def pytest_collectreport(self, report):\n        passed = report.outcome in (\"passed\", \"skipped\")\n        if passed:\n            if report.nodeid in self.lastfailed:\n                self.lastfailed.pop(report.nodeid)\n                self.lastfailed.update((item.nodeid, True) for item in report.result)\n        else:\n            self.lastfailed[report.nodeid] = True\n\n    def pytest_collection_modifyitems(self, session, config, items):\n        if not self.active:\n            return\n\n        if self.lastfailed:\n            previously_failed = []\n            previously_passed = []\n            for item in items:\n                if item.nodeid in self.lastfailed:\n                    previously_failed.append(item)\n                else:\n                    previously_passed.append(item)\n            self._previously_failed_count = len(previously_failed)\n\n            if not previously_failed:\n                # Running a subset of all tests with recorded failures\n                # only outside of it.\n                self._report_status = \"%d known failures not in selected tests\" % (\n                    len(self.lastfailed),\n                )\n            else:\n                if self.config.getoption(\"lf\"):\n                    items[:] = previously_failed\n                    config.hook.pytest_deselected(items=previously_passed)\n                else:  # --failedfirst\n                    items[:] = previously_failed + previously_passed\n\n                noun = \"failure\" if self._previously_failed_count == 1 else \"failures\"\n                suffix = \" first\" if self.config.getoption(\"failedfirst\") else \"\"\n                self._report_status = \"rerun previous {count} {noun}{suffix}\".format(\n                    count=self._previously_failed_count, suffix=suffix, noun=noun\n                )\n\n            if self._skipped_files > 0:\n                files_noun = \"file\" if self._skipped_files == 1 else \"files\"\n                self._report_status += \" (skipped {files} {files_noun})\".format(\n                    files=self._skipped_files, files_noun=files_noun\n                )\n        else:\n            self._report_status = \"no previously failed tests, \"\n            if self.config.getoption(\"last_failed_no_failures\") == \"none\":\n                self._report_status += \"deselecting all items.\"\n                config.hook.pytest_deselected(items=items[:])\n                items[:] = []\n            else:\n                self._report_status += \"not deselecting items.\"\n\n    def pytest_sessionfinish(self, session):\n        config = self.config\n        if config.getoption(\"cacheshow\") or hasattr(config, \"slaveinput\"):\n            return\n\n        saved_lastfailed = config.cache.get(\"cache/lastfailed\", {})\n        if saved_lastfailed != self.lastfailed:\n            config.cache.set(\"cache/lastfailed\", self.lastfailed)"}, {"id": "_pytest.cacheprovider.LFPlugin.__init__", "kind": "function", "range": [228, 4, 244, 13, 7795, 8514], "file_path": "src/_pytest/cacheprovider.py", "content": "def __init__(self, config: Config) -> None:\n        self.config = config\n        active_keys = \"lf\", \"failedfirst\"\n        self.active = any(config.getoption(key) for key in active_keys)\n        assert config.cache\n        self.lastfailed = config.cache.get(\n            \"cache/lastfailed\", {}\n        )  # type: Dict[str, bool]\n        self._previously_failed_count = None\n        self._report_status = None\n        self._skipped_files = 0  # count skipped files during collection due to --lf\n\n        if config.getoption(\"lf\"):\n            self._last_failed_paths = self.get_last_failed_paths()\n            config.pluginmanager.register(\n                LFPluginCollWrapper(self), \"lfplugin-collwrapper\"\n            )"}, {"id": "_pytest.cacheprovider.LFPlugin.get_last_failed_paths", "kind": "function", "range": [246, 4, 250, 48, 8520, 8826], "file_path": "src/_pytest/cacheprovider.py", "content": "def get_last_failed_paths(self) -> Set[Path]:\n        \"\"\"Returns a set with all Paths()s of the previously failed nodeids.\"\"\"\n        rootpath = Path(str(self.config.rootdir))\n        result = {rootpath / nodeid.split(\"::\")[0] for nodeid in self.lastfailed}\n        return {x for x in result if x.exists()}"}, {"id": "_pytest.cacheprovider.LFPlugin.pytest_report_collectionfinish", "kind": "function", "range": [252, 4, 254, 63, 8832, 9003], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_report_collectionfinish(self):\n        if self.active and self.config.getoption(\"verbose\") >= 0:\n            return \"run-last-failure: %s\" % self._report_status"}, {"id": "_pytest.cacheprovider.LFPlugin.pytest_runtest_logreport", "kind": "function", "range": [256, 4, 260, 49, 9009, 9255], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_runtest_logreport(self, report):\n        if (report.when == \"call\" and report.passed) or report.skipped:\n            self.lastfailed.pop(report.nodeid, None)\n        elif report.failed:\n            self.lastfailed[report.nodeid] = True"}, {"id": "_pytest.cacheprovider.LFPlugin.pytest_collectreport", "kind": "function", "range": [262, 4, 269, 49, 9261, 9626], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_collectreport(self, report):\n        passed = report.outcome in (\"passed\", \"skipped\")\n        if passed:\n            if report.nodeid in self.lastfailed:\n                self.lastfailed.pop(report.nodeid)\n                self.lastfailed.update((item.nodeid, True) for item in report.result)\n        else:\n            self.lastfailed[report.nodeid] = True"}, {"id": "_pytest.cacheprovider.LFPlugin.pytest_collection_modifyitems", "kind": "function", "range": [271, 4, 316, 63, 9632, 11739], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_collection_modifyitems(self, session, config, items):\n        if not self.active:\n            return\n\n        if self.lastfailed:\n            previously_failed = []\n            previously_passed = []\n            for item in items:\n                if item.nodeid in self.lastfailed:\n                    previously_failed.append(item)\n                else:\n                    previously_passed.append(item)\n            self._previously_failed_count = len(previously_failed)\n\n            if not previously_failed:\n                # Running a subset of all tests with recorded failures\n                # only outside of it.\n                self._report_status = \"%d known failures not in selected tests\" % (\n                    len(self.lastfailed),\n                )\n            else:\n                if self.config.getoption(\"lf\"):\n                    items[:] = previously_failed\n                    config.hook.pytest_deselected(items=previously_passed)\n                else:  # --failedfirst\n                    items[:] = previously_failed + previously_passed\n\n                noun = \"failure\" if self._previously_failed_count == 1 else \"failures\"\n                suffix = \" first\" if self.config.getoption(\"failedfirst\") else \"\"\n                self._report_status = \"rerun previous {count} {noun}{suffix}\".format(\n                    count=self._previously_failed_count, suffix=suffix, noun=noun\n                )\n\n            if self._skipped_files > 0:\n                files_noun = \"file\" if self._skipped_files == 1 else \"files\"\n                self._report_status += \" (skipped {files} {files_noun})\".format(\n                    files=self._skipped_files, files_noun=files_noun\n                )\n        else:\n            self._report_status = \"no previously failed tests, \"\n            if self.config.getoption(\"last_failed_no_failures\") == \"none\":\n                self._report_status += \"deselecting all items.\"\n                config.hook.pytest_deselected(items=items[:])\n                items[:] = []\n            else:\n                self._report_status += \"not deselecting items.\""}, {"id": "_pytest.cacheprovider.LFPlugin.pytest_sessionfinish", "kind": "function", "range": [318, 4, 325, 65, 11745, 12091], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_sessionfinish(self, session):\n        config = self.config\n        if config.getoption(\"cacheshow\") or hasattr(config, \"slaveinput\"):\n            return\n\n        saved_lastfailed = config.cache.get(\"cache/lastfailed\", {})\n        if saved_lastfailed != self.lastfailed:\n            config.cache.set(\"cache/lastfailed\", self.lastfailed)"}, {"id": "_pytest.cacheprovider.NFPlugin", "kind": "class", "range": [328, 0, 363, 70, 12094, 13529], "file_path": "src/_pytest/cacheprovider.py", "content": "class NFPlugin:\n    \"\"\" Plugin which implements the --nf (run new-first) option \"\"\"\n\n    def __init__(self, config):\n        self.config = config\n        self.active = config.option.newfirst\n        self.cached_nodeids = set(config.cache.get(\"cache/nodeids\", []))\n\n    def pytest_collection_modifyitems(\n        self, session: Session, config: Config, items: List[nodes.Item]\n    ) -> None:\n        if self.active:\n            new_items = OrderedDict()  # type: OrderedDict[str, nodes.Item]\n            other_items = OrderedDict()  # type: OrderedDict[str, nodes.Item]\n            for item in items:\n                if item.nodeid not in self.cached_nodeids:\n                    new_items[item.nodeid] = item\n                else:\n                    other_items[item.nodeid] = item\n\n            items[:] = self._get_increasing_order(\n                new_items.values()\n            ) + self._get_increasing_order(other_items.values())\n            self.cached_nodeids.update(new_items)\n        else:\n            self.cached_nodeids.update(item.nodeid for item in items)\n\n    def _get_increasing_order(self, items):\n        return sorted(items, key=lambda item: item.fspath.mtime(), reverse=True)\n\n    def pytest_sessionfinish(self, session):\n        config = self.config\n        if config.getoption(\"cacheshow\") or hasattr(config, \"slaveinput\"):\n            return\n\n        config.cache.set(\"cache/nodeids\", sorted(self.cached_nodeids))"}, {"id": "_pytest.cacheprovider.NFPlugin.__init__", "kind": "function", "range": [331, 4, 334, 72, 12183, 12357], "file_path": "src/_pytest/cacheprovider.py", "content": "def __init__(self, config):\n        self.config = config\n        self.active = config.option.newfirst\n        self.cached_nodeids = set(config.cache.get(\"cache/nodeids\", []))"}, {"id": "_pytest.cacheprovider.NFPlugin.pytest_collection_modifyitems", "kind": "function", "range": [336, 4, 353, 69, 12363, 13162], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_collection_modifyitems(\n        self, session: Session, config: Config, items: List[nodes.Item]\n    ) -> None:\n        if self.active:\n            new_items = OrderedDict()  # type: OrderedDict[str, nodes.Item]\n            other_items = OrderedDict()  # type: OrderedDict[str, nodes.Item]\n            for item in items:\n                if item.nodeid not in self.cached_nodeids:\n                    new_items[item.nodeid] = item\n                else:\n                    other_items[item.nodeid] = item\n\n            items[:] = self._get_increasing_order(\n                new_items.values()\n            ) + self._get_increasing_order(other_items.values())\n            self.cached_nodeids.update(new_items)\n        else:\n            self.cached_nodeids.update(item.nodeid for item in items)"}, {"id": "_pytest.cacheprovider.NFPlugin._get_increasing_order", "kind": "function", "range": [355, 4, 356, 80, 13168, 13288], "file_path": "src/_pytest/cacheprovider.py", "content": "def _get_increasing_order(self, items):\n        return sorted(items, key=lambda item: item.fspath.mtime(), reverse=True)"}, {"id": "_pytest.cacheprovider.NFPlugin.pytest_sessionfinish", "kind": "function", "range": [358, 4, 363, 70, 13294, 13529], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_sessionfinish(self, session):\n        config = self.config\n        if config.getoption(\"cacheshow\") or hasattr(config, \"slaveinput\"):\n            return\n\n        config.cache.set(\"cache/nodeids\", sorted(self.cached_nodeids))"}, {"id": "_pytest.cacheprovider.pytest_addoption", "kind": "function", "range": [366, 0, 421, 5, 13532, 15297], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_addoption(parser):\n    group = parser.getgroup(\"general\")\n    group.addoption(\n        \"--lf\",\n        \"--last-failed\",\n        action=\"store_true\",\n        dest=\"lf\",\n        help=\"rerun only the tests that failed \"\n        \"at the last run (or all if none failed)\",\n    )\n    group.addoption(\n        \"--ff\",\n        \"--failed-first\",\n        action=\"store_true\",\n        dest=\"failedfirst\",\n        help=\"run all tests but run the last failures first.  \"\n        \"This may re-order tests and thus lead to \"\n        \"repeated fixture setup/teardown\",\n    )\n    group.addoption(\n        \"--nf\",\n        \"--new-first\",\n        action=\"store_true\",\n        dest=\"newfirst\",\n        help=\"run tests from new files first, then the rest of the tests \"\n        \"sorted by file mtime\",\n    )\n    group.addoption(\n        \"--cache-show\",\n        action=\"append\",\n        nargs=\"?\",\n        dest=\"cacheshow\",\n        help=(\n            \"show cache contents, don't perform collection or tests. \"\n            \"Optional argument: glob (default: '*').\"\n        ),\n    )\n    group.addoption(\n        \"--cache-clear\",\n        action=\"store_true\",\n        dest=\"cacheclear\",\n        help=\"remove all cache contents at start of test run.\",\n    )\n    cache_dir_default = \".pytest_cache\"\n    if \"TOX_ENV_DIR\" in os.environ:\n        cache_dir_default = os.path.join(os.environ[\"TOX_ENV_DIR\"], cache_dir_default)\n    parser.addini(\"cache_dir\", default=cache_dir_default, help=\"cache directory path.\")\n    group.addoption(\n        \"--lfnf\",\n        \"--last-failed-no-failures\",\n        action=\"store\",\n        dest=\"last_failed_no_failures\",\n        choices=(\"all\", \"none\"),\n        default=\"all\",\n        help=\"which tests to run with no previously (known) failures.\",\n    )"}, {"id": "_pytest.cacheprovider.pytest_cmdline_main", "kind": "function", "range": [424, 0, 428, 46, 15300, 15458], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_cmdline_main(config):\n    if config.option.cacheshow:\n        from _pytest.main import wrap_session\n\n        return wrap_session(config, cacheshow)"}, {"id": "_pytest.cacheprovider.pytest_configure", "kind": "function", "range": [431, 0, 435, 63, 15461, 15710], "file_path": "src/_pytest/cacheprovider.py", "content": "@pytest.hookimpl(tryfirst=True)\ndef pytest_configure(config: Config) -> None:\n    config.cache = Cache.for_config(config)\n    config.pluginmanager.register(LFPlugin(config), \"lfplugin\")\n    config.pluginmanager.register(NFPlugin(config), \"nfplugin\")"}, {"id": "_pytest.cacheprovider.cache", "kind": "function", "range": [438, 0, 451, 31, 15713, 16150], "file_path": "src/_pytest/cacheprovider.py", "content": "@pytest.fixture\ndef cache(request):\n    \"\"\"\n    Return a cache object that can persist state between testing sessions.\n\n    cache.get(key, default)\n    cache.set(key, value)\n\n    Keys must be a ``/`` separated value, where the first part is usually the\n    name of your plugin or application to avoid clashes with other cache users.\n\n    Values can be any object handled by the json stdlib module.\n    \"\"\"\n    return request.config.cache"}, {"id": "_pytest.cacheprovider.pytest_report_header", "kind": "function", "range": [454, 0, 465, 49, 16153, 16669], "file_path": "src/_pytest/cacheprovider.py", "content": "def pytest_report_header(config):\n    \"\"\"Display cachedir with --cache-show and if non-default.\"\"\"\n    if config.option.verbose > 0 or config.getini(\"cache_dir\") != \".pytest_cache\":\n        cachedir = config.cache._cachedir\n        # TODO: evaluate generating upward relative paths\n        # starting with .., ../.. if sensible\n\n        try:\n            displaypath = cachedir.relative_to(config.rootdir)\n        except ValueError:\n            displaypath = cachedir\n        return \"cachedir: {}\".format(displaypath)"}, {"id": "_pytest.cacheprovider.cacheshow", "kind": "function", "range": [468, 0, 505, 12, 16672, 17992], "file_path": "src/_pytest/cacheprovider.py", "content": "def cacheshow(config, session):\n    from pprint import pformat\n\n    tw = TerminalWriter()\n    tw.line(\"cachedir: \" + str(config.cache._cachedir))\n    if not config.cache._cachedir.is_dir():\n        tw.line(\"cache is empty\")\n        return 0\n\n    glob = config.option.cacheshow[0]\n    if glob is None:\n        glob = \"*\"\n\n    dummy = object()\n    basedir = config.cache._cachedir\n    vdir = basedir / Cache._CACHE_PREFIX_VALUES\n    tw.sep(\"-\", \"cache values for %r\" % glob)\n    for valpath in sorted(x for x in vdir.rglob(glob) if x.is_file()):\n        key = valpath.relative_to(vdir)\n        val = config.cache.get(key, dummy)\n        if val is dummy:\n            tw.line(\"%s contains unreadable content, will be ignored\" % key)\n        else:\n            tw.line(\"%s contains:\" % key)\n            for line in pformat(val).splitlines():\n                tw.line(\"  \" + line)\n\n    ddir = basedir / Cache._CACHE_PREFIX_DIRS\n    if ddir.is_dir():\n        contents = sorted(ddir.rglob(glob))\n        tw.sep(\"-\", \"cache directories for %r\" % glob)\n        for p in contents:\n            # if p.check(dir=1):\n            #    print(\"%s/\" % p.relto(basedir))\n            if p.is_file():\n                key = p.relative_to(basedir)\n                tw.line(\"{} is a file of length {:d}\".format(key, p.stat().st_size))\n    return 0"}, {"id": "_pytest.warning_types.PytestWarning", "kind": "class", "range": [12, 0, 15, 25, 217, 334], "file_path": "src/_pytest/warning_types.py", "content": "class PytestWarning(UserWarning):\n    \"\"\"Base class for all warnings emitted by pytest.\"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestWarning.__module__", "kind": "variable", "range": [15, 4, 15, 25, 313, 334], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestAssertRewriteWarning", "kind": "class", "range": [18, 0, 21, 25, 337, 475], "file_path": "src/_pytest/warning_types.py", "content": "class PytestAssertRewriteWarning(PytestWarning):\n    \"\"\"Warning emitted by the pytest assert rewrite module.\"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestAssertRewriteWarning.__module__", "kind": "variable", "range": [21, 4, 21, 25, 454, 475], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestCacheWarning", "kind": "class", "range": [24, 0, 27, 25, 478, 614], "file_path": "src/_pytest/warning_types.py", "content": "class PytestCacheWarning(PytestWarning):\n    \"\"\"Warning emitted by the cache plugin in various situations.\"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestCacheWarning.__module__", "kind": "variable", "range": [27, 4, 27, 25, 593, 614], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestConfigWarning", "kind": "class", "range": [30, 0, 33, 25, 617, 737], "file_path": "src/_pytest/warning_types.py", "content": "class PytestConfigWarning(PytestWarning):\n    \"\"\"Warning emitted for configuration issues.\"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestConfigWarning.__module__", "kind": "variable", "range": [33, 4, 33, 25, 716, 737], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestCollectionWarning", "kind": "class", "range": [36, 0, 39, 25, 740, 903], "file_path": "src/_pytest/warning_types.py", "content": "class PytestCollectionWarning(PytestWarning):\n    \"\"\"Warning emitted when pytest is not able to collect a file or symbol in a module.\"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestCollectionWarning.__module__", "kind": "variable", "range": [39, 4, 39, 25, 882, 903], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestDeprecationWarning", "kind": "class", "range": [42, 0, 45, 25, 906, 1078], "file_path": "src/_pytest/warning_types.py", "content": "class PytestDeprecationWarning(PytestWarning, DeprecationWarning):\n    \"\"\"Warning class for features that will be removed in a future version.\"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestDeprecationWarning.__module__", "kind": "variable", "range": [45, 4, 45, 25, 1057, 1078], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestExperimentalApiWarning", "kind": "class", "range": [48, 0, 63, 9, 1081, 1585], "file_path": "src/_pytest/warning_types.py", "content": "class PytestExperimentalApiWarning(PytestWarning, FutureWarning):\n    \"\"\"Warning category used to denote experiments in pytest.\n\n    Use sparingly as the API might change or even be removed completely in a\n    future version.\n    \"\"\"\n\n    __module__ = \"pytest\"\n\n    @classmethod\n    def simple(cls, apiname: str) -> \"PytestExperimentalApiWarning\":\n        return cls(\n            \"{apiname} is an experimental api that may change over time\".format(\n                apiname=apiname\n            )\n        )"}, {"id": "_pytest.warning_types.PytestExperimentalApiWarning.__module__", "kind": "variable", "range": [55, 4, 55, 25, 1320, 1341], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestExperimentalApiWarning.simple", "kind": "function", "range": [57, 4, 63, 9, 1347, 1585], "file_path": "src/_pytest/warning_types.py", "content": "@classmethod\n    def simple(cls, apiname: str) -> \"PytestExperimentalApiWarning\":\n        return cls(\n            \"{apiname} is an experimental api that may change over time\".format(\n                apiname=apiname\n            )\n        )"}, {"id": "_pytest.warning_types.PytestUnhandledCoroutineWarning", "kind": "class", "range": [66, 0, 74, 25, 1588, 1900], "file_path": "src/_pytest/warning_types.py", "content": "class PytestUnhandledCoroutineWarning(PytestWarning):\n    \"\"\"Warning emitted for an unhandled coroutine.\n\n    A coroutine was encountered when collecting test functions, but was not\n    handled by any async-aware plugin.\n    Coroutine test functions are not natively supported.\n    \"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestUnhandledCoroutineWarning.__module__", "kind": "variable", "range": [74, 4, 74, 25, 1879, 1900], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestUnknownMarkWarning", "kind": "class", "range": [77, 0, 83, 25, 1903, 2100], "file_path": "src/_pytest/warning_types.py", "content": "class PytestUnknownMarkWarning(PytestWarning):\n    \"\"\"Warning emitted on use of unknown markers.\n\n    See https://docs.pytest.org/en/latest/mark.html for details.\n    \"\"\"\n\n    __module__ = \"pytest\""}, {"id": "_pytest.warning_types.PytestUnknownMarkWarning.__module__", "kind": "variable", "range": [83, 4, 83, 25, 2079, 2100], "file_path": "src/_pytest/warning_types.py", "content": "__module__ = \"pytest\""}, {"id": "_pytest.warning_types._W", "kind": "variable", "range": [86, 0, 86, 39, 2103, 2142], "file_path": "src/_pytest/warning_types.py", "content": "_W = TypeVar(\"_W\", bound=PytestWarning)"}, {"id": "_pytest.warning_types.UnformattedWarning", "kind": "class", "range": [89, 0, 102, 60, 2145, 2637], "file_path": "src/_pytest/warning_types.py", "content": "@attr.s\nclass UnformattedWarning(Generic[_W]):\n    \"\"\"A warning meant to be formatted during runtime.\n\n    This is used to hold warnings that need to format their message at runtime,\n    as opposed to a direct message.\n    \"\"\"\n\n    category = attr.ib(type=\"Type[_W]\")\n    template = attr.ib(type=str)\n\n    def format(self, **kwargs: Any) -> _W:\n        \"\"\"Returns an instance of the warning category, formatted with given kwargs\"\"\"\n        return self.category(self.template.format(**kwargs))"}, {"id": "_pytest.warning_types.UnformattedWarning.category", "kind": "variable", "range": [97, 4, 97, 39, 2377, 2412], "file_path": "src/_pytest/warning_types.py", "content": "category = attr.ib(type=\"Type[_W]\")"}, {"id": "_pytest.warning_types.UnformattedWarning.template", "kind": "variable", "range": [98, 4, 98, 32, 2417, 2445], "file_path": "src/_pytest/warning_types.py", "content": "template = attr.ib(type=str)"}, {"id": "_pytest.warning_types.UnformattedWarning.format", "kind": "function", "range": [100, 4, 102, 60, 2451, 2637], "file_path": "src/_pytest/warning_types.py", "content": "def format(self, **kwargs: Any) -> _W:\n        \"\"\"Returns an instance of the warning category, formatted with given kwargs\"\"\"\n        return self.category(self.template.format(**kwargs))"}, {"id": "_pytest.warning_types.PYTESTER_COPY_EXAMPLE", "kind": "variable", "range": [105, 0, 105, 83, 2640, 2723], "file_path": "src/_pytest/warning_types.py", "content": "PYTESTER_COPY_EXAMPLE = PytestExperimentalApiWarning.simple(\"testdir.copy_example\")"}]}